MODEL_NAME:  optuna_convbbt
Start time:  2023-09-04 19:09:08.806748
Device:  cuda
Max Epochs:  200
Early Stopping Reference Size:  5
Search Space:  {'lr': [1e-06, 1e-05, 0.0001, 0.001], 'beta1': [0.9, 0.95, 0.99, 0.999], 'beta2': [0.9, 0.95, 0.99, 0.999], 'eps': [1e-09, 1e-08, 1e-07, 1e-06], 'T_max': [50, 100, 150, 200], 'eta_min': [0, 1e-08, 1e-07, 1e-06, 1e-05], 'hidden_ch': [3, 5, 7, 8, 10, 15], 'depth': [3, 5, 6, 8], 'heads': [3, 5, 6, 8, 10], 'hidden_dim': [64, 128, 256, 512, 1024], 'mlp_dim': [256, 512, 1024, 2048], 'dropout': [0.01, 0.1, 0.25, 0.5, 0.8], 'emb_dropout': [0.01, 0.1, 0.25, 0.5, 0.8]}
Epoch 000: | Loss: 1.94637
Epoch 001: | Loss: 1.91979
Epoch 002: | Loss: 1.89568
Epoch 003: | Loss: 1.87858
Epoch 004: | Loss: 1.84949
Epoch 005: | Loss: 1.83659
Epoch 006: | Loss: 1.81924
Epoch 007: | Loss: 1.79900
Epoch 008: | Loss: 1.78242
Epoch 009: | Loss: 1.77361
Epoch 010: | Loss: 1.74837
Epoch 011: | Loss: 1.73858
Epoch 012: | Loss: 1.72597
Epoch 013: | Loss: 1.71042
Epoch 014: | Loss: 1.70414
Epoch 015: | Loss: 1.69703
Epoch 016: | Loss: 1.68845
Epoch 017: | Loss: 1.67642
Epoch 018: | Loss: 1.66595
Epoch 019: | Loss: 1.66305
Epoch 020: | Loss: 1.65356
Epoch 021: | Loss: 1.65234
Epoch 022: | Loss: 1.64227
Epoch 023: | Loss: 1.63576
Epoch 024: | Loss: 1.63152
Epoch 025: | Loss: 1.62235
Epoch 026: | Loss: 1.61888
Epoch 027: | Loss: 1.62046
Epoch 028: | Loss: 1.61730
Epoch 029: | Loss: 1.60910
Epoch 030: | Loss: 1.61165
Epoch 031: | Loss: 1.61419
Epoch 032: | Loss: 1.60623
Epoch 033: | Loss: 1.60532
Epoch 034: | Loss: 1.59738
Epoch 035: | Loss: 1.59986
Epoch 036: | Loss: 1.59962
Epoch 037: | Loss: 1.59206
Epoch 038: | Loss: 1.59163
Epoch 039: | Loss: 1.59682
Epoch 040: | Loss: 1.58840
Epoch 041: | Loss: 1.58698
Epoch 042: | Loss: 1.58579
Epoch 043: | Loss: 1.58081
Epoch 044: | Loss: 1.58442
Epoch 045: | Loss: 1.58389
Epoch 046: | Loss: 1.58069
Epoch 047: | Loss: 1.58227
Epoch 048: | Loss: 1.58448
Epoch 049: | Loss: 1.57654
Epoch 050: | Loss: 1.58410
Epoch 051: | Loss: 1.57881
Epoch 052: | Loss: 1.58120
Epoch 053: | Loss: 1.58128
Epoch 054: | Loss: 1.57831
Epoch 055: | Loss: 1.58463
Epoch 056: | Loss: 1.58406
Epoch 057: | Loss: 1.57680
Epoch 058: | Loss: 1.57560
Epoch 059: | Loss: 1.57948
Epoch 060: | Loss: 1.57413
Epoch 061: | Loss: 1.57324
Epoch 062: | Loss: 1.58081
Epoch 063: | Loss: 1.57544
Epoch 064: | Loss: 1.57990
Epoch 065: | Loss: 1.57337
Epoch 066: | Loss: 1.57160
Epoch 067: | Loss: 1.57281
Epoch 068: | Loss: 1.58175
Epoch 069: | Loss: 1.57092
Epoch 070: | Loss: 1.57678
Epoch 071: | Loss: 1.57785
Epoch 072: | Loss: 1.57393
Epoch 073: | Loss: 1.58367
Epoch 074: | Loss: 1.57715
Epoch 075: | Loss: 1.57436
Epoch 076: | Loss: 1.57609
Epoch 077: | Loss: 1.57721
Epoch 078: | Loss: 1.57452
Epoch 079: | Loss: 1.57828
Epoch 080: | Loss: 1.57290
Epoch 081: | Loss: 1.57037
Epoch 082: | Loss: 1.57240
Epoch 083: | Loss: 1.57502
Epoch 084: | Loss: 1.57553
Epoch 085: | Loss: 1.57689
Epoch 086: | Loss: 1.57629
Epoch 087: | Loss: 1.57833
Epoch 088: | Loss: 1.57552
Epoch 089: | Loss: 1.57565
Epoch 090: | Loss: 1.57891
Epoch 091: | Loss: 1.57203
Epoch 092: | Loss: 1.57418
Epoch 093: | Loss: 1.57478
Epoch 094: | Loss: 1.57756
Epoch 095: | Loss: 1.57180
Epoch 096: | Loss: 1.57608
Epoch 097: | Loss: 1.57258
Epoch 098: | Loss: 1.57786
Epoch 099: | Loss: 1.57280
Epoch 100: | Loss: 1.57382
Epoch 101: | Loss: 1.57073
Epoch 102: | Loss: 1.57807
Epoch 103: | Loss: 1.57462
Epoch 104: | Loss: 1.57574
Epoch 105: | Loss: 1.57042
Epoch 106: | Loss: 1.57693
Epoch 107: | Loss: 1.57018
Epoch 108: | Loss: 1.57596
Epoch 109: | Loss: 1.57139
Epoch 110: | Loss: 1.57267
Epoch 111: | Loss: 1.57674
Epoch 112: | Loss: 1.57307
Epoch 113: | Loss: 1.56523
Epoch 114: | Loss: 1.57287
Epoch 115: | Loss: 1.57092
Epoch 116: | Loss: 1.56961
Epoch 117: | Loss: 1.57155
Epoch 118: | Loss: 1.57027
Epoch 119: | Loss: 1.56936
Epoch 120: | Loss: 1.57597
Epoch 121: | Loss: 1.57221
Epoch 122: | Loss: 1.57263
Epoch 123: | Loss: 1.57482
Epoch 124: | Loss: 1.57759
Epoch 125: | Loss: 1.57474
Epoch 126: | Loss: 1.56868
Epoch 127: | Loss: 1.56908
Epoch 128: | Loss: 1.57537
Epoch 129: | Loss: 1.56493
Epoch 130: | Loss: 1.57457
Epoch 131: | Loss: 1.57802
Epoch 132: | Loss: 1.56299
Epoch 133: | Loss: 1.56810
Epoch 134: | Loss: 1.56711
Epoch 135: | Loss: 1.57390
Epoch 136: | Loss: 1.57487
Epoch 137: | Loss: 1.57135
Epoch 138: | Loss: 1.57306
Epoch 139: | Loss: 1.57178
Epoch 140: | Loss: 1.57172
Epoch 141: | Loss: 1.56826
Epoch 142: | Loss: 1.56826
Epoch 143: | Loss: 1.56710
Epoch 144: | Loss: 1.57001
Epoch 145: | Loss: 1.57168
Epoch 146: | Loss: 1.56910
Epoch 147: | Loss: 1.56604
Epoch 148: | Loss: 1.56887
Epoch 149: | Loss: 1.56987
Epoch 150: | Loss: 1.56719
Epoch 151: | Loss: 1.56986
Epoch 152: | Loss: 1.57283
Epoch 153: | Loss: 1.56974
Epoch 154: | Loss: 1.56707
Epoch 155: | Loss: 1.56527
Epoch 156: | Loss: 1.56445
Epoch 157: | Loss: 1.56948
Epoch 158: | Loss: 1.56485
Epoch 159: | Loss: 1.56465
Epoch 160: | Loss: 1.57202
Epoch 161: | Loss: 1.56777
Epoch 162: | Loss: 1.56193
Epoch 163: | Loss: 1.56676
Epoch 164: | Loss: 1.56591
Epoch 165: | Loss: 1.55927
Epoch 166: | Loss: 1.56749
Epoch 167: | Loss: 1.56382
Epoch 168: | Loss: 1.56811
Epoch 169: | Loss: 1.56868
Epoch 170: | Loss: 1.56484
Epoch 171: | Loss: 1.56227
Epoch 172: | Loss: 1.56394
Epoch 173: | Loss: 1.56371
Epoch 174: | Loss: 1.56276
Epoch 175: | Loss: 1.56244
Epoch 176: | Loss: 1.56749
Epoch 177: | Loss: 1.56047
Epoch 178: | Loss: 1.56447
Epoch 179: | Loss: 1.56582
Epoch 180: | Loss: 1.56374
Epoch 181: | Loss: 1.55669
Epoch 182: | Loss: 1.56239
Epoch 183: | Loss: 1.56067
Epoch 184: | Loss: 1.56588
Epoch 185: | Loss: 1.56245
Epoch 186: | Loss: 1.56099
Epoch 187: | Loss: 1.56445
Epoch 188: | Loss: 1.55827
Epoch 189: | Loss: 1.56031
Epoch 190: | Loss: 1.56154
Epoch 191: | Loss: 1.55484
Epoch 192: | Loss: 1.55607
Epoch 193: | Loss: 1.56012
Epoch 194: | Loss: 1.55741
Epoch 195: | Loss: 1.55835
Epoch 196: | Loss: 1.56139
Epoch 197: | Loss: 1.55706
Epoch 198: | Loss: 1.55052
Epoch 199: | Loss: 1.55970
Accuracy: 0.3849626068376068
Epoch 000: | Loss: 1.32648
Epoch 001: | Loss: 0.83841
Epoch 002: | Loss: 0.74955
Epoch 003: | Loss: 0.72656
Epoch 004: | Loss: 0.72472
Epoch 005: | Loss: 0.71797
Epoch 006: | Loss: 0.69950
Epoch 007: | Loss: 0.67601
Epoch 008: | Loss: 0.66968
Epoch 009: | Loss: 0.66428
Epoch 010: | Loss: 0.65118
Epoch 011: | Loss: 0.65024
Epoch 012: | Loss: 0.64073
Epoch 013: | Loss: 0.64011
Epoch 014: | Loss: 0.63384
Epoch 015: | Loss: 0.63054
Epoch 016: | Loss: 0.62677
Epoch 017: | Loss: 0.62394
Epoch 018: | Loss: 0.62258
Epoch 019: | Loss: 0.61788
Epoch 020: | Loss: 0.60834
Epoch 021: | Loss: 0.60779
Epoch 022: | Loss: 0.60558
Epoch 023: | Loss: 0.61045
Epoch 024: | Loss: 0.59939
Epoch 025: | Loss: 0.59765
Epoch 026: | Loss: 0.59852
Epoch 027: | Loss: 0.59746
Epoch 028: | Loss: 0.59774
Epoch 029: | Loss: 0.59401
Epoch 030: | Loss: 0.59477
Epoch 031: | Loss: 0.58303
Epoch 032: | Loss: 0.58154
Epoch 033: | Loss: 0.58665
Epoch 034: | Loss: 0.58702
Epoch 035: | Loss: 0.58584
Epoch 036: | Loss: 0.57616
Epoch 037: | Loss: 0.58281
Epoch 038: | Loss: 0.57904
Epoch 039: | Loss: 0.57755
Epoch 040: | Loss: 0.57451
Epoch 041: | Loss: 0.58064
Epoch 042: | Loss: 0.57645
Epoch 043: | Loss: 0.57723
Epoch 044: | Loss: 0.57664
Epoch 045: | Loss: 0.58139
Epoch 046: | Loss: 0.58081
Epoch 047: | Loss: 0.57496
Epoch 048: | Loss: 0.57280
Epoch 049: | Loss: 0.57492
Epoch 050: | Loss: 0.57130
Epoch 051: | Loss: 0.57111
Epoch 052: | Loss: 0.56908
Epoch 053: | Loss: 0.56798
Epoch 054: | Loss: 0.56928
Epoch 055: | Loss: 0.56220
Epoch 056: | Loss: 0.56789
Epoch 057: | Loss: 0.56476
Epoch 058: | Loss: 0.56538
Epoch 059: | Loss: 0.56349
Epoch 060: | Loss: 0.56486
Epoch 061: | Loss: 0.56562
Epoch 062: | Loss: 0.56283
Epoch 063: | Loss: 0.56294
Epoch 064: | Loss: 0.56764
Epoch 065: | Loss: 0.56293
Epoch 066: | Loss: 0.56186
Epoch 067: | Loss: 0.56147
Epoch 068: | Loss: 0.55805
Epoch 069: | Loss: 0.56594
Epoch 070: | Loss: 0.57068
Epoch 071: | Loss: 0.56728
Epoch 072: | Loss: 0.56274
Epoch 073: | Loss: 0.55923
Epoch 074: | Loss: 0.55538
Epoch 075: | Loss: 0.55887
Epoch 076: | Loss: 0.55831
Epoch 077: | Loss: 0.54959
Epoch 078: | Loss: 0.55328
Epoch 079: | Loss: 0.55204
Epoch 080: | Loss: 0.54922
Epoch 081: | Loss: 0.55797
Epoch 082: | Loss: 0.56096
Epoch 083: | Loss: 0.55835
Epoch 084: | Loss: 0.56004
Epoch 085: | Loss: 0.55332
Epoch 086: | Loss: 0.55186
Epoch 087: | Loss: 0.55670
Epoch 088: | Loss: 0.55486
Epoch 089: | Loss: 0.55170
Epoch 090: | Loss: 0.54994
Epoch 091: | Loss: 0.55075
Epoch 092: | Loss: 0.56045
Epoch 093: | Loss: 0.55662
Epoch 094: | Loss: 0.56065
Epoch 095: | Loss: 0.55161
Epoch 096: | Loss: 0.54913
Epoch 097: | Loss: 0.54714
Epoch 098: | Loss: 0.54780
Epoch 099: | Loss: 0.54620
Epoch 100: | Loss: 0.54632
Epoch 101: | Loss: 0.54656
Epoch 102: | Loss: 0.55053
Epoch 103: | Loss: 0.54926
Epoch 104: | Loss: 0.54651
Epoch 105: | Loss: 0.54612
Epoch 106: | Loss: 0.54375
Epoch 107: | Loss: 0.54808
Epoch 108: | Loss: 0.54719
Epoch 109: | Loss: 0.54511
Epoch 110: | Loss: 0.54483
Epoch 111: | Loss: 0.54087
Epoch 112: | Loss: 0.54495
Epoch 113: | Loss: 0.54504
Epoch 114: | Loss: 0.54607
Epoch 115: | Loss: 0.54097
Epoch 116: | Loss: 0.54296
Epoch 117: | Loss: 0.54205
Epoch 118: | Loss: 0.54182
Epoch 119: | Loss: 0.53999
Epoch 120: | Loss: 0.53950
Epoch 121: | Loss: 0.54169
Epoch 122: | Loss: 0.53747
Epoch 123: | Loss: 0.54009
Epoch 124: | Loss: 0.54045
Epoch 125: | Loss: 0.53860
Epoch 126: | Loss: 0.53936
Epoch 127: | Loss: 0.54459
Epoch 128: | Loss: 0.54004
Epoch 129: | Loss: 0.53940
Epoch 130: | Loss: 0.54240
Epoch 131: | Loss: 0.54146
Epoch 132: | Loss: 0.53822
Epoch 133: | Loss: 0.53923
Epoch 134: | Loss: 0.53703
Epoch 135: | Loss: 0.53654
Epoch 136: | Loss: 0.53484
Epoch 137: | Loss: 0.53873
Epoch 138: | Loss: 0.54015
Epoch 139: | Loss: 0.54054
Epoch 140: | Loss: 0.53670
Epoch 141: | Loss: 0.53492
Epoch 142: | Loss: 0.53638
Epoch 143: | Loss: 0.53799
Epoch 144: | Loss: 0.53478
Epoch 145: | Loss: 0.53667
Epoch 146: | Loss: 0.53558
Epoch 147: | Loss: 0.53533
Epoch 148: | Loss: 0.53705
Epoch 149: | Loss: 0.53372
Epoch 150: | Loss: 0.53553
Epoch 151: | Loss: 0.53738
Epoch 152: | Loss: 0.53282
Epoch 153: | Loss: 0.53622
Epoch 154: | Loss: 0.53577
Epoch 155: | Loss: 0.53320
Epoch 156: | Loss: 0.53317
Epoch 157: | Loss: 0.53499
Epoch 158: | Loss: 0.53254
Epoch 159: | Loss: 0.53571
Epoch 160: | Loss: 0.53523
Epoch 161: | Loss: 0.53437
Epoch 162: | Loss: 0.53274
Epoch 163: | Loss: 0.53313
Epoch 164: | Loss: 0.53159
Epoch 165: | Loss: 0.53394
Epoch 166: | Loss: 0.53155
Epoch 167: | Loss: 0.53172
Epoch 168: | Loss: 0.53351
Epoch 169: | Loss: 0.53152
Epoch 170: | Loss: 0.53448
Epoch 171: | Loss: 0.53122
Epoch 172: | Loss: 0.53231
Epoch 173: | Loss: 0.53341
Epoch 174: | Loss: 0.53179
Epoch 175: | Loss: 0.53550
Epoch 176: | Loss: 0.53181
Epoch 177: | Loss: 0.52838
Epoch 178: | Loss: 0.53377
Epoch 179: | Loss: 0.53241
Epoch 180: | Loss: 0.52836
Epoch 181: | Loss: 0.53258
Epoch 182: | Loss: 0.53277
Epoch 183: | Loss: 0.53271
Epoch 184: | Loss: 0.53270
Epoch 185: | Loss: 0.53419
Epoch 186: | Loss: 0.53084
Epoch 187: | Loss: 0.52971
Epoch 188: | Loss: 0.53510
Epoch 189: | Loss: 0.53278
Epoch 190: | Loss: 0.53030
Epoch 191: | Loss: 0.53026
Epoch 192: | Loss: 0.53312
Epoch 193: | Loss: 0.53094
Epoch 194: | Loss: 0.53136
Epoch 195: | Loss: 0.53341
Epoch 196: | Loss: 0.53133
Epoch 197: | Loss: 0.53453
Epoch 198: | Loss: 0.53076
Epoch 199: | Loss: 0.52958
Accuracy: 0.3136992521367521
Epoch 000: | Loss: 1.67886
Epoch 001: | Loss: 1.58963
Epoch 002: | Loss: 1.56838
Epoch 003: | Loss: 1.56339
Epoch 004: | Loss: 1.56035
Epoch 005: | Loss: 1.55350
Epoch 006: | Loss: 1.55686
Epoch 007: | Loss: 1.54776
Epoch 008: | Loss: 1.54445
Epoch 009: | Loss: 1.54580
Epoch 010: | Loss: 1.54327
Epoch 011: | Loss: 1.53551
Epoch 012: | Loss: 1.53231
Epoch 013: | Loss: 1.52677
Epoch 014: | Loss: 1.52823
Epoch 015: | Loss: 1.52810
Epoch 016: | Loss: 1.52764
Epoch 017: | Loss: 1.52253
Epoch 018: | Loss: 1.52004
Epoch 019: | Loss: 1.51749
Epoch 020: | Loss: 1.51999
Epoch 021: | Loss: 1.51888
Epoch 022: | Loss: 1.51751
Epoch 023: | Loss: 1.51526
Epoch 024: | Loss: 1.51316
Epoch 025: | Loss: 1.51272
Epoch 026: | Loss: 1.51518
Epoch 027: | Loss: 1.51352
Epoch 028: | Loss: 1.50942
Epoch 029: | Loss: 1.50823
Epoch 030: | Loss: 1.51022
Epoch 031: | Loss: 1.50861
Epoch 032: | Loss: 1.51093
Epoch 033: | Loss: 1.50889
Epoch 034: | Loss: 1.50396
Epoch 035: | Loss: 1.50473
Epoch 036: | Loss: 1.50241
Epoch 037: | Loss: 1.50147
Epoch 038: | Loss: 1.49772
Epoch 039: | Loss: 1.49753
Epoch 040: | Loss: 1.49815
Epoch 041: | Loss: 1.49660
Epoch 042: | Loss: 1.49345
Epoch 043: | Loss: 1.48844
Epoch 044: | Loss: 1.48529
Epoch 045: | Loss: 1.47979
Epoch 046: | Loss: 1.47685
Epoch 047: | Loss: 1.47835
Epoch 048: | Loss: 1.46415
Epoch 049: | Loss: 1.46013
Epoch 050: | Loss: 1.45613
Epoch 051: | Loss: 1.44706
Epoch 052: | Loss: 1.43687
Epoch 053: | Loss: 1.43281
Epoch 054: | Loss: 1.42607
Epoch 055: | Loss: 1.40943
Epoch 056: | Loss: 1.39892
Epoch 057: | Loss: 1.38910
Epoch 058: | Loss: 1.37323
Epoch 059: | Loss: 1.36504
Epoch 060: | Loss: 1.35418
Epoch 061: | Loss: 1.34814
Epoch 062: | Loss: 1.33992
Epoch 063: | Loss: 1.33565
Epoch 064: | Loss: 1.32497
Epoch 065: | Loss: 1.32017
Epoch 066: | Loss: 1.30986
Epoch 067: | Loss: 1.30950
Epoch 068: | Loss: 1.30226
Epoch 069: | Loss: 1.30012
Epoch 070: | Loss: 1.29617
Epoch 071: | Loss: 1.28569
Epoch 072: | Loss: 1.28869
Epoch 073: | Loss: 1.28176
Epoch 074: | Loss: 1.28182
Epoch 075: | Loss: 1.27539
Epoch 076: | Loss: 1.27014
Epoch 077: | Loss: 1.26918
Epoch 078: | Loss: 1.26708
Epoch 079: | Loss: 1.26672
Epoch 080: | Loss: 1.25802
Epoch 081: | Loss: 1.26061
Epoch 082: | Loss: 1.25774
Epoch 083: | Loss: 1.24994
Epoch 084: | Loss: 1.24708
Epoch 085: | Loss: 1.24407
Epoch 086: | Loss: 1.23784
Epoch 087: | Loss: 1.23179
Epoch 088: | Loss: 1.22842
Epoch 089: | Loss: 1.22789
Epoch 090: | Loss: 1.23029
Epoch 091: | Loss: 1.22444
Epoch 092: | Loss: 1.22251
Epoch 093: | Loss: 1.21032
Epoch 094: | Loss: 1.20723
Epoch 095: | Loss: 1.20370
Epoch 096: | Loss: 1.19734
Epoch 097: | Loss: 1.19834
Epoch 098: | Loss: 1.19501
Epoch 099: | Loss: 1.18568
Epoch 100: | Loss: 1.18531
Epoch 101: | Loss: 1.17521
Epoch 102: | Loss: 1.17072
Epoch 103: | Loss: 1.16759
Epoch 104: | Loss: 1.16438
Epoch 105: | Loss: 1.16226
Epoch 106: | Loss: 1.15435
Epoch 107: | Loss: 1.15349
Epoch 108: | Loss: 1.14184
Epoch 109: | Loss: 1.13831
Epoch 110: | Loss: 1.13565
Epoch 111: | Loss: 1.13834
Epoch 112: | Loss: 1.12603
Epoch 113: | Loss: 1.12599
Epoch 114: | Loss: 1.12618
Epoch 115: | Loss: 1.11777
Epoch 116: | Loss: 1.11668
Epoch 117: | Loss: 1.11735
Epoch 118: | Loss: 1.11300
Epoch 119: | Loss: 1.10339
Epoch 120: | Loss: 1.10276
Epoch 121: | Loss: 1.10152
Epoch 122: | Loss: 1.10144
Epoch 123: | Loss: 1.09551
Epoch 124: | Loss: 1.09570
Epoch 125: | Loss: 1.08598
Epoch 126: | Loss: 1.08202
Epoch 127: | Loss: 1.07817
Epoch 128: | Loss: 1.08520
Epoch 129: | Loss: 1.07661
Epoch 130: | Loss: 1.07333
Epoch 131: | Loss: 1.07390
Epoch 132: | Loss: 1.07115
Epoch 133: | Loss: 1.06662
Epoch 134: | Loss: 1.06973
Epoch 135: | Loss: 1.06670
Epoch 136: | Loss: 1.06117
Epoch 137: | Loss: 1.05762
Epoch 138: | Loss: 1.05918
Epoch 139: | Loss: 1.05713
Epoch 140: | Loss: 1.06011
Epoch 141: | Loss: 1.05308
Epoch 142: | Loss: 1.05005
Epoch 143: | Loss: 1.05412
Epoch 144: | Loss: 1.04993
Epoch 145: | Loss: 1.04568
Epoch 146: | Loss: 1.04803
Epoch 147: | Loss: 1.04220
Epoch 148: | Loss: 1.04405
Epoch 149: | Loss: 1.03948
Epoch 150: | Loss: 1.04459
Epoch 151: | Loss: 1.04171
Epoch 152: | Loss: 1.03970
Epoch 153: | Loss: 1.03716
Epoch 154: | Loss: 1.03463
Epoch 155: | Loss: 1.04393
Epoch 156: | Loss: 1.03652
Epoch 157: | Loss: 1.02716
Epoch 158: | Loss: 1.03316
Epoch 159: | Loss: 1.03043
Epoch 160: | Loss: 1.03619
Epoch 161: | Loss: 1.03309
Epoch 162: | Loss: 1.04042
Epoch 163: | Loss: 1.03077
Epoch 164: | Loss: 1.03261
Epoch 165: | Loss: 1.02747
Epoch 166: | Loss: 1.02858
Epoch 167: | Loss: 1.02922
Epoch 168: | Loss: 1.02783
Epoch 169: | Loss: 1.02730
Epoch 170: | Loss: 1.02502
Epoch 171: | Loss: 1.02610
Epoch 172: | Loss: 1.02349
Epoch 173: | Loss: 1.02160
Epoch 174: | Loss: 1.02398
Epoch 175: | Loss: 1.02416
Epoch 176: | Loss: 1.02696
Epoch 177: | Loss: 1.02696
Epoch 178: | Loss: 1.02647
Epoch 179: | Loss: 1.02215
Epoch 180: | Loss: 1.02233
Epoch 181: | Loss: 1.02674
Epoch 182: | Loss: 1.02408
Epoch 183: | Loss: 1.02805
Epoch 184: | Loss: 1.02265
Epoch 185: | Loss: 1.02175
Epoch 186: | Loss: 1.02590
Epoch 187: | Loss: 1.02430
Epoch 188: | Loss: 1.02049
Epoch 189: | Loss: 1.02070
Epoch 190: | Loss: 1.01830
Epoch 191: | Loss: 1.02678
Epoch 192: | Loss: 1.02074
Epoch 193: | Loss: 1.02470
Epoch 194: | Loss: 1.01351
Epoch 195: | Loss: 1.02280
Epoch 196: | Loss: 1.02368
Epoch 197: | Loss: 1.01707
Epoch 198: | Loss: 1.01887
Epoch 199: | Loss: 1.02613
Accuracy: 0.11110309829059828
Epoch 000: | Loss: 1.59261
Epoch 001: | Loss: 1.55802
Epoch 002: | Loss: 1.55509
Epoch 003: | Loss: 1.54829
Epoch 004: | Loss: 1.54498
Epoch 005: | Loss: 1.52965
Epoch 006: | Loss: 1.51336
Epoch 007: | Loss: 1.48802
Epoch 008: | Loss: 1.45565
Epoch 009: | Loss: 1.42123
Epoch 010: | Loss: 1.39111
Epoch 011: | Loss: 1.35910
Epoch 012: | Loss: 1.33421
Epoch 013: | Loss: 1.31148
Epoch 014: | Loss: 1.30061
Epoch 015: | Loss: 1.28111
Epoch 016: | Loss: 1.27279
Epoch 017: | Loss: 1.26513
Epoch 018: | Loss: 1.25063
Epoch 019: | Loss: 1.24785
Epoch 020: | Loss: 1.23909
Epoch 021: | Loss: 1.22247
Epoch 022: | Loss: 1.22344
Epoch 023: | Loss: 1.21610
Epoch 024: | Loss: 1.21357
Epoch 025: | Loss: 1.20432
Epoch 026: | Loss: 1.19864
Epoch 027: | Loss: 1.20283
Epoch 028: | Loss: 1.19118
Epoch 029: | Loss: 1.18610
Epoch 030: | Loss: 1.17619
Epoch 031: | Loss: 1.17467
Epoch 032: | Loss: 1.17623
Epoch 033: | Loss: 1.17593
Epoch 034: | Loss: 1.16955
Epoch 035: | Loss: 1.16647
Epoch 036: | Loss: 1.16380
Epoch 037: | Loss: 1.16233
Epoch 038: | Loss: 1.16443
Epoch 039: | Loss: 1.16113
Epoch 040: | Loss: 1.15996
Epoch 041: | Loss: 1.15663
Epoch 042: | Loss: 1.15672
Epoch 043: | Loss: 1.16036
Epoch 044: | Loss: 1.16162
Epoch 045: | Loss: 1.16237
Epoch 046: | Loss: 1.15356
Epoch 047: | Loss: 1.15709
Epoch 048: | Loss: 1.16201
Epoch 049: | Loss: 1.16257
Epoch 050: | Loss: 1.16083
Epoch 051: | Loss: 1.15430
Epoch 052: | Loss: 1.15412
Epoch 053: | Loss: 1.15260
Epoch 054: | Loss: 1.15843
Epoch 055: | Loss: 1.15966
Epoch 056: | Loss: 1.15735
Epoch 057: | Loss: 1.15513
Epoch 058: | Loss: 1.15619
Epoch 059: | Loss: 1.15113
Epoch 060: | Loss: 1.15685
Epoch 061: | Loss: 1.15451
Epoch 062: | Loss: 1.14775
Epoch 063: | Loss: 1.14518
Epoch 064: | Loss: 1.14952
Epoch 065: | Loss: 1.14695
Epoch 066: | Loss: 1.14263
Epoch 067: | Loss: 1.14609
Epoch 068: | Loss: 1.14233
Epoch 069: | Loss: 1.14353
Epoch 070: | Loss: 1.13597
Epoch 071: | Loss: 1.13090
Epoch 072: | Loss: 1.13102
Epoch 073: | Loss: 1.12046
Epoch 074: | Loss: 1.11991
Epoch 075: | Loss: 1.10943
Epoch 076: | Loss: 1.12072
Epoch 077: | Loss: 1.11032
Epoch 078: | Loss: 1.10131
Epoch 079: | Loss: 1.09911
Epoch 080: | Loss: 1.09471
Epoch 081: | Loss: 1.08487
Epoch 082: | Loss: 1.08361
Epoch 083: | Loss: 1.07693
Epoch 084: | Loss: 1.06846
Epoch 085: | Loss: 1.06554
Epoch 086: | Loss: 1.05366
Epoch 087: | Loss: 1.05227
Epoch 088: | Loss: 1.04874
Epoch 089: | Loss: 1.04231
Epoch 090: | Loss: 1.02826
Epoch 091: | Loss: 1.02513
Epoch 092: | Loss: 1.01172
Epoch 093: | Loss: 1.00407
Epoch 094: | Loss: 0.99398
Epoch 095: | Loss: 0.98400
Epoch 096: | Loss: 0.96870
Epoch 097: | Loss: 0.96742
Epoch 098: | Loss: 0.95330
Epoch 099: | Loss: 0.95141
Epoch 100: | Loss: 0.93624
Epoch 101: | Loss: 0.92290
Epoch 102: | Loss: 0.91693
Epoch 103: | Loss: 0.90917
Epoch 104: | Loss: 0.89610
Epoch 105: | Loss: 0.88982
Epoch 106: | Loss: 0.87860
Epoch 107: | Loss: 0.88010
Epoch 108: | Loss: 0.86342
Epoch 109: | Loss: 0.86236
Epoch 110: | Loss: 0.85596
Epoch 111: | Loss: 0.85206
Epoch 112: | Loss: 0.84809
Epoch 113: | Loss: 0.84088
Epoch 114: | Loss: 0.83492
Epoch 115: | Loss: 0.83026
Epoch 116: | Loss: 0.82864
Epoch 117: | Loss: 0.82165
Epoch 118: | Loss: 0.81935
Epoch 119: | Loss: 0.82340
Epoch 120: | Loss: 0.81545
Epoch 121: | Loss: 0.80407
Epoch 122: | Loss: 0.80760
Epoch 123: | Loss: 0.80876
Epoch 124: | Loss: 0.80349
Epoch 125: | Loss: 0.79841
Epoch 126: | Loss: 0.79861
Epoch 127: | Loss: 0.79352
Epoch 128: | Loss: 0.79204
Epoch 129: | Loss: 0.79200
Epoch 130: | Loss: 0.79813
Epoch 131: | Loss: 0.79073
Epoch 132: | Loss: 0.78867
Epoch 133: | Loss: 0.78399
Epoch 134: | Loss: 0.78530
Epoch 135: | Loss: 0.78989
Epoch 136: | Loss: 0.78194
Epoch 137: | Loss: 0.78327
Epoch 138: | Loss: 0.78330
Epoch 139: | Loss: 0.78412
Epoch 140: | Loss: 0.78029
Epoch 141: | Loss: 0.78651
Epoch 142: | Loss: 0.77426
Epoch 143: | Loss: 0.78130
Epoch 144: | Loss: 0.78063
Epoch 145: | Loss: 0.77969
Epoch 146: | Loss: 0.78008
Epoch 147: | Loss: 0.78216
Epoch 148: | Loss: 0.77978
Epoch 149: | Loss: 0.77939
Epoch 150: | Loss: 0.77819
Epoch 151: | Loss: 0.78352
Epoch 152: | Loss: 0.77748
Epoch 153: | Loss: 0.77686
Epoch 154: | Loss: 0.77895
Epoch 155: | Loss: 0.77881
Epoch 156: | Loss: 0.78198
Epoch 157: | Loss: 0.77853
Epoch 158: | Loss: 0.78005
Epoch 159: | Loss: 0.78035
Epoch 160: | Loss: 0.78484
Epoch 161: | Loss: 0.77438
Epoch 162: | Loss: 0.77305
Epoch 163: | Loss: 0.77820
Epoch 164: | Loss: 0.77602
Epoch 165: | Loss: 0.77401
Epoch 166: | Loss: 0.77069
Epoch 167: | Loss: 0.77524
Epoch 168: | Loss: 0.77068
Epoch 169: | Loss: 0.77206
Epoch 170: | Loss: 0.77134
Epoch 171: | Loss: 0.76967
Epoch 172: | Loss: 0.76556
Epoch 173: | Loss: 0.76575
Epoch 174: | Loss: 0.76335
Epoch 175: | Loss: 0.75935
Epoch 176: | Loss: 0.75831
Epoch 177: | Loss: 0.75739
Epoch 178: | Loss: 0.75222
Epoch 179: | Loss: 0.75323
Epoch 180: | Loss: 0.74865
Epoch 181: | Loss: 0.74781
Epoch 182: | Loss: 0.74849
Epoch 183: | Loss: 0.74082
Epoch 184: | Loss: 0.74078
Epoch 185: | Loss: 0.73715
Epoch 186: | Loss: 0.73523
Epoch 187: | Loss: 0.73601
Epoch 188: | Loss: 0.72780
Epoch 189: | Loss: 0.73419
Epoch 190: | Loss: 0.72854
Epoch 191: | Loss: 0.72179
Epoch 192: | Loss: 0.71499
Epoch 193: | Loss: 0.71269
Epoch 194: | Loss: 0.71444
Epoch 195: | Loss: 0.70943
Epoch 196: | Loss: 0.70163
Epoch 197: | Loss: 0.70619
Epoch 198: | Loss: 0.70202
Epoch 199: | Loss: 0.69564
Accuracy: 0.7367441239316239
Epoch 000: | Loss: 1.58632
Epoch 001: | Loss: 1.53684
Epoch 002: | Loss: 1.52782
Epoch 003: | Loss: 1.51223
Epoch 004: | Loss: 1.50687
Epoch 005: | Loss: 1.49570
Epoch 006: | Loss: 1.49689
Epoch 007: | Loss: 1.48900
Epoch 008: | Loss: 1.48616
Epoch 009: | Loss: 1.47692
Epoch 010: | Loss: 1.45969
Epoch 011: | Loss: 1.43050
Epoch 012: | Loss: 1.38864
Epoch 013: | Loss: 1.33577
Epoch 014: | Loss: 1.27799
Epoch 015: | Loss: 1.22817
Epoch 016: | Loss: 1.20816
Epoch 017: | Loss: 1.20617
Epoch 018: | Loss: 1.20415
Epoch 019: | Loss: 1.20133
Epoch 020: | Loss: 1.17193
Epoch 021: | Loss: 1.15429
Epoch 022: | Loss: 1.13344
Epoch 023: | Loss: 1.11587
Epoch 024: | Loss: 1.09922
Epoch 025: | Loss: 1.09150
Epoch 026: | Loss: 1.07406
Epoch 027: | Loss: 1.05565
Epoch 028: | Loss: 1.03970
Epoch 029: | Loss: 1.02192
Epoch 030: | Loss: 0.99640
Epoch 031: | Loss: 0.98017
Epoch 032: | Loss: 0.96486
Epoch 033: | Loss: 0.94934
Epoch 034: | Loss: 0.93513
Epoch 035: | Loss: 0.92008
Epoch 036: | Loss: 0.91027
Epoch 037: | Loss: 0.89836
Epoch 038: | Loss: 0.89069
Epoch 039: | Loss: 0.87816
Epoch 040: | Loss: 0.87347
Epoch 041: | Loss: 0.85774
Epoch 042: | Loss: 0.85165
Epoch 043: | Loss: 0.84371
Epoch 044: | Loss: 0.83896
Epoch 045: | Loss: 0.82901
Epoch 046: | Loss: 0.82759
Epoch 047: | Loss: 0.82238
Epoch 048: | Loss: 0.81169
Epoch 049: | Loss: 0.80962
Epoch 050: | Loss: 0.80398
Epoch 051: | Loss: 0.79634
Epoch 052: | Loss: 0.80004
Epoch 053: | Loss: 0.79419
Epoch 054: | Loss: 0.79223
Epoch 055: | Loss: 0.78900
Epoch 056: | Loss: 0.78565
Epoch 057: | Loss: 0.78321
Epoch 058: | Loss: 0.78362
Epoch 059: | Loss: 0.77765
Epoch 060: | Loss: 0.77618
Epoch 061: | Loss: 0.77636
Epoch 062: | Loss: 0.77046
Epoch 063: | Loss: 0.76971
Epoch 064: | Loss: 0.76771
Epoch 065: | Loss: 0.76796
Epoch 066: | Loss: 0.76656
Epoch 067: | Loss: 0.76566
Epoch 068: | Loss: 0.76361
Epoch 069: | Loss: 0.76341
Epoch 070: | Loss: 0.76180
Epoch 071: | Loss: 0.76254
Epoch 072: | Loss: 0.75913
Epoch 073: | Loss: 0.76035
Epoch 074: | Loss: 0.75610
Epoch 075: | Loss: 0.75899
Epoch 076: | Loss: 0.75364
Epoch 077: | Loss: 0.75839
Epoch 078: | Loss: 0.75292
Epoch 079: | Loss: 0.75741
Epoch 080: | Loss: 0.75431
Epoch 081: | Loss: 0.75854
Epoch 082: | Loss: 0.75351
Epoch 083: | Loss: 0.75360
Epoch 084: | Loss: 0.75622
Epoch 085: | Loss: 0.74983
Epoch 086: | Loss: 0.75438
Epoch 087: | Loss: 0.74935
Epoch 088: | Loss: 0.75654
Epoch 089: | Loss: 0.75614
Epoch 090: | Loss: 0.75540
Epoch 091: | Loss: 0.74975
Epoch 092: | Loss: 0.75366
Epoch 093: | Loss: 0.75460
Epoch 094: | Loss: 0.75278
Epoch 095: | Loss: 0.75610
Epoch 096: | Loss: 0.75028
Epoch 097: | Loss: 0.75419
Epoch 098: | Loss: 0.75507
Epoch 099: | Loss: 0.75024
Epoch 100: | Loss: 0.75406
Epoch 101: | Loss: 0.75469
Epoch 102: | Loss: 0.75167
Epoch 103: | Loss: 0.74930
Epoch 104: | Loss: 0.75176
Epoch 105: | Loss: 0.75342
Epoch 106: | Loss: 0.74984
Epoch 107: | Loss: 0.75293
Epoch 108: | Loss: 0.75347
Epoch 109: | Loss: 0.75257
Epoch 110: | Loss: 0.75307
Epoch 111: | Loss: 0.75122
Epoch 112: | Loss: 0.75321
Epoch 113: | Loss: 0.75113
Epoch 114: | Loss: 0.75071
Epoch 115: | Loss: 0.75011
Epoch 116: | Loss: 0.75622
Epoch 117: | Loss: 0.75034
Epoch 118: | Loss: 0.75174
Epoch 119: | Loss: 0.75155
Epoch 120: | Loss: 0.75006
Epoch 121: | Loss: 0.75220
Epoch 122: | Loss: 0.75218
Epoch 123: | Loss: 0.74911
Epoch 124: | Loss: 0.75111
Epoch 125: | Loss: 0.75334
Epoch 126: | Loss: 0.75022
Epoch 127: | Loss: 0.74828
Epoch 128: | Loss: 0.74811
Epoch 129: | Loss: 0.74518
Epoch 130: | Loss: 0.74128
Epoch 131: | Loss: 0.74267
Epoch 132: | Loss: 0.73870
Epoch 133: | Loss: 0.74399
Epoch 134: | Loss: 0.74365
Epoch 135: | Loss: 0.74134
Epoch 136: | Loss: 0.73839
Epoch 137: | Loss: 0.74064
Epoch 138: | Loss: 0.73660
Epoch 139: | Loss: 0.74060
Epoch 140: | Loss: 0.73587
Epoch 141: | Loss: 0.73441
Epoch 142: | Loss: 0.73351
Epoch 143: | Loss: 0.73128
Epoch 144: | Loss: 0.73407
Epoch 145: | Loss: 0.73092
Epoch 146: | Loss: 0.72854
Epoch 147: | Loss: 0.72571
Epoch 148: | Loss: 0.72388
Epoch 149: | Loss: 0.72328
Epoch 150: | Loss: 0.72551
Epoch 151: | Loss: 0.72373
Epoch 152: | Loss: 0.72064
Epoch 153: | Loss: 0.71830
Epoch 154: | Loss: 0.71545
Epoch 155: | Loss: 0.72030
Epoch 156: | Loss: 0.71509
Epoch 157: | Loss: 0.71095
Epoch 158: | Loss: 0.71541
Epoch 159: | Loss: 0.71149
Epoch 160: | Loss: 0.70605
Epoch 161: | Loss: 0.70807
Epoch 162: | Loss: 0.70959
Epoch 163: | Loss: 0.70523
Epoch 164: | Loss: 0.70282
Epoch 165: | Loss: 0.70044
Epoch 166: | Loss: 0.69899
Epoch 167: | Loss: 0.69809
Epoch 168: | Loss: 0.70041
Epoch 169: | Loss: 0.69302
Epoch 170: | Loss: 0.69033
Epoch 171: | Loss: 0.68840
Epoch 172: | Loss: 0.68829
Epoch 173: | Loss: 0.68687
Epoch 174: | Loss: 0.68753
Epoch 175: | Loss: 0.68468
Epoch 176: | Loss: 0.68289
Epoch 177: | Loss: 0.68124
Epoch 178: | Loss: 0.67913
Epoch 179: | Loss: 0.67859
Epoch 180: | Loss: 0.67242
Epoch 181: | Loss: 0.67278
Epoch 182: | Loss: 0.66800
Epoch 183: | Loss: 0.66872
Epoch 184: | Loss: 0.66689
Epoch 185: | Loss: 0.66035
Epoch 186: | Loss: 0.66529
Epoch 187: | Loss: 0.66211
Epoch 188: | Loss: 0.66169
Epoch 189: | Loss: 0.66244
Epoch 190: | Loss: 0.65985
Epoch 191: | Loss: 0.65578
Epoch 192: | Loss: 0.65459
Epoch 193: | Loss: 0.65449
Epoch 194: | Loss: 0.65175
Epoch 195: | Loss: 0.65268
Epoch 196: | Loss: 0.64884
Epoch 197: | Loss: 0.64739
Epoch 198: | Loss: 0.64407
Epoch 199: | Loss: 0.64655
Accuracy: 0.7685763888888889
Epoch 000: | Loss: 1.61910
Epoch 001: | Loss: 1.58852
Epoch 002: | Loss: 1.57849
Epoch 003: | Loss: 1.54356
Epoch 004: | Loss: 1.54195
Epoch 005: | Loss: 1.55690
Epoch 006: | Loss: 1.52547
Epoch 007: | Loss: 1.51473
Epoch 008: | Loss: 1.52141
Epoch 009: | Loss: 1.50066
Epoch 010: | Loss: 1.49894
Epoch 011: | Loss: 1.50605
Epoch 012: | Loss: 1.48991
Epoch 013: | Loss: 1.47208
Epoch 014: | Loss: 1.47533
Epoch 015: | Loss: 1.46909
Epoch 016: | Loss: 1.44946
Epoch 017: | Loss: 1.44536
Epoch 018: | Loss: 1.43903
Epoch 019: | Loss: 1.41738
Epoch 020: | Loss: 1.39788
Epoch 021: | Loss: 1.39291
Epoch 022: | Loss: 1.37386
Epoch 023: | Loss: 1.35144
Epoch 024: | Loss: 1.33644
Epoch 025: | Loss: 1.31876
Epoch 026: | Loss: 1.29614
Epoch 027: | Loss: 1.28535
Epoch 028: | Loss: 1.26255
Epoch 029: | Loss: 1.25192
Epoch 030: | Loss: 1.23564
Epoch 031: | Loss: 1.22318
Epoch 032: | Loss: 1.21293
Epoch 033: | Loss: 1.20432
Epoch 034: | Loss: 1.18838
Epoch 035: | Loss: 1.18159
Epoch 036: | Loss: 1.16475
Epoch 037: | Loss: 1.15550
Epoch 038: | Loss: 1.14056
Epoch 039: | Loss: 1.13457
Epoch 040: | Loss: 1.12831
Epoch 041: | Loss: 1.11523
Epoch 042: | Loss: 1.10877
Epoch 043: | Loss: 1.10135
Epoch 044: | Loss: 1.09557
Epoch 045: | Loss: 1.08397
Epoch 046: | Loss: 1.07866
Epoch 047: | Loss: 1.06140
Epoch 048: | Loss: 1.05541
Epoch 049: | Loss: 1.04453
Epoch 050: | Loss: 1.03869
Epoch 051: | Loss: 1.03370
Epoch 052: | Loss: 1.01748
Epoch 053: | Loss: 1.00829
Epoch 054: | Loss: 0.99794
Epoch 055: | Loss: 0.98702
Epoch 056: | Loss: 0.98661
Epoch 057: | Loss: 0.96790
Epoch 058: | Loss: 0.95815
Epoch 059: | Loss: 0.95187
Epoch 060: | Loss: 0.94264
Epoch 061: | Loss: 0.93910
Epoch 062: | Loss: 0.91756
Epoch 063: | Loss: 0.91527
Epoch 064: | Loss: 0.89574
Epoch 065: | Loss: 0.88809
Epoch 066: | Loss: 0.87543
Epoch 067: | Loss: 0.86707
Epoch 068: | Loss: 0.85904
Epoch 069: | Loss: 0.84976
Epoch 070: | Loss: 0.83950
Epoch 071: | Loss: 0.83466
Epoch 072: | Loss: 0.83010
Epoch 073: | Loss: 0.82137
Epoch 074: | Loss: 0.81631
Epoch 075: | Loss: 0.81114
Epoch 076: | Loss: 0.80064
Epoch 077: | Loss: 0.79530
Epoch 078: | Loss: 0.79867
Epoch 079: | Loss: 0.78793
Epoch 080: | Loss: 0.78936
Epoch 081: | Loss: 0.78108
Epoch 082: | Loss: 0.77368
Epoch 083: | Loss: 0.76527
Epoch 084: | Loss: 0.76773
Epoch 085: | Loss: 0.75763
Epoch 086: | Loss: 0.75558
Epoch 087: | Loss: 0.74915
Epoch 088: | Loss: 0.74713
Epoch 089: | Loss: 0.74231
Epoch 090: | Loss: 0.73924
Epoch 091: | Loss: 0.72937
Epoch 092: | Loss: 0.72869
Epoch 093: | Loss: 0.72043
Epoch 094: | Loss: 0.72085
Epoch 095: | Loss: 0.71646
Epoch 096: | Loss: 0.71627
Epoch 097: | Loss: 0.71294
Epoch 098: | Loss: 0.70926
Epoch 099: | Loss: 0.70245
Epoch 100: | Loss: 0.69967
Epoch 101: | Loss: 0.69861
Epoch 102: | Loss: 0.68462
Epoch 103: | Loss: 0.68965
Epoch 104: | Loss: 0.68184
Epoch 105: | Loss: 0.67709
Epoch 106: | Loss: 0.66374
Epoch 107: | Loss: 0.65784
Epoch 108: | Loss: 0.65017
Epoch 109: | Loss: 0.64953
Epoch 110: | Loss: 0.64677
Epoch 111: | Loss: 0.64544
Epoch 112: | Loss: 0.63676
Epoch 113: | Loss: 0.63340
Epoch 114: | Loss: 0.62937
Epoch 115: | Loss: 0.62851
Epoch 116: | Loss: 0.62391
Epoch 117: | Loss: 0.61970
Epoch 118: | Loss: 0.61668
Epoch 119: | Loss: 0.60276
Epoch 120: | Loss: 0.60593
Epoch 121: | Loss: 0.60824
Epoch 122: | Loss: 0.59926
Epoch 123: | Loss: 0.59070
Epoch 124: | Loss: 0.58213
Epoch 125: | Loss: 0.57397
Epoch 126: | Loss: 0.57144
Epoch 127: | Loss: 0.56659
Epoch 128: | Loss: 0.55511
Epoch 129: | Loss: 0.55413
Epoch 130: | Loss: 0.54622
Epoch 131: | Loss: 0.54997
Epoch 132: | Loss: 0.54250
Epoch 133: | Loss: 0.53280
Epoch 134: | Loss: 0.52917
Epoch 135: | Loss: 0.52751
Epoch 136: | Loss: 0.52613
Epoch 137: | Loss: 0.52328
Epoch 138: | Loss: 0.51745
Epoch 139: | Loss: 0.51302
Epoch 140: | Loss: 0.50439
Epoch 141: | Loss: 0.50185
Epoch 142: | Loss: 0.50546
Epoch 143: | Loss: 0.49569
Epoch 144: | Loss: 0.49214
Epoch 145: | Loss: 0.48970
Epoch 146: | Loss: 0.48789
Epoch 147: | Loss: 0.48239
Epoch 148: | Loss: 0.47786
Epoch 149: | Loss: 0.47144
Epoch 150: | Loss: 0.46929
Epoch 151: | Loss: 0.46181
Epoch 152: | Loss: 0.46264
Epoch 153: | Loss: 0.45706
Epoch 154: | Loss: 0.45133
Epoch 155: | Loss: 0.45251
Epoch 156: | Loss: 0.44903
Epoch 157: | Loss: 0.44162
Epoch 158: | Loss: 0.43947
Epoch 159: | Loss: 0.43874
Epoch 160: | Loss: 0.43572
Epoch 161: | Loss: 0.43379
Epoch 162: | Loss: 0.42353
Epoch 163: | Loss: 0.42252
Epoch 164: | Loss: 0.42490
Epoch 165: | Loss: 0.41895
Epoch 166: | Loss: 0.41668
Epoch 167: | Loss: 0.40955
Epoch 168: | Loss: 0.40774
Epoch 169: | Loss: 0.40630
Epoch 170: | Loss: 0.40643
Epoch 171: | Loss: 0.40506
Epoch 172: | Loss: 0.39830
Epoch 173: | Loss: 0.39733
Epoch 174: | Loss: 0.40110
Epoch 175: | Loss: 0.39074
Epoch 176: | Loss: 0.39224
Epoch 177: | Loss: 0.38920
Epoch 178: | Loss: 0.38704
Epoch 179: | Loss: 0.38428
Epoch 180: | Loss: 0.38191
Epoch 181: | Loss: 0.37965
Epoch 182: | Loss: 0.37513
Epoch 183: | Loss: 0.37380
Epoch 184: | Loss: 0.37432
Epoch 185: | Loss: 0.36801
Epoch 186: | Loss: 0.36901
Epoch 187: | Loss: 0.36557
Epoch 188: | Loss: 0.36145
Epoch 189: | Loss: 0.36125
Epoch 190: | Loss: 0.35944
Epoch 191: | Loss: 0.35435
Epoch 192: | Loss: 0.35200
Epoch 193: | Loss: 0.34876
Epoch 194: | Loss: 0.34543
Epoch 195: | Loss: 0.34275
Epoch 196: | Loss: 0.34645
Epoch 197: | Loss: 0.33846
Epoch 198: | Loss: 0.34227
Epoch 199: | Loss: 0.33633
Accuracy: 0.8389716880341881
Epoch 000: | Loss: 1.45949
Epoch 001: | Loss: 1.21227
Epoch 002: | Loss: 1.06161
Epoch 003: | Loss: 0.94653
Epoch 004: | Loss: 0.82688
Epoch 005: | Loss: 0.73193
Epoch 006: | Loss: 0.66150
Epoch 007: | Loss: 0.61280
Epoch 008: | Loss: 0.58370
Epoch 009: | Loss: 0.55780
Epoch 010: | Loss: 0.54000
Epoch 011: | Loss: 0.52545
Epoch 012: | Loss: 0.51108
Epoch 013: | Loss: 0.50232
Epoch 014: | Loss: 0.49266
Epoch 015: | Loss: 0.48489
Epoch 016: | Loss: 0.47000
Epoch 017: | Loss: 0.46689
Epoch 018: | Loss: 0.45502
Epoch 019: | Loss: 0.44654
Epoch 020: | Loss: 0.43679
Epoch 021: | Loss: 0.42935
Epoch 022: | Loss: 0.42235
Epoch 023: | Loss: 0.41368
Epoch 024: | Loss: 0.39900
Epoch 025: | Loss: 0.39229
Epoch 026: | Loss: 0.37598
Epoch 027: | Loss: 0.36265
Epoch 028: | Loss: 0.35829
Epoch 029: | Loss: 0.34473
Epoch 030: | Loss: 0.33637
Epoch 031: | Loss: 0.33037
Epoch 032: | Loss: 0.32217
Epoch 033: | Loss: 0.31900
Epoch 034: | Loss: 0.30673
Epoch 035: | Loss: 0.29897
Epoch 036: | Loss: 0.29384
Epoch 037: | Loss: 0.28626
Epoch 038: | Loss: 0.27406
Epoch 039: | Loss: 0.27115
Epoch 040: | Loss: 0.26146
Epoch 041: | Loss: 0.25554
Epoch 042: | Loss: 0.24923
Epoch 043: | Loss: 0.23884
Epoch 044: | Loss: 0.23270
Epoch 045: | Loss: 0.22625
Epoch 046: | Loss: 0.22125
Epoch 047: | Loss: 0.21262
Epoch 048: | Loss: 0.21050
Epoch 049: | Loss: 0.19958
Epoch 050: | Loss: 0.19534
Epoch 051: | Loss: 0.19072
Epoch 052: | Loss: 0.18259
Epoch 053: | Loss: 0.18134
Epoch 054: | Loss: 0.17682
Epoch 055: | Loss: 0.16885
Epoch 056: | Loss: 0.16822
Epoch 057: | Loss: 0.16686
Epoch 058: | Loss: 0.15839
Epoch 059: | Loss: 0.15225
Epoch 060: | Loss: 0.15380
Epoch 061: | Loss: 0.14977
Epoch 062: | Loss: 0.14757
Epoch 063: | Loss: 0.13969
Epoch 064: | Loss: 0.13732
Epoch 065: | Loss: 0.13414
Epoch 066: | Loss: 0.13089
Epoch 067: | Loss: 0.13384
Epoch 068: | Loss: 0.12650
Epoch 069: | Loss: 0.12395
Epoch 070: | Loss: 0.11735
Epoch 071: | Loss: 0.11576
Epoch 072: | Loss: 0.11867
Epoch 073: | Loss: 0.11746
Epoch 074: | Loss: 0.11256
Epoch 075: | Loss: 0.10655
Epoch 076: | Loss: 0.10995
Epoch 077: | Loss: 0.10528
Epoch 078: | Loss: 0.10117
Epoch 079: | Loss: 0.10278
Epoch 080: | Loss: 0.09904
Epoch 081: | Loss: 0.09854
Epoch 082: | Loss: 0.09445
Epoch 083: | Loss: 0.09767
Epoch 084: | Loss: 0.09186
Epoch 085: | Loss: 0.09236
Epoch 086: | Loss: 0.08492
Epoch 087: | Loss: 0.08630
Epoch 088: | Loss: 0.08508
Epoch 089: | Loss: 0.08237
Epoch 090: | Loss: 0.08341
Epoch 091: | Loss: 0.08292
Epoch 092: | Loss: 0.07755
Epoch 093: | Loss: 0.07346
Epoch 094: | Loss: 0.07631
Epoch 095: | Loss: 0.07652
Epoch 096: | Loss: 0.07369
Epoch 097: | Loss: 0.07025
Epoch 098: | Loss: 0.07333
Epoch 099: | Loss: 0.07181
Epoch 100: | Loss: 0.06715
Epoch 101: | Loss: 0.06955
Epoch 102: | Loss: 0.06503
Epoch 103: | Loss: 0.06833
Epoch 104: | Loss: 0.06902
Epoch 105: | Loss: 0.06517
Epoch 106: | Loss: 0.06705
Epoch 107: | Loss: 0.06377
Epoch 108: | Loss: 0.06566
Epoch 109: | Loss: 0.06337
Epoch 110: | Loss: 0.06021
Epoch 111: | Loss: 0.06215
Epoch 112: | Loss: 0.05868
Epoch 113: | Loss: 0.05718
Epoch 114: | Loss: 0.05759
Epoch 115: | Loss: 0.06108
Epoch 116: | Loss: 0.05789
Epoch 117: | Loss: 0.05422
Epoch 118: | Loss: 0.05763
Epoch 119: | Loss: 0.05708
Epoch 120: | Loss: 0.05484
Epoch 121: | Loss: 0.05420
Epoch 122: | Loss: 0.05376
Epoch 123: | Loss: 0.05140
Epoch 124: | Loss: 0.05580
Epoch 125: | Loss: 0.05285
Epoch 126: | Loss: 0.05084
Epoch 127: | Loss: 0.05126
Epoch 128: | Loss: 0.05076
Epoch 129: | Loss: 0.05183
Epoch 130: | Loss: 0.05022
Epoch 131: | Loss: 0.04798
Epoch 132: | Loss: 0.04954
Epoch 133: | Loss: 0.04957
Epoch 134: | Loss: 0.04956
Epoch 135: | Loss: 0.05117
Epoch 136: | Loss: 0.04809
Epoch 137: | Loss: 0.04941
Epoch 138: | Loss: 0.04631
Epoch 139: | Loss: 0.04614
Epoch 140: | Loss: 0.04644
Epoch 141: | Loss: 0.04824
Epoch 142: | Loss: 0.04877
Epoch 143: | Loss: 0.04329
Epoch 144: | Loss: 0.04812
Epoch 145: | Loss: 0.04759
Epoch 146: | Loss: 0.04759
Epoch 147: | Loss: 0.04902
Epoch 148: | Loss: 0.04551
Epoch 149: | Loss: 0.04456
Epoch 150: | Loss: 0.04203
Epoch 151: | Loss: 0.04514
Epoch 152: | Loss: 0.04336
Epoch 153: | Loss: 0.04593
Epoch 154: | Loss: 0.04318
Epoch 155: | Loss: 0.04281
Epoch 156: | Loss: 0.04380
Epoch 157: | Loss: 0.04287
Epoch 158: | Loss: 0.04142
Epoch 159: | Loss: 0.04305
Epoch 160: | Loss: 0.04406
Epoch 161: | Loss: 0.04141
Epoch 162: | Loss: 0.03949
Epoch 163: | Loss: 0.04121
Epoch 164: | Loss: 0.04319
Epoch 165: | Loss: 0.03856
Epoch 166: | Loss: 0.04265
Epoch 167: | Loss: 0.04305
Epoch 168: | Loss: 0.04068
Epoch 169: | Loss: 0.04167
Epoch 170: | Loss: 0.04043
Epoch 171: | Loss: 0.04112
Epoch 172: | Loss: 0.03866
Epoch 173: | Loss: 0.04138
Epoch 174: | Loss: 0.04274
Epoch 175: | Loss: 0.03998
Epoch 176: | Loss: 0.04126
Epoch 177: | Loss: 0.04128
Epoch 178: | Loss: 0.04130
Epoch 179: | Loss: 0.03875
Epoch 180: | Loss: 0.03676
Epoch 181: | Loss: 0.03842
Epoch 182: | Loss: 0.04180
Epoch 183: | Loss: 0.03817
Epoch 184: | Loss: 0.03901
Epoch 185: | Loss: 0.04060
Epoch 186: | Loss: 0.03990
Epoch 187: | Loss: 0.04089
Epoch 188: | Loss: 0.03634
Epoch 189: | Loss: 0.03707
Epoch 190: | Loss: 0.03851
Epoch 191: | Loss: 0.03517
Epoch 192: | Loss: 0.03722
Epoch 193: | Loss: 0.03912
Epoch 194: | Loss: 0.04027
Epoch 195: | Loss: 0.03787
Epoch 196: | Loss: 0.03757
Epoch 197: | Loss: 0.03293
Epoch 198: | Loss: 0.03544
Epoch 199: | Loss: 0.03610
Accuracy: 0.9310844017094018
Epoch 000: | Loss: 1.57956
Epoch 001: | Loss: 1.53141
Epoch 002: | Loss: 1.52351
Epoch 003: | Loss: 1.51374
Epoch 004: | Loss: 1.51189
Epoch 005: | Loss: 1.50604
Epoch 006: | Loss: 1.46086
Epoch 007: | Loss: 1.33773
Epoch 008: | Loss: 1.23739
Epoch 009: | Loss: 1.13603
Epoch 010: | Loss: 1.04056
Epoch 011: | Loss: 0.94287
Epoch 012: | Loss: 0.87391
Epoch 013: | Loss: 0.82473
Epoch 014: | Loss: 0.79099
Epoch 015: | Loss: 0.75759
Epoch 016: | Loss: 0.73372
Epoch 017: | Loss: 0.71248
Epoch 018: | Loss: 0.69316
Epoch 019: | Loss: 0.68224
Epoch 020: | Loss: 0.66597
Epoch 021: | Loss: 0.65996
Epoch 022: | Loss: 0.64791
Epoch 023: | Loss: 0.64294
Epoch 024: | Loss: 0.63082
Epoch 025: | Loss: 0.63613
Epoch 026: | Loss: 0.62550
Epoch 027: | Loss: 0.62482
Epoch 028: | Loss: 0.62424
Epoch 029: | Loss: 0.62236
Epoch 030: | Loss: 0.61861
Epoch 031: | Loss: 0.61346
Epoch 032: | Loss: 0.61582
Epoch 033: | Loss: 0.60791
Epoch 034: | Loss: 0.61622
Epoch 035: | Loss: 0.61443
Epoch 036: | Loss: 0.60675
Epoch 037: | Loss: 0.60603
Epoch 038: | Loss: 0.60162
Epoch 039: | Loss: 0.60366
Epoch 040: | Loss: 0.60387
Epoch 041: | Loss: 0.59513
Epoch 042: | Loss: 0.60160
Epoch 043: | Loss: 0.59454
Epoch 044: | Loss: 0.59279
Epoch 045: | Loss: 0.59774
Epoch 046: | Loss: 0.59443
Epoch 047: | Loss: 0.59426
Epoch 048: | Loss: 0.59254
Epoch 049: | Loss: 0.59134
Epoch 050: | Loss: 0.59454
Epoch 051: | Loss: 0.59049
Epoch 052: | Loss: 0.58954
Epoch 053: | Loss: 0.58489
Epoch 054: | Loss: 0.58604
Epoch 055: | Loss: 0.58545
Epoch 056: | Loss: 0.58317
Epoch 057: | Loss: 0.58159
Epoch 058: | Loss: 0.58058
Epoch 059: | Loss: 0.57860
Epoch 060: | Loss: 0.58097
Epoch 061: | Loss: 0.57788
Epoch 062: | Loss: 0.57898
Epoch 063: | Loss: 0.57450
Epoch 064: | Loss: 0.57405
Epoch 065: | Loss: 0.57319
Epoch 066: | Loss: 0.57437
Epoch 067: | Loss: 0.57230
Epoch 068: | Loss: 0.57072
Epoch 069: | Loss: 0.57220
Epoch 070: | Loss: 0.56916
Epoch 071: | Loss: 0.56995
Epoch 072: | Loss: 0.57246
Epoch 073: | Loss: 0.56793
Epoch 074: | Loss: 0.56741
Epoch 075: | Loss: 0.56659
Epoch 076: | Loss: 0.56770
Epoch 077: | Loss: 0.56536
Epoch 078: | Loss: 0.56580
Epoch 079: | Loss: 0.56286
Epoch 080: | Loss: 0.55894
Epoch 081: | Loss: 0.55593
Epoch 082: | Loss: 0.56078
Epoch 083: | Loss: 0.55703
Epoch 084: | Loss: 0.55936
Epoch 085: | Loss: 0.55500
Epoch 086: | Loss: 0.55830
Epoch 087: | Loss: 0.55535
Epoch 088: | Loss: 0.55206
Epoch 089: | Loss: 0.55142
Epoch 090: | Loss: 0.55150
Epoch 091: | Loss: 0.54558
Epoch 092: | Loss: 0.54637
Epoch 093: | Loss: 0.54215
Epoch 094: | Loss: 0.54496
Epoch 095: | Loss: 0.54631
Epoch 096: | Loss: 0.54229
Epoch 097: | Loss: 0.54283
Epoch 098: | Loss: 0.54388
Epoch 099: | Loss: 0.54204
Epoch 100: | Loss: 0.53937
Epoch 101: | Loss: 0.54282
Epoch 102: | Loss: 0.54057
Epoch 103: | Loss: 0.53882
Epoch 104: | Loss: 0.53464
Epoch 105: | Loss: 0.53502
Epoch 106: | Loss: 0.53062
Epoch 107: | Loss: 0.53539
Epoch 108: | Loss: 0.53231
Epoch 109: | Loss: 0.53600
Epoch 110: | Loss: 0.53134
Epoch 111: | Loss: 0.53428
Epoch 112: | Loss: 0.53090
Epoch 113: | Loss: 0.53066
Epoch 114: | Loss: 0.53172
Epoch 115: | Loss: 0.52864
Epoch 116: | Loss: 0.52736
Epoch 117: | Loss: 0.52541
Epoch 118: | Loss: 0.52777
Epoch 119: | Loss: 0.52589
Epoch 120: | Loss: 0.52390
Epoch 121: | Loss: 0.52722
Epoch 122: | Loss: 0.52440
Epoch 123: | Loss: 0.52632
Epoch 124: | Loss: 0.52688
Epoch 125: | Loss: 0.52321
Epoch 126: | Loss: 0.52397
Epoch 127: | Loss: 0.52321
Epoch 128: | Loss: 0.52132
Epoch 129: | Loss: 0.51929
Epoch 130: | Loss: 0.52519
Epoch 131: | Loss: 0.52125
Epoch 132: | Loss: 0.51720
Epoch 133: | Loss: 0.51806
Epoch 134: | Loss: 0.51985
Epoch 135: | Loss: 0.51805
Epoch 136: | Loss: 0.52243
Epoch 137: | Loss: 0.51870
Epoch 138: | Loss: 0.51881
Epoch 139: | Loss: 0.51658
Epoch 140: | Loss: 0.51812
Epoch 141: | Loss: 0.51371
Epoch 142: | Loss: 0.51444
Epoch 143: | Loss: 0.51767
Epoch 144: | Loss: 0.51699
Epoch 145: | Loss: 0.51237
Epoch 146: | Loss: 0.51499
Epoch 147: | Loss: 0.51657
Epoch 148: | Loss: 0.51634
Epoch 149: | Loss: 0.51757
Epoch 150: | Loss: 0.51160
Epoch 151: | Loss: 0.51054
Epoch 152: | Loss: 0.51288
Epoch 153: | Loss: 0.51492
Epoch 154: | Loss: 0.51382
Epoch 155: | Loss: 0.51080
Epoch 156: | Loss: 0.51037
Epoch 157: | Loss: 0.50681
Epoch 158: | Loss: 0.51074
Epoch 159: | Loss: 0.50718
Epoch 160: | Loss: 0.51154
Epoch 161: | Loss: 0.50918
Epoch 162: | Loss: 0.50715
Epoch 163: | Loss: 0.51123
Epoch 164: | Loss: 0.51216
Epoch 165: | Loss: 0.51256
Epoch 166: | Loss: 0.51285
Epoch 167: | Loss: 0.50983
Epoch 168: | Loss: 0.50341
Epoch 169: | Loss: 0.50914
Epoch 170: | Loss: 0.50687
Epoch 171: | Loss: 0.50572
Epoch 172: | Loss: 0.50644
Epoch 173: | Loss: 0.50834
Epoch 174: | Loss: 0.51010
Epoch 175: | Loss: 0.50496
Epoch 176: | Loss: 0.50641
Epoch 177: | Loss: 0.50825
Epoch 178: | Loss: 0.50532
Epoch 179: | Loss: 0.50778
Epoch 180: | Loss: 0.50192
Epoch 181: | Loss: 0.50254
Epoch 182: | Loss: 0.50657
Epoch 183: | Loss: 0.50044
Epoch 184: | Loss: 0.50573
Epoch 185: | Loss: 0.50566
Epoch 186: | Loss: 0.50317
Epoch 187: | Loss: 0.50417
Epoch 188: | Loss: 0.50182
Epoch 189: | Loss: 0.50635
Epoch 190: | Loss: 0.50262
Epoch 191: | Loss: 0.50434
Epoch 192: | Loss: 0.50155
Epoch 193: | Loss: 0.50009
Epoch 194: | Loss: 0.50263
Epoch 195: | Loss: 0.50229
Epoch 196: | Loss: 0.50384
Epoch 197: | Loss: 0.50547
Epoch 198: | Loss: 0.50383
Epoch 199: | Loss: 0.50282
Accuracy: 0.05563034188034188
Epoch 000: | Loss: 1.78393
Epoch 001: | Loss: 1.66701
Epoch 002: | Loss: 1.60725
Epoch 003: | Loss: 1.58130
Epoch 004: | Loss: 1.56774
Epoch 005: | Loss: 1.56895
Epoch 006: | Loss: 1.56199
Epoch 007: | Loss: 1.55408
Epoch 008: | Loss: 1.55145
Epoch 009: | Loss: 1.54826
Epoch 010: | Loss: 1.55035
Epoch 011: | Loss: 1.54666
Epoch 012: | Loss: 1.54209
Epoch 013: | Loss: 1.53933
Epoch 014: | Loss: 1.53773
Epoch 015: | Loss: 1.53600
Epoch 016: | Loss: 1.52566
Epoch 017: | Loss: 1.52800
Epoch 018: | Loss: 1.52619
Epoch 019: | Loss: 1.52486
Epoch 020: | Loss: 1.52263
Epoch 021: | Loss: 1.51852
Epoch 022: | Loss: 1.51790
Epoch 023: | Loss: 1.51661
Epoch 024: | Loss: 1.51562
Epoch 025: | Loss: 1.51480
Epoch 026: | Loss: 1.51388
Epoch 027: | Loss: 1.51303
Epoch 028: | Loss: 1.51196
Epoch 029: | Loss: 1.51342
Epoch 030: | Loss: 1.51217
Epoch 031: | Loss: 1.51268
Epoch 032: | Loss: 1.51017
Epoch 033: | Loss: 1.51037
Epoch 034: | Loss: 1.51040
Epoch 035: | Loss: 1.51011
Epoch 036: | Loss: 1.50601
Epoch 037: | Loss: 1.51151
Epoch 038: | Loss: 1.51096
Epoch 039: | Loss: 1.50780
Epoch 040: | Loss: 1.50788
Epoch 041: | Loss: 1.50307
Epoch 042: | Loss: 1.50458
Epoch 043: | Loss: 1.50579
Epoch 044: | Loss: 1.50580
Epoch 045: | Loss: 1.50601
Epoch 046: | Loss: 1.50278
Epoch 047: | Loss: 1.50508
Epoch 048: | Loss: 1.50577
Epoch 049: | Loss: 1.50593
Epoch 050: | Loss: 1.50509
Epoch 051: | Loss: 1.50591
Epoch 052: | Loss: 1.50426
Epoch 053: | Loss: 1.50381
Epoch 054: | Loss: 1.50258
Epoch 055: | Loss: 1.50612
Epoch 056: | Loss: 1.50296
Epoch 057: | Loss: 1.50250
Epoch 058: | Loss: 1.50591
Epoch 059: | Loss: 1.50752
Epoch 060: | Loss: 1.50682
Epoch 061: | Loss: 1.50015
Epoch 062: | Loss: 1.50328
Epoch 063: | Loss: 1.50336
Epoch 064: | Loss: 1.50416
Epoch 065: | Loss: 1.50286
Epoch 066: | Loss: 1.50262
Epoch 067: | Loss: 1.50186
Epoch 068: | Loss: 1.50041
Epoch 069: | Loss: 1.50411
Epoch 070: | Loss: 1.50263
Epoch 071: | Loss: 1.50015
Epoch 072: | Loss: 1.49845
Epoch 073: | Loss: 1.49962
Epoch 074: | Loss: 1.50068
Epoch 075: | Loss: 1.50049
Epoch 076: | Loss: 1.50064
Epoch 077: | Loss: 1.50285
Epoch 078: | Loss: 1.49998
Epoch 079: | Loss: 1.50213
Epoch 080: | Loss: 1.49869
Epoch 081: | Loss: 1.49999
Epoch 082: | Loss: 1.49873
Epoch 083: | Loss: 1.50153
Epoch 084: | Loss: 1.50006
Epoch 085: | Loss: 1.50151
Epoch 086: | Loss: 1.50040
Epoch 087: | Loss: 1.49906
Epoch 088: | Loss: 1.49980
Epoch 089: | Loss: 1.49624
Epoch 090: | Loss: 1.50249
Epoch 091: | Loss: 1.49890
Epoch 092: | Loss: 1.50290
Epoch 093: | Loss: 1.49918
Epoch 094: | Loss: 1.49805
Epoch 095: | Loss: 1.49998
Epoch 096: | Loss: 1.49893
Epoch 097: | Loss: 1.50055
Epoch 098: | Loss: 1.49905
Epoch 099: | Loss: 1.49992
Epoch 100: | Loss: 1.49870
Epoch 101: | Loss: 1.49896
Epoch 102: | Loss: 1.49893
Epoch 103: | Loss: 1.49885
Epoch 104: | Loss: 1.49799
Epoch 105: | Loss: 1.49713
Epoch 106: | Loss: 1.49774
Epoch 107: | Loss: 1.49843
Epoch 108: | Loss: 1.49751
Epoch 109: | Loss: 1.49739
Epoch 110: | Loss: 1.49809
Epoch 111: | Loss: 1.49656
Epoch 112: | Loss: 1.49949
Epoch 113: | Loss: 1.49799
Epoch 114: | Loss: 1.49718
Epoch 115: | Loss: 1.49723
Epoch 116: | Loss: 1.49638
Epoch 117: | Loss: 1.49772
Epoch 118: | Loss: 1.49455
Epoch 119: | Loss: 1.49878
Epoch 120: | Loss: 1.49701
Epoch 121: | Loss: 1.49720
Epoch 122: | Loss: 1.49732
Epoch 123: | Loss: 1.49990
Epoch 124: | Loss: 1.49866
Epoch 125: | Loss: 1.49811
Epoch 126: | Loss: 1.49848
Epoch 127: | Loss: 1.49789
Epoch 128: | Loss: 1.49591
Epoch 129: | Loss: 1.49668
Epoch 130: | Loss: 1.49621
Epoch 131: | Loss: 1.49612
Epoch 132: | Loss: 1.49887
Epoch 133: | Loss: 1.49530
Epoch 134: | Loss: 1.49742
Epoch 135: | Loss: 1.49792
Epoch 136: | Loss: 1.49537
Epoch 137: | Loss: 1.49709
Epoch 138: | Loss: 1.49568
Epoch 139: | Loss: 1.49918
Epoch 140: | Loss: 1.49702
Epoch 141: | Loss: 1.49803
Epoch 142: | Loss: 1.50006
Epoch 143: | Loss: 1.49527
Epoch 144: | Loss: 1.49558
Epoch 145: | Loss: 1.49778
Epoch 146: | Loss: 1.49691
Epoch 147: | Loss: 1.49532
Epoch 148: | Loss: 1.49845
Epoch 149: | Loss: 1.49548
Epoch 150: | Loss: 1.49900
Epoch 151: | Loss: 1.49444
Epoch 152: | Loss: 1.49857
Epoch 153: | Loss: 1.49666
Epoch 154: | Loss: 1.49773
Epoch 155: | Loss: 1.49667
Epoch 156: | Loss: 1.49812
Epoch 157: | Loss: 1.49853
Epoch 158: | Loss: 1.49553
Epoch 159: | Loss: 1.49871
Epoch 160: | Loss: 1.49479
Epoch 161: | Loss: 1.49653
Epoch 162: | Loss: 1.49658
Epoch 163: | Loss: 1.49790
Epoch 164: | Loss: 1.49672
Epoch 165: | Loss: 1.49894
Epoch 166: | Loss: 1.49760
Epoch 167: | Loss: 1.49708
Epoch 168: | Loss: 1.49638
Epoch 169: | Loss: 1.49795
Epoch 170: | Loss: 1.49602
Epoch 171: | Loss: 1.49497
Epoch 172: | Loss: 1.49755
Epoch 173: | Loss: 1.49629
Epoch 174: | Loss: 1.49769
Epoch 175: | Loss: 1.49861
Epoch 176: | Loss: 1.49725
Epoch 177: | Loss: 1.49760
Epoch 178: | Loss: 1.49939
Epoch 179: | Loss: 1.49365
Epoch 180: | Loss: 1.49729
Epoch 181: | Loss: 1.49624
Epoch 182: | Loss: 1.49633
Epoch 183: | Loss: 1.49519
Epoch 184: | Loss: 1.49379
Epoch 185: | Loss: 1.49673
Epoch 186: | Loss: 1.49539
Epoch 187: | Loss: 1.49634
Epoch 188: | Loss: 1.49891
Epoch 189: | Loss: 1.49586
Epoch 190: | Loss: 1.49761
Epoch 191: | Loss: 1.49558
Epoch 192: | Loss: 1.49339
Epoch 193: | Loss: 1.49450
Epoch 194: | Loss: 1.49443
Epoch 195: | Loss: 1.49353
Epoch 196: | Loss: 1.49646
Epoch 197: | Loss: 1.49266
Epoch 198: | Loss: 1.49492
Epoch 199: | Loss: 1.49626
Accuracy: 0.3849626068376068
Epoch 000: | Loss: 1.86313
Epoch 001: | Loss: 1.61008
Epoch 002: | Loss: 1.53052
Epoch 003: | Loss: 1.52338
Epoch 004: | Loss: 1.51899
Epoch 005: | Loss: 1.51028
Epoch 006: | Loss: 1.51612
Epoch 007: | Loss: 1.51291
Epoch 008: | Loss: 1.51479
Epoch 009: | Loss: 1.51486
Epoch 010: | Loss: 1.51366
Epoch 011: | Loss: 1.51031
Epoch 012: | Loss: 1.50916
Epoch 013: | Loss: 1.51142
Epoch 014: | Loss: 1.50975
Epoch 015: | Loss: 1.50685
Epoch 016: | Loss: 1.50489
Epoch 017: | Loss: 1.50791
Epoch 018: | Loss: 1.50546
Epoch 019: | Loss: 1.50788
Epoch 020: | Loss: 1.50604
Epoch 021: | Loss: 1.50469
Epoch 022: | Loss: 1.50508
Epoch 023: | Loss: 1.50140
Epoch 024: | Loss: 1.50212
Epoch 025: | Loss: 1.49719
Epoch 026: | Loss: 1.49612
Epoch 027: | Loss: 1.49597
Epoch 028: | Loss: 1.49282
Epoch 029: | Loss: 1.49266
Epoch 030: | Loss: 1.48942
Epoch 031: | Loss: 1.49039
Epoch 032: | Loss: 1.48718
Epoch 033: | Loss: 1.48296
Epoch 034: | Loss: 1.48184
Epoch 035: | Loss: 1.47839
Epoch 036: | Loss: 1.47820
Epoch 037: | Loss: 1.47145
Epoch 038: | Loss: 1.46993
Epoch 039: | Loss: 1.46403
Epoch 040: | Loss: 1.45862
Epoch 041: | Loss: 1.45123
Epoch 042: | Loss: 1.44575
Epoch 043: | Loss: 1.44136
Epoch 044: | Loss: 1.42990
Epoch 045: | Loss: 1.41965
Epoch 046: | Loss: 1.40926
Epoch 047: | Loss: 1.39377
Epoch 048: | Loss: 1.38167
Epoch 049: | Loss: 1.36352
Epoch 050: | Loss: 1.34668
Epoch 051: | Loss: 1.33140
Epoch 052: | Loss: 1.30589
Epoch 053: | Loss: 1.28783
Epoch 054: | Loss: 1.26739
Epoch 055: | Loss: 1.25025
Epoch 056: | Loss: 1.22706
Epoch 057: | Loss: 1.20990
Epoch 058: | Loss: 1.19620
Epoch 059: | Loss: 1.17351
Epoch 060: | Loss: 1.16425
Epoch 061: | Loss: 1.15358
Epoch 062: | Loss: 1.13821
Epoch 063: | Loss: 1.12912
Epoch 064: | Loss: 1.11730
Epoch 065: | Loss: 1.10524
Epoch 066: | Loss: 1.09942
Epoch 067: | Loss: 1.08923
Epoch 068: | Loss: 1.08222
Epoch 069: | Loss: 1.08055
Epoch 070: | Loss: 1.06683
Epoch 071: | Loss: 1.06066
Epoch 072: | Loss: 1.05100
Epoch 073: | Loss: 1.05003
Epoch 074: | Loss: 1.03871
Epoch 075: | Loss: 1.03257
Epoch 076: | Loss: 1.02860
Epoch 077: | Loss: 1.01788
Epoch 078: | Loss: 1.01403
Epoch 079: | Loss: 1.01217
Epoch 080: | Loss: 1.00136
Epoch 081: | Loss: 0.99786
Epoch 082: | Loss: 0.98502
Epoch 083: | Loss: 0.98772
Epoch 084: | Loss: 0.97534
Epoch 085: | Loss: 0.97637
Epoch 086: | Loss: 0.96945
Epoch 087: | Loss: 0.96571
Epoch 088: | Loss: 0.96152
Epoch 089: | Loss: 0.95244
Epoch 090: | Loss: 0.95620
Epoch 091: | Loss: 0.94788
Epoch 092: | Loss: 0.94134
Epoch 093: | Loss: 0.94024
Epoch 094: | Loss: 0.93288
Epoch 095: | Loss: 0.93005
Epoch 096: | Loss: 0.91884
Epoch 097: | Loss: 0.92346
Epoch 098: | Loss: 0.91473
Epoch 099: | Loss: 0.91486
Epoch 100: | Loss: 0.91375
Epoch 101: | Loss: 0.90920
Epoch 102: | Loss: 0.90701
Epoch 103: | Loss: 0.90221
Epoch 104: | Loss: 0.89821
Epoch 105: | Loss: 0.90140
Epoch 106: | Loss: 0.89104
Epoch 107: | Loss: 0.88732
Epoch 108: | Loss: 0.88537
Epoch 109: | Loss: 0.88135
Epoch 110: | Loss: 0.88192
Epoch 111: | Loss: 0.88265
Epoch 112: | Loss: 0.86933
Epoch 113: | Loss: 0.87489
Epoch 114: | Loss: 0.87577
Epoch 115: | Loss: 0.87221
Epoch 116: | Loss: 0.86399
Epoch 117: | Loss: 0.87054
Epoch 118: | Loss: 0.86239
Epoch 119: | Loss: 0.86732
Epoch 120: | Loss: 0.86501
Epoch 121: | Loss: 0.85995
Epoch 122: | Loss: 0.85570
Epoch 123: | Loss: 0.86015
Epoch 124: | Loss: 0.85190
Epoch 125: | Loss: 0.85418
Epoch 126: | Loss: 0.85350
Epoch 127: | Loss: 0.84926
Epoch 128: | Loss: 0.85011
Epoch 129: | Loss: 0.84484
Epoch 130: | Loss: 0.84969
Epoch 131: | Loss: 0.84652
Epoch 132: | Loss: 0.85070
Epoch 133: | Loss: 0.84030
Epoch 134: | Loss: 0.84272
Epoch 135: | Loss: 0.84042
Epoch 136: | Loss: 0.83723
Epoch 137: | Loss: 0.84260
Epoch 138: | Loss: 0.84103
Epoch 139: | Loss: 0.84007
Epoch 140: | Loss: 0.83404
Epoch 141: | Loss: 0.84174
Epoch 142: | Loss: 0.83832
Epoch 143: | Loss: 0.83576
Epoch 144: | Loss: 0.83150
Epoch 145: | Loss: 0.83332
Epoch 146: | Loss: 0.83489
Epoch 147: | Loss: 0.83325
Epoch 148: | Loss: 0.83248
Epoch 149: | Loss: 0.83092
Epoch 150: | Loss: 0.82862
Epoch 151: | Loss: 0.83197
Epoch 152: | Loss: 0.83335
Epoch 153: | Loss: 0.83036
Epoch 154: | Loss: 0.82604
Epoch 155: | Loss: 0.82870
Epoch 156: | Loss: 0.82836
Epoch 157: | Loss: 0.82998
Epoch 158: | Loss: 0.82886
Epoch 159: | Loss: 0.82953
Epoch 160: | Loss: 0.82970
Epoch 161: | Loss: 0.83162
Epoch 162: | Loss: 0.82581
Epoch 163: | Loss: 0.82190
Epoch 164: | Loss: 0.82194
Epoch 165: | Loss: 0.82693
Epoch 166: | Loss: 0.82443
Epoch 167: | Loss: 0.82435
Epoch 168: | Loss: 0.82425
Epoch 169: | Loss: 0.82608
Epoch 170: | Loss: 0.82214
Epoch 171: | Loss: 0.82570
Epoch 172: | Loss: 0.82398
Epoch 173: | Loss: 0.82397
Epoch 174: | Loss: 0.82931
Epoch 175: | Loss: 0.82629
Epoch 176: | Loss: 0.82513
Epoch 177: | Loss: 0.82369
Epoch 178: | Loss: 0.82513
Epoch 179: | Loss: 0.82191
Epoch 180: | Loss: 0.82300
Epoch 181: | Loss: 0.82349
Epoch 182: | Loss: 0.82109
Epoch 183: | Loss: 0.82438
Epoch 184: | Loss: 0.82468
Epoch 185: | Loss: 0.82445
Epoch 186: | Loss: 0.81798
Epoch 187: | Loss: 0.82302
Epoch 188: | Loss: 0.82228
Epoch 189: | Loss: 0.81722
Epoch 190: | Loss: 0.82330
Epoch 191: | Loss: 0.82470
Epoch 192: | Loss: 0.82488
Epoch 193: | Loss: 0.82632
Epoch 194: | Loss: 0.82072
Epoch 195: | Loss: 0.82134
Epoch 196: | Loss: 0.82031
Epoch 197: | Loss: 0.81950
Epoch 198: | Loss: 0.82592
Epoch 199: | Loss: 0.82309
Accuracy: 0.11110309829059828
Epoch 000: | Loss: 1.41930
Epoch 001: | Loss: 0.97232
Epoch 002: | Loss: 0.78976
Epoch 003: | Loss: 0.71231
Epoch 004: | Loss: 0.68434
Epoch 005: | Loss: 0.65974
Epoch 006: | Loss: 0.63787
Epoch 007: | Loss: 0.62525
Epoch 008: | Loss: 0.60883
Epoch 009: | Loss: 0.59550
Epoch 010: | Loss: 0.57863
Epoch 011: | Loss: 0.57211
Epoch 012: | Loss: 0.55357
Epoch 013: | Loss: 0.54670
Epoch 014: | Loss: 0.53850
Epoch 015: | Loss: 0.53186
Epoch 016: | Loss: 0.51664
Epoch 017: | Loss: 0.51181
Epoch 018: | Loss: 0.50778
Epoch 019: | Loss: 0.49030
Epoch 020: | Loss: 0.48602
Epoch 021: | Loss: 0.47519
Epoch 022: | Loss: 0.46963
Epoch 023: | Loss: 0.46261
Epoch 024: | Loss: 0.44975
Epoch 025: | Loss: 0.44854
Epoch 026: | Loss: 0.43949
Epoch 027: | Loss: 0.42820
Epoch 028: | Loss: 0.42406
Epoch 029: | Loss: 0.41702
Epoch 030: | Loss: 0.41564
Epoch 031: | Loss: 0.40569
Epoch 032: | Loss: 0.39949
Epoch 033: | Loss: 0.39709
Epoch 034: | Loss: 0.39032
Epoch 035: | Loss: 0.38300
Epoch 036: | Loss: 0.37954
Epoch 037: | Loss: 0.37323
Epoch 038: | Loss: 0.36260
Epoch 039: | Loss: 0.36467
Epoch 040: | Loss: 0.35433
Epoch 041: | Loss: 0.35215
Epoch 042: | Loss: 0.35183
Epoch 043: | Loss: 0.34367
Epoch 044: | Loss: 0.34336
Epoch 045: | Loss: 0.33295
Epoch 046: | Loss: 0.32851
Epoch 047: | Loss: 0.32638
Epoch 048: | Loss: 0.32375
Epoch 049: | Loss: 0.31923
Epoch 050: | Loss: 0.32091
Epoch 051: | Loss: 0.31776
Epoch 052: | Loss: 0.30729
Epoch 053: | Loss: 0.30859
Epoch 054: | Loss: 0.30838
Epoch 055: | Loss: 0.30703
Epoch 056: | Loss: 0.29706
Epoch 057: | Loss: 0.29689
Epoch 058: | Loss: 0.28958
Epoch 059: | Loss: 0.29652
Epoch 060: | Loss: 0.28655
Epoch 061: | Loss: 0.29230
Epoch 062: | Loss: 0.28249
Epoch 063: | Loss: 0.27772
Epoch 064: | Loss: 0.27404
Epoch 065: | Loss: 0.27547
Epoch 066: | Loss: 0.27405
Epoch 067: | Loss: 0.27957
Epoch 068: | Loss: 0.26992
Epoch 069: | Loss: 0.26362
Epoch 070: | Loss: 0.26840
Epoch 071: | Loss: 0.26179
Epoch 072: | Loss: 0.26242
Epoch 073: | Loss: 0.25775
Epoch 074: | Loss: 0.26014
Epoch 075: | Loss: 0.25687
Epoch 076: | Loss: 0.25310
Epoch 077: | Loss: 0.25151
Epoch 078: | Loss: 0.25490
Epoch 079: | Loss: 0.24616
Epoch 080: | Loss: 0.24378
Epoch 081: | Loss: 0.24441
Epoch 082: | Loss: 0.24288
Epoch 083: | Loss: 0.24065
Epoch 084: | Loss: 0.23966
Epoch 085: | Loss: 0.23761
Epoch 086: | Loss: 0.24031
Epoch 087: | Loss: 0.23730
Epoch 088: | Loss: 0.23411
Epoch 089: | Loss: 0.23021
Epoch 090: | Loss: 0.22951
Epoch 091: | Loss: 0.23112
Epoch 092: | Loss: 0.23386
Epoch 093: | Loss: 0.22919
Epoch 094: | Loss: 0.22856
Epoch 095: | Loss: 0.22575
Epoch 096: | Loss: 0.22307
Epoch 097: | Loss: 0.22207
Epoch 098: | Loss: 0.21923
Epoch 099: | Loss: 0.22263
Epoch 100: | Loss: 0.22058
Epoch 101: | Loss: 0.21940
Epoch 102: | Loss: 0.21783
Epoch 103: | Loss: 0.21867
Epoch 104: | Loss: 0.21819
Epoch 105: | Loss: 0.21441
Epoch 106: | Loss: 0.21535
Epoch 107: | Loss: 0.21160
Epoch 108: | Loss: 0.20842
Epoch 109: | Loss: 0.21088
Epoch 110: | Loss: 0.20834
Epoch 111: | Loss: 0.21190
Epoch 112: | Loss: 0.20694
Epoch 113: | Loss: 0.20931
Epoch 114: | Loss: 0.21307
Epoch 115: | Loss: 0.20869
Epoch 116: | Loss: 0.21118
Epoch 117: | Loss: 0.20996
Epoch 118: | Loss: 0.20451
Epoch 119: | Loss: 0.20629
Epoch 120: | Loss: 0.20190
Epoch 121: | Loss: 0.20360
Epoch 122: | Loss: 0.20631
Epoch 123: | Loss: 0.20211
Epoch 124: | Loss: 0.20333
Epoch 125: | Loss: 0.20230
Epoch 126: | Loss: 0.20421
Epoch 127: | Loss: 0.20359
Epoch 128: | Loss: 0.20245
Epoch 129: | Loss: 0.20135
Epoch 130: | Loss: 0.20066
Epoch 131: | Loss: 0.20104
Epoch 132: | Loss: 0.20341
Epoch 133: | Loss: 0.19939
Epoch 134: | Loss: 0.20547
Epoch 135: | Loss: 0.20429
Epoch 136: | Loss: 0.19936
Epoch 137: | Loss: 0.19821
Epoch 138: | Loss: 0.19754
Epoch 139: | Loss: 0.20243
Epoch 140: | Loss: 0.20155
Epoch 141: | Loss: 0.19843
Epoch 142: | Loss: 0.19607
Epoch 143: | Loss: 0.20157
Epoch 144: | Loss: 0.19735
Epoch 145: | Loss: 0.20165
Epoch 146: | Loss: 0.19929
Epoch 147: | Loss: 0.20238
Epoch 148: | Loss: 0.20094
Epoch 149: | Loss: 0.19949
Epoch 150: | Loss: 0.19700
Epoch 151: | Loss: 0.20175
Epoch 152: | Loss: 0.19945
Epoch 153: | Loss: 0.19874
Epoch 154: | Loss: 0.19784
Epoch 155: | Loss: 0.19527
Epoch 156: | Loss: 0.20070
Epoch 157: | Loss: 0.19892
Epoch 158: | Loss: 0.20059
Epoch 159: | Loss: 0.19556
Epoch 160: | Loss: 0.19534
Epoch 161: | Loss: 0.19869
Epoch 162: | Loss: 0.20168
Epoch 163: | Loss: 0.20381
Epoch 164: | Loss: 0.19842
Epoch 165: | Loss: 0.19829
Epoch 166: | Loss: 0.20387
Epoch 167: | Loss: 0.19840
Epoch 168: | Loss: 0.19993
Epoch 169: | Loss: 0.19770
Epoch 170: | Loss: 0.20018
Epoch 171: | Loss: 0.20107
Epoch 172: | Loss: 0.19998
Epoch 173: | Loss: 0.20020
Epoch 174: | Loss: 0.19731
Epoch 175: | Loss: 0.19896
Epoch 176: | Loss: 0.20124
Epoch 177: | Loss: 0.19709
Epoch 178: | Loss: 0.19755
Epoch 179: | Loss: 0.19767
Epoch 180: | Loss: 0.19796
Epoch 181: | Loss: 0.20365
Epoch 182: | Loss: 0.19635
Epoch 183: | Loss: 0.19784
Epoch 184: | Loss: 0.19519
Epoch 185: | Loss: 0.19933
Epoch 186: | Loss: 0.20233
Epoch 187: | Loss: 0.19570
Epoch 188: | Loss: 0.19690
Epoch 189: | Loss: 0.19597
Epoch 190: | Loss: 0.19641
Epoch 191: | Loss: 0.19386
Epoch 192: | Loss: 0.19955
Epoch 193: | Loss: 0.19727
Epoch 194: | Loss: 0.19763
Epoch 195: | Loss: 0.19766
Epoch 196: | Loss: 0.19645
Epoch 197: | Loss: 0.18858
Epoch 198: | Loss: 0.19281
Epoch 199: | Loss: 0.19142
Accuracy: 0.9136752136752136
Epoch 000: | Loss: 1.48850
Epoch 001: | Loss: 1.07971
Epoch 002: | Loss: 0.83293
Epoch 003: | Loss: 0.74273
Epoch 004: | Loss: 0.66817
Epoch 005: | Loss: 0.63153
Epoch 006: | Loss: 0.61018
Epoch 007: | Loss: 0.58920
Epoch 008: | Loss: 0.57834
Epoch 009: | Loss: 0.55179
Epoch 010: | Loss: 0.53653
Epoch 011: | Loss: 0.52375
Epoch 012: | Loss: 0.50936
Epoch 013: | Loss: 0.49619
Epoch 014: | Loss: 0.49302
Epoch 015: | Loss: 0.48164
Epoch 016: | Loss: 0.47456
Epoch 017: | Loss: 0.46027
Epoch 018: | Loss: 0.45527
Epoch 019: | Loss: 0.44445
Epoch 020: | Loss: 0.44161
Epoch 021: | Loss: 0.42204
Epoch 022: | Loss: 0.42316
Epoch 023: | Loss: 0.41523
Epoch 024: | Loss: 0.40696
Epoch 025: | Loss: 0.40408
Epoch 026: | Loss: 0.39231
Epoch 027: | Loss: 0.38729
Epoch 028: | Loss: 0.37355
Epoch 029: | Loss: 0.36886
Epoch 030: | Loss: 0.36463
Epoch 031: | Loss: 0.36472
Epoch 032: | Loss: 0.35765
Epoch 033: | Loss: 0.35139
Epoch 034: | Loss: 0.33995
Epoch 035: | Loss: 0.33945
Epoch 036: | Loss: 0.33739
Epoch 037: | Loss: 0.33587
Epoch 038: | Loss: 0.32967
Epoch 039: | Loss: 0.32500
Epoch 040: | Loss: 0.32055
Epoch 041: | Loss: 0.31253
Epoch 042: | Loss: 0.31291
Epoch 043: | Loss: 0.30108
Epoch 044: | Loss: 0.30193
Epoch 045: | Loss: 0.29697
Epoch 046: | Loss: 0.29182
Epoch 047: | Loss: 0.29132
Epoch 048: | Loss: 0.28239
Epoch 049: | Loss: 0.28013
Epoch 050: | Loss: 0.28721
Epoch 051: | Loss: 0.27712
Epoch 052: | Loss: 0.27948
Epoch 053: | Loss: 0.27062
Epoch 054: | Loss: 0.26990
Epoch 055: | Loss: 0.26409
Epoch 056: | Loss: 0.26121
Epoch 057: | Loss: 0.26024
Epoch 058: | Loss: 0.25088
Epoch 059: | Loss: 0.25462
Epoch 060: | Loss: 0.25223
Epoch 061: | Loss: 0.24655
Epoch 062: | Loss: 0.25369
Epoch 063: | Loss: 0.24512
Epoch 064: | Loss: 0.23703
Epoch 065: | Loss: 0.23504
Epoch 066: | Loss: 0.23444
Epoch 067: | Loss: 0.23666
Epoch 068: | Loss: 0.22964
Epoch 069: | Loss: 0.22721
Epoch 070: | Loss: 0.22546
Epoch 071: | Loss: 0.22433
Epoch 072: | Loss: 0.22220
Epoch 073: | Loss: 0.22334
Epoch 074: | Loss: 0.22397
Epoch 075: | Loss: 0.22415
Epoch 076: | Loss: 0.21603
Epoch 077: | Loss: 0.20934
Epoch 078: | Loss: 0.21097
Epoch 079: | Loss: 0.20866
Epoch 080: | Loss: 0.21087
Epoch 081: | Loss: 0.20865
Epoch 082: | Loss: 0.20299
Epoch 083: | Loss: 0.20689
Epoch 084: | Loss: 0.20696
Epoch 085: | Loss: 0.19630
Epoch 086: | Loss: 0.20061
Epoch 087: | Loss: 0.19711
Epoch 088: | Loss: 0.19721
Epoch 089: | Loss: 0.19650
Epoch 090: | Loss: 0.19518
Epoch 091: | Loss: 0.19395
Epoch 092: | Loss: 0.19383
Epoch 093: | Loss: 0.19155
Epoch 094: | Loss: 0.19213
Epoch 095: | Loss: 0.18783
Epoch 096: | Loss: 0.18737
Epoch 097: | Loss: 0.18618
Epoch 098: | Loss: 0.18646
Epoch 099: | Loss: 0.18882
Epoch 100: | Loss: 0.18564
Epoch 101: | Loss: 0.18854
Epoch 102: | Loss: 0.18433
Epoch 103: | Loss: 0.18385
Epoch 104: | Loss: 0.18014
Epoch 105: | Loss: 0.18090
Epoch 106: | Loss: 0.17760
Epoch 107: | Loss: 0.17806
Epoch 108: | Loss: 0.17564
Epoch 109: | Loss: 0.17646
Epoch 110: | Loss: 0.17047
Epoch 111: | Loss: 0.17496
Epoch 112: | Loss: 0.17533
Epoch 113: | Loss: 0.16882
Epoch 114: | Loss: 0.16668
Epoch 115: | Loss: 0.17165
Epoch 116: | Loss: 0.17226
Epoch 117: | Loss: 0.17395
Epoch 118: | Loss: 0.16982
Epoch 119: | Loss: 0.16930
Epoch 120: | Loss: 0.17255
Epoch 121: | Loss: 0.17067
Epoch 122: | Loss: 0.16801
Epoch 123: | Loss: 0.16701
Epoch 124: | Loss: 0.16614
Epoch 125: | Loss: 0.16493
Epoch 126: | Loss: 0.16866
Epoch 127: | Loss: 0.16168
Epoch 128: | Loss: 0.16648
Epoch 129: | Loss: 0.16750
Epoch 130: | Loss: 0.16470
Epoch 131: | Loss: 0.16472
Epoch 132: | Loss: 0.16366
Epoch 133: | Loss: 0.16585
Epoch 134: | Loss: 0.16681
Epoch 135: | Loss: 0.16334
Epoch 136: | Loss: 0.16313
Epoch 137: | Loss: 0.16811
Epoch 138: | Loss: 0.16575
Epoch 139: | Loss: 0.16159
Epoch 140: | Loss: 0.16262
Epoch 141: | Loss: 0.16425
Epoch 142: | Loss: 0.15878
Epoch 143: | Loss: 0.16674
Epoch 144: | Loss: 0.16203
Epoch 145: | Loss: 0.16303
Epoch 146: | Loss: 0.16270
Epoch 147: | Loss: 0.16282
Epoch 148: | Loss: 0.16152
Epoch 149: | Loss: 0.16451
Epoch 150: | Loss: 0.16210
Epoch 151: | Loss: 0.16011
Epoch 152: | Loss: 0.16301
Epoch 153: | Loss: 0.15901
Epoch 154: | Loss: 0.16341
Epoch 155: | Loss: 0.16219
Epoch 156: | Loss: 0.16132
Epoch 157: | Loss: 0.16338
Epoch 158: | Loss: 0.16916
Epoch 159: | Loss: 0.16246
Epoch 160: | Loss: 0.16045
Epoch 161: | Loss: 0.16206
Epoch 162: | Loss: 0.16351
Epoch 163: | Loss: 0.16558
Epoch 164: | Loss: 0.16222
Epoch 165: | Loss: 0.16139
Epoch 166: | Loss: 0.16612
Epoch 167: | Loss: 0.16450
Epoch 168: | Loss: 0.16025
Epoch 169: | Loss: 0.16241
Epoch 170: | Loss: 0.16417
Epoch 171: | Loss: 0.16537
Epoch 172: | Loss: 0.16218
Epoch 173: | Loss: 0.16072
Epoch 174: | Loss: 0.16256
Epoch 175: | Loss: 0.15928
Epoch 176: | Loss: 0.16174
Epoch 177: | Loss: 0.16760
Epoch 178: | Loss: 0.15752
Epoch 179: | Loss: 0.16344
Epoch 180: | Loss: 0.16549
Epoch 181: | Loss: 0.16117
Epoch 182: | Loss: 0.16179
Epoch 183: | Loss: 0.16601
Epoch 184: | Loss: 0.16208
Epoch 185: | Loss: 0.16564
Epoch 186: | Loss: 0.15917
Epoch 187: | Loss: 0.16143
Epoch 188: | Loss: 0.16090
Epoch 189: | Loss: 0.15966
Epoch 190: | Loss: 0.16696
Epoch 191: | Loss: 0.16360
Epoch 192: | Loss: 0.16412
Epoch 193: | Loss: 0.16200
Epoch 194: | Loss: 0.16410
Epoch 195: | Loss: 0.16295
Epoch 196: | Loss: 0.16415
Epoch 197: | Loss: 0.16520
Epoch 198: | Loss: 0.16191
Epoch 199: | Loss: 0.16354
Accuracy: 0.9330902777777778
Epoch 000: | Loss: 1.50290
Epoch 001: | Loss: 1.03911
Epoch 002: | Loss: 0.78343
Epoch 003: | Loss: 0.73681
Epoch 004: | Loss: 0.70404
Epoch 005: | Loss: 0.67596
Epoch 006: | Loss: 0.65761
Epoch 007: | Loss: 0.63874
Epoch 008: | Loss: 0.63533
Epoch 009: | Loss: 0.62896
Epoch 010: | Loss: 0.61172
Epoch 011: | Loss: 0.59849
Epoch 012: | Loss: 0.59436
Epoch 013: | Loss: 0.58688
Epoch 014: | Loss: 0.57249
Epoch 015: | Loss: 0.57395
Epoch 016: | Loss: 0.56580
Epoch 017: | Loss: 0.56179
Epoch 018: | Loss: 0.55393
Epoch 019: | Loss: 0.55212
Epoch 020: | Loss: 0.54712
Epoch 021: | Loss: 0.54502
Epoch 022: | Loss: 0.53218
Epoch 023: | Loss: 0.52881
Epoch 024: | Loss: 0.52406
Epoch 025: | Loss: 0.52001
Epoch 026: | Loss: 0.51616
Epoch 027: | Loss: 0.50510
Epoch 028: | Loss: 0.49294
Epoch 029: | Loss: 0.48754
Epoch 030: | Loss: 0.47824
Epoch 031: | Loss: 0.47170
Epoch 032: | Loss: 0.46424
Epoch 033: | Loss: 0.45939
Epoch 034: | Loss: 0.45219
Epoch 035: | Loss: 0.44433
Epoch 036: | Loss: 0.43894
Epoch 037: | Loss: 0.43043
Epoch 038: | Loss: 0.43193
Epoch 039: | Loss: 0.42145
Epoch 040: | Loss: 0.41995
Epoch 041: | Loss: 0.41971
Epoch 042: | Loss: 0.40744
Epoch 043: | Loss: 0.40823
Epoch 044: | Loss: 0.40162
Epoch 045: | Loss: 0.40182
Epoch 046: | Loss: 0.39442
Epoch 047: | Loss: 0.39413
Epoch 048: | Loss: 0.38635
Epoch 049: | Loss: 0.38763
Epoch 050: | Loss: 0.38364
Epoch 051: | Loss: 0.37943
Epoch 052: | Loss: 0.37151
Epoch 053: | Loss: 0.36796
Epoch 054: | Loss: 0.37059
Epoch 055: | Loss: 0.36343
Epoch 056: | Loss: 0.36464
Epoch 057: | Loss: 0.36194
Epoch 058: | Loss: 0.35650
Epoch 059: | Loss: 0.35544
Epoch 060: | Loss: 0.35108
Epoch 061: | Loss: 0.34497
Epoch 062: | Loss: 0.34400
Epoch 063: | Loss: 0.34310
Epoch 064: | Loss: 0.33705
Epoch 065: | Loss: 0.34121
Epoch 066: | Loss: 0.33630
Epoch 067: | Loss: 0.33766
Epoch 068: | Loss: 0.32648
Epoch 069: | Loss: 0.32445
Epoch 070: | Loss: 0.32280
Epoch 071: | Loss: 0.32549
Epoch 072: | Loss: 0.32127
Epoch 073: | Loss: 0.31661
Epoch 074: | Loss: 0.31497
Epoch 075: | Loss: 0.31760
Epoch 076: | Loss: 0.30767
Epoch 077: | Loss: 0.31270
Epoch 078: | Loss: 0.30554
Epoch 079: | Loss: 0.30458
Epoch 080: | Loss: 0.30241
Epoch 081: | Loss: 0.29840
Epoch 082: | Loss: 0.29852
Epoch 083: | Loss: 0.29801
Epoch 084: | Loss: 0.29116
Epoch 085: | Loss: 0.29558
Epoch 086: | Loss: 0.29525
Epoch 087: | Loss: 0.29251
Epoch 088: | Loss: 0.28898
Epoch 089: | Loss: 0.29081
Epoch 090: | Loss: 0.28280
Epoch 091: | Loss: 0.28684
Epoch 092: | Loss: 0.28700
Epoch 093: | Loss: 0.28114
Epoch 094: | Loss: 0.28737
Epoch 095: | Loss: 0.28140
Epoch 096: | Loss: 0.28152
Epoch 097: | Loss: 0.28189
Epoch 098: | Loss: 0.28026
Epoch 099: | Loss: 0.27893
Epoch 100: | Loss: 0.27317
Epoch 101: | Loss: 0.27788
Epoch 102: | Loss: 0.27404
Epoch 103: | Loss: 0.27397
Epoch 104: | Loss: 0.26869
Epoch 105: | Loss: 0.26856
Epoch 106: | Loss: 0.27472
Epoch 107: | Loss: 0.27228
Epoch 108: | Loss: 0.26857
Epoch 109: | Loss: 0.26466
Epoch 110: | Loss: 0.26789
Epoch 111: | Loss: 0.26791
Epoch 112: | Loss: 0.26798
Epoch 113: | Loss: 0.26649
Epoch 114: | Loss: 0.26129
Epoch 115: | Loss: 0.26249
Epoch 116: | Loss: 0.25950
Epoch 117: | Loss: 0.26306
Epoch 118: | Loss: 0.26322
Epoch 119: | Loss: 0.26208
Epoch 120: | Loss: 0.26119
Epoch 121: | Loss: 0.26559
Epoch 122: | Loss: 0.25950
Epoch 123: | Loss: 0.26161
Epoch 124: | Loss: 0.26132
Epoch 125: | Loss: 0.25720
Epoch 126: | Loss: 0.26277
Epoch 127: | Loss: 0.26611
Epoch 128: | Loss: 0.25465
Epoch 129: | Loss: 0.25489
Epoch 130: | Loss: 0.25734
Epoch 131: | Loss: 0.25716
Epoch 132: | Loss: 0.25509
Epoch 133: | Loss: 0.25721
Epoch 134: | Loss: 0.26016
Epoch 135: | Loss: 0.25280
Epoch 136: | Loss: 0.25578
Epoch 137: | Loss: 0.25936
Epoch 138: | Loss: 0.25601
Epoch 139: | Loss: 0.25303
Epoch 140: | Loss: 0.25316
Epoch 141: | Loss: 0.25536
Epoch 142: | Loss: 0.25407
Epoch 143: | Loss: 0.25493
Epoch 144: | Loss: 0.25511
Epoch 145: | Loss: 0.25498
Epoch 146: | Loss: 0.25257
Epoch 147: | Loss: 0.25336
Epoch 148: | Loss: 0.25335
Epoch 149: | Loss: 0.25771
Epoch 150: | Loss: 0.25523
Epoch 151: | Loss: 0.25759
Epoch 152: | Loss: 0.25296
Epoch 153: | Loss: 0.25531
Epoch 154: | Loss: 0.25370
Epoch 155: | Loss: 0.25331
Epoch 156: | Loss: 0.25833
Epoch 157: | Loss: 0.25685
Epoch 158: | Loss: 0.25239
Epoch 159: | Loss: 0.25940
Epoch 160: | Loss: 0.25290
Epoch 161: | Loss: 0.25354
Epoch 162: | Loss: 0.25655
Epoch 163: | Loss: 0.25590
Epoch 164: | Loss: 0.25403
Epoch 165: | Loss: 0.25715
Epoch 166: | Loss: 0.25567
Epoch 167: | Loss: 0.25403
Epoch 168: | Loss: 0.25276
Epoch 169: | Loss: 0.25449
Epoch 170: | Loss: 0.25800
Epoch 171: | Loss: 0.25326
Epoch 172: | Loss: 0.26027
Epoch 173: | Loss: 0.25245
Epoch 174: | Loss: 0.25321
Epoch 175: | Loss: 0.25367
Epoch 176: | Loss: 0.25476
Epoch 177: | Loss: 0.25606
Epoch 178: | Loss: 0.25637
early stopping at epoch 179 with loss 0.25615
Accuracy: 0.9050213675213675
Epoch 000: | Loss: 1.43624
Epoch 001: | Loss: 0.94475
Epoch 002: | Loss: 0.79004
Epoch 003: | Loss: 0.71862
Epoch 004: | Loss: 0.68542
Epoch 005: | Loss: 0.64808
Epoch 006: | Loss: 0.62784
Epoch 007: | Loss: 0.61280
Epoch 008: | Loss: 0.60326
Epoch 009: | Loss: 0.58549
Epoch 010: | Loss: 0.56852
Epoch 011: | Loss: 0.55583
Epoch 012: | Loss: 0.55505
Epoch 013: | Loss: 0.54354
Epoch 014: | Loss: 0.53608
Epoch 015: | Loss: 0.52720
Epoch 016: | Loss: 0.51370
Epoch 017: | Loss: 0.51161
Epoch 018: | Loss: 0.49753
Epoch 019: | Loss: 0.49775
Epoch 020: | Loss: 0.48547
Epoch 021: | Loss: 0.47895
Epoch 022: | Loss: 0.47271
Epoch 023: | Loss: 0.46638
Epoch 024: | Loss: 0.46278
Epoch 025: | Loss: 0.45889
Epoch 026: | Loss: 0.45362
Epoch 027: | Loss: 0.44123
Epoch 028: | Loss: 0.43827
Epoch 029: | Loss: 0.43037
Epoch 030: | Loss: 0.42405
Epoch 031: | Loss: 0.41831
Epoch 032: | Loss: 0.41562
Epoch 033: | Loss: 0.40784
Epoch 034: | Loss: 0.40687
Epoch 035: | Loss: 0.40494
Epoch 036: | Loss: 0.39925
Epoch 037: | Loss: 0.39584
Epoch 038: | Loss: 0.39168
Epoch 039: | Loss: 0.38585
Epoch 040: | Loss: 0.38046
Epoch 041: | Loss: 0.38061
Epoch 042: | Loss: 0.37187
Epoch 043: | Loss: 0.37106
Epoch 044: | Loss: 0.36687
Epoch 045: | Loss: 0.36172
Epoch 046: | Loss: 0.35324
Epoch 047: | Loss: 0.35643
Epoch 048: | Loss: 0.34952
Epoch 049: | Loss: 0.34918
Epoch 050: | Loss: 0.34542
Epoch 051: | Loss: 0.33658
Epoch 052: | Loss: 0.33516
Epoch 053: | Loss: 0.33373
Epoch 054: | Loss: 0.32834
Epoch 055: | Loss: 0.32503
Epoch 056: | Loss: 0.32370
Epoch 057: | Loss: 0.31884
Epoch 058: | Loss: 0.31617
Epoch 059: | Loss: 0.31208
Epoch 060: | Loss: 0.30425
Epoch 061: | Loss: 0.30034
Epoch 062: | Loss: 0.30319
Epoch 063: | Loss: 0.29803
Epoch 064: | Loss: 0.28951
Epoch 065: | Loss: 0.28567
Epoch 066: | Loss: 0.28276
Epoch 067: | Loss: 0.28238
Epoch 068: | Loss: 0.27385
Epoch 069: | Loss: 0.27353
Epoch 070: | Loss: 0.27145
Epoch 071: | Loss: 0.26924
Epoch 072: | Loss: 0.26969
Epoch 073: | Loss: 0.26607
Epoch 074: | Loss: 0.25748
Epoch 075: | Loss: 0.26246
Epoch 076: | Loss: 0.25694
Epoch 077: | Loss: 0.25116
Epoch 078: | Loss: 0.25170
Epoch 079: | Loss: 0.24350
Epoch 080: | Loss: 0.24621
Epoch 081: | Loss: 0.23927
Epoch 082: | Loss: 0.23911
Epoch 083: | Loss: 0.24013
Epoch 084: | Loss: 0.23982
Epoch 085: | Loss: 0.23368
Epoch 086: | Loss: 0.23102
Epoch 087: | Loss: 0.22908
Epoch 088: | Loss: 0.22707
Epoch 089: | Loss: 0.22352
Epoch 090: | Loss: 0.22591
Epoch 091: | Loss: 0.22109
Epoch 092: | Loss: 0.22060
Epoch 093: | Loss: 0.22257
Epoch 094: | Loss: 0.22223
Epoch 095: | Loss: 0.21692
Epoch 096: | Loss: 0.21025
Epoch 097: | Loss: 0.20634
Epoch 098: | Loss: 0.20846
Epoch 099: | Loss: 0.20638
Epoch 100: | Loss: 0.20803
Epoch 101: | Loss: 0.20384
Epoch 102: | Loss: 0.19996
Epoch 103: | Loss: 0.20312
Epoch 104: | Loss: 0.20201
Epoch 105: | Loss: 0.19422
Epoch 106: | Loss: 0.19854
Epoch 107: | Loss: 0.19887
Epoch 108: | Loss: 0.19957
Epoch 109: | Loss: 0.19906
Epoch 110: | Loss: 0.19510
Epoch 111: | Loss: 0.19107
Epoch 112: | Loss: 0.19197
Epoch 113: | Loss: 0.19297
Epoch 114: | Loss: 0.18933
Epoch 115: | Loss: 0.18465
Epoch 116: | Loss: 0.18883
Epoch 117: | Loss: 0.19006
Epoch 118: | Loss: 0.18313
Epoch 119: | Loss: 0.18506
Epoch 120: | Loss: 0.18366
Epoch 121: | Loss: 0.18596
Epoch 122: | Loss: 0.18366
Epoch 123: | Loss: 0.18423
Epoch 124: | Loss: 0.18020
Epoch 125: | Loss: 0.18204
Epoch 126: | Loss: 0.17539
Epoch 127: | Loss: 0.17917
Epoch 128: | Loss: 0.18116
Epoch 129: | Loss: 0.17818
Epoch 130: | Loss: 0.17811
Epoch 131: | Loss: 0.17910
Epoch 132: | Loss: 0.17855
Epoch 133: | Loss: 0.17837
Epoch 134: | Loss: 0.17593
Epoch 135: | Loss: 0.17465
Epoch 136: | Loss: 0.17948
Epoch 137: | Loss: 0.17702
Epoch 138: | Loss: 0.17516
Epoch 139: | Loss: 0.17583
Epoch 140: | Loss: 0.17561
Epoch 141: | Loss: 0.18024
Epoch 142: | Loss: 0.17868
Epoch 143: | Loss: 0.17528
Epoch 144: | Loss: 0.18095
Epoch 145: | Loss: 0.17871
Epoch 146: | Loss: 0.17440
Epoch 147: | Loss: 0.17602
Epoch 148: | Loss: 0.17515
Epoch 149: | Loss: 0.17770
Epoch 150: | Loss: 0.17373
Epoch 151: | Loss: 0.17873
Epoch 152: | Loss: 0.17655
Epoch 153: | Loss: 0.17479
Epoch 154: | Loss: 0.17740
Epoch 155: | Loss: 0.18039
Epoch 156: | Loss: 0.17616
Epoch 157: | Loss: 0.17739
Epoch 158: | Loss: 0.18040
Epoch 159: | Loss: 0.17485
Epoch 160: | Loss: 0.17682
Epoch 161: | Loss: 0.17684
Epoch 162: | Loss: 0.17438
Epoch 163: | Loss: 0.17431
Epoch 164: | Loss: 0.18142
Epoch 165: | Loss: 0.17771
Epoch 166: | Loss: 0.17475
Epoch 167: | Loss: 0.17636
Epoch 168: | Loss: 0.17397
Epoch 169: | Loss: 0.17615
Epoch 170: | Loss: 0.17444
Epoch 171: | Loss: 0.17324
Epoch 172: | Loss: 0.17095
Epoch 173: | Loss: 0.17493
Epoch 174: | Loss: 0.17105
Epoch 175: | Loss: 0.17764
Epoch 176: | Loss: 0.17189
Epoch 177: | Loss: 0.17285
Epoch 178: | Loss: 0.17047
Epoch 179: | Loss: 0.17213
Epoch 180: | Loss: 0.17189
Epoch 181: | Loss: 0.17160
Epoch 182: | Loss: 0.17170
Epoch 183: | Loss: 0.17455
Epoch 184: | Loss: 0.16846
Epoch 185: | Loss: 0.17367
Epoch 186: | Loss: 0.17169
Epoch 187: | Loss: 0.17146
Epoch 188: | Loss: 0.17037
Epoch 189: | Loss: 0.17084
Epoch 190: | Loss: 0.16689
Epoch 191: | Loss: 0.16834
Epoch 192: | Loss: 0.16865
Epoch 193: | Loss: 0.16883
Epoch 194: | Loss: 0.16648
Epoch 195: | Loss: 0.16927
Epoch 196: | Loss: 0.16176
Epoch 197: | Loss: 0.16519
Epoch 198: | Loss: 0.16604
Epoch 199: | Loss: 0.16369
Accuracy: 0.8996127136752137
Epoch 000: | Loss: 1.42744
Epoch 001: | Loss: 0.97696
Epoch 002: | Loss: 0.70807
Epoch 003: | Loss: 0.64578
Epoch 004: | Loss: 0.58597
Epoch 005: | Loss: 0.57589
Epoch 006: | Loss: 0.54491
Epoch 007: | Loss: 0.54392
Epoch 008: | Loss: 0.50673
Epoch 009: | Loss: 0.49650
Epoch 010: | Loss: 0.47921
Epoch 011: | Loss: 0.46222
Epoch 012: | Loss: 0.45015
Epoch 013: | Loss: 0.43938
Epoch 014: | Loss: 0.40093
Epoch 015: | Loss: 0.39799
Epoch 016: | Loss: 0.39646
Epoch 017: | Loss: 0.37814
Epoch 018: | Loss: 0.36148
Epoch 019: | Loss: 0.34937
Epoch 020: | Loss: 0.33150
Epoch 021: | Loss: 0.31088
Epoch 022: | Loss: 0.30505
Epoch 023: | Loss: 0.29350
Epoch 024: | Loss: 0.27778
Epoch 025: | Loss: 0.27502
Epoch 026: | Loss: 0.26751
Epoch 027: | Loss: 0.24839
Epoch 028: | Loss: 0.23024
Epoch 029: | Loss: 0.21600
Epoch 030: | Loss: 0.21786
Epoch 031: | Loss: 0.20303
Epoch 032: | Loss: 0.19897
Epoch 033: | Loss: 0.17591
Epoch 034: | Loss: 0.17160
Epoch 035: | Loss: 0.16056
Epoch 036: | Loss: 0.15518
Epoch 037: | Loss: 0.13571
Epoch 038: | Loss: 0.13845
Epoch 039: | Loss: 0.12243
Epoch 040: | Loss: 0.12025
Epoch 041: | Loss: 0.11680
Epoch 042: | Loss: 0.10560
Epoch 043: | Loss: 0.09667
Epoch 044: | Loss: 0.09073
Epoch 045: | Loss: 0.08741
Epoch 046: | Loss: 0.08386
Epoch 047: | Loss: 0.07798
Epoch 048: | Loss: 0.07754
Epoch 049: | Loss: 0.07387
Epoch 050: | Loss: 0.07165
Epoch 051: | Loss: 0.06998
Epoch 052: | Loss: 0.07020
Epoch 053: | Loss: 0.06983
Epoch 054: | Loss: 0.06664
Epoch 055: | Loss: 0.07260
Epoch 056: | Loss: 0.07176
Epoch 057: | Loss: 0.06957
Epoch 058: | Loss: 0.06786
Epoch 059: | Loss: 0.07600
Epoch 060: | Loss: 0.08718
Epoch 061: | Loss: 0.07778
Epoch 062: | Loss: 0.08303
Epoch 063: | Loss: 0.09517
Epoch 064: | Loss: 0.08298
Epoch 065: | Loss: 0.09299
Epoch 066: | Loss: 0.09363
Epoch 067: | Loss: 0.08882
Epoch 068: | Loss: 0.10183
Epoch 069: | Loss: 0.10078
Epoch 070: | Loss: 0.10871
Epoch 071: | Loss: 0.11032
Epoch 072: | Loss: 0.10801
Epoch 073: | Loss: 0.12173
Epoch 074: | Loss: 0.12578
Epoch 075: | Loss: 0.12037
Epoch 076: | Loss: 0.12142
Epoch 077: | Loss: 0.14660
Epoch 078: | Loss: 0.14079
Epoch 079: | Loss: 0.12852
Epoch 080: | Loss: 0.14791
Epoch 081: | Loss: 0.13143
Epoch 082: | Loss: 0.14356
Epoch 083: | Loss: 0.12656
Epoch 084: | Loss: 0.15424
Epoch 085: | Loss: 0.14533
Epoch 086: | Loss: 0.15386
Epoch 087: | Loss: 0.15382
Epoch 088: | Loss: 0.16103
Epoch 089: | Loss: 0.15631
Epoch 090: | Loss: 0.14647
Epoch 091: | Loss: 0.15630
Epoch 092: | Loss: 0.16246
Epoch 093: | Loss: 0.14066
Epoch 094: | Loss: 0.15908
Epoch 095: | Loss: 0.16654
Epoch 096: | Loss: 0.15231
Epoch 097: | Loss: 0.15250
Epoch 098: | Loss: 0.14954
Epoch 099: | Loss: 0.13989
Epoch 100: | Loss: 0.14613
Epoch 101: | Loss: 0.16101
Epoch 102: | Loss: 0.15189
Epoch 103: | Loss: 0.16279
Epoch 104: | Loss: 0.13511
Epoch 105: | Loss: 0.13443
Epoch 106: | Loss: 0.12905
Epoch 107: | Loss: 0.14278
Epoch 108: | Loss: 0.12877
Epoch 109: | Loss: 0.12728
Epoch 110: | Loss: 0.12441
Epoch 111: | Loss: 0.12163
Epoch 112: | Loss: 0.11155
Epoch 113: | Loss: 0.11035
Epoch 114: | Loss: 0.10395
Epoch 115: | Loss: 0.09636
Epoch 116: | Loss: 0.09895
Epoch 117: | Loss: 0.10238
Epoch 118: | Loss: 0.08589
Epoch 119: | Loss: 0.08075
Epoch 120: | Loss: 0.08738
Epoch 121: | Loss: 0.08553
Epoch 122: | Loss: 0.06607
Epoch 123: | Loss: 0.06266
Epoch 124: | Loss: 0.05490
Epoch 125: | Loss: 0.06114
Epoch 126: | Loss: 0.04897
Epoch 127: | Loss: 0.04749
Epoch 128: | Loss: 0.04672
Epoch 129: | Loss: 0.03881
Epoch 130: | Loss: 0.03482
Epoch 131: | Loss: 0.02918
Epoch 132: | Loss: 0.02874
Epoch 133: | Loss: 0.02423
Epoch 134: | Loss: 0.02466
Epoch 135: | Loss: 0.01960
Epoch 136: | Loss: 0.01649
Epoch 137: | Loss: 0.01623
Epoch 138: | Loss: 0.01210
Epoch 139: | Loss: 0.00784
Epoch 140: | Loss: 0.00960
Epoch 141: | Loss: 0.01093
Epoch 142: | Loss: 0.00822
Epoch 143: | Loss: 0.00769
Epoch 144: | Loss: 0.00668
Epoch 145: | Loss: 0.00674
Epoch 146: | Loss: 0.00686
Epoch 147: | Loss: 0.00501
Epoch 148: | Loss: 0.00601
Epoch 149: | Loss: 0.00536
Epoch 150: | Loss: 0.00761
Epoch 151: | Loss: 0.00632
Epoch 152: | Loss: 0.00459
Epoch 153: | Loss: 0.00762
Epoch 154: | Loss: 0.00563
Epoch 155: | Loss: 0.00369
Epoch 156: | Loss: 0.00762
Epoch 157: | Loss: 0.00761
Epoch 158: | Loss: 0.00756
Epoch 159: | Loss: 0.01524
Epoch 160: | Loss: 0.01347
Epoch 161: | Loss: 0.01527
Epoch 162: | Loss: 0.01312
Epoch 163: | Loss: 0.02389
Epoch 164: | Loss: 0.02576
Epoch 165: | Loss: 0.01877
Epoch 166: | Loss: 0.02069
Epoch 167: | Loss: 0.02145
Epoch 168: | Loss: 0.03355
Epoch 169: | Loss: 0.02738
Epoch 170: | Loss: 0.04196
Epoch 171: | Loss: 0.04014
Epoch 172: | Loss: 0.03224
Epoch 173: | Loss: 0.03075
Epoch 174: | Loss: 0.03760
Epoch 175: | Loss: 0.03792
Epoch 176: | Loss: 0.04608
Epoch 177: | Loss: 0.04758
Epoch 178: | Loss: 0.04137
Epoch 179: | Loss: 0.06095
Epoch 180: | Loss: 0.06538
Epoch 181: | Loss: 0.06733
Epoch 182: | Loss: 0.06044
Epoch 183: | Loss: 0.06414
Epoch 184: | Loss: 0.06599
Epoch 185: | Loss: 0.10526
Epoch 186: | Loss: 0.09430
Epoch 187: | Loss: 0.08768
Epoch 188: | Loss: 0.07170
Epoch 189: | Loss: 0.08308
Epoch 190: | Loss: 0.06147
Epoch 191: | Loss: 0.07989
Epoch 192: | Loss: 0.07132
Epoch 193: | Loss: 0.08894
Epoch 194: | Loss: 0.09452
Epoch 195: | Loss: 0.07570
Epoch 196: | Loss: 0.07749
Epoch 197: | Loss: 0.07845
Epoch 198: | Loss: 0.08705
Epoch 199: | Loss: 0.07934
Accuracy: 0.9342922008547009
Epoch 000: | Loss: 1.58313
Epoch 001: | Loss: 0.79504
Epoch 002: | Loss: 0.67060
Epoch 003: | Loss: 0.65302
Epoch 004: | Loss: 0.59387
Epoch 005: | Loss: 0.58678
Epoch 006: | Loss: 0.55309
Epoch 007: | Loss: 0.52044
Epoch 008: | Loss: 0.51715
Epoch 009: | Loss: 0.52784
Epoch 010: | Loss: 0.49810
Epoch 011: | Loss: 0.51829
Epoch 012: | Loss: 0.52754
Epoch 013: | Loss: 0.49544
Epoch 014: | Loss: 0.55143
Epoch 015: | Loss: 0.57263
Epoch 016: | Loss: 0.55389
Epoch 017: | Loss: 0.52353
Epoch 018: | Loss: 0.52126
Epoch 019: | Loss: 0.51033
Epoch 020: | Loss: 0.52420
Epoch 021: | Loss: 0.52469
Epoch 022: | Loss: 0.49810
Epoch 023: | Loss: 0.51780
Epoch 024: | Loss: 0.49846
Epoch 025: | Loss: 0.48628
Epoch 026: | Loss: 0.48248
Epoch 027: | Loss: 0.47710
Epoch 028: | Loss: 0.47157
Epoch 029: | Loss: 0.46890
Epoch 030: | Loss: 0.46102
Epoch 031: | Loss: 0.46005
Epoch 032: | Loss: 0.45565
Epoch 033: | Loss: 0.45555
Epoch 034: | Loss: 0.46026
Epoch 035: | Loss: 0.45106
Epoch 036: | Loss: 0.45028
Epoch 037: | Loss: 0.44456
Epoch 038: | Loss: 0.44568
Epoch 039: | Loss: 0.44924
Epoch 040: | Loss: 0.44470
Epoch 041: | Loss: 0.44139
Epoch 042: | Loss: 0.44001
Epoch 043: | Loss: 0.43639
Epoch 044: | Loss: 0.43508
Epoch 045: | Loss: 0.43312
Epoch 046: | Loss: 0.43183
Epoch 047: | Loss: 0.43469
Epoch 048: | Loss: 0.43183
Epoch 049: | Loss: 0.43244
Epoch 050: | Loss: 0.42996
Epoch 051: | Loss: 0.42877
Epoch 052: | Loss: 0.42807
Epoch 053: | Loss: 0.43176
Epoch 054: | Loss: 0.43317
Epoch 055: | Loss: 0.43216
Epoch 056: | Loss: 0.43324
Epoch 057: | Loss: 0.43406
Epoch 058: | Loss: 0.43029
Epoch 059: | Loss: 0.42912
Epoch 060: | Loss: 0.43061
Epoch 061: | Loss: 0.44551
Epoch 062: | Loss: 0.44183
Epoch 063: | Loss: 0.44005
Epoch 064: | Loss: 0.44446
Epoch 065: | Loss: 0.44815
Epoch 066: | Loss: 0.45035
Epoch 067: | Loss: 0.44705
Epoch 068: | Loss: 0.45264
Epoch 069: | Loss: 0.46303
Epoch 070: | Loss: 0.44970
Epoch 071: | Loss: 0.44553
Epoch 072: | Loss: 0.44210
Epoch 073: | Loss: 0.48951
Epoch 074: | Loss: 0.52036
Epoch 075: | Loss: 0.48991
Epoch 076: | Loss: 0.59251
Epoch 077: | Loss: 0.60099
Epoch 078: | Loss: 0.60647
Epoch 079: | Loss: 0.56964
Epoch 080: | Loss: 0.54161
Epoch 081: | Loss: 0.55257
Epoch 082: | Loss: 0.50323
Epoch 083: | Loss: 0.50920
Epoch 084: | Loss: 0.61620
Epoch 085: | Loss: 0.58991
Epoch 086: | Loss: 0.62546
Epoch 087: | Loss: 0.56733
Epoch 088: | Loss: 0.54485
Epoch 089: | Loss: 0.52904
Epoch 090: | Loss: 0.50843
Epoch 091: | Loss: 0.51589
Epoch 092: | Loss: 0.49244
Epoch 093: | Loss: 0.48412
Epoch 094: | Loss: 0.48212
Epoch 095: | Loss: 0.49571
Epoch 096: | Loss: 0.47566
Epoch 097: | Loss: 0.47058
Epoch 098: | Loss: 0.48281
Epoch 099: | Loss: 0.50123
Epoch 100: | Loss: 0.52971
Epoch 101: | Loss: 0.48878
Epoch 102: | Loss: 0.57864
Epoch 103: | Loss: 0.62200
Epoch 104: | Loss: 0.54694
Epoch 105: | Loss: 0.52901
Epoch 106: | Loss: 0.50843
Epoch 107: | Loss: 0.49416
Epoch 108: | Loss: 0.48701
Epoch 109: | Loss: 0.48278
Epoch 110: | Loss: 0.49940
Epoch 111: | Loss: 0.49375
Epoch 112: | Loss: 0.47641
Epoch 113: | Loss: 0.64126
Epoch 114: | Loss: 0.58845
Epoch 115: | Loss: 0.59008
Epoch 116: | Loss: 0.55813
Epoch 117: | Loss: 0.51049
Epoch 118: | Loss: 0.53497
Epoch 119: | Loss: 0.56458
Epoch 120: | Loss: 0.57480
Epoch 121: | Loss: 0.52892
Epoch 122: | Loss: 0.51195
Epoch 123: | Loss: 0.52790
Epoch 124: | Loss: 0.53814
Epoch 125: | Loss: 0.51422
Epoch 126: | Loss: 0.51194
Epoch 127: | Loss: 0.50083
Epoch 128: | Loss: 0.49347
Epoch 129: | Loss: 0.48793
Epoch 130: | Loss: 0.48503
Epoch 131: | Loss: 0.47621
Epoch 132: | Loss: 0.47662
Epoch 133: | Loss: 0.47516
Epoch 134: | Loss: 0.47527
Epoch 135: | Loss: 0.48137
Epoch 136: | Loss: 0.47206
Epoch 137: | Loss: 0.46980
Epoch 138: | Loss: 0.46784
Epoch 139: | Loss: 0.46325
Epoch 140: | Loss: 0.45900
Epoch 141: | Loss: 0.46047
Epoch 142: | Loss: 0.45779
Epoch 143: | Loss: 0.45617
Epoch 144: | Loss: 0.45665
Epoch 145: | Loss: 0.45690
Epoch 146: | Loss: 0.45273
Epoch 147: | Loss: 0.45387
Epoch 148: | Loss: 0.45267
Epoch 149: | Loss: 0.45404
Epoch 150: | Loss: 0.45379
Epoch 151: | Loss: 0.45181
Epoch 152: | Loss: 0.45247
Epoch 153: | Loss: 0.45289
Epoch 154: | Loss: 0.45166
Epoch 155: | Loss: 0.45142
Epoch 156: | Loss: 0.45404
Epoch 157: | Loss: 0.45074
Epoch 158: | Loss: 0.45519
Epoch 159: | Loss: 0.45280
Epoch 160: | Loss: 0.44979
Epoch 161: | Loss: 0.45056
Epoch 162: | Loss: 0.45246
Epoch 163: | Loss: 0.45503
Epoch 164: | Loss: 0.45429
Epoch 165: | Loss: 0.45463
Epoch 166: | Loss: 0.45189
Epoch 167: | Loss: 0.45480
Epoch 168: | Loss: 0.44806
Epoch 169: | Loss: 0.44908
Epoch 170: | Loss: 0.44816
Epoch 171: | Loss: 0.50115
Epoch 172: | Loss: 0.48276
Epoch 173: | Loss: 0.46089
Epoch 174: | Loss: 0.45349
Epoch 175: | Loss: 0.46243
Epoch 176: | Loss: 0.44802
Epoch 177: | Loss: 0.48036
Epoch 178: | Loss: 0.46032
Epoch 179: | Loss: 0.47055
Epoch 180: | Loss: 0.47056
Epoch 181: | Loss: 0.47089
Epoch 182: | Loss: 0.50734
Epoch 183: | Loss: 0.46874
Epoch 184: | Loss: 0.45170
Epoch 185: | Loss: 0.44910
Epoch 186: | Loss: 0.44826
Epoch 187: | Loss: 0.43929
Epoch 188: | Loss: 0.48412
Epoch 189: | Loss: 0.47398
Epoch 190: | Loss: 0.44544
Epoch 191: | Loss: 0.55612
Epoch 192: | Loss: 0.54383
Epoch 193: | Loss: 0.50475
Epoch 194: | Loss: 0.45776
Epoch 195: | Loss: 0.46588
Epoch 196: | Loss: 0.44395
Epoch 197: | Loss: 0.44208
Epoch 198: | Loss: 0.46617
Epoch 199: | Loss: 0.43124
Accuracy: 0.8302991452991453
Epoch 000: | Loss: 1.24400
Epoch 001: | Loss: 0.84785
Epoch 002: | Loss: 0.77344
Epoch 003: | Loss: 0.73086
Epoch 004: | Loss: 0.68616
Epoch 005: | Loss: 0.65830
Epoch 006: | Loss: 0.64178
Epoch 007: | Loss: 0.62898
Epoch 008: | Loss: 0.61252
Epoch 009: | Loss: 0.60353
Epoch 010: | Loss: 0.58891
Epoch 011: | Loss: 0.57880
Epoch 012: | Loss: 0.57323
Epoch 013: | Loss: 0.55764
Epoch 014: | Loss: 0.54479
Epoch 015: | Loss: 0.54703
Epoch 016: | Loss: 0.52981
Epoch 017: | Loss: 0.52476
Epoch 018: | Loss: 0.51670
Epoch 019: | Loss: 0.51089
Epoch 020: | Loss: 0.50171
Epoch 021: | Loss: 0.49463
Epoch 022: | Loss: 0.48324
Epoch 023: | Loss: 0.47830
Epoch 024: | Loss: 0.46410
Epoch 025: | Loss: 0.45293
Epoch 026: | Loss: 0.44852
Epoch 027: | Loss: 0.44038
Epoch 028: | Loss: 0.42430
Epoch 029: | Loss: 0.42111
Epoch 030: | Loss: 0.41210
Epoch 031: | Loss: 0.40270
Epoch 032: | Loss: 0.39661
Epoch 033: | Loss: 0.39313
Epoch 034: | Loss: 0.38436
Epoch 035: | Loss: 0.38186
Epoch 036: | Loss: 0.37483
Epoch 037: | Loss: 0.37114
Epoch 038: | Loss: 0.36644
Epoch 039: | Loss: 0.36060
Epoch 040: | Loss: 0.35547
Epoch 041: | Loss: 0.35457
Epoch 042: | Loss: 0.35043
Epoch 043: | Loss: 0.34710
Epoch 044: | Loss: 0.34656
Epoch 045: | Loss: 0.34376
Epoch 046: | Loss: 0.34156
Epoch 047: | Loss: 0.34083
Epoch 048: | Loss: 0.33870
Epoch 049: | Loss: 0.33989
Epoch 050: | Loss: 0.34111
Epoch 051: | Loss: 0.33918
Epoch 052: | Loss: 0.33968
Epoch 053: | Loss: 0.33739
Epoch 054: | Loss: 0.33711
Epoch 055: | Loss: 0.33845
Epoch 056: | Loss: 0.33746
Epoch 057: | Loss: 0.33854
Epoch 058: | Loss: 0.34110
Epoch 059: | Loss: 0.33983
Epoch 060: | Loss: 0.34484
Epoch 061: | Loss: 0.34053
Epoch 062: | Loss: 0.34411
Epoch 063: | Loss: 0.34606
Epoch 064: | Loss: 0.34444
Epoch 065: | Loss: 0.34269
Epoch 066: | Loss: 0.34150
Epoch 067: | Loss: 0.34231
Epoch 068: | Loss: 0.34484
Epoch 069: | Loss: 0.34432
Epoch 070: | Loss: 0.34639
Epoch 071: | Loss: 0.35289
Epoch 072: | Loss: 0.34568
Epoch 073: | Loss: 0.34784
Epoch 074: | Loss: 0.34322
Epoch 075: | Loss: 0.34013
Epoch 076: | Loss: 0.33769
Epoch 077: | Loss: 0.34367
Epoch 078: | Loss: 0.34035
Epoch 079: | Loss: 0.33506
Epoch 080: | Loss: 0.33575
Epoch 081: | Loss: 0.33490
Epoch 082: | Loss: 0.33740
Epoch 083: | Loss: 0.33407
Epoch 084: | Loss: 0.32586
Epoch 085: | Loss: 0.34000
Epoch 086: | Loss: 0.33345
Epoch 087: | Loss: 0.32179
Epoch 088: | Loss: 0.32414
Epoch 089: | Loss: 0.32622
Epoch 090: | Loss: 0.31434
Epoch 091: | Loss: 0.31868
Epoch 092: | Loss: 0.31220
Epoch 093: | Loss: 0.31097
Epoch 094: | Loss: 0.30105
Epoch 095: | Loss: 0.30130
Epoch 096: | Loss: 0.30146
Epoch 097: | Loss: 0.30257
Epoch 098: | Loss: 0.29396
Epoch 099: | Loss: 0.28550
Epoch 100: | Loss: 0.28742
Epoch 101: | Loss: 0.28815
Epoch 102: | Loss: 0.28208
Epoch 103: | Loss: 0.27548
Epoch 104: | Loss: 0.27472
Epoch 105: | Loss: 0.27216
Epoch 106: | Loss: 0.26044
Epoch 107: | Loss: 0.25203
Epoch 108: | Loss: 0.25498
Epoch 109: | Loss: 0.26050
Epoch 110: | Loss: 0.25038
Epoch 111: | Loss: 0.24893
Epoch 112: | Loss: 0.23424
Epoch 113: | Loss: 0.23492
Epoch 114: | Loss: 0.23493
Epoch 115: | Loss: 0.21899
Epoch 116: | Loss: 0.21667
Epoch 117: | Loss: 0.20621
Epoch 118: | Loss: 0.20413
Epoch 119: | Loss: 0.20552
Epoch 120: | Loss: 0.19175
Epoch 121: | Loss: 0.18840
Epoch 122: | Loss: 0.18344
Epoch 123: | Loss: 0.17905
Epoch 124: | Loss: 0.17150
Epoch 125: | Loss: 0.17721
Epoch 126: | Loss: 0.16511
Epoch 127: | Loss: 0.16019
Epoch 128: | Loss: 0.14780
Epoch 129: | Loss: 0.14378
Epoch 130: | Loss: 0.14127
Epoch 131: | Loss: 0.14471
Epoch 132: | Loss: 0.13902
Epoch 133: | Loss: 0.13001
Epoch 134: | Loss: 0.12305
Epoch 135: | Loss: 0.11295
Epoch 136: | Loss: 0.11504
Epoch 137: | Loss: 0.11070
Epoch 138: | Loss: 0.10997
Epoch 139: | Loss: 0.10492
Epoch 140: | Loss: 0.10415
Epoch 141: | Loss: 0.09935
Epoch 142: | Loss: 0.10022
Epoch 143: | Loss: 0.09683
Epoch 144: | Loss: 0.09351
Epoch 145: | Loss: 0.09067
Epoch 146: | Loss: 0.09055
Epoch 147: | Loss: 0.09056
Epoch 148: | Loss: 0.09014
Epoch 149: | Loss: 0.08853
Epoch 150: | Loss: 0.08811
Epoch 151: | Loss: 0.09220
Epoch 152: | Loss: 0.08801
Epoch 153: | Loss: 0.08890
Epoch 154: | Loss: 0.08902
Epoch 155: | Loss: 0.08857
Epoch 156: | Loss: 0.09025
Epoch 157: | Loss: 0.08933
Epoch 158: | Loss: 0.09409
Epoch 159: | Loss: 0.09234
Epoch 160: | Loss: 0.09377
Epoch 161: | Loss: 0.09745
Epoch 162: | Loss: 0.09615
Epoch 163: | Loss: 0.09809
Epoch 164: | Loss: 0.09898
Epoch 165: | Loss: 0.10710
Epoch 166: | Loss: 0.10421
Epoch 167: | Loss: 0.11341
Epoch 168: | Loss: 0.10784
Epoch 169: | Loss: 0.10811
Epoch 170: | Loss: 0.10988
Epoch 171: | Loss: 0.10734
Epoch 172: | Loss: 0.11966
Epoch 173: | Loss: 0.11923
Epoch 174: | Loss: 0.12722
Epoch 175: | Loss: 0.11855
Epoch 176: | Loss: 0.12559
Epoch 177: | Loss: 0.12242
Epoch 178: | Loss: 0.13330
Epoch 179: | Loss: 0.12457
Epoch 180: | Loss: 0.12756
Epoch 181: | Loss: 0.13026
Epoch 182: | Loss: 0.13030
Epoch 183: | Loss: 0.14943
Epoch 184: | Loss: 0.14237
Epoch 185: | Loss: 0.13461
Epoch 186: | Loss: 0.13601
Epoch 187: | Loss: 0.13600
Epoch 188: | Loss: 0.15034
Epoch 189: | Loss: 0.13639
Epoch 190: | Loss: 0.13534
Epoch 191: | Loss: 0.13211
Epoch 192: | Loss: 0.13485
Epoch 193: | Loss: 0.13807
Epoch 194: | Loss: 0.13479
Epoch 195: | Loss: 0.14233
Epoch 196: | Loss: 0.14283
Epoch 197: | Loss: 0.13563
Epoch 198: | Loss: 0.13238
Epoch 199: | Loss: 0.12777
Accuracy: 0.9280235042735042
Epoch 000: | Loss: 1.56956
Epoch 001: | Loss: 1.51331
Epoch 002: | Loss: 1.50266
Epoch 003: | Loss: 1.43325
Epoch 004: | Loss: 1.13874
Epoch 005: | Loss: 0.93614
Epoch 006: | Loss: 0.81768
Epoch 007: | Loss: 0.76773
Epoch 008: | Loss: 0.73556
Epoch 009: | Loss: 0.71028
Epoch 010: | Loss: 0.69412
Epoch 011: | Loss: 0.68282
Epoch 012: | Loss: 0.67327
Epoch 013: | Loss: 0.66036
Epoch 014: | Loss: 0.66224
Epoch 015: | Loss: 0.65968
Epoch 016: | Loss: 0.65531
Epoch 017: | Loss: 0.64747
Epoch 018: | Loss: 0.64606
Epoch 019: | Loss: 0.64285
Epoch 020: | Loss: 0.64426
Epoch 021: | Loss: 0.64069
Epoch 022: | Loss: 0.63626
Epoch 023: | Loss: 0.63759
Epoch 024: | Loss: 0.62829
Epoch 025: | Loss: 0.62658
Epoch 026: | Loss: 0.62579
Epoch 027: | Loss: 0.62708
Epoch 028: | Loss: 0.62215
Epoch 029: | Loss: 0.62429
Epoch 030: | Loss: 0.62033
Epoch 031: | Loss: 0.62416
Epoch 032: | Loss: 0.61952
Epoch 033: | Loss: 0.62065
Epoch 034: | Loss: 0.61952
Epoch 035: | Loss: 0.61771
Epoch 036: | Loss: 0.61596
Epoch 037: | Loss: 0.61612
Epoch 038: | Loss: 0.61520
Epoch 039: | Loss: 0.61678
Epoch 040: | Loss: 0.61348
Epoch 041: | Loss: 0.61411
Epoch 042: | Loss: 0.61030
Epoch 043: | Loss: 0.61623
Epoch 044: | Loss: 0.61116
Epoch 045: | Loss: 0.61048
Epoch 046: | Loss: 0.61148
Epoch 047: | Loss: 0.61468
Epoch 048: | Loss: 0.60876
Epoch 049: | Loss: 0.60858
Epoch 050: | Loss: 0.61016
Epoch 051: | Loss: 0.60899
Epoch 052: | Loss: 0.60948
Epoch 053: | Loss: 0.60898
Epoch 054: | Loss: 0.61314
Epoch 055: | Loss: 0.60839
Epoch 056: | Loss: 0.60798
Epoch 057: | Loss: 0.60587
Epoch 058: | Loss: 0.60724
Epoch 059: | Loss: 0.60611
Epoch 060: | Loss: 0.60845
Epoch 061: | Loss: 0.60484
Epoch 062: | Loss: 0.60762
Epoch 063: | Loss: 0.60956
Epoch 064: | Loss: 0.60671
Epoch 065: | Loss: 0.60814
Epoch 066: | Loss: 0.60500
Epoch 067: | Loss: 0.60337
Epoch 068: | Loss: 0.60587
Epoch 069: | Loss: 0.60462
Epoch 070: | Loss: 0.60434
Epoch 071: | Loss: 0.60307
Epoch 072: | Loss: 0.60052
Epoch 073: | Loss: 0.59892
Epoch 074: | Loss: 0.59779
Epoch 075: | Loss: 0.59903
Epoch 076: | Loss: 0.60097
Epoch 077: | Loss: 0.59892
Epoch 078: | Loss: 0.59527
Epoch 079: | Loss: 0.59495
Epoch 080: | Loss: 0.59573
Epoch 081: | Loss: 0.59371
Epoch 082: | Loss: 0.59152
Epoch 083: | Loss: 0.58970
Epoch 084: | Loss: 0.58923
Epoch 085: | Loss: 0.58810
Epoch 086: | Loss: 0.58485
Epoch 087: | Loss: 0.58577
Epoch 088: | Loss: 0.58459
Epoch 089: | Loss: 0.58093
Epoch 090: | Loss: 0.57849
Epoch 091: | Loss: 0.57518
Epoch 092: | Loss: 0.57034
Epoch 093: | Loss: 0.56994
Epoch 094: | Loss: 0.56363
Epoch 095: | Loss: 0.56189
Epoch 096: | Loss: 0.55880
Epoch 097: | Loss: 0.56262
Epoch 098: | Loss: 0.55433
Epoch 099: | Loss: 0.55008
Epoch 100: | Loss: 0.54524
Epoch 101: | Loss: 0.54774
Epoch 102: | Loss: 0.54149
Epoch 103: | Loss: 0.54005
Epoch 104: | Loss: 0.53436
Epoch 105: | Loss: 0.53390
Epoch 106: | Loss: 0.53023
Epoch 107: | Loss: 0.52787
Epoch 108: | Loss: 0.52717
Epoch 109: | Loss: 0.52239
Epoch 110: | Loss: 0.51624
Epoch 111: | Loss: 0.51785
Epoch 112: | Loss: 0.51499
Epoch 113: | Loss: 0.51669
Epoch 114: | Loss: 0.50979
Epoch 115: | Loss: 0.50947
Epoch 116: | Loss: 0.50948
Epoch 117: | Loss: 0.50645
Epoch 118: | Loss: 0.50426
Epoch 119: | Loss: 0.50023
Epoch 120: | Loss: 0.49921
Epoch 121: | Loss: 0.49660
Epoch 122: | Loss: 0.50098
Epoch 123: | Loss: 0.50007
Epoch 124: | Loss: 0.49264
Epoch 125: | Loss: 0.49477
Epoch 126: | Loss: 0.48968
Epoch 127: | Loss: 0.48770
Epoch 128: | Loss: 0.48499
Epoch 129: | Loss: 0.48679
Epoch 130: | Loss: 0.48669
Epoch 131: | Loss: 0.48722
Epoch 132: | Loss: 0.48005
Epoch 133: | Loss: 0.48121
Epoch 134: | Loss: 0.48073
Epoch 135: | Loss: 0.48563
Epoch 136: | Loss: 0.48057
Epoch 137: | Loss: 0.47726
Epoch 138: | Loss: 0.47522
Epoch 139: | Loss: 0.47559
Epoch 140: | Loss: 0.47797
Epoch 141: | Loss: 0.47789
Epoch 142: | Loss: 0.47712
Epoch 143: | Loss: 0.47462
Epoch 144: | Loss: 0.47365
Epoch 145: | Loss: 0.47358
Epoch 146: | Loss: 0.47150
Epoch 147: | Loss: 0.46844
Epoch 148: | Loss: 0.47261
Epoch 149: | Loss: 0.47137
Epoch 150: | Loss: 0.47078
Epoch 151: | Loss: 0.47221
Epoch 152: | Loss: 0.46839
Epoch 153: | Loss: 0.47093
Epoch 154: | Loss: 0.47020
Epoch 155: | Loss: 0.47135
Epoch 156: | Loss: 0.47505
Epoch 157: | Loss: 0.46717
Epoch 158: | Loss: 0.47137
Epoch 159: | Loss: 0.46902
Epoch 160: | Loss: 0.46792
Epoch 161: | Loss: 0.46868
Epoch 162: | Loss: 0.47007
Epoch 163: | Loss: 0.46774
Epoch 164: | Loss: 0.47090
Epoch 165: | Loss: 0.46955
Epoch 166: | Loss: 0.46718
Epoch 167: | Loss: 0.46653
Epoch 168: | Loss: 0.46522
Epoch 169: | Loss: 0.46594
Epoch 170: | Loss: 0.46640
Epoch 171: | Loss: 0.46696
Epoch 172: | Loss: 0.46398
Epoch 173: | Loss: 0.46279
Epoch 174: | Loss: 0.46296
Epoch 175: | Loss: 0.46291
Epoch 176: | Loss: 0.46252
Epoch 177: | Loss: 0.46216
Epoch 178: | Loss: 0.45905
Epoch 179: | Loss: 0.45831
Epoch 180: | Loss: 0.45531
Epoch 181: | Loss: 0.45441
Epoch 182: | Loss: 0.45400
Epoch 183: | Loss: 0.45556
Epoch 184: | Loss: 0.45123
Epoch 185: | Loss: 0.45178
Epoch 186: | Loss: 0.45222
Epoch 187: | Loss: 0.45089
Epoch 188: | Loss: 0.45016
Epoch 189: | Loss: 0.44487
Epoch 190: | Loss: 0.44703
Epoch 191: | Loss: 0.44644
Epoch 192: | Loss: 0.44415
Epoch 193: | Loss: 0.44368
Epoch 194: | Loss: 0.44058
Epoch 195: | Loss: 0.43714
Epoch 196: | Loss: 0.44097
Epoch 197: | Loss: 0.43942
Epoch 198: | Loss: 0.43231
Epoch 199: | Loss: 0.43179
Accuracy: 0.44650106837606834
Epoch 000: | Loss: 1.28837
Epoch 001: | Loss: 0.89670
Epoch 002: | Loss: 0.75500
Epoch 003: | Loss: 0.69891
Epoch 004: | Loss: 0.64849
Epoch 005: | Loss: 0.61922
Epoch 006: | Loss: 0.59719
Epoch 007: | Loss: 0.59298
Epoch 008: | Loss: 0.56950
Epoch 009: | Loss: 0.56102
Epoch 010: | Loss: 0.53344
Epoch 011: | Loss: 0.52218
Epoch 012: | Loss: 0.51479
Epoch 013: | Loss: 0.49822
Epoch 014: | Loss: 0.48546
Epoch 015: | Loss: 0.47474
Epoch 016: | Loss: 0.45735
Epoch 017: | Loss: 0.45266
Epoch 018: | Loss: 0.44017
Epoch 019: | Loss: 0.43197
Epoch 020: | Loss: 0.43132
Epoch 021: | Loss: 0.41600
Epoch 022: | Loss: 0.40152
Epoch 023: | Loss: 0.39405
Epoch 024: | Loss: 0.38494
Epoch 025: | Loss: 0.37196
Epoch 026: | Loss: 0.36180
Epoch 027: | Loss: 0.35532
Epoch 028: | Loss: 0.34090
Epoch 029: | Loss: 0.33405
Epoch 030: | Loss: 0.32970
Epoch 031: | Loss: 0.32047
Epoch 032: | Loss: 0.31755
Epoch 033: | Loss: 0.30187
Epoch 034: | Loss: 0.29853
Epoch 035: | Loss: 0.29030
Epoch 036: | Loss: 0.28252
Epoch 037: | Loss: 0.27495
Epoch 038: | Loss: 0.26866
Epoch 039: | Loss: 0.26468
Epoch 040: | Loss: 0.26073
Epoch 041: | Loss: 0.25530
Epoch 042: | Loss: 0.24683
Epoch 043: | Loss: 0.24467
Epoch 044: | Loss: 0.24174
Epoch 045: | Loss: 0.23861
Epoch 046: | Loss: 0.23932
Epoch 047: | Loss: 0.23493
Epoch 048: | Loss: 0.23286
Epoch 049: | Loss: 0.22987
Epoch 050: | Loss: 0.23223
Epoch 051: | Loss: 0.23374
Epoch 052: | Loss: 0.23369
Epoch 053: | Loss: 0.23272
Epoch 054: | Loss: 0.23388
Epoch 055: | Loss: 0.23378
Epoch 056: | Loss: 0.23357
Epoch 057: | Loss: 0.23593
Epoch 058: | Loss: 0.23674
Epoch 059: | Loss: 0.23493
Epoch 060: | Loss: 0.23556
Epoch 061: | Loss: 0.24251
Epoch 062: | Loss: 0.24381
Epoch 063: | Loss: 0.24324
Epoch 064: | Loss: 0.24373
Epoch 065: | Loss: 0.24150
Epoch 066: | Loss: 0.25016
Epoch 067: | Loss: 0.24687
Epoch 068: | Loss: 0.24705
Epoch 069: | Loss: 0.25881
Epoch 070: | Loss: 0.25450
Epoch 071: | Loss: 0.25536
Epoch 072: | Loss: 0.25667
Epoch 073: | Loss: 0.25859
Epoch 074: | Loss: 0.25959
Epoch 075: | Loss: 0.26490
early stopping at epoch 76 with loss 0.26877
Accuracy: 0.09207532051282052
Epoch 000: | Loss: 1.50376
Epoch 001: | Loss: 0.78290
Epoch 002: | Loss: 0.66640
Epoch 003: | Loss: 0.68685
Epoch 004: | Loss: 0.87356
Epoch 005: | Loss: 0.65346
Epoch 006: | Loss: 0.68130
Epoch 007: | Loss: 0.69771
Epoch 008: | Loss: 0.71418
Epoch 009: | Loss: 0.68547
Epoch 010: | Loss: 0.68984
Epoch 011: | Loss: 0.74359
Epoch 012: | Loss: 0.69263
Epoch 013: | Loss: 0.76093
Epoch 014: | Loss: 0.80149
Epoch 015: | Loss: 0.71616
Epoch 016: | Loss: 0.69722
Epoch 017: | Loss: 0.68607
Epoch 018: | Loss: 0.66946
Epoch 019: | Loss: 0.65721
Epoch 020: | Loss: 0.65831
Epoch 021: | Loss: 0.63036
Epoch 022: | Loss: 0.61883
Epoch 023: | Loss: 0.62757
Epoch 024: | Loss: 0.60932
Epoch 025: | Loss: 0.61045
Epoch 026: | Loss: 0.60263
Epoch 027: | Loss: 0.58451
Epoch 028: | Loss: 0.60899
Epoch 029: | Loss: 0.59424
Epoch 030: | Loss: 0.58289
Epoch 031: | Loss: 0.57604
Epoch 032: | Loss: 0.58341
Epoch 033: | Loss: 0.57465
Epoch 034: | Loss: 0.56298
Epoch 035: | Loss: 0.58931
Epoch 036: | Loss: 0.72918
Epoch 037: | Loss: 0.62931
Epoch 038: | Loss: 0.58623
Epoch 039: | Loss: 0.56858
Epoch 040: | Loss: 0.58800
Epoch 041: | Loss: 0.60903
Epoch 042: | Loss: 0.58714
Epoch 043: | Loss: 0.58320
Epoch 044: | Loss: 0.57713
Epoch 045: | Loss: 0.56014
Epoch 046: | Loss: 0.55916
Epoch 047: | Loss: 0.54120
Epoch 048: | Loss: 0.53449
Epoch 049: | Loss: 0.53314
Epoch 050: | Loss: 0.53782
Epoch 051: | Loss: 0.53676
Epoch 052: | Loss: 0.52887
Epoch 053: | Loss: 0.55193
Epoch 054: | Loss: 0.53095
Epoch 055: | Loss: 0.52147
Epoch 056: | Loss: 0.54525
Epoch 057: | Loss: 0.53993
Epoch 058: | Loss: 0.52504
Epoch 059: | Loss: 0.51514
Epoch 060: | Loss: 0.51380
Epoch 061: | Loss: 0.53016
Epoch 062: | Loss: 0.53899
Epoch 063: | Loss: 0.53785
Epoch 064: | Loss: 0.51711
Epoch 065: | Loss: 0.51794
Epoch 066: | Loss: 0.51328
Epoch 067: | Loss: 0.52460
Epoch 068: | Loss: 0.51047
Epoch 069: | Loss: 0.50858
Epoch 070: | Loss: 0.50386
Epoch 071: | Loss: 0.50049
Epoch 072: | Loss: 0.49963
Epoch 073: | Loss: 0.49782
Epoch 074: | Loss: 0.49534
Epoch 075: | Loss: 0.49483
Epoch 076: | Loss: 0.49943
Epoch 077: | Loss: 0.49765
Epoch 078: | Loss: 0.49356
Epoch 079: | Loss: 0.49329
Epoch 080: | Loss: 0.49425
Epoch 081: | Loss: 0.49092
Epoch 082: | Loss: 0.48725
Epoch 083: | Loss: 0.48949
Epoch 084: | Loss: 0.48913
Epoch 085: | Loss: 0.48914
Epoch 086: | Loss: 0.48875
Epoch 087: | Loss: 0.48816
Epoch 088: | Loss: 0.48499
Epoch 089: | Loss: 0.48495
Epoch 090: | Loss: 0.48887
Epoch 091: | Loss: 0.48472
Epoch 092: | Loss: 0.48576
Epoch 093: | Loss: 0.48635
Epoch 094: | Loss: 0.48387
Epoch 095: | Loss: 0.48459
Epoch 096: | Loss: 0.48339
Epoch 097: | Loss: 0.48448
Epoch 098: | Loss: 0.48572
Epoch 099: | Loss: 0.48563
Epoch 100: | Loss: 0.48330
Epoch 101: | Loss: 0.48310
Epoch 102: | Loss: 0.48653
Epoch 103: | Loss: 0.48332
Epoch 104: | Loss: 0.48467
Epoch 105: | Loss: 0.48412
Epoch 106: | Loss: 0.48659
Epoch 107: | Loss: 0.48279
Epoch 108: | Loss: 0.48162
Epoch 109: | Loss: 0.48649
Epoch 110: | Loss: 0.48557
Epoch 111: | Loss: 0.48711
Epoch 112: | Loss: 0.48500
Epoch 113: | Loss: 0.48674
Epoch 114: | Loss: 0.48473
Epoch 115: | Loss: 0.48317
Epoch 116: | Loss: 0.48290
Epoch 117: | Loss: 0.48453
Epoch 118: | Loss: 0.48963
Epoch 119: | Loss: 0.48784
Epoch 120: | Loss: 0.48675
Epoch 121: | Loss: 0.48431
Epoch 122: | Loss: 0.48599
Epoch 123: | Loss: 0.48670
Epoch 124: | Loss: 0.48521
Epoch 125: | Loss: 0.48378
Epoch 126: | Loss: 0.48119
Epoch 127: | Loss: 0.48288
Epoch 128: | Loss: 0.48456
Epoch 129: | Loss: 0.48328
Epoch 130: | Loss: 0.48633
Epoch 131: | Loss: 0.48765
Epoch 132: | Loss: 0.48949
Epoch 133: | Loss: 0.47965
Epoch 134: | Loss: 0.48189
Epoch 135: | Loss: 0.48432
Epoch 136: | Loss: 0.48084
Epoch 137: | Loss: 0.49650
Epoch 138: | Loss: 0.48977
Epoch 139: | Loss: 0.48680
Epoch 140: | Loss: 0.49651
Epoch 141: | Loss: 0.49207
Epoch 142: | Loss: 0.49105
Epoch 143: | Loss: 0.48663
Epoch 144: | Loss: 0.47782
Epoch 145: | Loss: 0.47810
Epoch 146: | Loss: 0.47804
Epoch 147: | Loss: 0.48725
Epoch 148: | Loss: 0.49337
Epoch 149: | Loss: 0.49197
Epoch 150: | Loss: 0.48895
Epoch 151: | Loss: 0.48271
Epoch 152: | Loss: 0.48585
Epoch 153: | Loss: 0.48345
Epoch 154: | Loss: 0.47993
Epoch 155: | Loss: 0.47620
Epoch 156: | Loss: 0.49670
Epoch 157: | Loss: 0.49354
Epoch 158: | Loss: 0.47900
Epoch 159: | Loss: 0.48152
Epoch 160: | Loss: 0.47770
Epoch 161: | Loss: 0.46611
Epoch 162: | Loss: 0.48045
Epoch 163: | Loss: 0.47482
Epoch 164: | Loss: 0.49240
Epoch 165: | Loss: 0.47779
Epoch 166: | Loss: 0.47459
Epoch 167: | Loss: 0.49626
Epoch 168: | Loss: 0.52687
Epoch 169: | Loss: 0.48730
Epoch 170: | Loss: 0.46783
Epoch 171: | Loss: 0.47380
Epoch 172: | Loss: 0.47398
Epoch 173: | Loss: 0.46356
Epoch 174: | Loss: 0.49215
Epoch 175: | Loss: 0.61137
Epoch 176: | Loss: 0.64669
Epoch 177: | Loss: 0.75840
Epoch 178: | Loss: 1.02649
early stopping at epoch 179 with loss 0.95640
Accuracy: 0.8262499999999999
Epoch 000: | Loss: 1.51099
Epoch 001: | Loss: 1.31043
Epoch 002: | Loss: 1.11161
Epoch 003: | Loss: 1.00850
Epoch 004: | Loss: 0.96620
Epoch 005: | Loss: 0.92693
Epoch 006: | Loss: 0.88948
Epoch 007: | Loss: 0.84907
Epoch 008: | Loss: 0.80802
Epoch 009: | Loss: 0.76393
Epoch 010: | Loss: 0.71858
Epoch 011: | Loss: 0.69146
Epoch 012: | Loss: 0.66464
Epoch 013: | Loss: 0.64993
Epoch 014: | Loss: 0.63396
Epoch 015: | Loss: 0.62789
Epoch 016: | Loss: 0.61976
Epoch 017: | Loss: 0.60184
Epoch 018: | Loss: 0.59022
Epoch 019: | Loss: 0.58385
Epoch 020: | Loss: 0.57811
Epoch 021: | Loss: 0.57184
Epoch 022: | Loss: 0.56726
Epoch 023: | Loss: 0.55977
Epoch 024: | Loss: 0.55449
Epoch 025: | Loss: 0.54944
Epoch 026: | Loss: 0.54755
Epoch 027: | Loss: 0.54115
Epoch 028: | Loss: 0.53775
Epoch 029: | Loss: 0.53500
Epoch 030: | Loss: 0.52807
Epoch 031: | Loss: 0.52669
Epoch 032: | Loss: 0.52325
Epoch 033: | Loss: 0.52177
Epoch 034: | Loss: 0.52484
Epoch 035: | Loss: 0.51765
Epoch 036: | Loss: 0.51658
Epoch 037: | Loss: 0.51862
Epoch 038: | Loss: 0.51037
Epoch 039: | Loss: 0.51629
Epoch 040: | Loss: 0.51230
Epoch 041: | Loss: 0.51220
Epoch 042: | Loss: 0.51010
Epoch 043: | Loss: 0.50894
Epoch 044: | Loss: 0.50509
Epoch 045: | Loss: 0.51132
Epoch 046: | Loss: 0.50877
Epoch 047: | Loss: 0.51167
Epoch 048: | Loss: 0.50932
Epoch 049: | Loss: 0.51232
Epoch 050: | Loss: 0.50535
Epoch 051: | Loss: 0.50934
Epoch 052: | Loss: 0.50848
Epoch 053: | Loss: 0.50703
Epoch 054: | Loss: 0.50637
Epoch 055: | Loss: 0.50960
Epoch 056: | Loss: 0.50618
Epoch 057: | Loss: 0.51075
Epoch 058: | Loss: 0.50567
Epoch 059: | Loss: 0.50625
Epoch 060: | Loss: 0.50642
Epoch 061: | Loss: 0.51129
Epoch 062: | Loss: 0.50509
Epoch 063: | Loss: 0.50633
Epoch 064: | Loss: 0.50943
Epoch 065: | Loss: 0.50217
Epoch 066: | Loss: 0.50543
Epoch 067: | Loss: 0.50634
Epoch 068: | Loss: 0.50542
Epoch 069: | Loss: 0.50448
Epoch 070: | Loss: 0.50013
Epoch 071: | Loss: 0.49952
Epoch 072: | Loss: 0.49495
Epoch 073: | Loss: 0.49233
Epoch 074: | Loss: 0.49182
Epoch 075: | Loss: 0.49078
Epoch 076: | Loss: 0.48631
Epoch 077: | Loss: 0.48531
Epoch 078: | Loss: 0.48352
Epoch 079: | Loss: 0.48014
Epoch 080: | Loss: 0.48118
Epoch 081: | Loss: 0.47471
Epoch 082: | Loss: 0.47143
Epoch 083: | Loss: 0.47162
Epoch 084: | Loss: 0.46563
Epoch 085: | Loss: 0.46292
Epoch 086: | Loss: 0.46278
Epoch 087: | Loss: 0.45428
Epoch 088: | Loss: 0.45953
Epoch 089: | Loss: 0.45448
Epoch 090: | Loss: 0.44864
Epoch 091: | Loss: 0.44328
Epoch 092: | Loss: 0.44549
Epoch 093: | Loss: 0.44253
Epoch 094: | Loss: 0.43869
Epoch 095: | Loss: 0.43907
Epoch 096: | Loss: 0.43398
Epoch 097: | Loss: 0.42861
Epoch 098: | Loss: 0.42669
Epoch 099: | Loss: 0.42462
Epoch 100: | Loss: 0.41932
Epoch 101: | Loss: 0.42292
Epoch 102: | Loss: 0.41401
Epoch 103: | Loss: 0.41169
Epoch 104: | Loss: 0.40924
Epoch 105: | Loss: 0.40610
Epoch 106: | Loss: 0.40269
Epoch 107: | Loss: 0.40117
Epoch 108: | Loss: 0.39403
Epoch 109: | Loss: 0.39551
Epoch 110: | Loss: 0.39454
Epoch 111: | Loss: 0.39790
Epoch 112: | Loss: 0.38581
Epoch 113: | Loss: 0.38649
Epoch 114: | Loss: 0.37942
Epoch 115: | Loss: 0.38195
Epoch 116: | Loss: 0.37623
Epoch 117: | Loss: 0.37601
Epoch 118: | Loss: 0.36972
Epoch 119: | Loss: 0.37112
Epoch 120: | Loss: 0.36924
Epoch 121: | Loss: 0.36025
Epoch 122: | Loss: 0.35884
Epoch 123: | Loss: 0.35828
Epoch 124: | Loss: 0.35843
Epoch 125: | Loss: 0.36157
Epoch 126: | Loss: 0.35662
Epoch 127: | Loss: 0.35400
Epoch 128: | Loss: 0.34628
Epoch 129: | Loss: 0.34517
Epoch 130: | Loss: 0.35002
Epoch 131: | Loss: 0.34213
Epoch 132: | Loss: 0.34167
Epoch 133: | Loss: 0.34388
Epoch 134: | Loss: 0.34154
Epoch 135: | Loss: 0.33646
Epoch 136: | Loss: 0.33241
Epoch 137: | Loss: 0.33863
Epoch 138: | Loss: 0.33361
Epoch 139: | Loss: 0.33443
Epoch 140: | Loss: 0.33267
Epoch 141: | Loss: 0.32687
Epoch 142: | Loss: 0.33362
Epoch 143: | Loss: 0.33237
Epoch 144: | Loss: 0.33134
Epoch 145: | Loss: 0.32667
Epoch 146: | Loss: 0.32876
Epoch 147: | Loss: 0.32933
Epoch 148: | Loss: 0.32836
Epoch 149: | Loss: 0.32642
Epoch 150: | Loss: 0.33322
Epoch 151: | Loss: 0.33098
Epoch 152: | Loss: 0.32638
Epoch 153: | Loss: 0.32861
Epoch 154: | Loss: 0.33041
Epoch 155: | Loss: 0.32852
Epoch 156: | Loss: 0.32811
Epoch 157: | Loss: 0.32622
Epoch 158: | Loss: 0.32635
Epoch 159: | Loss: 0.32780
Epoch 160: | Loss: 0.33002
Epoch 161: | Loss: 0.33015
Epoch 162: | Loss: 0.32890
Epoch 163: | Loss: 0.33299
Epoch 164: | Loss: 0.33211
Epoch 165: | Loss: 0.32345
Epoch 166: | Loss: 0.33077
Epoch 167: | Loss: 0.32849
Epoch 168: | Loss: 0.32374
Epoch 169: | Loss: 0.32972
Epoch 170: | Loss: 0.33474
Epoch 171: | Loss: 0.32835
Epoch 172: | Loss: 0.32444
Epoch 173: | Loss: 0.32458
Epoch 174: | Loss: 0.32657
Epoch 175: | Loss: 0.32239
Epoch 176: | Loss: 0.32517
Epoch 177: | Loss: 0.32474
Epoch 178: | Loss: 0.32305
Epoch 179: | Loss: 0.32308
Epoch 180: | Loss: 0.32063
Epoch 181: | Loss: 0.31722
Epoch 182: | Loss: 0.32242
Epoch 183: | Loss: 0.31718
Epoch 184: | Loss: 0.31588
Epoch 185: | Loss: 0.31188
Epoch 186: | Loss: 0.31640
Epoch 187: | Loss: 0.31574
Epoch 188: | Loss: 0.31371
Epoch 189: | Loss: 0.30976
Epoch 190: | Loss: 0.30567
Epoch 191: | Loss: 0.30576
Epoch 192: | Loss: 0.29917
Epoch 193: | Loss: 0.30001
Epoch 194: | Loss: 0.30542
Epoch 195: | Loss: 0.29980
Epoch 196: | Loss: 0.29345
Epoch 197: | Loss: 0.28948
Epoch 198: | Loss: 0.28617
Epoch 199: | Loss: 0.28954
Accuracy: 0.794196047008547
Epoch 000: | Loss: 1.52185
Epoch 001: | Loss: 1.27273
Epoch 002: | Loss: 0.85453
Epoch 003: | Loss: 0.72852
Epoch 004: | Loss: 0.66978
Epoch 005: | Loss: 0.63720
Epoch 006: | Loss: 0.62512
Epoch 007: | Loss: 0.60820
Epoch 008: | Loss: 0.59929
Epoch 009: | Loss: 0.58521
Epoch 010: | Loss: 0.58052
Epoch 011: | Loss: 0.56932
Epoch 012: | Loss: 0.56395
Epoch 013: | Loss: 0.55692
Epoch 014: | Loss: 0.54824
Epoch 015: | Loss: 0.53545
Epoch 016: | Loss: 0.53278
Epoch 017: | Loss: 0.52824
Epoch 018: | Loss: 0.52139
Epoch 019: | Loss: 0.51711
Epoch 020: | Loss: 0.51125
Epoch 021: | Loss: 0.50659
Epoch 022: | Loss: 0.49626
Epoch 023: | Loss: 0.48659
Epoch 024: | Loss: 0.49225
Epoch 025: | Loss: 0.48011
Epoch 026: | Loss: 0.47751
Epoch 027: | Loss: 0.46911
Epoch 028: | Loss: 0.46641
Epoch 029: | Loss: 0.46084
Epoch 030: | Loss: 0.45601
Epoch 031: | Loss: 0.45124
Epoch 032: | Loss: 0.44790
Epoch 033: | Loss: 0.44548
Epoch 034: | Loss: 0.43757
Epoch 035: | Loss: 0.43393
Epoch 036: | Loss: 0.43031
Epoch 037: | Loss: 0.42631
Epoch 038: | Loss: 0.42734
Epoch 039: | Loss: 0.42136
Epoch 040: | Loss: 0.41524
Epoch 041: | Loss: 0.41378
Epoch 042: | Loss: 0.41414
Epoch 043: | Loss: 0.40218
Epoch 044: | Loss: 0.40274
Epoch 045: | Loss: 0.40189
Epoch 046: | Loss: 0.39709
Epoch 047: | Loss: 0.39093
Epoch 048: | Loss: 0.38897
Epoch 049: | Loss: 0.38746
Epoch 050: | Loss: 0.38507
Epoch 051: | Loss: 0.38451
Epoch 052: | Loss: 0.38120
Epoch 053: | Loss: 0.37926
Epoch 054: | Loss: 0.37683
Epoch 055: | Loss: 0.37330
Epoch 056: | Loss: 0.36800
Epoch 057: | Loss: 0.36771
Epoch 058: | Loss: 0.36738
Epoch 059: | Loss: 0.35962
Epoch 060: | Loss: 0.35766
Epoch 061: | Loss: 0.35896
Epoch 062: | Loss: 0.35418
Epoch 063: | Loss: 0.34857
Epoch 064: | Loss: 0.35074
Epoch 065: | Loss: 0.34657
Epoch 066: | Loss: 0.34701
Epoch 067: | Loss: 0.34524
Epoch 068: | Loss: 0.33625
Epoch 069: | Loss: 0.33628
Epoch 070: | Loss: 0.33090
Epoch 071: | Loss: 0.33176
Epoch 072: | Loss: 0.33346
Epoch 073: | Loss: 0.33261
Epoch 074: | Loss: 0.32694
Epoch 075: | Loss: 0.32349
Epoch 076: | Loss: 0.32733
Epoch 077: | Loss: 0.32399
Epoch 078: | Loss: 0.32639
Epoch 079: | Loss: 0.31688
Epoch 080: | Loss: 0.31938
Epoch 081: | Loss: 0.31597
Epoch 082: | Loss: 0.31763
Epoch 083: | Loss: 0.31083
Epoch 084: | Loss: 0.31189
Epoch 085: | Loss: 0.31698
Epoch 086: | Loss: 0.31002
Epoch 087: | Loss: 0.30853
Epoch 088: | Loss: 0.30839
Epoch 089: | Loss: 0.30736
Epoch 090: | Loss: 0.30371
Epoch 091: | Loss: 0.30462
Epoch 092: | Loss: 0.30239
Epoch 093: | Loss: 0.30332
Epoch 094: | Loss: 0.29882
Epoch 095: | Loss: 0.30059
Epoch 096: | Loss: 0.29779
Epoch 097: | Loss: 0.29697
Epoch 098: | Loss: 0.29518
Epoch 099: | Loss: 0.29733
Epoch 100: | Loss: 0.29609
Epoch 101: | Loss: 0.29218
Epoch 102: | Loss: 0.29222
Epoch 103: | Loss: 0.29130
Epoch 104: | Loss: 0.28808
Epoch 105: | Loss: 0.28804
Epoch 106: | Loss: 0.28909
Epoch 107: | Loss: 0.28879
Epoch 108: | Loss: 0.28672
Epoch 109: | Loss: 0.28348
Epoch 110: | Loss: 0.28370
Epoch 111: | Loss: 0.28731
Epoch 112: | Loss: 0.28471
Epoch 113: | Loss: 0.28444
Epoch 114: | Loss: 0.28359
Epoch 115: | Loss: 0.28643
Epoch 116: | Loss: 0.28178
Epoch 117: | Loss: 0.28112
Epoch 118: | Loss: 0.28416
Epoch 119: | Loss: 0.28152
Epoch 120: | Loss: 0.28058
Epoch 121: | Loss: 0.28127
Epoch 122: | Loss: 0.27865
Epoch 123: | Loss: 0.27841
Epoch 124: | Loss: 0.27780
Epoch 125: | Loss: 0.27803
Epoch 126: | Loss: 0.27847
Epoch 127: | Loss: 0.28062
Epoch 128: | Loss: 0.27398
Epoch 129: | Loss: 0.27755
Epoch 130: | Loss: 0.27430
Epoch 131: | Loss: 0.27857
Epoch 132: | Loss: 0.27702
Epoch 133: | Loss: 0.27199
Epoch 134: | Loss: 0.27449
Epoch 135: | Loss: 0.27334
Epoch 136: | Loss: 0.27631
Epoch 137: | Loss: 0.27419
Epoch 138: | Loss: 0.27318
Epoch 139: | Loss: 0.27379
Epoch 140: | Loss: 0.27124
Epoch 141: | Loss: 0.27481
Epoch 142: | Loss: 0.27321
Epoch 143: | Loss: 0.27320
Epoch 144: | Loss: 0.27304
Epoch 145: | Loss: 0.27664
Epoch 146: | Loss: 0.26662
Epoch 147: | Loss: 0.26907
Epoch 148: | Loss: 0.27245
Epoch 149: | Loss: 0.26958
Epoch 150: | Loss: 0.26633
Epoch 151: | Loss: 0.26962
Epoch 152: | Loss: 0.26841
Epoch 153: | Loss: 0.27181
Epoch 154: | Loss: 0.26829
Epoch 155: | Loss: 0.26506
Epoch 156: | Loss: 0.27171
Epoch 157: | Loss: 0.26478
Epoch 158: | Loss: 0.26784
Epoch 159: | Loss: 0.26916
Epoch 160: | Loss: 0.26774
Epoch 161: | Loss: 0.26706
Epoch 162: | Loss: 0.26909
Epoch 163: | Loss: 0.26730
Epoch 164: | Loss: 0.26599
Epoch 165: | Loss: 0.26506
Epoch 166: | Loss: 0.26635
Epoch 167: | Loss: 0.26540
Epoch 168: | Loss: 0.26777
Epoch 169: | Loss: 0.26609
Epoch 170: | Loss: 0.26663
Epoch 171: | Loss: 0.26997
Epoch 172: | Loss: 0.26329
Epoch 173: | Loss: 0.26635
Epoch 174: | Loss: 0.26530
Epoch 175: | Loss: 0.26454
Epoch 176: | Loss: 0.26297
Epoch 177: | Loss: 0.26397
Epoch 178: | Loss: 0.26207
Epoch 179: | Loss: 0.26579
Epoch 180: | Loss: 0.26265
Epoch 181: | Loss: 0.26636
Epoch 182: | Loss: 0.26443
Epoch 183: | Loss: 0.26007
Epoch 184: | Loss: 0.26483
Epoch 185: | Loss: 0.25929
Epoch 186: | Loss: 0.25433
Epoch 187: | Loss: 0.26389
Epoch 188: | Loss: 0.25871
Epoch 189: | Loss: 0.26199
Epoch 190: | Loss: 0.25910
Epoch 191: | Loss: 0.25912
Epoch 192: | Loss: 0.25863
Epoch 193: | Loss: 0.26406
Epoch 194: | Loss: 0.25565
Epoch 195: | Loss: 0.25801
Epoch 196: | Loss: 0.26137
Epoch 197: | Loss: 0.25344
Epoch 198: | Loss: 0.26079
Epoch 199: | Loss: 0.25712
Accuracy: 0.9046607905982905
Epoch 000: | Loss: 1.43567
Epoch 001: | Loss: 0.87136
Epoch 002: | Loss: 0.68286
Epoch 003: | Loss: 0.61945
Epoch 004: | Loss: 0.58765
Epoch 005: | Loss: 0.56166
Epoch 006: | Loss: 0.54263
Epoch 007: | Loss: 0.52318
Epoch 008: | Loss: 0.49982
Epoch 009: | Loss: 0.47919
Epoch 010: | Loss: 0.46377
Epoch 011: | Loss: 0.44801
Epoch 012: | Loss: 0.43642
Epoch 013: | Loss: 0.42256
Epoch 014: | Loss: 0.41598
Epoch 015: | Loss: 0.40463
Epoch 016: | Loss: 0.39595
Epoch 017: | Loss: 0.38503
Epoch 018: | Loss: 0.37920
Epoch 019: | Loss: 0.36278
Epoch 020: | Loss: 0.36113
Epoch 021: | Loss: 0.35511
Epoch 022: | Loss: 0.33876
Epoch 023: | Loss: 0.33905
Epoch 024: | Loss: 0.32544
Epoch 025: | Loss: 0.31745
Epoch 026: | Loss: 0.31581
Epoch 027: | Loss: 0.30488
Epoch 028: | Loss: 0.29930
Epoch 029: | Loss: 0.29453
Epoch 030: | Loss: 0.29388
Epoch 031: | Loss: 0.28163
Epoch 032: | Loss: 0.27642
Epoch 033: | Loss: 0.26924
Epoch 034: | Loss: 0.26437
Epoch 035: | Loss: 0.25582
Epoch 036: | Loss: 0.25629
Epoch 037: | Loss: 0.25047
Epoch 038: | Loss: 0.24414
Epoch 039: | Loss: 0.24379
Epoch 040: | Loss: 0.23413
Epoch 041: | Loss: 0.23184
Epoch 042: | Loss: 0.23030
Epoch 043: | Loss: 0.22457
Epoch 044: | Loss: 0.21955
Epoch 045: | Loss: 0.21141
Epoch 046: | Loss: 0.21128
Epoch 047: | Loss: 0.20977
Epoch 048: | Loss: 0.20710
Epoch 049: | Loss: 0.20691
Epoch 050: | Loss: 0.19741
Epoch 051: | Loss: 0.19513
Epoch 052: | Loss: 0.19619
Epoch 053: | Loss: 0.18860
Epoch 054: | Loss: 0.18616
Epoch 055: | Loss: 0.17934
Epoch 056: | Loss: 0.17973
Epoch 057: | Loss: 0.17698
Epoch 058: | Loss: 0.17259
Epoch 059: | Loss: 0.17185
Epoch 060: | Loss: 0.16286
Epoch 061: | Loss: 0.17337
Epoch 062: | Loss: 0.16146
Epoch 063: | Loss: 0.16216
Epoch 064: | Loss: 0.16039
Epoch 065: | Loss: 0.15799
Epoch 066: | Loss: 0.15064
Epoch 067: | Loss: 0.15613
Epoch 068: | Loss: 0.14683
Epoch 069: | Loss: 0.14672
Epoch 070: | Loss: 0.15033
Epoch 071: | Loss: 0.14864
Epoch 072: | Loss: 0.14038
Epoch 073: | Loss: 0.14315
Epoch 074: | Loss: 0.14254
Epoch 075: | Loss: 0.13856
Epoch 076: | Loss: 0.13576
Epoch 077: | Loss: 0.13891
Epoch 078: | Loss: 0.13343
Epoch 079: | Loss: 0.12930
Epoch 080: | Loss: 0.13336
Epoch 081: | Loss: 0.12742
Epoch 082: | Loss: 0.12990
Epoch 083: | Loss: 0.12885
Epoch 084: | Loss: 0.12501
Epoch 085: | Loss: 0.12788
Epoch 086: | Loss: 0.12180
Epoch 087: | Loss: 0.12182
Epoch 088: | Loss: 0.12039
Epoch 089: | Loss: 0.11754
Epoch 090: | Loss: 0.12138
Epoch 091: | Loss: 0.11819
Epoch 092: | Loss: 0.11428
Epoch 093: | Loss: 0.11471
Epoch 094: | Loss: 0.11589
Epoch 095: | Loss: 0.10865
Epoch 096: | Loss: 0.10815
Epoch 097: | Loss: 0.11088
Epoch 098: | Loss: 0.11273
Epoch 099: | Loss: 0.10952
Epoch 100: | Loss: 0.10892
Epoch 101: | Loss: 0.10442
Epoch 102: | Loss: 0.10264
Epoch 103: | Loss: 0.09795
Epoch 104: | Loss: 0.10657
Epoch 105: | Loss: 0.10497
Epoch 106: | Loss: 0.10102
Epoch 107: | Loss: 0.09862
Epoch 108: | Loss: 0.10035
Epoch 109: | Loss: 0.10127
Epoch 110: | Loss: 0.09812
Epoch 111: | Loss: 0.10140
Epoch 112: | Loss: 0.09796
Epoch 113: | Loss: 0.09880
Epoch 114: | Loss: 0.09695
Epoch 115: | Loss: 0.09458
Epoch 116: | Loss: 0.09436
Epoch 117: | Loss: 0.09876
Epoch 118: | Loss: 0.09272
Epoch 119: | Loss: 0.09039
Epoch 120: | Loss: 0.09137
Epoch 121: | Loss: 0.09180
Epoch 122: | Loss: 0.09181
Epoch 123: | Loss: 0.08935
Epoch 124: | Loss: 0.09028
Epoch 125: | Loss: 0.09078
Epoch 126: | Loss: 0.09270
Epoch 127: | Loss: 0.09021
Epoch 128: | Loss: 0.09061
Epoch 129: | Loss: 0.08628
Epoch 130: | Loss: 0.09110
Epoch 131: | Loss: 0.08821
Epoch 132: | Loss: 0.08933
Epoch 133: | Loss: 0.08795
Epoch 134: | Loss: 0.09085
Epoch 135: | Loss: 0.08589
Epoch 136: | Loss: 0.08769
Epoch 137: | Loss: 0.08535
Epoch 138: | Loss: 0.08377
Epoch 139: | Loss: 0.08487
Epoch 140: | Loss: 0.08147
Epoch 141: | Loss: 0.08427
Epoch 142: | Loss: 0.08429
Epoch 143: | Loss: 0.08017
Epoch 144: | Loss: 0.08494
Epoch 145: | Loss: 0.08128
Epoch 146: | Loss: 0.08232
Epoch 147: | Loss: 0.07981
Epoch 148: | Loss: 0.08199
Epoch 149: | Loss: 0.08198
Epoch 150: | Loss: 0.08270
Epoch 151: | Loss: 0.08933
Epoch 152: | Loss: 0.08392
Epoch 153: | Loss: 0.07942
Epoch 154: | Loss: 0.08065
Epoch 155: | Loss: 0.08456
Epoch 156: | Loss: 0.07803
Epoch 157: | Loss: 0.07898
Epoch 158: | Loss: 0.08217
Epoch 159: | Loss: 0.07967
Epoch 160: | Loss: 0.07895
Epoch 161: | Loss: 0.08143
Epoch 162: | Loss: 0.08090
Epoch 163: | Loss: 0.08162
Epoch 164: | Loss: 0.08188
Epoch 165: | Loss: 0.08311
Epoch 166: | Loss: 0.07974
Epoch 167: | Loss: 0.07939
Epoch 168: | Loss: 0.08026
Epoch 169: | Loss: 0.07887
Epoch 170: | Loss: 0.07891
Epoch 171: | Loss: 0.08120
Epoch 172: | Loss: 0.07846
Epoch 173: | Loss: 0.08013
Epoch 174: | Loss: 0.07550
Epoch 175: | Loss: 0.08145
Epoch 176: | Loss: 0.07939
Epoch 177: | Loss: 0.07759
Epoch 178: | Loss: 0.07954
Epoch 179: | Loss: 0.08148
Epoch 180: | Loss: 0.07796
Epoch 181: | Loss: 0.08202
Epoch 182: | Loss: 0.07663
Epoch 183: | Loss: 0.07413
Epoch 184: | Loss: 0.07910
Epoch 185: | Loss: 0.08069
Epoch 186: | Loss: 0.07718
Epoch 187: | Loss: 0.08117
Epoch 188: | Loss: 0.07946
Epoch 189: | Loss: 0.08346
Epoch 190: | Loss: 0.07455
Epoch 191: | Loss: 0.07413
Epoch 192: | Loss: 0.07874
Epoch 193: | Loss: 0.07662
Epoch 194: | Loss: 0.08026
Epoch 195: | Loss: 0.07585
Epoch 196: | Loss: 0.07845
Epoch 197: | Loss: 0.07532
Epoch 198: | Loss: 0.07979
Epoch 199: | Loss: 0.07813
Accuracy: 0.9534855769230769
Epoch 000: | Loss: 1.34311
Epoch 001: | Loss: 1.02303
Epoch 002: | Loss: 0.86615
Epoch 003: | Loss: 0.78740
Epoch 004: | Loss: 0.74542
Epoch 005: | Loss: 0.72091
Epoch 006: | Loss: 0.69135
Epoch 007: | Loss: 0.67523
Epoch 008: | Loss: 0.65377
Epoch 009: | Loss: 0.63484
Epoch 010: | Loss: 0.61848
Epoch 011: | Loss: 0.60008
Epoch 012: | Loss: 0.58356
Epoch 013: | Loss: 0.57900
Epoch 014: | Loss: 0.57072
Epoch 015: | Loss: 0.56572
Epoch 016: | Loss: 0.55627
Epoch 017: | Loss: 0.54670
Epoch 018: | Loss: 0.53746
Epoch 019: | Loss: 0.53094
Epoch 020: | Loss: 0.52699
Epoch 021: | Loss: 0.50958
Epoch 022: | Loss: 0.50373
Epoch 023: | Loss: 0.49701
Epoch 024: | Loss: 0.48671
Epoch 025: | Loss: 0.48240
Epoch 026: | Loss: 0.46837
Epoch 027: | Loss: 0.46437
Epoch 028: | Loss: 0.45436
Epoch 029: | Loss: 0.44575
Epoch 030: | Loss: 0.43114
Epoch 031: | Loss: 0.42499
Epoch 032: | Loss: 0.41704
Epoch 033: | Loss: 0.40980
Epoch 034: | Loss: 0.40525
Epoch 035: | Loss: 0.39846
Epoch 036: | Loss: 0.39304
Epoch 037: | Loss: 0.38464
Epoch 038: | Loss: 0.37352
Epoch 039: | Loss: 0.37404
Epoch 040: | Loss: 0.36354
Epoch 041: | Loss: 0.35855
Epoch 042: | Loss: 0.35477
Epoch 043: | Loss: 0.34603
Epoch 044: | Loss: 0.34427
Epoch 045: | Loss: 0.33426
Epoch 046: | Loss: 0.32961
Epoch 047: | Loss: 0.32840
Epoch 048: | Loss: 0.31958
Epoch 049: | Loss: 0.32423
Epoch 050: | Loss: 0.31417
Epoch 051: | Loss: 0.30898
Epoch 052: | Loss: 0.30685
Epoch 053: | Loss: 0.30236
Epoch 054: | Loss: 0.29709
Epoch 055: | Loss: 0.29164
Epoch 056: | Loss: 0.28924
Epoch 057: | Loss: 0.28204
Epoch 058: | Loss: 0.27931
Epoch 059: | Loss: 0.27908
Epoch 060: | Loss: 0.27215
Epoch 061: | Loss: 0.26583
Epoch 062: | Loss: 0.26629
Epoch 063: | Loss: 0.26453
Epoch 064: | Loss: 0.25720
Epoch 065: | Loss: 0.25679
Epoch 066: | Loss: 0.25243
Epoch 067: | Loss: 0.24911
Epoch 068: | Loss: 0.24907
Epoch 069: | Loss: 0.24409
Epoch 070: | Loss: 0.23740
Epoch 071: | Loss: 0.23743
Epoch 072: | Loss: 0.23749
Epoch 073: | Loss: 0.23042
Epoch 074: | Loss: 0.23068
Epoch 075: | Loss: 0.22564
Epoch 076: | Loss: 0.22273
Epoch 077: | Loss: 0.22322
Epoch 078: | Loss: 0.21797
Epoch 079: | Loss: 0.22211
Epoch 080: | Loss: 0.21510
Epoch 081: | Loss: 0.21348
Epoch 082: | Loss: 0.21001
Epoch 083: | Loss: 0.20736
Epoch 084: | Loss: 0.20581
Epoch 085: | Loss: 0.19998
Epoch 086: | Loss: 0.20081
Epoch 087: | Loss: 0.19633
Epoch 088: | Loss: 0.19753
Epoch 089: | Loss: 0.19114
Epoch 090: | Loss: 0.19806
Epoch 091: | Loss: 0.19087
Epoch 092: | Loss: 0.19136
Epoch 093: | Loss: 0.18708
Epoch 094: | Loss: 0.18505
Epoch 095: | Loss: 0.18230
Epoch 096: | Loss: 0.17982
Epoch 097: | Loss: 0.17842
Epoch 098: | Loss: 0.17793
Epoch 099: | Loss: 0.17642
Epoch 100: | Loss: 0.17590
Epoch 101: | Loss: 0.17679
Epoch 102: | Loss: 0.16756
Epoch 103: | Loss: 0.17459
Epoch 104: | Loss: 0.17239
Epoch 105: | Loss: 0.16883
Epoch 106: | Loss: 0.16747
Epoch 107: | Loss: 0.16152
Epoch 108: | Loss: 0.16272
Epoch 109: | Loss: 0.16494
Epoch 110: | Loss: 0.16406
Epoch 111: | Loss: 0.15971
Epoch 112: | Loss: 0.15801
Epoch 113: | Loss: 0.15495
Epoch 114: | Loss: 0.15941
Epoch 115: | Loss: 0.15452
Epoch 116: | Loss: 0.15331
Epoch 117: | Loss: 0.15469
Epoch 118: | Loss: 0.15486
Epoch 119: | Loss: 0.15538
Epoch 120: | Loss: 0.15088
Epoch 121: | Loss: 0.15389
Epoch 122: | Loss: 0.15097
Epoch 123: | Loss: 0.14884
Epoch 124: | Loss: 0.14759
Epoch 125: | Loss: 0.14711
Epoch 126: | Loss: 0.15052
Epoch 127: | Loss: 0.14162
Epoch 128: | Loss: 0.14131
Epoch 129: | Loss: 0.14191
Epoch 130: | Loss: 0.14315
Epoch 131: | Loss: 0.13984
Epoch 132: | Loss: 0.14340
Epoch 133: | Loss: 0.13566
Epoch 134: | Loss: 0.14041
Epoch 135: | Loss: 0.14200
Epoch 136: | Loss: 0.13871
Epoch 137: | Loss: 0.14324
Epoch 138: | Loss: 0.13548
Epoch 139: | Loss: 0.13766
Epoch 140: | Loss: 0.13801
Epoch 141: | Loss: 0.13603
Epoch 142: | Loss: 0.13171
Epoch 143: | Loss: 0.13958
Epoch 144: | Loss: 0.13679
Epoch 145: | Loss: 0.13727
Epoch 146: | Loss: 0.13242
Epoch 147: | Loss: 0.13399
Epoch 148: | Loss: 0.13219
Epoch 149: | Loss: 0.13126
Epoch 150: | Loss: 0.13107
Epoch 151: | Loss: 0.13385
Epoch 152: | Loss: 0.13315
Epoch 153: | Loss: 0.13723
Epoch 154: | Loss: 0.13297
Epoch 155: | Loss: 0.13499
Epoch 156: | Loss: 0.13139
Epoch 157: | Loss: 0.13078
Epoch 158: | Loss: 0.12955
Epoch 159: | Loss: 0.12754
Epoch 160: | Loss: 0.12966
Epoch 161: | Loss: 0.12834
Epoch 162: | Loss: 0.13265
Epoch 163: | Loss: 0.13025
Epoch 164: | Loss: 0.12940
Epoch 165: | Loss: 0.12967
Epoch 166: | Loss: 0.12679
Epoch 167: | Loss: 0.12551
Epoch 168: | Loss: 0.12708
Epoch 169: | Loss: 0.12678
Epoch 170: | Loss: 0.12980
Epoch 171: | Loss: 0.12627
Epoch 172: | Loss: 0.12665
Epoch 173: | Loss: 0.12417
Epoch 174: | Loss: 0.12766
Epoch 175: | Loss: 0.12428
Epoch 176: | Loss: 0.12425
Epoch 177: | Loss: 0.12534
Epoch 178: | Loss: 0.12726
Epoch 179: | Loss: 0.12351
Epoch 180: | Loss: 0.12461
Epoch 181: | Loss: 0.12376
Epoch 182: | Loss: 0.12757
Epoch 183: | Loss: 0.12052
Epoch 184: | Loss: 0.12306
Epoch 185: | Loss: 0.11964
Epoch 186: | Loss: 0.12319
Epoch 187: | Loss: 0.12112
Epoch 188: | Loss: 0.11839
Epoch 189: | Loss: 0.12182
Epoch 190: | Loss: 0.12544
Epoch 191: | Loss: 0.11128
Epoch 192: | Loss: 0.11941
Epoch 193: | Loss: 0.11587
Epoch 194: | Loss: 0.11411
Epoch 195: | Loss: 0.11989
Epoch 196: | Loss: 0.12054
Epoch 197: | Loss: 0.11493
Epoch 198: | Loss: 0.11530
Epoch 199: | Loss: 0.11479
Accuracy: 0.9167254273504273
Epoch 000: | Loss: 1.55409
Epoch 001: | Loss: 1.19636
Epoch 002: | Loss: 0.86942
Epoch 003: | Loss: 0.75349
Epoch 004: | Loss: 0.69291
Epoch 005: | Loss: 0.65744
Epoch 006: | Loss: 0.64318
Epoch 007: | Loss: 0.62794
Epoch 008: | Loss: 0.61753
Epoch 009: | Loss: 0.60606
Epoch 010: | Loss: 0.60078
Epoch 011: | Loss: 0.59353
Epoch 012: | Loss: 0.58386
Epoch 013: | Loss: 0.57567
Epoch 014: | Loss: 0.57313
Epoch 015: | Loss: 0.56370
Epoch 016: | Loss: 0.56275
Epoch 017: | Loss: 0.55059
Epoch 018: | Loss: 0.54751
Epoch 019: | Loss: 0.53595
Epoch 020: | Loss: 0.53335
Epoch 021: | Loss: 0.52842
Epoch 022: | Loss: 0.51756
Epoch 023: | Loss: 0.50932
Epoch 024: | Loss: 0.50505
Epoch 025: | Loss: 0.49795
Epoch 026: | Loss: 0.49415
Epoch 027: | Loss: 0.48511
Epoch 028: | Loss: 0.47593
Epoch 029: | Loss: 0.47326
Epoch 030: | Loss: 0.46466
Epoch 031: | Loss: 0.45885
Epoch 032: | Loss: 0.45714
Epoch 033: | Loss: 0.45075
Epoch 034: | Loss: 0.44511
Epoch 035: | Loss: 0.43956
Epoch 036: | Loss: 0.43857
Epoch 037: | Loss: 0.43562
Epoch 038: | Loss: 0.42887
Epoch 039: | Loss: 0.42528
Epoch 040: | Loss: 0.42179
Epoch 041: | Loss: 0.41758
Epoch 042: | Loss: 0.41616
Epoch 043: | Loss: 0.40899
Epoch 044: | Loss: 0.40792
Epoch 045: | Loss: 0.39989
Epoch 046: | Loss: 0.40038
Epoch 047: | Loss: 0.39457
Epoch 048: | Loss: 0.39549
Epoch 049: | Loss: 0.38655
Epoch 050: | Loss: 0.38951
Epoch 051: | Loss: 0.38174
Epoch 052: | Loss: 0.37871
Epoch 053: | Loss: 0.37724
Epoch 054: | Loss: 0.37510
Epoch 055: | Loss: 0.37158
Epoch 056: | Loss: 0.36864
Epoch 057: | Loss: 0.36820
Epoch 058: | Loss: 0.36294
Epoch 059: | Loss: 0.35983
Epoch 060: | Loss: 0.35594
Epoch 061: | Loss: 0.35461
Epoch 062: | Loss: 0.35373
Epoch 063: | Loss: 0.35122
Epoch 064: | Loss: 0.34906
Epoch 065: | Loss: 0.34665
Epoch 066: | Loss: 0.34485
Epoch 067: | Loss: 0.33925
Epoch 068: | Loss: 0.34068
Epoch 069: | Loss: 0.33683
Epoch 070: | Loss: 0.33180
Epoch 071: | Loss: 0.32673
Epoch 072: | Loss: 0.33061
Epoch 073: | Loss: 0.32104
Epoch 074: | Loss: 0.32589
Epoch 075: | Loss: 0.32268
Epoch 076: | Loss: 0.31649
Epoch 077: | Loss: 0.31671
Epoch 078: | Loss: 0.31649
Epoch 079: | Loss: 0.31634
Epoch 080: | Loss: 0.31466
Epoch 081: | Loss: 0.30598
Epoch 082: | Loss: 0.30790
Epoch 083: | Loss: 0.30744
Epoch 084: | Loss: 0.30451
Epoch 085: | Loss: 0.30111
Epoch 086: | Loss: 0.30125
Epoch 087: | Loss: 0.30050
Epoch 088: | Loss: 0.29980
Epoch 089: | Loss: 0.30106
Epoch 090: | Loss: 0.29688
Epoch 091: | Loss: 0.29288
Epoch 092: | Loss: 0.29676
Epoch 093: | Loss: 0.29382
Epoch 094: | Loss: 0.28780
Epoch 095: | Loss: 0.28725
Epoch 096: | Loss: 0.28605
Epoch 097: | Loss: 0.28506
Epoch 098: | Loss: 0.28219
Epoch 099: | Loss: 0.28552
Epoch 100: | Loss: 0.28503
Epoch 101: | Loss: 0.27709
Epoch 102: | Loss: 0.28048
Epoch 103: | Loss: 0.28312
Epoch 104: | Loss: 0.27780
Epoch 105: | Loss: 0.27277
Epoch 106: | Loss: 0.27346
Epoch 107: | Loss: 0.27546
Epoch 108: | Loss: 0.27260
Epoch 109: | Loss: 0.27338
Epoch 110: | Loss: 0.27078
Epoch 111: | Loss: 0.26816
Epoch 112: | Loss: 0.26522
Epoch 113: | Loss: 0.26752
Epoch 114: | Loss: 0.26697
Epoch 115: | Loss: 0.26791
Epoch 116: | Loss: 0.26812
Epoch 117: | Loss: 0.26617
Epoch 118: | Loss: 0.26456
Epoch 119: | Loss: 0.26563
Epoch 120: | Loss: 0.26126
Epoch 121: | Loss: 0.26238
Epoch 122: | Loss: 0.26371
Epoch 123: | Loss: 0.26159
Epoch 124: | Loss: 0.26113
Epoch 125: | Loss: 0.26011
Epoch 126: | Loss: 0.25549
Epoch 127: | Loss: 0.25842
Epoch 128: | Loss: 0.25945
Epoch 129: | Loss: 0.25884
Epoch 130: | Loss: 0.25611
Epoch 131: | Loss: 0.25839
Epoch 132: | Loss: 0.25761
Epoch 133: | Loss: 0.25830
Epoch 134: | Loss: 0.25502
Epoch 135: | Loss: 0.25474
Epoch 136: | Loss: 0.25615
Epoch 137: | Loss: 0.25589
Epoch 138: | Loss: 0.25063
Epoch 139: | Loss: 0.25013
Epoch 140: | Loss: 0.25798
Epoch 141: | Loss: 0.25714
Epoch 142: | Loss: 0.25045
Epoch 143: | Loss: 0.24937
Epoch 144: | Loss: 0.24906
Epoch 145: | Loss: 0.25358
Epoch 146: | Loss: 0.24840
Epoch 147: | Loss: 0.25141
Epoch 148: | Loss: 0.24951
Epoch 149: | Loss: 0.25143
Epoch 150: | Loss: 0.24724
Epoch 151: | Loss: 0.24628
Epoch 152: | Loss: 0.24694
Epoch 153: | Loss: 0.24624
Epoch 154: | Loss: 0.24380
Epoch 155: | Loss: 0.24510
Epoch 156: | Loss: 0.24831
Epoch 157: | Loss: 0.24799
Epoch 158: | Loss: 0.24912
Epoch 159: | Loss: 0.24698
Epoch 160: | Loss: 0.25142
Epoch 161: | Loss: 0.24816
Epoch 162: | Loss: 0.24708
Epoch 163: | Loss: 0.24499
Epoch 164: | Loss: 0.24557
Epoch 165: | Loss: 0.24533
Epoch 166: | Loss: 0.24559
Epoch 167: | Loss: 0.24544
Epoch 168: | Loss: 0.24517
Epoch 169: | Loss: 0.24072
Epoch 170: | Loss: 0.24933
Epoch 171: | Loss: 0.24588
Epoch 172: | Loss: 0.23949
Epoch 173: | Loss: 0.24321
Epoch 174: | Loss: 0.24415
Epoch 175: | Loss: 0.24136
Epoch 176: | Loss: 0.24324
Epoch 177: | Loss: 0.24285
Epoch 178: | Loss: 0.24015
Epoch 179: | Loss: 0.24025
Epoch 180: | Loss: 0.24392
Epoch 181: | Loss: 0.24236
Epoch 182: | Loss: 0.24067
Epoch 183: | Loss: 0.23882
Epoch 184: | Loss: 0.24343
Epoch 185: | Loss: 0.23709
Epoch 186: | Loss: 0.24425
Epoch 187: | Loss: 0.23874
Epoch 188: | Loss: 0.23951
Epoch 189: | Loss: 0.23882
Epoch 190: | Loss: 0.23789
Epoch 191: | Loss: 0.23900
Epoch 192: | Loss: 0.23987
Epoch 193: | Loss: 0.23254
Epoch 194: | Loss: 0.23632
Epoch 195: | Loss: 0.23683
Epoch 196: | Loss: 0.23419
Epoch 197: | Loss: 0.23772
Epoch 198: | Loss: 0.23364
Epoch 199: | Loss: 0.23640
Accuracy: 0.693076923076923
Epoch 000: | Loss: 1.09377
Epoch 001: | Loss: 0.83764
Epoch 002: | Loss: 0.73044
Epoch 003: | Loss: 0.70058
Epoch 004: | Loss: 0.67770
Epoch 005: | Loss: 0.64548
Epoch 006: | Loss: 0.65451
Epoch 007: | Loss: 0.63222
Epoch 008: | Loss: 0.61781
Epoch 009: | Loss: 0.60154
Epoch 010: | Loss: 0.58170
Epoch 011: | Loss: 0.57642
Epoch 012: | Loss: 0.55716
Epoch 013: | Loss: 0.53872
Epoch 014: | Loss: 0.50718
Epoch 015: | Loss: 0.48987
Epoch 016: | Loss: 0.47464
Epoch 017: | Loss: 0.45705
Epoch 018: | Loss: 0.44894
Epoch 019: | Loss: 0.42516
Epoch 020: | Loss: 0.42156
Epoch 021: | Loss: 0.40001
Epoch 022: | Loss: 0.40011
Epoch 023: | Loss: 0.38467
Epoch 024: | Loss: 0.36561
Epoch 025: | Loss: 0.35356
Epoch 026: | Loss: 0.33426
Epoch 027: | Loss: 0.33029
Epoch 028: | Loss: 0.31036
Epoch 029: | Loss: 0.29814
Epoch 030: | Loss: 0.28690
Epoch 031: | Loss: 0.26629
Epoch 032: | Loss: 0.26371
Epoch 033: | Loss: 0.24765
Epoch 034: | Loss: 0.24217
Epoch 035: | Loss: 0.24015
Epoch 036: | Loss: 0.22184
Epoch 037: | Loss: 0.22181
Epoch 038: | Loss: 0.20603
Epoch 039: | Loss: 0.20442
Epoch 040: | Loss: 0.18440
Epoch 041: | Loss: 0.18755
Epoch 042: | Loss: 0.18062
Epoch 043: | Loss: 0.17263
Epoch 044: | Loss: 0.16578
Epoch 045: | Loss: 0.16172
Epoch 046: | Loss: 0.14945
Epoch 047: | Loss: 0.13706
Epoch 048: | Loss: 0.13952
Epoch 049: | Loss: 0.13274
Epoch 050: | Loss: 0.14010
Epoch 051: | Loss: 0.12558
Epoch 052: | Loss: 0.12109
Epoch 053: | Loss: 0.11060
Epoch 054: | Loss: 0.10414
Epoch 055: | Loss: 0.10931
Epoch 056: | Loss: 0.09470
Epoch 057: | Loss: 0.09289
Epoch 058: | Loss: 0.09293
Epoch 059: | Loss: 0.08323
Epoch 060: | Loss: 0.07770
Epoch 061: | Loss: 0.08113
Epoch 062: | Loss: 0.08825
Epoch 063: | Loss: 0.06896
Epoch 064: | Loss: 0.06174
Epoch 065: | Loss: 0.06484
Epoch 066: | Loss: 0.06596
Epoch 067: | Loss: 0.05930
Epoch 068: | Loss: 0.05631
Epoch 069: | Loss: 0.05057
Epoch 070: | Loss: 0.04972
Epoch 071: | Loss: 0.04932
Epoch 072: | Loss: 0.04166
Epoch 073: | Loss: 0.04591
Epoch 074: | Loss: 0.04334
Epoch 075: | Loss: 0.03930
Epoch 076: | Loss: 0.03985
Epoch 077: | Loss: 0.03414
Epoch 078: | Loss: 0.03009
Epoch 079: | Loss: 0.03105
Epoch 080: | Loss: 0.03121
Epoch 081: | Loss: 0.02970
Epoch 082: | Loss: 0.03411
Epoch 083: | Loss: 0.03128
Epoch 084: | Loss: 0.02215
Epoch 085: | Loss: 0.02566
Epoch 086: | Loss: 0.01834
Epoch 087: | Loss: 0.02203
Epoch 088: | Loss: 0.01690
Epoch 089: | Loss: 0.01667
Epoch 090: | Loss: 0.02181
Epoch 091: | Loss: 0.01719
Epoch 092: | Loss: 0.01777
Epoch 093: | Loss: 0.01654
Epoch 094: | Loss: 0.01401
Epoch 095: | Loss: 0.01366
Epoch 096: | Loss: 0.01119
Epoch 097: | Loss: 0.01607
Epoch 098: | Loss: 0.02349
Epoch 099: | Loss: 0.01264
Epoch 100: | Loss: 0.01003
Epoch 101: | Loss: 0.00875
Epoch 102: | Loss: 0.00761
Epoch 103: | Loss: 0.00990
Epoch 104: | Loss: 0.00942
Epoch 105: | Loss: 0.00864
Epoch 106: | Loss: 0.00735
Epoch 107: | Loss: 0.00646
Epoch 108: | Loss: 0.00682
Epoch 109: | Loss: 0.00505
Epoch 110: | Loss: 0.00531
Epoch 111: | Loss: 0.00552
Epoch 112: | Loss: 0.00552
Epoch 113: | Loss: 0.00635
Epoch 114: | Loss: 0.00513
Epoch 115: | Loss: 0.00473
Epoch 116: | Loss: 0.00443
Epoch 117: | Loss: 0.00430
Epoch 118: | Loss: 0.00502
Epoch 119: | Loss: 0.00414
Epoch 120: | Loss: 0.00337
Epoch 121: | Loss: 0.00417
Epoch 122: | Loss: 0.00352
Epoch 123: | Loss: 0.00292
Epoch 124: | Loss: 0.00371
Epoch 125: | Loss: 0.00287
Epoch 126: | Loss: 0.00277
Epoch 127: | Loss: 0.00242
Epoch 128: | Loss: 0.00299
Epoch 129: | Loss: 0.00289
Epoch 130: | Loss: 0.00201
Epoch 131: | Loss: 0.00177
Epoch 132: | Loss: 0.00180
Epoch 133: | Loss: 0.00192
Epoch 134: | Loss: 0.00259
Epoch 135: | Loss: 0.00190
Epoch 136: | Loss: 0.00211
Epoch 137: | Loss: 0.00173
Epoch 138: | Loss: 0.00208
Epoch 139: | Loss: 0.00258
Epoch 140: | Loss: 0.00163
Epoch 141: | Loss: 0.00192
Epoch 142: | Loss: 0.00197
Epoch 143: | Loss: 0.00187
Epoch 144: | Loss: 0.00170
Epoch 145: | Loss: 0.00148
Epoch 146: | Loss: 0.00168
Epoch 147: | Loss: 0.00157
Epoch 148: | Loss: 0.00161
Epoch 149: | Loss: 0.00127
Epoch 150: | Loss: 0.00122
Epoch 151: | Loss: 0.00140
Epoch 152: | Loss: 0.00190
Epoch 153: | Loss: 0.00136
Epoch 154: | Loss: 0.00186
Epoch 155: | Loss: 0.00168
Epoch 156: | Loss: 0.00226
Epoch 157: | Loss: 0.00152
Epoch 158: | Loss: 0.00198
Epoch 159: | Loss: 0.00145
Epoch 160: | Loss: 0.00167
Epoch 161: | Loss: 0.00170
Epoch 162: | Loss: 0.00188
Epoch 163: | Loss: 0.00188
Epoch 164: | Loss: 0.00204
early stopping at epoch 165 with loss 0.00164
Accuracy: 0.11110309829059828
Epoch 000: | Loss: 1.42786
Epoch 001: | Loss: 1.18709
Epoch 002: | Loss: 1.03987
Epoch 003: | Loss: 0.95619
Epoch 004: | Loss: 0.88738
Epoch 005: | Loss: 0.82738
Epoch 006: | Loss: 0.77323
Epoch 007: | Loss: 0.73731
Epoch 008: | Loss: 0.71574
Epoch 009: | Loss: 0.69586
Epoch 010: | Loss: 0.68384
Epoch 011: | Loss: 0.67268
Epoch 012: | Loss: 0.66332
Epoch 013: | Loss: 0.65646
Epoch 014: | Loss: 0.65486
Epoch 015: | Loss: 0.64573
Epoch 016: | Loss: 0.63995
Epoch 017: | Loss: 0.64023
Epoch 018: | Loss: 0.63138
Epoch 019: | Loss: 0.62690
Epoch 020: | Loss: 0.62024
Epoch 021: | Loss: 0.61793
Epoch 022: | Loss: 0.61788
Epoch 023: | Loss: 0.61099
Epoch 024: | Loss: 0.60995
Epoch 025: | Loss: 0.60373
Epoch 026: | Loss: 0.60254
Epoch 027: | Loss: 0.60415
Epoch 028: | Loss: 0.60151
Epoch 029: | Loss: 0.60221
Epoch 030: | Loss: 0.59584
Epoch 031: | Loss: 0.58537
Epoch 032: | Loss: 0.59141
Epoch 033: | Loss: 0.58501
Epoch 034: | Loss: 0.57940
Epoch 035: | Loss: 0.58072
Epoch 036: | Loss: 0.57473
Epoch 037: | Loss: 0.57686
Epoch 038: | Loss: 0.57374
Epoch 039: | Loss: 0.57150
Epoch 040: | Loss: 0.56800
Epoch 041: | Loss: 0.56646
Epoch 042: | Loss: 0.56594
Epoch 043: | Loss: 0.56555
Epoch 044: | Loss: 0.56395
Epoch 045: | Loss: 0.56216
Epoch 046: | Loss: 0.56062
Epoch 047: | Loss: 0.55663
Epoch 048: | Loss: 0.55915
Epoch 049: | Loss: 0.55514
Epoch 050: | Loss: 0.55896
Epoch 051: | Loss: 0.55486
Epoch 052: | Loss: 0.55508
Epoch 053: | Loss: 0.55499
Epoch 054: | Loss: 0.55612
Epoch 055: | Loss: 0.55253
Epoch 056: | Loss: 0.55230
Epoch 057: | Loss: 0.55153
Epoch 058: | Loss: 0.55118
Epoch 059: | Loss: 0.55005
Epoch 060: | Loss: 0.54982
Epoch 061: | Loss: 0.55066
Epoch 062: | Loss: 0.54345
Epoch 063: | Loss: 0.54234
Epoch 064: | Loss: 0.54424
Epoch 065: | Loss: 0.53909
Epoch 066: | Loss: 0.53934
Epoch 067: | Loss: 0.53307
Epoch 068: | Loss: 0.53470
Epoch 069: | Loss: 0.53472
Epoch 070: | Loss: 0.52871
Epoch 071: | Loss: 0.53278
Epoch 072: | Loss: 0.53112
Epoch 073: | Loss: 0.52554
Epoch 074: | Loss: 0.52539
Epoch 075: | Loss: 0.52898
Epoch 076: | Loss: 0.52069
Epoch 077: | Loss: 0.52309
Epoch 078: | Loss: 0.52053
Epoch 079: | Loss: 0.51697
Epoch 080: | Loss: 0.51398
Epoch 081: | Loss: 0.51383
Epoch 082: | Loss: 0.50951
Epoch 083: | Loss: 0.51016
Epoch 084: | Loss: 0.50230
Epoch 085: | Loss: 0.49845
Epoch 086: | Loss: 0.50223
Epoch 087: | Loss: 0.49642
Epoch 088: | Loss: 0.49544
Epoch 089: | Loss: 0.49256
Epoch 090: | Loss: 0.49008
Epoch 091: | Loss: 0.49076
Epoch 092: | Loss: 0.48690
Epoch 093: | Loss: 0.48497
Epoch 094: | Loss: 0.48410
Epoch 095: | Loss: 0.47827
Epoch 096: | Loss: 0.47700
Epoch 097: | Loss: 0.47049
Epoch 098: | Loss: 0.46947
Epoch 099: | Loss: 0.46375
Epoch 100: | Loss: 0.46129
Epoch 101: | Loss: 0.46431
Epoch 102: | Loss: 0.45951
Epoch 103: | Loss: 0.45700
Epoch 104: | Loss: 0.45206
Epoch 105: | Loss: 0.44830
Epoch 106: | Loss: 0.45090
Epoch 107: | Loss: 0.44494
Epoch 108: | Loss: 0.44065
Epoch 109: | Loss: 0.43813
Epoch 110: | Loss: 0.43585
Epoch 111: | Loss: 0.43830
Epoch 112: | Loss: 0.43666
Epoch 113: | Loss: 0.43240
Epoch 114: | Loss: 0.42912
Epoch 115: | Loss: 0.42512
Epoch 116: | Loss: 0.42344
Epoch 117: | Loss: 0.41571
Epoch 118: | Loss: 0.41590
Epoch 119: | Loss: 0.41915
Epoch 120: | Loss: 0.41370
Epoch 121: | Loss: 0.40983
Epoch 122: | Loss: 0.40692
Epoch 123: | Loss: 0.40584
Epoch 124: | Loss: 0.40187
Epoch 125: | Loss: 0.39866
Epoch 126: | Loss: 0.39139
Epoch 127: | Loss: 0.39572
Epoch 128: | Loss: 0.39199
Epoch 129: | Loss: 0.38822
Epoch 130: | Loss: 0.38640
Epoch 131: | Loss: 0.38624
Epoch 132: | Loss: 0.38243
Epoch 133: | Loss: 0.38060
Epoch 134: | Loss: 0.38145
Epoch 135: | Loss: 0.37817
Epoch 136: | Loss: 0.37534
Epoch 137: | Loss: 0.37675
Epoch 138: | Loss: 0.37569
Epoch 139: | Loss: 0.37069
Epoch 140: | Loss: 0.37535
Epoch 141: | Loss: 0.37534
Epoch 142: | Loss: 0.37170
Epoch 143: | Loss: 0.37174
Epoch 144: | Loss: 0.36801
Epoch 145: | Loss: 0.36509
Epoch 146: | Loss: 0.36746
Epoch 147: | Loss: 0.36619
Epoch 148: | Loss: 0.36808
Epoch 149: | Loss: 0.36694
Epoch 150: | Loss: 0.35988
Epoch 151: | Loss: 0.36372
Epoch 152: | Loss: 0.36389
Epoch 153: | Loss: 0.35996
Epoch 154: | Loss: 0.36217
Epoch 155: | Loss: 0.36200
Epoch 156: | Loss: 0.36206
Epoch 157: | Loss: 0.35872
Epoch 158: | Loss: 0.35845
Epoch 159: | Loss: 0.36612
Epoch 160: | Loss: 0.36125
Epoch 161: | Loss: 0.35461
Epoch 162: | Loss: 0.35392
Epoch 163: | Loss: 0.36016
Epoch 164: | Loss: 0.35512
Epoch 165: | Loss: 0.35427
Epoch 166: | Loss: 0.35631
Epoch 167: | Loss: 0.35585
Epoch 168: | Loss: 0.36001
Epoch 169: | Loss: 0.35446
Epoch 170: | Loss: 0.35782
Epoch 171: | Loss: 0.35551
Epoch 172: | Loss: 0.35510
Epoch 173: | Loss: 0.35075
Epoch 174: | Loss: 0.34882
Epoch 175: | Loss: 0.35127
Epoch 176: | Loss: 0.34627
Epoch 177: | Loss: 0.34419
Epoch 178: | Loss: 0.34049
Epoch 179: | Loss: 0.33850
Epoch 180: | Loss: 0.33399
Epoch 181: | Loss: 0.33521
Epoch 182: | Loss: 0.33308
Epoch 183: | Loss: 0.32920
Epoch 184: | Loss: 0.33410
Epoch 185: | Loss: 0.33359
Epoch 186: | Loss: 0.32740
Epoch 187: | Loss: 0.32647
Epoch 188: | Loss: 0.32475
Epoch 189: | Loss: 0.32174
Epoch 190: | Loss: 0.32532
Epoch 191: | Loss: 0.31836
Epoch 192: | Loss: 0.31898
Epoch 193: | Loss: 0.31526
Epoch 194: | Loss: 0.31018
Epoch 195: | Loss: 0.30663
Epoch 196: | Loss: 0.30971
Epoch 197: | Loss: 0.31047
Epoch 198: | Loss: 0.30678
Epoch 199: | Loss: 0.30630
Accuracy: 0.8816025641025641
Epoch 000: | Loss: 1.51839
Epoch 001: | Loss: 1.20915
Epoch 002: | Loss: 0.84941
Epoch 003: | Loss: 0.81453
Epoch 004: | Loss: 0.82274
Epoch 005: | Loss: 0.75984
Epoch 006: | Loss: 0.74145
Epoch 007: | Loss: 0.72801
Epoch 008: | Loss: 0.70934
Epoch 009: | Loss: 0.72972
Epoch 010: | Loss: 0.73227
Epoch 011: | Loss: 0.74294
Epoch 012: | Loss: 0.71682
Epoch 013: | Loss: 0.70963
Epoch 014: | Loss: 0.72264
Epoch 015: | Loss: 0.71649
Epoch 016: | Loss: 0.67971
Epoch 017: | Loss: 0.66219
Epoch 018: | Loss: 0.65344
Epoch 019: | Loss: 0.65964
Epoch 020: | Loss: 0.64412
Epoch 021: | Loss: 0.64308
Epoch 022: | Loss: 0.64506
Epoch 023: | Loss: 0.63582
Epoch 024: | Loss: 0.63666
Epoch 025: | Loss: 0.82157
Epoch 026: | Loss: 0.82413
Epoch 027: | Loss: 0.76891
Epoch 028: | Loss: 0.70590
Epoch 029: | Loss: 0.65544
Epoch 030: | Loss: 0.62803
Epoch 031: | Loss: 0.62195
Epoch 032: | Loss: 0.61600
Epoch 033: | Loss: 0.64379
Epoch 034: | Loss: 0.62623
Epoch 035: | Loss: 0.62153
Epoch 036: | Loss: 0.61431
Epoch 037: | Loss: 0.61466
Epoch 038: | Loss: 0.59680
Epoch 039: | Loss: 0.58847
Epoch 040: | Loss: 0.58165
Epoch 041: | Loss: 0.56905
Epoch 042: | Loss: 0.55950
Epoch 043: | Loss: 0.56341
Epoch 044: | Loss: 0.55722
Epoch 045: | Loss: 0.54975
Epoch 046: | Loss: 0.54510
Epoch 047: | Loss: 0.54287
Epoch 048: | Loss: 0.53297
Epoch 049: | Loss: 0.52693
Epoch 050: | Loss: 0.52513
Epoch 051: | Loss: 0.52602
Epoch 052: | Loss: 0.52534
Epoch 053: | Loss: 0.53396
Epoch 054: | Loss: 0.52344
Epoch 055: | Loss: 0.51471
Epoch 056: | Loss: 0.51913
Epoch 057: | Loss: 0.51382
Epoch 058: | Loss: 0.51030
Epoch 059: | Loss: 0.51205
Epoch 060: | Loss: 0.51872
Epoch 061: | Loss: 0.51112
Epoch 062: | Loss: 0.51275
Epoch 063: | Loss: 0.51647
Epoch 064: | Loss: 0.51102
Epoch 065: | Loss: 0.50897
Epoch 066: | Loss: 0.50309
Epoch 067: | Loss: 0.50135
Epoch 068: | Loss: 0.50795
Epoch 069: | Loss: 0.69489
Epoch 070: | Loss: 0.83434
Epoch 071: | Loss: 0.78565
Epoch 072: | Loss: 0.88558
Epoch 073: | Loss: 0.75407
Epoch 074: | Loss: 0.72597
Epoch 075: | Loss: 0.70294
Epoch 076: | Loss: 0.68102
Epoch 077: | Loss: 0.68502
Epoch 078: | Loss: 0.69504
Epoch 079: | Loss: 0.65245
Epoch 080: | Loss: 0.65664
Epoch 081: | Loss: 0.63539
Epoch 082: | Loss: 0.64340
Epoch 083: | Loss: 0.62939
Epoch 084: | Loss: 0.61998
Epoch 085: | Loss: 0.64548
Epoch 086: | Loss: 0.63225
Epoch 087: | Loss: 0.61719
Epoch 088: | Loss: 0.60974
Epoch 089: | Loss: 0.79808
Epoch 090: | Loss: 0.69128
Epoch 091: | Loss: 0.65360
Epoch 092: | Loss: 0.63644
Epoch 093: | Loss: 0.62494
Epoch 094: | Loss: 0.62018
Epoch 095: | Loss: 0.61619
Epoch 096: | Loss: 0.61051
Epoch 097: | Loss: 0.61051
Epoch 098: | Loss: 0.60799
Epoch 099: | Loss: 0.60383
Epoch 100: | Loss: 0.60608
Epoch 101: | Loss: 0.60525
Epoch 102: | Loss: 0.61210
Epoch 103: | Loss: 0.71178
Epoch 104: | Loss: 0.73375
Epoch 105: | Loss: 0.69852
Epoch 106: | Loss: 0.66950
Epoch 107: | Loss: 0.64520
Epoch 108: | Loss: 0.62409
Epoch 109: | Loss: 0.67728
Epoch 110: | Loss: 0.75577
Epoch 111: | Loss: 0.66626
Epoch 112: | Loss: 0.67463
Epoch 113: | Loss: 0.67152
Epoch 114: | Loss: 0.63151
Epoch 115: | Loss: 0.59997
Epoch 116: | Loss: 0.61273
Epoch 117: | Loss: 0.59940
Epoch 118: | Loss: 0.60631
Epoch 119: | Loss: 0.60834
Epoch 120: | Loss: 0.60051
Epoch 121: | Loss: 0.58846
Epoch 122: | Loss: 0.57667
Epoch 123: | Loss: 0.56955
Epoch 124: | Loss: 0.56648
Epoch 125: | Loss: 0.56767
Epoch 126: | Loss: 0.59593
Epoch 127: | Loss: 0.58342
Epoch 128: | Loss: 0.56759
Epoch 129: | Loss: 0.56362
Epoch 130: | Loss: 0.55494
Epoch 131: | Loss: 0.54963
Epoch 132: | Loss: 0.54862
Epoch 133: | Loss: 0.54157
Epoch 134: | Loss: 0.53537
Epoch 135: | Loss: 0.53517
Epoch 136: | Loss: 0.54381
Epoch 137: | Loss: 0.53975
Epoch 138: | Loss: 0.62642
Epoch 139: | Loss: 0.61768
Epoch 140: | Loss: 0.58535
Epoch 141: | Loss: 0.89997
Epoch 142: | Loss: 0.97343
Epoch 143: | Loss: 0.79008
Epoch 144: | Loss: 0.70436
Epoch 145: | Loss: 0.70189
Epoch 146: | Loss: 1.17791
Epoch 147: | Loss: 1.41615
Epoch 148: | Loss: 1.62237
Epoch 149: | Loss: 1.55591
Epoch 150: | Loss: nan
Epoch 151: | Loss: nan
Epoch 152: | Loss: nan
Epoch 153: | Loss: nan
Epoch 154: | Loss: nan
Epoch 155: | Loss: nan
Epoch 156: | Loss: nan
Epoch 157: | Loss: nan
Epoch 158: | Loss: nan
Epoch 159: | Loss: nan
Epoch 160: | Loss: nan
Epoch 161: | Loss: nan
Epoch 162: | Loss: nan
Epoch 163: | Loss: nan
Epoch 164: | Loss: nan
Epoch 165: | Loss: nan
Epoch 166: | Loss: nan
Epoch 167: | Loss: nan
Epoch 168: | Loss: nan
Epoch 169: | Loss: nan
Epoch 170: | Loss: nan
Epoch 171: | Loss: nan
Epoch 172: | Loss: nan
Epoch 173: | Loss: nan
Epoch 174: | Loss: nan
Epoch 175: | Loss: nan
Epoch 176: | Loss: nan
Epoch 177: | Loss: nan
Epoch 178: | Loss: nan
Epoch 179: | Loss: nan
Epoch 180: | Loss: nan
Epoch 181: | Loss: nan
Epoch 182: | Loss: nan
Epoch 183: | Loss: nan
Epoch 184: | Loss: nan
Epoch 185: | Loss: nan
Epoch 186: | Loss: nan
Epoch 187: | Loss: nan
Epoch 188: | Loss: nan
Epoch 189: | Loss: nan
Epoch 190: | Loss: nan
Epoch 191: | Loss: nan
Epoch 192: | Loss: nan
Epoch 193: | Loss: nan
Epoch 194: | Loss: nan
Epoch 195: | Loss: nan
Epoch 196: | Loss: nan
Epoch 197: | Loss: nan
Epoch 198: | Loss: nan
Epoch 199: | Loss: nan
Accuracy: 0.05563034188034188
Epoch 000: | Loss: 1.53298
Epoch 001: | Loss: 1.49370
Epoch 002: | Loss: 1.49058
Epoch 003: | Loss: 1.48998
Epoch 004: | Loss: 1.48763
Epoch 005: | Loss: 1.48142
Epoch 006: | Loss: 1.47424
Epoch 007: | Loss: 1.46666
Epoch 008: | Loss: 1.44624
Epoch 009: | Loss: 1.41682
Epoch 010: | Loss: 1.38413
Epoch 011: | Loss: 1.33653
Epoch 012: | Loss: 1.28191
Epoch 013: | Loss: 1.22206
Epoch 014: | Loss: 1.16567
Epoch 015: | Loss: 1.11564
Epoch 016: | Loss: 1.07709
Epoch 017: | Loss: 1.04617
Epoch 018: | Loss: 1.02051
Epoch 019: | Loss: 0.99350
Epoch 020: | Loss: 0.97132
Epoch 021: | Loss: 0.95058
Epoch 022: | Loss: 0.93060
Epoch 023: | Loss: 0.91257
Epoch 024: | Loss: 0.89423
Epoch 025: | Loss: 0.87909
Epoch 026: | Loss: 0.86410
Epoch 027: | Loss: 0.84803
Epoch 028: | Loss: 0.83718
Epoch 029: | Loss: 0.82872
Epoch 030: | Loss: 0.82267
Epoch 031: | Loss: 0.81305
Epoch 032: | Loss: 0.80297
Epoch 033: | Loss: 0.79858
Epoch 034: | Loss: 0.79466
Epoch 035: | Loss: 0.78590
Epoch 036: | Loss: 0.78095
Epoch 037: | Loss: 0.77641
Epoch 038: | Loss: 0.77191
Epoch 039: | Loss: 0.76481
Epoch 040: | Loss: 0.76374
Epoch 041: | Loss: 0.76100
Epoch 042: | Loss: 0.75215
Epoch 043: | Loss: 0.75067
Epoch 044: | Loss: 0.74807
Epoch 045: | Loss: 0.74473
Epoch 046: | Loss: 0.73918
Epoch 047: | Loss: 0.73913
Epoch 048: | Loss: 0.73547
Epoch 049: | Loss: 0.72908
Epoch 050: | Loss: 0.73015
Epoch 051: | Loss: 0.72797
Epoch 052: | Loss: 0.72505
Epoch 053: | Loss: 0.71808
Epoch 054: | Loss: 0.71643
Epoch 055: | Loss: 0.71704
Epoch 056: | Loss: 0.71312
Epoch 057: | Loss: 0.71388
Epoch 058: | Loss: 0.70460
Epoch 059: | Loss: 0.70564
Epoch 060: | Loss: 0.70406
Epoch 061: | Loss: 0.70365
Epoch 062: | Loss: 0.70129
Epoch 063: | Loss: 0.69959
Epoch 064: | Loss: 0.70000
Epoch 065: | Loss: 0.69561
Epoch 066: | Loss: 0.69576
Epoch 067: | Loss: 0.69168
Epoch 068: | Loss: 0.69169
Epoch 069: | Loss: 0.68604
Epoch 070: | Loss: 0.68576
Epoch 071: | Loss: 0.69121
Epoch 072: | Loss: 0.68858
Epoch 073: | Loss: 0.68497
Epoch 074: | Loss: 0.68104
Epoch 075: | Loss: 0.68188
Epoch 076: | Loss: 0.67868
Epoch 077: | Loss: 0.67904
Epoch 078: | Loss: 0.67874
Epoch 079: | Loss: 0.67814
Epoch 080: | Loss: 0.67632
Epoch 081: | Loss: 0.67390
Epoch 082: | Loss: 0.67189
Epoch 083: | Loss: 0.67180
Epoch 084: | Loss: 0.67162
Epoch 085: | Loss: 0.67142
Epoch 086: | Loss: 0.66864
Epoch 087: | Loss: 0.67167
Epoch 088: | Loss: 0.66933
Epoch 089: | Loss: 0.66851
Epoch 090: | Loss: 0.66718
Epoch 091: | Loss: 0.66679
Epoch 092: | Loss: 0.66478
Epoch 093: | Loss: 0.66364
Epoch 094: | Loss: 0.66351
Epoch 095: | Loss: 0.66238
Epoch 096: | Loss: 0.66382
Epoch 097: | Loss: 0.65855
Epoch 098: | Loss: 0.65933
Epoch 099: | Loss: 0.65933
Epoch 100: | Loss: 0.65543
Epoch 101: | Loss: 0.65704
Epoch 102: | Loss: 0.65555
Epoch 103: | Loss: 0.65415
Epoch 104: | Loss: 0.65526
Epoch 105: | Loss: 0.65106
Epoch 106: | Loss: 0.65158
Epoch 107: | Loss: 0.65339
Epoch 108: | Loss: 0.64930
Epoch 109: | Loss: 0.64909
Epoch 110: | Loss: 0.65043
Epoch 111: | Loss: 0.64928
Epoch 112: | Loss: 0.64946
Epoch 113: | Loss: 0.64895
Epoch 114: | Loss: 0.64779
Epoch 115: | Loss: 0.65081
Epoch 116: | Loss: 0.64486
Epoch 117: | Loss: 0.64680
Epoch 118: | Loss: 0.64349
Epoch 119: | Loss: 0.64331
Epoch 120: | Loss: 0.64064
Epoch 121: | Loss: 0.64431
Epoch 122: | Loss: 0.64118
Epoch 123: | Loss: 0.64110
Epoch 124: | Loss: 0.64565
Epoch 125: | Loss: 0.64252
Epoch 126: | Loss: 0.63752
Epoch 127: | Loss: 0.63982
Epoch 128: | Loss: 0.63694
Epoch 129: | Loss: 0.63914
Epoch 130: | Loss: 0.63797
Epoch 131: | Loss: 0.63195
Epoch 132: | Loss: 0.63948
Epoch 133: | Loss: 0.63769
Epoch 134: | Loss: 0.63131
Epoch 135: | Loss: 0.63310
Epoch 136: | Loss: 0.63268
Epoch 137: | Loss: 0.63371
Epoch 138: | Loss: 0.63006
Epoch 139: | Loss: 0.63275
Epoch 140: | Loss: 0.63021
Epoch 141: | Loss: 0.62991
Epoch 142: | Loss: 0.62701
Epoch 143: | Loss: 0.63273
Epoch 144: | Loss: 0.63137
Epoch 145: | Loss: 0.62642
Epoch 146: | Loss: 0.62696
Epoch 147: | Loss: 0.62689
Epoch 148: | Loss: 0.62167
Epoch 149: | Loss: 0.62309
Epoch 150: | Loss: 0.62289
Epoch 151: | Loss: 0.62316
Epoch 152: | Loss: 0.62262
Epoch 153: | Loss: 0.62333
Epoch 154: | Loss: 0.62155
Epoch 155: | Loss: 0.62232
Epoch 156: | Loss: 0.62054
Epoch 157: | Loss: 0.61906
Epoch 158: | Loss: 0.61481
Epoch 159: | Loss: 0.61864
Epoch 160: | Loss: 0.61743
Epoch 161: | Loss: 0.61740
Epoch 162: | Loss: 0.61346
Epoch 163: | Loss: 0.61842
Epoch 164: | Loss: 0.61048
Epoch 165: | Loss: 0.61749
Epoch 166: | Loss: 0.61449
Epoch 167: | Loss: 0.61505
Epoch 168: | Loss: 0.61391
Epoch 169: | Loss: 0.61165
Epoch 170: | Loss: 0.61188
Epoch 171: | Loss: 0.61283
Epoch 172: | Loss: 0.61375
Epoch 173: | Loss: 0.61525
Epoch 174: | Loss: 0.61070
Epoch 175: | Loss: 0.61217
Epoch 176: | Loss: 0.61212
Epoch 177: | Loss: 0.61149
Epoch 178: | Loss: 0.60632
Epoch 179: | Loss: 0.60971
Epoch 180: | Loss: 0.60486
Epoch 181: | Loss: 0.60799
Epoch 182: | Loss: 0.60623
Epoch 183: | Loss: 0.60476
Epoch 184: | Loss: 0.60597
Epoch 185: | Loss: 0.60617
Epoch 186: | Loss: 0.60612
Epoch 187: | Loss: 0.60260
Epoch 188: | Loss: 0.60287
Epoch 189: | Loss: 0.60528
Epoch 190: | Loss: 0.59921
Epoch 191: | Loss: 0.60297
Epoch 192: | Loss: 0.59819
Epoch 193: | Loss: 0.60223
Epoch 194: | Loss: 0.59787
Epoch 195: | Loss: 0.59739
Epoch 196: | Loss: 0.59675
Epoch 197: | Loss: 0.60254
Epoch 198: | Loss: 0.59596
Epoch 199: | Loss: 0.59922
Accuracy: 0.7827403846153845
Epoch 000: | Loss: 1.82951
Epoch 001: | Loss: 1.59692
Epoch 002: | Loss: 1.52184
Epoch 003: | Loss: 1.51457
Epoch 004: | Loss: 1.51100
Epoch 005: | Loss: 1.51037
Epoch 006: | Loss: 1.50903
Epoch 007: | Loss: 1.50900
Epoch 008: | Loss: 1.50964
Epoch 009: | Loss: 1.50883
Epoch 010: | Loss: 1.50659
Epoch 011: | Loss: 1.50812
Epoch 012: | Loss: 1.50725
Epoch 013: | Loss: 1.50648
Epoch 014: | Loss: 1.50403
Epoch 015: | Loss: 1.50726
Epoch 016: | Loss: 1.50604
Epoch 017: | Loss: 1.50178
Epoch 018: | Loss: 1.50477
Epoch 019: | Loss: 1.50770
Epoch 020: | Loss: 1.50235
Epoch 021: | Loss: 1.50233
Epoch 022: | Loss: 1.50357
Epoch 023: | Loss: 1.50216
Epoch 024: | Loss: 1.50229
Epoch 025: | Loss: 1.50280
Epoch 026: | Loss: 1.50525
Epoch 027: | Loss: 1.50349
Epoch 028: | Loss: 1.50352
Epoch 029: | Loss: 1.49919
Epoch 030: | Loss: 1.50310
Epoch 031: | Loss: 1.50154
Epoch 032: | Loss: 1.50098
Epoch 033: | Loss: 1.50134
Epoch 034: | Loss: 1.50173
Epoch 035: | Loss: 1.50221
Epoch 036: | Loss: 1.50230
Epoch 037: | Loss: 1.50166
Epoch 038: | Loss: 1.50093
Epoch 039: | Loss: 1.50197
Epoch 040: | Loss: 1.49844
Epoch 041: | Loss: 1.50074
Epoch 042: | Loss: 1.50046
Epoch 043: | Loss: 1.49894
Epoch 044: | Loss: 1.50015
Epoch 045: | Loss: 1.50124
Epoch 046: | Loss: 1.50085
Epoch 047: | Loss: 1.49972
Epoch 048: | Loss: 1.49711
Epoch 049: | Loss: 1.50012
Epoch 050: | Loss: 1.50133
Epoch 051: | Loss: 1.50030
Epoch 052: | Loss: 1.50106
Epoch 053: | Loss: 1.49855
Epoch 054: | Loss: 1.49908
Epoch 055: | Loss: 1.49969
Epoch 056: | Loss: 1.49814
Epoch 057: | Loss: 1.49947
Epoch 058: | Loss: 1.49776
Epoch 059: | Loss: 1.49852
Epoch 060: | Loss: 1.49922
Epoch 061: | Loss: 1.49927
Epoch 062: | Loss: 1.49842
Epoch 063: | Loss: 1.49717
Epoch 064: | Loss: 1.49894
Epoch 065: | Loss: 1.49814
Epoch 066: | Loss: 1.49991
Epoch 067: | Loss: 1.49911
Epoch 068: | Loss: 1.50012
Epoch 069: | Loss: 1.49845
Epoch 070: | Loss: 1.49965
Epoch 071: | Loss: 1.50135
Epoch 072: | Loss: 1.49649
Epoch 073: | Loss: 1.49749
Epoch 074: | Loss: 1.49777
Epoch 075: | Loss: 1.49832
Epoch 076: | Loss: 1.49616
Epoch 077: | Loss: 1.50054
Epoch 078: | Loss: 1.49770
Epoch 079: | Loss: 1.49794
Epoch 080: | Loss: 1.49841
Epoch 081: | Loss: 1.49916
Epoch 082: | Loss: 1.49886
Epoch 083: | Loss: 1.49894
Epoch 084: | Loss: 1.49594
Epoch 085: | Loss: 1.50026
Epoch 086: | Loss: 1.49783
Epoch 087: | Loss: 1.49943
Epoch 088: | Loss: 1.49966
Epoch 089: | Loss: 1.49831
Epoch 090: | Loss: 1.49893
Epoch 091: | Loss: 1.49658
Epoch 092: | Loss: 1.49790
Epoch 093: | Loss: 1.49752
Epoch 094: | Loss: 1.49840
Epoch 095: | Loss: 1.49567
Epoch 096: | Loss: 1.49856
Epoch 097: | Loss: 1.49805
Epoch 098: | Loss: 1.49625
Epoch 099: | Loss: 1.50061
Epoch 100: | Loss: 1.49819
Epoch 101: | Loss: 1.49674
Epoch 102: | Loss: 1.49938
Epoch 103: | Loss: 1.49956
Epoch 104: | Loss: 1.49791
Epoch 105: | Loss: 1.49744
Epoch 106: | Loss: 1.50064
Epoch 107: | Loss: 1.49727
Epoch 108: | Loss: 1.49998
Epoch 109: | Loss: 1.49795
Epoch 110: | Loss: 1.49606
Epoch 111: | Loss: 1.49900
Epoch 112: | Loss: 1.49784
Epoch 113: | Loss: 1.49841
Epoch 114: | Loss: 1.49619
Epoch 115: | Loss: 1.49698
Epoch 116: | Loss: 1.49829
Epoch 117: | Loss: 1.49763
Epoch 118: | Loss: 1.49835
Epoch 119: | Loss: 1.49733
Epoch 120: | Loss: 1.49850
Epoch 121: | Loss: 1.49764
Epoch 122: | Loss: 1.49877
Epoch 123: | Loss: 1.49754
Epoch 124: | Loss: 1.49654
Epoch 125: | Loss: 1.49831
Epoch 126: | Loss: 1.49768
Epoch 127: | Loss: 1.49747
Epoch 128: | Loss: 1.49446
Epoch 129: | Loss: 1.49739
Epoch 130: | Loss: 1.49868
Epoch 131: | Loss: 1.50060
Epoch 132: | Loss: 1.49758
Epoch 133: | Loss: 1.49728
Epoch 134: | Loss: 1.49861
Epoch 135: | Loss: 1.49734
Epoch 136: | Loss: 1.49711
Epoch 137: | Loss: 1.49528
Epoch 138: | Loss: 1.49564
Epoch 139: | Loss: 1.49958
Epoch 140: | Loss: 1.49907
Epoch 141: | Loss: 1.49900
Epoch 142: | Loss: 1.49603
Epoch 143: | Loss: 1.49875
Epoch 144: | Loss: 1.49656
Epoch 145: | Loss: 1.49584
Epoch 146: | Loss: 1.49660
Epoch 147: | Loss: 1.49695
Epoch 148: | Loss: 1.49871
Epoch 149: | Loss: 1.49629
Epoch 150: | Loss: 1.49625
Epoch 151: | Loss: 1.49717
Epoch 152: | Loss: 1.49654
Epoch 153: | Loss: 1.49538
Epoch 154: | Loss: 1.49678
Epoch 155: | Loss: 1.49626
Epoch 156: | Loss: 1.49777
Epoch 157: | Loss: 1.49682
Epoch 158: | Loss: 1.49559
Epoch 159: | Loss: 1.49567
Epoch 160: | Loss: 1.49763
Epoch 161: | Loss: 1.49694
Epoch 162: | Loss: 1.49760
Epoch 163: | Loss: 1.49521
Epoch 164: | Loss: 1.49586
Epoch 165: | Loss: 1.49737
Epoch 166: | Loss: 1.49482
Epoch 167: | Loss: 1.49483
Epoch 168: | Loss: 1.49491
Epoch 169: | Loss: 1.49643
Epoch 170: | Loss: 1.49617
Epoch 171: | Loss: 1.49498
Epoch 172: | Loss: 1.49531
Epoch 173: | Loss: 1.49686
Epoch 174: | Loss: 1.49496
Epoch 175: | Loss: 1.49452
Epoch 176: | Loss: 1.49553
Epoch 177: | Loss: 1.49466
Epoch 178: | Loss: 1.49562
Epoch 179: | Loss: 1.49361
Epoch 180: | Loss: 1.49451
Epoch 181: | Loss: 1.49518
Epoch 182: | Loss: 1.49152
Epoch 183: | Loss: 1.49411
Epoch 184: | Loss: 1.49269
Epoch 185: | Loss: 1.49257
Epoch 186: | Loss: 1.49254
Epoch 187: | Loss: 1.49373
Epoch 188: | Loss: 1.49208
Epoch 189: | Loss: 1.49334
Epoch 190: | Loss: 1.49155
Epoch 191: | Loss: 1.49295
Epoch 192: | Loss: 1.49155
Epoch 193: | Loss: 1.49322
Epoch 194: | Loss: 1.49242
Epoch 195: | Loss: 1.49281
Epoch 196: | Loss: 1.49201
Epoch 197: | Loss: 1.49239
Epoch 198: | Loss: 1.49158
Epoch 199: | Loss: 1.49131
Accuracy: 0.3849626068376068
Epoch 000: | Loss: 1.56280
Epoch 001: | Loss: 1.52207
Epoch 002: | Loss: 1.41676
Epoch 003: | Loss: 1.05705
Epoch 004: | Loss: 0.88899
Epoch 005: | Loss: 0.81635
Epoch 006: | Loss: 0.77353
Epoch 007: | Loss: 0.74724
Epoch 008: | Loss: 0.73368
Epoch 009: | Loss: 0.71871
Epoch 010: | Loss: 0.70747
Epoch 011: | Loss: 0.70511
Epoch 012: | Loss: 0.69750
Epoch 013: | Loss: 0.69205
Epoch 014: | Loss: 0.68597
Epoch 015: | Loss: 0.68245
Epoch 016: | Loss: 0.67087
Epoch 017: | Loss: 0.66309
Epoch 018: | Loss: 0.66209
Epoch 019: | Loss: 0.65220
Epoch 020: | Loss: 0.64854
Epoch 021: | Loss: 0.63835
Epoch 022: | Loss: 0.63568
Epoch 023: | Loss: 0.63200
Epoch 024: | Loss: 0.62628
Epoch 025: | Loss: 0.62874
Epoch 026: | Loss: 0.62193
Epoch 027: | Loss: 0.61763
Epoch 028: | Loss: 0.61688
Epoch 029: | Loss: 0.61835
Epoch 030: | Loss: 0.61345
Epoch 031: | Loss: 0.61276
Epoch 032: | Loss: 0.60950
Epoch 033: | Loss: 0.60659
Epoch 034: | Loss: 0.60625
Epoch 035: | Loss: 0.60542
Epoch 036: | Loss: 0.60096
Epoch 037: | Loss: 0.60390
Epoch 038: | Loss: 0.60122
Epoch 039: | Loss: 0.60280
Epoch 040: | Loss: 0.60204
Epoch 041: | Loss: 0.60026
Epoch 042: | Loss: 0.59957
Epoch 043: | Loss: 0.59821
Epoch 044: | Loss: 0.59845
Epoch 045: | Loss: 0.59989
Epoch 046: | Loss: 0.59675
Epoch 047: | Loss: 0.59760
Epoch 048: | Loss: 0.59638
Epoch 049: | Loss: 0.59545
Epoch 050: | Loss: 0.59530
Epoch 051: | Loss: 0.59844
Epoch 052: | Loss: 0.59619
Epoch 053: | Loss: 0.59544
Epoch 054: | Loss: 0.59680
Epoch 055: | Loss: 0.59606
Epoch 056: | Loss: 0.59713
Epoch 057: | Loss: 0.59740
Epoch 058: | Loss: 0.59573
Epoch 059: | Loss: 0.59742
Epoch 060: | Loss: 0.59703
Epoch 061: | Loss: 0.59400
Epoch 062: | Loss: 0.59681
Epoch 063: | Loss: 0.59222
Epoch 064: | Loss: 0.59475
Epoch 065: | Loss: 0.59648
Epoch 066: | Loss: 0.59077
Epoch 067: | Loss: 0.59461
Epoch 068: | Loss: 0.59577
Epoch 069: | Loss: 0.59240
Epoch 070: | Loss: 0.59220
Epoch 071: | Loss: 0.58681
Epoch 072: | Loss: 0.58969
Epoch 073: | Loss: 0.58703
Epoch 074: | Loss: 0.58583
Epoch 075: | Loss: 0.58915
Epoch 076: | Loss: 0.58566
Epoch 077: | Loss: 0.58174
Epoch 078: | Loss: 0.58836
Epoch 079: | Loss: 0.58268
Epoch 080: | Loss: 0.57818
Epoch 081: | Loss: 0.57174
Epoch 082: | Loss: 0.57279
Epoch 083: | Loss: 0.57627
Epoch 084: | Loss: 0.56728
Epoch 085: | Loss: 0.57294
Epoch 086: | Loss: 0.57056
Epoch 087: | Loss: 0.57041
Epoch 088: | Loss: 0.56256
Epoch 089: | Loss: 0.56382
Epoch 090: | Loss: 0.55877
Epoch 091: | Loss: 0.56016
Epoch 092: | Loss: 0.55519
Epoch 093: | Loss: 0.55191
Epoch 094: | Loss: 0.55852
Epoch 095: | Loss: 0.54780
Epoch 096: | Loss: 0.55080
Epoch 097: | Loss: 0.54515
Epoch 098: | Loss: 0.54416
Epoch 099: | Loss: 0.54357
Epoch 100: | Loss: 0.53985
Epoch 101: | Loss: 0.53819
Epoch 102: | Loss: 0.53691
Epoch 103: | Loss: 0.53984
Epoch 104: | Loss: 0.53664
Epoch 105: | Loss: 0.52830
Epoch 106: | Loss: 0.52657
Epoch 107: | Loss: 0.52520
Epoch 108: | Loss: 0.52238
Epoch 109: | Loss: 0.52316
Epoch 110: | Loss: 0.52076
Epoch 111: | Loss: 0.51569
Epoch 112: | Loss: 0.51266
Epoch 113: | Loss: 0.51924
Epoch 114: | Loss: 0.51417
Epoch 115: | Loss: 0.51074
Epoch 116: | Loss: 0.50551
Epoch 117: | Loss: 0.50500
Epoch 118: | Loss: 0.50233
Epoch 119: | Loss: 0.49872
Epoch 120: | Loss: 0.50121
Epoch 121: | Loss: 0.49754
Epoch 122: | Loss: 0.49341
Epoch 123: | Loss: 0.49294
Epoch 124: | Loss: 0.48865
Epoch 125: | Loss: 0.48842
Epoch 126: | Loss: 0.48748
Epoch 127: | Loss: 0.48163
Epoch 128: | Loss: 0.48093
Epoch 129: | Loss: 0.47795
Epoch 130: | Loss: 0.47211
Epoch 131: | Loss: 0.47679
Epoch 132: | Loss: 0.47074
Epoch 133: | Loss: 0.47191
Epoch 134: | Loss: 0.47775
Epoch 135: | Loss: 0.47215
Epoch 136: | Loss: 0.46743
Epoch 137: | Loss: 0.46622
Epoch 138: | Loss: 0.46854
Epoch 139: | Loss: 0.46464
Epoch 140: | Loss: 0.46648
Epoch 141: | Loss: 0.46450
Epoch 142: | Loss: 0.46658
Epoch 143: | Loss: 0.46512
Epoch 144: | Loss: 0.46174
Epoch 145: | Loss: 0.46097
Epoch 146: | Loss: 0.46067
Epoch 147: | Loss: 0.46395
Epoch 148: | Loss: 0.46548
Epoch 149: | Loss: 0.46192
Epoch 150: | Loss: 0.46209
Epoch 151: | Loss: 0.46230
Epoch 152: | Loss: 0.46282
Epoch 153: | Loss: 0.46116
Epoch 154: | Loss: 0.46260
Epoch 155: | Loss: 0.46303
Epoch 156: | Loss: 0.46698
Epoch 157: | Loss: 0.46342
Epoch 158: | Loss: 0.46335
Epoch 159: | Loss: 0.46241
Epoch 160: | Loss: 0.46439
Epoch 161: | Loss: 0.46229
Epoch 162: | Loss: 0.46281
Epoch 163: | Loss: 0.46348
Epoch 164: | Loss: 0.46177
Epoch 165: | Loss: 0.46510
Epoch 166: | Loss: 0.46245
Epoch 167: | Loss: 0.46498
Epoch 168: | Loss: 0.46372
Epoch 169: | Loss: 0.46091
Epoch 170: | Loss: 0.46275
Epoch 171: | Loss: 0.46489
Epoch 172: | Loss: 0.45932
Epoch 173: | Loss: 0.46103
Epoch 174: | Loss: 0.45691
Epoch 175: | Loss: 0.45599
Epoch 176: | Loss: 0.46010
Epoch 177: | Loss: 0.45709
Epoch 178: | Loss: 0.46178
Epoch 179: | Loss: 0.45864
Epoch 180: | Loss: 0.46108
Epoch 181: | Loss: 0.45236
Epoch 182: | Loss: 0.45628
Epoch 183: | Loss: 0.45419
Epoch 184: | Loss: 0.45269
Epoch 185: | Loss: 0.45457
Epoch 186: | Loss: 0.45147
Epoch 187: | Loss: 0.44887
Epoch 188: | Loss: 0.44912
Epoch 189: | Loss: 0.44432
Epoch 190: | Loss: 0.44371
Epoch 191: | Loss: 0.44795
Epoch 192: | Loss: 0.44539
Epoch 193: | Loss: 0.44589
Epoch 194: | Loss: 0.44395
Epoch 195: | Loss: 0.44056
Epoch 196: | Loss: 0.43938
Epoch 197: | Loss: 0.43708
Epoch 198: | Loss: 0.43584
Epoch 199: | Loss: 0.43603
Accuracy: 0.8364663461538461
Epoch 000: | Loss: 1.52654
Epoch 001: | Loss: 1.45205
Epoch 002: | Loss: 0.89406
Epoch 003: | Loss: 0.74482
Epoch 004: | Loss: 0.70869
Epoch 005: | Loss: 0.68361
Epoch 006: | Loss: 0.65759
Epoch 007: | Loss: 0.64101
Epoch 008: | Loss: 0.62976
Epoch 009: | Loss: 0.62047
Epoch 010: | Loss: 0.61216
Epoch 011: | Loss: 0.60436
Epoch 012: | Loss: 0.60029
Epoch 013: | Loss: 0.59158
Epoch 014: | Loss: 0.58845
Epoch 015: | Loss: 0.58655
Epoch 016: | Loss: 0.57960
Epoch 017: | Loss: 0.57006
Epoch 018: | Loss: 0.56733
Epoch 019: | Loss: 0.56453
Epoch 020: | Loss: 0.55632
Epoch 021: | Loss: 0.55189
Epoch 022: | Loss: 0.54705
Epoch 023: | Loss: 0.53970
Epoch 024: | Loss: 0.53930
Epoch 025: | Loss: 0.53416
Epoch 026: | Loss: 0.53184
Epoch 027: | Loss: 0.52987
Epoch 028: | Loss: 0.52579
Epoch 029: | Loss: 0.52049
Epoch 030: | Loss: 0.51741
Epoch 031: | Loss: 0.51316
Epoch 032: | Loss: 0.51175
Epoch 033: | Loss: 0.50419
Epoch 034: | Loss: 0.49745
Epoch 035: | Loss: 0.49416
Epoch 036: | Loss: 0.48993
Epoch 037: | Loss: 0.48436
Epoch 038: | Loss: 0.47819
Epoch 039: | Loss: 0.47867
Epoch 040: | Loss: 0.47001
Epoch 041: | Loss: 0.47147
Epoch 042: | Loss: 0.46441
Epoch 043: | Loss: 0.46331
Epoch 044: | Loss: 0.45883
Epoch 045: | Loss: 0.45442
Epoch 046: | Loss: 0.45388
Epoch 047: | Loss: 0.44653
Epoch 048: | Loss: 0.44242
Epoch 049: | Loss: 0.44059
Epoch 050: | Loss: 0.43423
Epoch 051: | Loss: 0.43467
Epoch 052: | Loss: 0.42981
Epoch 053: | Loss: 0.42731
Epoch 054: | Loss: 0.42109
Epoch 055: | Loss: 0.42136
Epoch 056: | Loss: 0.41459
Epoch 057: | Loss: 0.40537
Epoch 058: | Loss: 0.40837
Epoch 059: | Loss: 0.40592
Epoch 060: | Loss: 0.40135
Epoch 061: | Loss: 0.39791
Epoch 062: | Loss: 0.39788
Epoch 063: | Loss: 0.38974
Epoch 064: | Loss: 0.38906
Epoch 065: | Loss: 0.39162
Epoch 066: | Loss: 0.38085
Epoch 067: | Loss: 0.38215
Epoch 068: | Loss: 0.37864
Epoch 069: | Loss: 0.37519
Epoch 070: | Loss: 0.37242
Epoch 071: | Loss: 0.36722
Epoch 072: | Loss: 0.36777
Epoch 073: | Loss: 0.36613
Epoch 074: | Loss: 0.36016
Epoch 075: | Loss: 0.35992
Epoch 076: | Loss: 0.35760
Epoch 077: | Loss: 0.35515
Epoch 078: | Loss: 0.35306
Epoch 079: | Loss: 0.35542
Epoch 080: | Loss: 0.34790
Epoch 081: | Loss: 0.34475
Epoch 082: | Loss: 0.34690
Epoch 083: | Loss: 0.34291
Epoch 084: | Loss: 0.33929
Epoch 085: | Loss: 0.33796
Epoch 086: | Loss: 0.34351
Epoch 087: | Loss: 0.34197
Epoch 088: | Loss: 0.33485
Epoch 089: | Loss: 0.33245
Epoch 090: | Loss: 0.33510
Epoch 091: | Loss: 0.33053
Epoch 092: | Loss: 0.33238
Epoch 093: | Loss: 0.33399
Epoch 094: | Loss: 0.32264
Epoch 095: | Loss: 0.32393
Epoch 096: | Loss: 0.32382
Epoch 097: | Loss: 0.32361
Epoch 098: | Loss: 0.32136
Epoch 099: | Loss: 0.32072
Epoch 100: | Loss: 0.31707
Epoch 101: | Loss: 0.31972
Epoch 102: | Loss: 0.31466
Epoch 103: | Loss: 0.31544
Epoch 104: | Loss: 0.31411
Epoch 105: | Loss: 0.31665
Epoch 106: | Loss: 0.31273
Epoch 107: | Loss: 0.31510
Epoch 108: | Loss: 0.30695
Epoch 109: | Loss: 0.31174
Epoch 110: | Loss: 0.31033
Epoch 111: | Loss: 0.30963
Epoch 112: | Loss: 0.30437
Epoch 113: | Loss: 0.30970
Epoch 114: | Loss: 0.30513
Epoch 115: | Loss: 0.30366
Epoch 116: | Loss: 0.30462
Epoch 117: | Loss: 0.30561
Epoch 118: | Loss: 0.30181
Epoch 119: | Loss: 0.30307
Epoch 120: | Loss: 0.30467
Epoch 121: | Loss: 0.30014
Epoch 122: | Loss: 0.29637
Epoch 123: | Loss: 0.30220
Epoch 124: | Loss: 0.29798
Epoch 125: | Loss: 0.29837
Epoch 126: | Loss: 0.29843
Epoch 127: | Loss: 0.29843
Epoch 128: | Loss: 0.29712
Epoch 129: | Loss: 0.29821
Epoch 130: | Loss: 0.29410
Epoch 131: | Loss: 0.29858
Epoch 132: | Loss: 0.29389
Epoch 133: | Loss: 0.29292
Epoch 134: | Loss: 0.29250
Epoch 135: | Loss: 0.29376
Epoch 136: | Loss: 0.29291
Epoch 137: | Loss: 0.29332
Epoch 138: | Loss: 0.29291
Epoch 139: | Loss: 0.29436
Epoch 140: | Loss: 0.29095
Epoch 141: | Loss: 0.28657
Epoch 142: | Loss: 0.28983
Epoch 143: | Loss: 0.29553
Epoch 144: | Loss: 0.29131
Epoch 145: | Loss: 0.28833
Epoch 146: | Loss: 0.29309
Epoch 147: | Loss: 0.28995
Epoch 148: | Loss: 0.29126
Epoch 149: | Loss: 0.28900
Epoch 150: | Loss: 0.29222
Epoch 151: | Loss: 0.28569
Epoch 152: | Loss: 0.29169
Epoch 153: | Loss: 0.28814
Epoch 154: | Loss: 0.28956
Epoch 155: | Loss: 0.28631
Epoch 156: | Loss: 0.28336
Epoch 157: | Loss: 0.28612
Epoch 158: | Loss: 0.28573
Epoch 159: | Loss: 0.28961
Epoch 160: | Loss: 0.28406
Epoch 161: | Loss: 0.28487
Epoch 162: | Loss: 0.28427
Epoch 163: | Loss: 0.28671
Epoch 164: | Loss: 0.28659
Epoch 165: | Loss: 0.28587
Epoch 166: | Loss: 0.28371
Epoch 167: | Loss: 0.28443
Epoch 168: | Loss: 0.28462
Epoch 169: | Loss: 0.28275
Epoch 170: | Loss: 0.27920
Epoch 171: | Loss: 0.28269
Epoch 172: | Loss: 0.28339
Epoch 173: | Loss: 0.28523
Epoch 174: | Loss: 0.28242
Epoch 175: | Loss: 0.28563
Epoch 176: | Loss: 0.28019
Epoch 177: | Loss: 0.28562
Epoch 178: | Loss: 0.27955
Epoch 179: | Loss: 0.28222
Epoch 180: | Loss: 0.28010
Epoch 181: | Loss: 0.27887
Epoch 182: | Loss: 0.27868
Epoch 183: | Loss: 0.27819
Epoch 184: | Loss: 0.28065
Epoch 185: | Loss: 0.27908
Epoch 186: | Loss: 0.27945
Epoch 187: | Loss: 0.27989
Epoch 188: | Loss: 0.27803
Epoch 189: | Loss: 0.27137
Epoch 190: | Loss: 0.27842
Epoch 191: | Loss: 0.28045
Epoch 192: | Loss: 0.27770
Epoch 193: | Loss: 0.27289
Epoch 194: | Loss: 0.27262
Epoch 195: | Loss: 0.27431
Epoch 196: | Loss: 0.27748
Epoch 197: | Loss: 0.27121
Epoch 198: | Loss: 0.27163
Epoch 199: | Loss: 0.26923
Accuracy: 0.8875934829059828
Epoch 000: | Loss: 1.53351
Epoch 001: | Loss: 1.25344
Epoch 002: | Loss: 0.88490
Epoch 003: | Loss: 0.75974
Epoch 004: | Loss: 0.69530
Epoch 005: | Loss: 0.65732
Epoch 006: | Loss: 0.64025
Epoch 007: | Loss: 0.61673
Epoch 008: | Loss: 0.59922
Epoch 009: | Loss: 0.58273
Epoch 010: | Loss: 0.56762
Epoch 011: | Loss: 0.55714
Epoch 012: | Loss: 0.53955
Epoch 013: | Loss: 0.52287
Epoch 014: | Loss: 0.50950
Epoch 015: | Loss: 0.50069
Epoch 016: | Loss: 0.48724
Epoch 017: | Loss: 0.47451
Epoch 018: | Loss: 0.47448
Epoch 019: | Loss: 0.46534
Epoch 020: | Loss: 0.46166
Epoch 021: | Loss: 0.44794
Epoch 022: | Loss: 0.44302
Epoch 023: | Loss: 0.43909
Epoch 024: | Loss: 0.43414
Epoch 025: | Loss: 0.42424
Epoch 026: | Loss: 0.42676
Epoch 027: | Loss: 0.41474
Epoch 028: | Loss: 0.41011
Epoch 029: | Loss: 0.40752
Epoch 030: | Loss: 0.40520
Epoch 031: | Loss: 0.39775
Epoch 032: | Loss: 0.39292
Epoch 033: | Loss: 0.38763
Epoch 034: | Loss: 0.38533
Epoch 035: | Loss: 0.37865
Epoch 036: | Loss: 0.37023
Epoch 037: | Loss: 0.37037
Epoch 038: | Loss: 0.36446
Epoch 039: | Loss: 0.35631
Epoch 040: | Loss: 0.35846
Epoch 041: | Loss: 0.35412
Epoch 042: | Loss: 0.35114
Epoch 043: | Loss: 0.34863
Epoch 044: | Loss: 0.34940
Epoch 045: | Loss: 0.33861
Epoch 046: | Loss: 0.33493
Epoch 047: | Loss: 0.33429
Epoch 048: | Loss: 0.33282
Epoch 049: | Loss: 0.32988
Epoch 050: | Loss: 0.32501
Epoch 051: | Loss: 0.32349
Epoch 052: | Loss: 0.31974
Epoch 053: | Loss: 0.32026
Epoch 054: | Loss: 0.31853
Epoch 055: | Loss: 0.31355
Epoch 056: | Loss: 0.31440
Epoch 057: | Loss: 0.30808
Epoch 058: | Loss: 0.30788
Epoch 059: | Loss: 0.30514
Epoch 060: | Loss: 0.30033
Epoch 061: | Loss: 0.29294
Epoch 062: | Loss: 0.29302
Epoch 063: | Loss: 0.29239
Epoch 064: | Loss: 0.29230
Epoch 065: | Loss: 0.29254
Epoch 066: | Loss: 0.29231
Epoch 067: | Loss: 0.28390
Epoch 068: | Loss: 0.28246
Epoch 069: | Loss: 0.27925
Epoch 070: | Loss: 0.28046
Epoch 071: | Loss: 0.27556
Epoch 072: | Loss: 0.27887
Epoch 073: | Loss: 0.26984
Epoch 074: | Loss: 0.27191
Epoch 075: | Loss: 0.26955
Epoch 076: | Loss: 0.26944
Epoch 077: | Loss: 0.26935
Epoch 078: | Loss: 0.26603
Epoch 079: | Loss: 0.26578
Epoch 080: | Loss: 0.26153
Epoch 081: | Loss: 0.26202
Epoch 082: | Loss: 0.26562
Epoch 083: | Loss: 0.26184
Epoch 084: | Loss: 0.25503
Epoch 085: | Loss: 0.26085
Epoch 086: | Loss: 0.25720
Epoch 087: | Loss: 0.25443
Epoch 088: | Loss: 0.25015
Epoch 089: | Loss: 0.25261
Epoch 090: | Loss: 0.24843
Epoch 091: | Loss: 0.24877
Epoch 092: | Loss: 0.24543
Epoch 093: | Loss: 0.24866
Epoch 094: | Loss: 0.24126
Epoch 095: | Loss: 0.24778
Epoch 096: | Loss: 0.24009
Epoch 097: | Loss: 0.24260
Epoch 098: | Loss: 0.23754
Epoch 099: | Loss: 0.23708
Epoch 100: | Loss: 0.24345
Epoch 101: | Loss: 0.24067
Epoch 102: | Loss: 0.24131
Epoch 103: | Loss: 0.23674
Epoch 104: | Loss: 0.23345
Epoch 105: | Loss: 0.23277
Epoch 106: | Loss: 0.23536
Epoch 107: | Loss: 0.23011
Epoch 108: | Loss: 0.23345
Epoch 109: | Loss: 0.23039
Epoch 110: | Loss: 0.23382
Epoch 111: | Loss: 0.23341
Epoch 112: | Loss: 0.22685
Epoch 113: | Loss: 0.23099
Epoch 114: | Loss: 0.22706
Epoch 115: | Loss: 0.22695
Epoch 116: | Loss: 0.22707
Epoch 117: | Loss: 0.22481
Epoch 118: | Loss: 0.23058
Epoch 119: | Loss: 0.22535
Epoch 120: | Loss: 0.22332
Epoch 121: | Loss: 0.22499
Epoch 122: | Loss: 0.22303
Epoch 123: | Loss: 0.22594
Epoch 124: | Loss: 0.21969
Epoch 125: | Loss: 0.21998
Epoch 126: | Loss: 0.22119
Epoch 127: | Loss: 0.22450
Epoch 128: | Loss: 0.22168
Epoch 129: | Loss: 0.22172
Epoch 130: | Loss: 0.22178
Epoch 131: | Loss: 0.21730
Epoch 132: | Loss: 0.21566
Epoch 133: | Loss: 0.22093
Epoch 134: | Loss: 0.22064
Epoch 135: | Loss: 0.21580
Epoch 136: | Loss: 0.21368
Epoch 137: | Loss: 0.21667
Epoch 138: | Loss: 0.21708
Epoch 139: | Loss: 0.21724
Epoch 140: | Loss: 0.21168
Epoch 141: | Loss: 0.21241
Epoch 142: | Loss: 0.21291
Epoch 143: | Loss: 0.21305
Epoch 144: | Loss: 0.21467
Epoch 145: | Loss: 0.21321
Epoch 146: | Loss: 0.21472
Epoch 147: | Loss: 0.21232
Epoch 148: | Loss: 0.21431
Epoch 149: | Loss: 0.21547
Epoch 150: | Loss: 0.21150
Epoch 151: | Loss: 0.21429
Epoch 152: | Loss: 0.21641
Epoch 153: | Loss: 0.20775
Epoch 154: | Loss: 0.21455
Epoch 155: | Loss: 0.21059
Epoch 156: | Loss: 0.21138
Epoch 157: | Loss: 0.20916
Epoch 158: | Loss: 0.21165
Epoch 159: | Loss: 0.21151
Epoch 160: | Loss: 0.21253
Epoch 161: | Loss: 0.20985
Epoch 162: | Loss: 0.21540
Epoch 163: | Loss: 0.21251
Epoch 164: | Loss: 0.21014
Epoch 165: | Loss: 0.21063
Epoch 166: | Loss: 0.21570
Epoch 167: | Loss: 0.21123
Epoch 168: | Loss: 0.20654
Epoch 169: | Loss: 0.20781
Epoch 170: | Loss: 0.20978
Epoch 171: | Loss: 0.20639
Epoch 172: | Loss: 0.21177
Epoch 173: | Loss: 0.20594
Epoch 174: | Loss: 0.20573
Epoch 175: | Loss: 0.21036
Epoch 176: | Loss: 0.20960
Epoch 177: | Loss: 0.20801
Epoch 178: | Loss: 0.20810
Epoch 179: | Loss: 0.20803
Epoch 180: | Loss: 0.20900
Epoch 181: | Loss: 0.20906
Epoch 182: | Loss: 0.20495
Epoch 183: | Loss: 0.20851
Epoch 184: | Loss: 0.20736
Epoch 185: | Loss: 0.20389
Epoch 186: | Loss: 0.20735
Epoch 187: | Loss: 0.20754
Epoch 188: | Loss: 0.20477
Epoch 189: | Loss: 0.20466
Epoch 190: | Loss: 0.20781
Epoch 191: | Loss: 0.20397
Epoch 192: | Loss: 0.20290
Epoch 193: | Loss: 0.20472
Epoch 194: | Loss: 0.20428
Epoch 195: | Loss: 0.20296
Epoch 196: | Loss: 0.20214
Epoch 197: | Loss: 0.20164
Epoch 198: | Loss: 0.19915
Epoch 199: | Loss: 0.20489
Accuracy: 0.9191666666666666
Epoch 000: | Loss: 1.53067
Epoch 001: | Loss: 1.04506
Epoch 002: | Loss: 0.78887
Epoch 003: | Loss: 0.72717
Epoch 004: | Loss: 0.70084
Epoch 005: | Loss: 0.68586
Epoch 006: | Loss: 0.66737
Epoch 007: | Loss: 0.65482
Epoch 008: | Loss: 0.64484
Epoch 009: | Loss: 0.62642
Epoch 010: | Loss: 0.61313
Epoch 011: | Loss: 0.60230
Epoch 012: | Loss: 0.59087
Epoch 013: | Loss: 0.58535
Epoch 014: | Loss: 0.57617
Epoch 015: | Loss: 0.57137
Epoch 016: | Loss: 0.56188
Epoch 017: | Loss: 0.55414
Epoch 018: | Loss: 0.55302
Epoch 019: | Loss: 0.54239
Epoch 020: | Loss: 0.53495
Epoch 021: | Loss: 0.52838
Epoch 022: | Loss: 0.52420
Epoch 023: | Loss: 0.52289
Epoch 024: | Loss: 0.51399
Epoch 025: | Loss: 0.50821
Epoch 026: | Loss: 0.50134
Epoch 027: | Loss: 0.50011
Epoch 028: | Loss: 0.49291
Epoch 029: | Loss: 0.48189
Epoch 030: | Loss: 0.47880
Epoch 031: | Loss: 0.47424
Epoch 032: | Loss: 0.46373
Epoch 033: | Loss: 0.46503
Epoch 034: | Loss: 0.45342
Epoch 035: | Loss: 0.45654
Epoch 036: | Loss: 0.44933
Epoch 037: | Loss: 0.44515
Epoch 038: | Loss: 0.43793
Epoch 039: | Loss: 0.43118
Epoch 040: | Loss: 0.42911
Epoch 041: | Loss: 0.42571
Epoch 042: | Loss: 0.41300
Epoch 043: | Loss: 0.41151
Epoch 044: | Loss: 0.40966
Epoch 045: | Loss: 0.40637
Epoch 046: | Loss: 0.40081
Epoch 047: | Loss: 0.39545
Epoch 048: | Loss: 0.39522
Epoch 049: | Loss: 0.39033
Epoch 050: | Loss: 0.38644
Epoch 051: | Loss: 0.38339
Epoch 052: | Loss: 0.37635
Epoch 053: | Loss: 0.37546
Epoch 054: | Loss: 0.37224
Epoch 055: | Loss: 0.36775
Epoch 056: | Loss: 0.36593
Epoch 057: | Loss: 0.36866
Epoch 058: | Loss: 0.36394
Epoch 059: | Loss: 0.35007
Epoch 060: | Loss: 0.35493
Epoch 061: | Loss: 0.35351
Epoch 062: | Loss: 0.34876
Epoch 063: | Loss: 0.34586
Epoch 064: | Loss: 0.34386
Epoch 065: | Loss: 0.34050
Epoch 066: | Loss: 0.33844
Epoch 067: | Loss: 0.33477
Epoch 068: | Loss: 0.33406
Epoch 069: | Loss: 0.33014
Epoch 070: | Loss: 0.32413
Epoch 071: | Loss: 0.32476
Epoch 072: | Loss: 0.32079
Epoch 073: | Loss: 0.31991
Epoch 074: | Loss: 0.31808
Epoch 075: | Loss: 0.31385
Epoch 076: | Loss: 0.31606
Epoch 077: | Loss: 0.30928
Epoch 078: | Loss: 0.30711
Epoch 079: | Loss: 0.30649
Epoch 080: | Loss: 0.30447
Epoch 081: | Loss: 0.30324
Epoch 082: | Loss: 0.30157
Epoch 083: | Loss: 0.30179
Epoch 084: | Loss: 0.29849
Epoch 085: | Loss: 0.29372
Epoch 086: | Loss: 0.29671
Epoch 087: | Loss: 0.29357
Epoch 088: | Loss: 0.29413
Epoch 089: | Loss: 0.28613
Epoch 090: | Loss: 0.28807
Epoch 091: | Loss: 0.28991
Epoch 092: | Loss: 0.28235
Epoch 093: | Loss: 0.28270
Epoch 094: | Loss: 0.28151
Epoch 095: | Loss: 0.28090
Epoch 096: | Loss: 0.27702
Epoch 097: | Loss: 0.28125
Epoch 098: | Loss: 0.27662
Epoch 099: | Loss: 0.27387
Epoch 100: | Loss: 0.27749
Epoch 101: | Loss: 0.27140
Epoch 102: | Loss: 0.27098
Epoch 103: | Loss: 0.26960
Epoch 104: | Loss: 0.26649
Epoch 105: | Loss: 0.26483
Epoch 106: | Loss: 0.27002
Epoch 107: | Loss: 0.26825
Epoch 108: | Loss: 0.26636
Epoch 109: | Loss: 0.26337
Epoch 110: | Loss: 0.26441
Epoch 111: | Loss: 0.26059
Epoch 112: | Loss: 0.26545
Epoch 113: | Loss: 0.25955
Epoch 114: | Loss: 0.26365
Epoch 115: | Loss: 0.26417
Epoch 116: | Loss: 0.25677
Epoch 117: | Loss: 0.25925
Epoch 118: | Loss: 0.25684
Epoch 119: | Loss: 0.25874
Epoch 120: | Loss: 0.26109
Epoch 121: | Loss: 0.25541
Epoch 122: | Loss: 0.25497
Epoch 123: | Loss: 0.25370
Epoch 124: | Loss: 0.25713
Epoch 125: | Loss: 0.25241
Epoch 126: | Loss: 0.25127
Epoch 127: | Loss: 0.25326
Epoch 128: | Loss: 0.25154
Epoch 129: | Loss: 0.24920
Epoch 130: | Loss: 0.25125
Epoch 131: | Loss: 0.25313
Epoch 132: | Loss: 0.24691
Epoch 133: | Loss: 0.25219
Epoch 134: | Loss: 0.25166
Epoch 135: | Loss: 0.25225
Epoch 136: | Loss: 0.24683
Epoch 137: | Loss: 0.24492
Epoch 138: | Loss: 0.25052
Epoch 139: | Loss: 0.24509
Epoch 140: | Loss: 0.24847
Epoch 141: | Loss: 0.24634
Epoch 142: | Loss: 0.24178
Epoch 143: | Loss: 0.24937
Epoch 144: | Loss: 0.24156
Epoch 145: | Loss: 0.24704
Epoch 146: | Loss: 0.24784
Epoch 147: | Loss: 0.24330
Epoch 148: | Loss: 0.24252
Epoch 149: | Loss: 0.24359
Epoch 150: | Loss: 0.24009
Epoch 151: | Loss: 0.24320
Epoch 152: | Loss: 0.24172
Epoch 153: | Loss: 0.24465
Epoch 154: | Loss: 0.24455
Epoch 155: | Loss: 0.24423
Epoch 156: | Loss: 0.24150
Epoch 157: | Loss: 0.24122
Epoch 158: | Loss: 0.24286
Epoch 159: | Loss: 0.24004
Epoch 160: | Loss: 0.24473
Epoch 161: | Loss: 0.23748
Epoch 162: | Loss: 0.24132
Epoch 163: | Loss: 0.23766
Epoch 164: | Loss: 0.23832
Epoch 165: | Loss: 0.24459
Epoch 166: | Loss: 0.23821
Epoch 167: | Loss: 0.24064
Epoch 168: | Loss: 0.24141
Epoch 169: | Loss: 0.23964
Epoch 170: | Loss: 0.24030
Epoch 171: | Loss: 0.23458
Epoch 172: | Loss: 0.23764
Epoch 173: | Loss: 0.23768
Epoch 174: | Loss: 0.23847
Epoch 175: | Loss: 0.23435
Epoch 176: | Loss: 0.23757
Epoch 177: | Loss: 0.23647
Epoch 178: | Loss: 0.23328
Epoch 179: | Loss: 0.23819
Epoch 180: | Loss: 0.23725
Epoch 181: | Loss: 0.23518
Epoch 182: | Loss: 0.23254
Epoch 183: | Loss: 0.23660
Epoch 184: | Loss: 0.23542
Epoch 185: | Loss: 0.23257
Epoch 186: | Loss: 0.23018
Epoch 187: | Loss: 0.23653
Epoch 188: | Loss: 0.23284
Epoch 189: | Loss: 0.23031
Epoch 190: | Loss: 0.23244
Epoch 191: | Loss: 0.23002
Epoch 192: | Loss: 0.22945
Epoch 193: | Loss: 0.23233
Epoch 194: | Loss: 0.22807
Epoch 195: | Loss: 0.22439
Epoch 196: | Loss: 0.22917
Epoch 197: | Loss: 0.23063
Epoch 198: | Loss: 0.22831
Epoch 199: | Loss: 0.23229
Accuracy: 0.9117334401709402
Epoch 000: | Loss: 1.60742
Epoch 001: | Loss: 1.56385
Epoch 002: | Loss: 1.54225
Epoch 003: | Loss: 1.47511
Epoch 004: | Loss: 1.22830
Epoch 005: | Loss: 0.97370
Epoch 006: | Loss: 0.86665
Epoch 007: | Loss: 0.80262
Epoch 008: | Loss: 0.74243
Epoch 009: | Loss: 0.70886
Epoch 010: | Loss: 0.69066
Epoch 011: | Loss: 0.67730
Epoch 012: | Loss: 0.67201
Epoch 013: | Loss: 0.66281
Epoch 014: | Loss: 0.65731
Epoch 015: | Loss: 0.65367
Epoch 016: | Loss: 0.64284
Epoch 017: | Loss: 0.63690
Epoch 018: | Loss: 0.62752
Epoch 019: | Loss: 0.62400
Epoch 020: | Loss: 0.61243
Epoch 021: | Loss: 0.61853
Epoch 022: | Loss: 0.60715
Epoch 023: | Loss: 0.60320
Epoch 024: | Loss: 0.59584
Epoch 025: | Loss: 0.59374
Epoch 026: | Loss: 0.58861
Epoch 027: | Loss: 0.57944
Epoch 028: | Loss: 0.57358
Epoch 029: | Loss: 0.56826
Epoch 030: | Loss: 0.56384
Epoch 031: | Loss: 0.56075
Epoch 032: | Loss: 0.55805
Epoch 033: | Loss: 0.55665
Epoch 034: | Loss: 0.55226
Epoch 035: | Loss: 0.54947
Epoch 036: | Loss: 0.54515
Epoch 037: | Loss: 0.54697
Epoch 038: | Loss: 0.53858
Epoch 039: | Loss: 0.53493
Epoch 040: | Loss: 0.53652
Epoch 041: | Loss: 0.53190
Epoch 042: | Loss: 0.52701
Epoch 043: | Loss: 0.52681
Epoch 044: | Loss: 0.51830
Epoch 045: | Loss: 0.51171
Epoch 046: | Loss: 0.50774
Epoch 047: | Loss: 0.49849
Epoch 048: | Loss: 0.48681
Epoch 049: | Loss: 0.47241
Epoch 050: | Loss: 0.45873
Epoch 051: | Loss: 0.44972
Epoch 052: | Loss: 0.44452
Epoch 053: | Loss: 0.43976
Epoch 054: | Loss: 0.42912
Epoch 055: | Loss: 0.43027
Epoch 056: | Loss: 0.42863
Epoch 057: | Loss: 0.42471
Epoch 058: | Loss: 0.42268
Epoch 059: | Loss: 0.41980
Epoch 060: | Loss: 0.41679
Epoch 061: | Loss: 0.41629
Epoch 062: | Loss: 0.41070
Epoch 063: | Loss: 0.41043
Epoch 064: | Loss: 0.40847
Epoch 065: | Loss: 0.41322
Epoch 066: | Loss: 0.40530
Epoch 067: | Loss: 0.39946
Epoch 068: | Loss: 0.40154
Epoch 069: | Loss: 0.40419
Epoch 070: | Loss: 0.39506
Epoch 071: | Loss: 0.39548
Epoch 072: | Loss: 0.39371
Epoch 073: | Loss: 0.39497
Epoch 074: | Loss: 0.39473
Epoch 075: | Loss: 0.39162
Epoch 076: | Loss: 0.39338
Epoch 077: | Loss: 0.38283
Epoch 078: | Loss: 0.38198
Epoch 079: | Loss: 0.38678
Epoch 080: | Loss: 0.38213
Epoch 081: | Loss: 0.38300
Epoch 082: | Loss: 0.38397
Epoch 083: | Loss: 0.38286
Epoch 084: | Loss: 0.37987
Epoch 085: | Loss: 0.37592
Epoch 086: | Loss: 0.37757
Epoch 087: | Loss: 0.37574
Epoch 088: | Loss: 0.37424
Epoch 089: | Loss: 0.37987
Epoch 090: | Loss: 0.37427
Epoch 091: | Loss: 0.37324
Epoch 092: | Loss: 0.36993
Epoch 093: | Loss: 0.36743
Epoch 094: | Loss: 0.37079
Epoch 095: | Loss: 0.36897
Epoch 096: | Loss: 0.36808
Epoch 097: | Loss: 0.36489
Epoch 098: | Loss: 0.36964
Epoch 099: | Loss: 0.36422
Epoch 100: | Loss: 0.36472
Epoch 101: | Loss: 0.36569
Epoch 102: | Loss: 0.35517
Epoch 103: | Loss: 0.35370
Epoch 104: | Loss: 0.36006
Epoch 105: | Loss: 0.35545
Epoch 106: | Loss: 0.35991
Epoch 107: | Loss: 0.35911
Epoch 108: | Loss: 0.35535
Epoch 109: | Loss: 0.35379
Epoch 110: | Loss: 0.35245
Epoch 111: | Loss: 0.35061
Epoch 112: | Loss: 0.35279
Epoch 113: | Loss: 0.35394
Epoch 114: | Loss: 0.34962
Epoch 115: | Loss: 0.35269
Epoch 116: | Loss: 0.34666
Epoch 117: | Loss: 0.34660
Epoch 118: | Loss: 0.34612
Epoch 119: | Loss: 0.34741
Epoch 120: | Loss: 0.34808
Epoch 121: | Loss: 0.34330
Epoch 122: | Loss: 0.34591
Epoch 123: | Loss: 0.34569
Epoch 124: | Loss: 0.34208
Epoch 125: | Loss: 0.34264
Epoch 126: | Loss: 0.34139
Epoch 127: | Loss: 0.34239
Epoch 128: | Loss: 0.33999
Epoch 129: | Loss: 0.33898
Epoch 130: | Loss: 0.33992
Epoch 131: | Loss: 0.33884
Epoch 132: | Loss: 0.33815
Epoch 133: | Loss: 0.33548
Epoch 134: | Loss: 0.33804
Epoch 135: | Loss: 0.33748
Epoch 136: | Loss: 0.33692
Epoch 137: | Loss: 0.33554
Epoch 138: | Loss: 0.33116
Epoch 139: | Loss: 0.33259
Epoch 140: | Loss: 0.33149
Epoch 141: | Loss: 0.33058
Epoch 142: | Loss: 0.33270
Epoch 143: | Loss: 0.33180
Epoch 144: | Loss: 0.33012
Epoch 145: | Loss: 0.33514
Epoch 146: | Loss: 0.32919
Epoch 147: | Loss: 0.33331
Epoch 148: | Loss: 0.32966
Epoch 149: | Loss: 0.32899
Epoch 150: | Loss: 0.32575
Epoch 151: | Loss: 0.32783
Epoch 152: | Loss: 0.32569
Epoch 153: | Loss: 0.32813
Epoch 154: | Loss: 0.32570
Epoch 155: | Loss: 0.32550
Epoch 156: | Loss: 0.32363
Epoch 157: | Loss: 0.32199
Epoch 158: | Loss: 0.32625
Epoch 159: | Loss: 0.32568
Epoch 160: | Loss: 0.32133
Epoch 161: | Loss: 0.32244
Epoch 162: | Loss: 0.32296
Epoch 163: | Loss: 0.32219
Epoch 164: | Loss: 0.31943
Epoch 165: | Loss: 0.32182
Epoch 166: | Loss: 0.32348
Epoch 167: | Loss: 0.32084
Epoch 168: | Loss: 0.32149
Epoch 169: | Loss: 0.32137
Epoch 170: | Loss: 0.32189
Epoch 171: | Loss: 0.32349
Epoch 172: | Loss: 0.32154
Epoch 173: | Loss: 0.32443
Epoch 174: | Loss: 0.31984
Epoch 175: | Loss: 0.31993
Epoch 176: | Loss: 0.32119
Epoch 177: | Loss: 0.31928
Epoch 178: | Loss: 0.31607
Epoch 179: | Loss: 0.32085
Epoch 180: | Loss: 0.31668
Epoch 181: | Loss: 0.32080
Epoch 182: | Loss: 0.32070
Epoch 183: | Loss: 0.31737
Epoch 184: | Loss: 0.31765
Epoch 185: | Loss: 0.31836
Epoch 186: | Loss: 0.31929
Epoch 187: | Loss: 0.31871
Epoch 188: | Loss: 0.31572
Epoch 189: | Loss: 0.31633
Epoch 190: | Loss: 0.31468
Epoch 191: | Loss: 0.31306
Epoch 192: | Loss: 0.31490
Epoch 193: | Loss: 0.31762
Epoch 194: | Loss: 0.31277
Epoch 195: | Loss: 0.31746
Epoch 196: | Loss: 0.31350
Epoch 197: | Loss: 0.32061
Epoch 198: | Loss: 0.31394
Epoch 199: | Loss: 0.31383
Accuracy: 0.3136992521367521
Epoch 000: | Loss: 1.53325
Epoch 001: | Loss: 1.49894
Epoch 002: | Loss: 1.49553
Epoch 003: | Loss: 1.49429
Epoch 004: | Loss: 1.49345
Epoch 005: | Loss: 1.49413
Epoch 006: | Loss: 1.49197
Epoch 007: | Loss: 1.49229
Epoch 008: | Loss: 1.49392
Epoch 009: | Loss: 1.49328
Epoch 010: | Loss: 1.49361
Epoch 011: | Loss: 1.49267
Epoch 012: | Loss: 1.49088
Epoch 013: | Loss: 1.49315
Epoch 014: | Loss: 1.48883
Epoch 015: | Loss: 1.48761
Epoch 016: | Loss: 1.47032
Epoch 017: | Loss: 1.43764
Epoch 018: | Loss: 1.39730
Epoch 019: | Loss: 1.35446
Epoch 020: | Loss: 1.31708
Epoch 021: | Loss: 1.27949
Epoch 022: | Loss: 1.25443
Epoch 023: | Loss: 1.23064
Epoch 024: | Loss: 1.20461
Epoch 025: | Loss: 1.17986
Epoch 026: | Loss: 1.15742
Epoch 027: | Loss: 1.13886
Epoch 028: | Loss: 1.12915
Epoch 029: | Loss: 1.10424
Epoch 030: | Loss: 1.09055
Epoch 031: | Loss: 1.07138
Epoch 032: | Loss: 1.05989
Epoch 033: | Loss: 1.04863
Epoch 034: | Loss: 1.03502
Epoch 035: | Loss: 1.02783
Epoch 036: | Loss: 1.01458
Epoch 037: | Loss: 1.00055
Epoch 038: | Loss: 0.99084
Epoch 039: | Loss: 0.98461
Epoch 040: | Loss: 0.96828
Epoch 041: | Loss: 0.96251
Epoch 042: | Loss: 0.95238
Epoch 043: | Loss: 0.94625
Epoch 044: | Loss: 0.93714
Epoch 045: | Loss: 0.92913
Epoch 046: | Loss: 0.91905
Epoch 047: | Loss: 0.90914
Epoch 048: | Loss: 0.90538
Epoch 049: | Loss: 0.89273
Epoch 050: | Loss: 0.89221
Epoch 051: | Loss: 0.88810
Epoch 052: | Loss: 0.88793
Epoch 053: | Loss: 0.87881
Epoch 054: | Loss: 0.86990
Epoch 055: | Loss: 0.86581
Epoch 056: | Loss: 0.86024
Epoch 057: | Loss: 0.86393
Epoch 058: | Loss: 0.85063
Epoch 059: | Loss: 0.84988
Epoch 060: | Loss: 0.84902
Epoch 061: | Loss: 0.84393
Epoch 062: | Loss: 0.83517
Epoch 063: | Loss: 0.83448
Epoch 064: | Loss: 0.83565
Epoch 065: | Loss: 0.83417
Epoch 066: | Loss: 0.83045
Epoch 067: | Loss: 0.82322
Epoch 068: | Loss: 0.81786
Epoch 069: | Loss: 0.82049
Epoch 070: | Loss: 0.82210
Epoch 071: | Loss: 0.81934
Epoch 072: | Loss: 0.81064
Epoch 073: | Loss: 0.81784
Epoch 074: | Loss: 0.81060
Epoch 075: | Loss: 0.81087
Epoch 076: | Loss: 0.80976
Epoch 077: | Loss: 0.80941
Epoch 078: | Loss: 0.80559
Epoch 079: | Loss: 0.81104
Epoch 080: | Loss: 0.79900
Epoch 081: | Loss: 0.80303
Epoch 082: | Loss: 0.79782
Epoch 083: | Loss: 0.79818
Epoch 084: | Loss: 0.79484
Epoch 085: | Loss: 0.79687
Epoch 086: | Loss: 0.79550
Epoch 087: | Loss: 0.78941
Epoch 088: | Loss: 0.79607
Epoch 089: | Loss: 0.79397
Epoch 090: | Loss: 0.79143
Epoch 091: | Loss: 0.79170
Epoch 092: | Loss: 0.78930
Epoch 093: | Loss: 0.78726
Epoch 094: | Loss: 0.78800
Epoch 095: | Loss: 0.78979
Epoch 096: | Loss: 0.78778
Epoch 097: | Loss: 0.78961
Epoch 098: | Loss: 0.78981
Epoch 099: | Loss: 0.78446
Epoch 100: | Loss: 0.78096
Epoch 101: | Loss: 0.78651
Epoch 102: | Loss: 0.77716
Epoch 103: | Loss: 0.78276
Epoch 104: | Loss: 0.78099
Epoch 105: | Loss: 0.78228
Epoch 106: | Loss: 0.77928
Epoch 107: | Loss: 0.78011
Epoch 108: | Loss: 0.78065
Epoch 109: | Loss: 0.78063
Epoch 110: | Loss: 0.78183
Epoch 111: | Loss: 0.77687
Epoch 112: | Loss: 0.77698
Epoch 113: | Loss: 0.77867
Epoch 114: | Loss: 0.77506
Epoch 115: | Loss: 0.77452
Epoch 116: | Loss: 0.77580
Epoch 117: | Loss: 0.77659
Epoch 118: | Loss: 0.77834
Epoch 119: | Loss: 0.77828
Epoch 120: | Loss: 0.77501
Epoch 121: | Loss: 0.77767
Epoch 122: | Loss: 0.77339
Epoch 123: | Loss: 0.77275
Epoch 124: | Loss: 0.77319
Epoch 125: | Loss: 0.77534
Epoch 126: | Loss: 0.77194
Epoch 127: | Loss: 0.77107
Epoch 128: | Loss: 0.77549
Epoch 129: | Loss: 0.77468
Epoch 130: | Loss: 0.77107
Epoch 131: | Loss: 0.77209
Epoch 132: | Loss: 0.76945
Epoch 133: | Loss: 0.77334
Epoch 134: | Loss: 0.77235
Epoch 135: | Loss: 0.77452
Epoch 136: | Loss: 0.77379
Epoch 137: | Loss: 0.77268
Epoch 138: | Loss: 0.77386
Epoch 139: | Loss: 0.77216
Epoch 140: | Loss: 0.76985
Epoch 141: | Loss: 0.77064
Epoch 142: | Loss: 0.77407
Epoch 143: | Loss: 0.77764
Epoch 144: | Loss: 0.77064
Epoch 145: | Loss: 0.77366
Epoch 146: | Loss: 0.76919
Epoch 147: | Loss: 0.77469
Epoch 148: | Loss: 0.77079
Epoch 149: | Loss: 0.77050
Epoch 150: | Loss: 0.77527
Epoch 151: | Loss: 0.76810
Epoch 152: | Loss: 0.77544
Epoch 153: | Loss: 0.77360
Epoch 154: | Loss: 0.77069
Epoch 155: | Loss: 0.77445
Epoch 156: | Loss: 0.77284
Epoch 157: | Loss: 0.77299
Epoch 158: | Loss: 0.77195
Epoch 159: | Loss: 0.77244
Epoch 160: | Loss: 0.77098
Epoch 161: | Loss: 0.76989
Epoch 162: | Loss: 0.77342
Epoch 163: | Loss: 0.76930
Epoch 164: | Loss: 0.77006
Epoch 165: | Loss: 0.77323
Epoch 166: | Loss: 0.77149
Epoch 167: | Loss: 0.77168
Epoch 168: | Loss: 0.77263
Epoch 169: | Loss: 0.77053
Epoch 170: | Loss: 0.77304
Epoch 171: | Loss: 0.77641
Epoch 172: | Loss: 0.77116
Epoch 173: | Loss: 0.77434
Epoch 174: | Loss: 0.76997
Epoch 175: | Loss: 0.76716
Epoch 176: | Loss: 0.77456
Epoch 177: | Loss: 0.76833
Epoch 178: | Loss: 0.77000
Epoch 179: | Loss: 0.76732
Epoch 180: | Loss: 0.77474
Epoch 181: | Loss: 0.77392
Epoch 182: | Loss: 0.76918
Epoch 183: | Loss: 0.77289
Epoch 184: | Loss: 0.77067
Epoch 185: | Loss: 0.77206
Epoch 186: | Loss: 0.77442
Epoch 187: | Loss: 0.77444
Epoch 188: | Loss: 0.77200
Epoch 189: | Loss: 0.76725
Epoch 190: | Loss: 0.76970
Epoch 191: | Loss: 0.77062
Epoch 192: | Loss: 0.77156
Epoch 193: | Loss: 0.76826
Epoch 194: | Loss: 0.76993
Epoch 195: | Loss: 0.77333
Epoch 196: | Loss: 0.76998
Epoch 197: | Loss: 0.77708
Epoch 198: | Loss: 0.76609
Epoch 199: | Loss: 0.76858
Accuracy: 0.682991452991453
Epoch 000: | Loss: 1.50964
Epoch 001: | Loss: 1.04444
Epoch 002: | Loss: 0.77459
Epoch 003: | Loss: 0.73616
Epoch 004: | Loss: 0.71795
Epoch 005: | Loss: 0.72033
Epoch 006: | Loss: 0.70202
Epoch 007: | Loss: 0.68405
Epoch 008: | Loss: 0.64857
Epoch 009: | Loss: 0.62400
Epoch 010: | Loss: 0.61875
Epoch 011: | Loss: 0.61014
Epoch 012: | Loss: 0.60632
Epoch 013: | Loss: 0.60074
Epoch 014: | Loss: 0.59686
Epoch 015: | Loss: 0.59281
Epoch 016: | Loss: 0.59054
Epoch 017: | Loss: 0.58305
Epoch 018: | Loss: 0.58852
Epoch 019: | Loss: 0.57849
Epoch 020: | Loss: 0.58203
Epoch 021: | Loss: 0.57317
Epoch 022: | Loss: 0.57426
Epoch 023: | Loss: 0.57189
Epoch 024: | Loss: 0.57338
Epoch 025: | Loss: 0.56782
Epoch 026: | Loss: 0.56853
Epoch 027: | Loss: 0.56789
Epoch 028: | Loss: 0.56310
Epoch 029: | Loss: 0.56152
Epoch 030: | Loss: 0.56128
Epoch 031: | Loss: 0.55787
Epoch 032: | Loss: 0.55336
Epoch 033: | Loss: 0.56090
Epoch 034: | Loss: 0.55801
Epoch 035: | Loss: 0.55494
Epoch 036: | Loss: 0.54818
Epoch 037: | Loss: 0.54893
Epoch 038: | Loss: 0.54503
Epoch 039: | Loss: 0.54579
Epoch 040: | Loss: 0.54119
Epoch 041: | Loss: 0.53970
Epoch 042: | Loss: 0.54134
Epoch 043: | Loss: 0.53968
Epoch 044: | Loss: 0.53741
Epoch 045: | Loss: 0.53987
Epoch 046: | Loss: 0.53188
Epoch 047: | Loss: 0.53413
Epoch 048: | Loss: 0.53088
Epoch 049: | Loss: 0.52766
Epoch 050: | Loss: 0.53413
Epoch 051: | Loss: 0.53150
Epoch 052: | Loss: 0.52584
Epoch 053: | Loss: 0.52719
Epoch 054: | Loss: 0.52416
Epoch 055: | Loss: 0.52392
Epoch 056: | Loss: 0.52121
Epoch 057: | Loss: 0.52389
Epoch 058: | Loss: 0.52047
Epoch 059: | Loss: 0.51452
Epoch 060: | Loss: 0.51557
Epoch 061: | Loss: 0.51914
Epoch 062: | Loss: 0.51722
Epoch 063: | Loss: 0.50852
Epoch 064: | Loss: 0.51657
Epoch 065: | Loss: 0.51649
Epoch 066: | Loss: 0.51245
Epoch 067: | Loss: 0.50828
Epoch 068: | Loss: 0.50966
Epoch 069: | Loss: 0.50985
Epoch 070: | Loss: 0.50709
Epoch 071: | Loss: 0.50568
Epoch 072: | Loss: 0.50311
Epoch 073: | Loss: 0.50215
Epoch 074: | Loss: 0.50648
Epoch 075: | Loss: 0.50215
Epoch 076: | Loss: 0.50239
Epoch 077: | Loss: 0.50276
Epoch 078: | Loss: 0.49722
Epoch 079: | Loss: 0.49764
Epoch 080: | Loss: 0.49917
Epoch 081: | Loss: 0.49909
Epoch 082: | Loss: 0.49642
Epoch 083: | Loss: 0.49965
Epoch 084: | Loss: 0.49197
Epoch 085: | Loss: 0.49613
Epoch 086: | Loss: 0.48852
Epoch 087: | Loss: 0.48788
Epoch 088: | Loss: 0.49266
Epoch 089: | Loss: 0.49124
Epoch 090: | Loss: 0.49157
Epoch 091: | Loss: 0.48795
Epoch 092: | Loss: 0.48367
Epoch 093: | Loss: 0.48785
Epoch 094: | Loss: 0.48565
Epoch 095: | Loss: 0.48736
Epoch 096: | Loss: 0.48803
Epoch 097: | Loss: 0.48322
Epoch 098: | Loss: 0.48429
Epoch 099: | Loss: 0.48389
Epoch 100: | Loss: 0.47797
Epoch 101: | Loss: 0.47761
Epoch 102: | Loss: 0.48402
Epoch 103: | Loss: 0.47979
Epoch 104: | Loss: 0.48237
Epoch 105: | Loss: 0.47638
Epoch 106: | Loss: 0.47629
Epoch 107: | Loss: 0.47866
Epoch 108: | Loss: 0.48096
Epoch 109: | Loss: 0.47867
Epoch 110: | Loss: 0.47413
Epoch 111: | Loss: 0.47788
Epoch 112: | Loss: 0.47438
Epoch 113: | Loss: 0.47668
Epoch 114: | Loss: 0.47583
Epoch 115: | Loss: 0.47898
Epoch 116: | Loss: 0.47696
Epoch 117: | Loss: 0.47634
Epoch 118: | Loss: 0.47533
Epoch 119: | Loss: 0.47015
Epoch 120: | Loss: 0.47362
Epoch 121: | Loss: 0.47090
Epoch 122: | Loss: 0.46946
Epoch 123: | Loss: 0.47463
Epoch 124: | Loss: 0.47187
Epoch 125: | Loss: 0.47463
Epoch 126: | Loss: 0.46935
Epoch 127: | Loss: 0.47151
Epoch 128: | Loss: 0.46993
Epoch 129: | Loss: 0.47335
Epoch 130: | Loss: 0.46819
Epoch 131: | Loss: 0.46987
Epoch 132: | Loss: 0.47083
Epoch 133: | Loss: 0.46868
Epoch 134: | Loss: 0.47371
Epoch 135: | Loss: 0.46700
Epoch 136: | Loss: 0.46782
Epoch 137: | Loss: 0.46585
Epoch 138: | Loss: 0.46946
Epoch 139: | Loss: 0.46887
Epoch 140: | Loss: 0.46711
Epoch 141: | Loss: 0.46815
Epoch 142: | Loss: 0.47145
Epoch 143: | Loss: 0.46952
Epoch 144: | Loss: 0.46969
Epoch 145: | Loss: 0.46697
Epoch 146: | Loss: 0.46878
Epoch 147: | Loss: 0.47091
Epoch 148: | Loss: 0.47130
Epoch 149: | Loss: 0.46651
Epoch 150: | Loss: 0.47030
Epoch 151: | Loss: 0.46937
Epoch 152: | Loss: 0.46819
Epoch 153: | Loss: 0.46507
Epoch 154: | Loss: 0.46903
Epoch 155: | Loss: 0.46576
Epoch 156: | Loss: 0.46957
Epoch 157: | Loss: 0.46896
Epoch 158: | Loss: 0.46674
Epoch 159: | Loss: 0.46814
Epoch 160: | Loss: 0.46905
Epoch 161: | Loss: 0.46693
Epoch 162: | Loss: 0.46702
Epoch 163: | Loss: 0.47102
Epoch 164: | Loss: 0.46628
Epoch 165: | Loss: 0.47371
Epoch 166: | Loss: 0.46423
Epoch 167: | Loss: 0.46862
Epoch 168: | Loss: 0.47039
Epoch 169: | Loss: 0.47002
Epoch 170: | Loss: 0.46450
Epoch 171: | Loss: 0.46875
Epoch 172: | Loss: 0.46574
Epoch 173: | Loss: 0.46755
Epoch 174: | Loss: 0.46914
Epoch 175: | Loss: 0.47093
Epoch 176: | Loss: 0.46993
Epoch 177: | Loss: 0.46982
Epoch 178: | Loss: 0.46640
Epoch 179: | Loss: 0.46979
Epoch 180: | Loss: 0.47038
Epoch 181: | Loss: 0.46686
Epoch 182: | Loss: 0.46830
Epoch 183: | Loss: 0.46790
Epoch 184: | Loss: 0.46552
Epoch 185: | Loss: 0.46939
Epoch 186: | Loss: 0.46839
Epoch 187: | Loss: 0.47078
Epoch 188: | Loss: 0.46873
Epoch 189: | Loss: 0.46874
Epoch 190: | Loss: 0.46691
Epoch 191: | Loss: 0.46463
Epoch 192: | Loss: 0.47069
Epoch 193: | Loss: 0.47090
Epoch 194: | Loss: 0.47077
Epoch 195: | Loss: 0.47001
Epoch 196: | Loss: 0.46986
Epoch 197: | Loss: 0.46642
Epoch 198: | Loss: 0.46779
Epoch 199: | Loss: 0.46889
Accuracy: 0.8326014957264958
Epoch 000: | Loss: 1.62705
Epoch 001: | Loss: 1.56664
Epoch 002: | Loss: 1.53727
Epoch 003: | Loss: 1.50932
Epoch 004: | Loss: 1.50702
Epoch 005: | Loss: 1.50858
Epoch 006: | Loss: 1.50591
Epoch 007: | Loss: 1.50333
Epoch 008: | Loss: 1.49784
Epoch 009: | Loss: 1.49207
Epoch 010: | Loss: 1.49294
Epoch 011: | Loss: 1.49408
Epoch 012: | Loss: 1.49023
Epoch 013: | Loss: 1.48116
Epoch 014: | Loss: 1.47361
Epoch 015: | Loss: 1.46200
Epoch 016: | Loss: 1.44211
Epoch 017: | Loss: 1.41439
Epoch 018: | Loss: 1.38934
Epoch 019: | Loss: 1.36821
Epoch 020: | Loss: 1.34742
Epoch 021: | Loss: 1.32405
Epoch 022: | Loss: 1.30189
Epoch 023: | Loss: 1.27959
Epoch 024: | Loss: 1.26174
Epoch 025: | Loss: 1.24049
Epoch 026: | Loss: 1.21679
Epoch 027: | Loss: 1.20264
Epoch 028: | Loss: 1.18860
Epoch 029: | Loss: 1.17138
Epoch 030: | Loss: 1.15460
Epoch 031: | Loss: 1.14133
Epoch 032: | Loss: 1.13228
Epoch 033: | Loss: 1.11547
Epoch 034: | Loss: 1.10866
Epoch 035: | Loss: 1.10147
Epoch 036: | Loss: 1.08682
Epoch 037: | Loss: 1.08769
Epoch 038: | Loss: 1.07589
Epoch 039: | Loss: 1.06821
Epoch 040: | Loss: 1.05947
Epoch 041: | Loss: 1.04582
Epoch 042: | Loss: 1.04043
Epoch 043: | Loss: 1.02978
Epoch 044: | Loss: 1.03225
Epoch 045: | Loss: 1.01798
Epoch 046: | Loss: 1.01371
Epoch 047: | Loss: 1.00141
Epoch 048: | Loss: 0.99560
Epoch 049: | Loss: 0.98979
Epoch 050: | Loss: 0.98712
Epoch 051: | Loss: 0.97556
Epoch 052: | Loss: 0.97197
Epoch 053: | Loss: 0.96615
Epoch 054: | Loss: 0.95567
Epoch 055: | Loss: 0.94865
Epoch 056: | Loss: 0.94283
Epoch 057: | Loss: 0.93427
Epoch 058: | Loss: 0.93058
Epoch 059: | Loss: 0.92357
Epoch 060: | Loss: 0.91619
Epoch 061: | Loss: 0.90916
Epoch 062: | Loss: 0.90735
Epoch 063: | Loss: 0.89889
Epoch 064: | Loss: 0.89459
Epoch 065: | Loss: 0.88309
Epoch 066: | Loss: 0.88213
Epoch 067: | Loss: 0.87561
Epoch 068: | Loss: 0.86784
Epoch 069: | Loss: 0.86076
Epoch 070: | Loss: 0.85726
Epoch 071: | Loss: 0.85569
Epoch 072: | Loss: 0.85092
Epoch 073: | Loss: 0.84128
Epoch 074: | Loss: 0.83815
Epoch 075: | Loss: 0.82862
Epoch 076: | Loss: 0.82891
Epoch 077: | Loss: 0.82192
Epoch 078: | Loss: 0.82280
Epoch 079: | Loss: 0.81530
Epoch 080: | Loss: 0.80677
Epoch 081: | Loss: 0.80788
Epoch 082: | Loss: 0.80278
Epoch 083: | Loss: 0.80023
Epoch 084: | Loss: 0.79175
Epoch 085: | Loss: 0.78894
Epoch 086: | Loss: 0.78600
Epoch 087: | Loss: 0.78198
Epoch 088: | Loss: 0.78022
Epoch 089: | Loss: 0.77613
Epoch 090: | Loss: 0.76770
Epoch 091: | Loss: 0.76155
Epoch 092: | Loss: 0.76174
Epoch 093: | Loss: 0.75629
Epoch 094: | Loss: 0.75208
Epoch 095: | Loss: 0.74958
Epoch 096: | Loss: 0.74834
Epoch 097: | Loss: 0.74131
Epoch 098: | Loss: 0.74264
Epoch 099: | Loss: 0.73525
Epoch 100: | Loss: 0.73467
Epoch 101: | Loss: 0.73369
Epoch 102: | Loss: 0.72847
Epoch 103: | Loss: 0.72196
Epoch 104: | Loss: 0.72287
Epoch 105: | Loss: 0.71415
Epoch 106: | Loss: 0.71725
Epoch 107: | Loss: 0.71548
Epoch 108: | Loss: 0.70868
Epoch 109: | Loss: 0.70787
Epoch 110: | Loss: 0.70719
Epoch 111: | Loss: 0.69986
Epoch 112: | Loss: 0.70443
Epoch 113: | Loss: 0.70555
Epoch 114: | Loss: 0.70057
Epoch 115: | Loss: 0.69491
Epoch 116: | Loss: 0.68827
Epoch 117: | Loss: 0.69434
Epoch 118: | Loss: 0.68748
Epoch 119: | Loss: 0.69105
Epoch 120: | Loss: 0.68592
Epoch 121: | Loss: 0.68019
Epoch 122: | Loss: 0.68478
Epoch 123: | Loss: 0.67692
Epoch 124: | Loss: 0.67556
Epoch 125: | Loss: 0.67723
Epoch 126: | Loss: 0.67457
Epoch 127: | Loss: 0.66842
Epoch 128: | Loss: 0.66722
Epoch 129: | Loss: 0.67332
Epoch 130: | Loss: 0.66615
Epoch 131: | Loss: 0.66532
Epoch 132: | Loss: 0.66350
Epoch 133: | Loss: 0.66701
Epoch 134: | Loss: 0.66135
Epoch 135: | Loss: 0.65979
Epoch 136: | Loss: 0.65804
Epoch 137: | Loss: 0.66023
Epoch 138: | Loss: 0.65713
Epoch 139: | Loss: 0.65478
Epoch 140: | Loss: 0.65581
Epoch 141: | Loss: 0.65538
Epoch 142: | Loss: 0.65795
Epoch 143: | Loss: 0.65444
Epoch 144: | Loss: 0.65636
Epoch 145: | Loss: 0.66118
Epoch 146: | Loss: 0.65202
Epoch 147: | Loss: 0.64957
Epoch 148: | Loss: 0.65230
Epoch 149: | Loss: 0.64821
Epoch 150: | Loss: 0.64683
Epoch 151: | Loss: 0.65049
Epoch 152: | Loss: 0.64706
Epoch 153: | Loss: 0.64480
Epoch 154: | Loss: 0.64295
Epoch 155: | Loss: 0.64435
Epoch 156: | Loss: 0.63919
Epoch 157: | Loss: 0.63969
Epoch 158: | Loss: 0.64620
Epoch 159: | Loss: 0.64434
Epoch 160: | Loss: 0.64217
Epoch 161: | Loss: 0.64119
Epoch 162: | Loss: 0.63961
Epoch 163: | Loss: 0.64092
Epoch 164: | Loss: 0.64605
Epoch 165: | Loss: 0.64067
Epoch 166: | Loss: 0.63985
Epoch 167: | Loss: 0.64051
Epoch 168: | Loss: 0.64245
Epoch 169: | Loss: 0.64311
Epoch 170: | Loss: 0.64168
Epoch 171: | Loss: 0.64147
Epoch 172: | Loss: 0.63823
Epoch 173: | Loss: 0.63955
Epoch 174: | Loss: 0.63772
Epoch 175: | Loss: 0.63754
Epoch 176: | Loss: 0.63765
Epoch 177: | Loss: 0.64138
Epoch 178: | Loss: 0.64131
Epoch 179: | Loss: 0.63546
Epoch 180: | Loss: 0.63406
Epoch 181: | Loss: 0.63506
Epoch 182: | Loss: 0.63512
Epoch 183: | Loss: 0.63689
Epoch 184: | Loss: 0.63928
Epoch 185: | Loss: 0.63785
Epoch 186: | Loss: 0.63128
Epoch 187: | Loss: 0.63460
Epoch 188: | Loss: 0.63544
Epoch 189: | Loss: 0.63185
Epoch 190: | Loss: 0.63505
Epoch 191: | Loss: 0.63374
Epoch 192: | Loss: 0.63499
Epoch 193: | Loss: 0.63459
Epoch 194: | Loss: 0.63787
Epoch 195: | Loss: 0.63650
Epoch 196: | Loss: 0.63973
Epoch 197: | Loss: 0.63380
Epoch 198: | Loss: 0.63454
Epoch 199: | Loss: 0.63816
Accuracy: 0.04252938034188034
Epoch 000: | Loss: 1.59509
Epoch 001: | Loss: 1.54639
Epoch 002: | Loss: 1.33571
Epoch 003: | Loss: 0.97941
Epoch 004: | Loss: 0.85971
Epoch 005: | Loss: 0.78460
Epoch 006: | Loss: 0.74072
Epoch 007: | Loss: 0.72031
Epoch 008: | Loss: 0.71352
Epoch 009: | Loss: 0.69933
Epoch 010: | Loss: 0.69200
Epoch 011: | Loss: 0.67243
Epoch 012: | Loss: 0.66233
Epoch 013: | Loss: 0.65635
Epoch 014: | Loss: 0.64443
Epoch 015: | Loss: 0.63861
Epoch 016: | Loss: 0.63707
Epoch 017: | Loss: 0.62690
Epoch 018: | Loss: 0.62299
Epoch 019: | Loss: 0.61683
Epoch 020: | Loss: 0.61497
Epoch 021: | Loss: 0.61190
Epoch 022: | Loss: 0.61263
Epoch 023: | Loss: 0.59712
Epoch 024: | Loss: 0.60224
Epoch 025: | Loss: 0.59498
Epoch 026: | Loss: 0.59488
Epoch 027: | Loss: 0.59150
Epoch 028: | Loss: 0.58759
Epoch 029: | Loss: 0.58968
Epoch 030: | Loss: 0.57974
Epoch 031: | Loss: 0.57183
Epoch 032: | Loss: 0.56680
Epoch 033: | Loss: 0.56758
Epoch 034: | Loss: 0.57445
Epoch 035: | Loss: 0.56208
Epoch 036: | Loss: 0.55969
Epoch 037: | Loss: 0.55818
Epoch 038: | Loss: 0.55425
Epoch 039: | Loss: 0.56144
Epoch 040: | Loss: 0.55389
Epoch 041: | Loss: 0.54716
Epoch 042: | Loss: 0.54575
Epoch 043: | Loss: 0.54425
Epoch 044: | Loss: 0.54325
Epoch 045: | Loss: 0.53885
Epoch 046: | Loss: 0.53718
Epoch 047: | Loss: 0.53386
Epoch 048: | Loss: 0.52751
Epoch 049: | Loss: 0.53385
Epoch 050: | Loss: 0.53251
Epoch 051: | Loss: 0.53166
Epoch 052: | Loss: 0.52927
Epoch 053: | Loss: 0.52546
Epoch 054: | Loss: 0.52249
Epoch 055: | Loss: 0.52039
Epoch 056: | Loss: 0.51754
Epoch 057: | Loss: 0.52046
Epoch 058: | Loss: 0.52253
Epoch 059: | Loss: 0.51778
Epoch 060: | Loss: 0.51348
Epoch 061: | Loss: 0.50834
Epoch 062: | Loss: 0.51139
Epoch 063: | Loss: 0.50923
Epoch 064: | Loss: 0.50445
Epoch 065: | Loss: 0.50116
Epoch 066: | Loss: 0.50151
Epoch 067: | Loss: 0.49704
Epoch 068: | Loss: 0.49682
Epoch 069: | Loss: 0.49460
Epoch 070: | Loss: 0.49225
Epoch 071: | Loss: 0.49099
Epoch 072: | Loss: 0.48588
Epoch 073: | Loss: 0.48719
Epoch 074: | Loss: 0.48629
Epoch 075: | Loss: 0.48418
Epoch 076: | Loss: 0.48538
Epoch 077: | Loss: 0.47736
Epoch 078: | Loss: 0.47454
Epoch 079: | Loss: 0.47645
Epoch 080: | Loss: 0.47240
Epoch 081: | Loss: 0.47170
Epoch 082: | Loss: 0.46843
Epoch 083: | Loss: 0.46565
Epoch 084: | Loss: 0.46752
Epoch 085: | Loss: 0.46229
Epoch 086: | Loss: 0.46219
Epoch 087: | Loss: 0.46675
Epoch 088: | Loss: 0.45883
Epoch 089: | Loss: 0.45688
Epoch 090: | Loss: 0.45264
Epoch 091: | Loss: 0.45402
Epoch 092: | Loss: 0.45466
Epoch 093: | Loss: 0.44962
Epoch 094: | Loss: 0.44673
Epoch 095: | Loss: 0.44667
Epoch 096: | Loss: 0.44184
Epoch 097: | Loss: 0.44309
Epoch 098: | Loss: 0.44549
Epoch 099: | Loss: 0.44453
Epoch 100: | Loss: 0.43935
Epoch 101: | Loss: 0.43582
Epoch 102: | Loss: 0.43693
Epoch 103: | Loss: 0.43949
Epoch 104: | Loss: 0.43756
Epoch 105: | Loss: 0.43792
Epoch 106: | Loss: 0.43796
Epoch 107: | Loss: 0.43418
Epoch 108: | Loss: 0.43408
Epoch 109: | Loss: 0.42834
Epoch 110: | Loss: 0.43219
Epoch 111: | Loss: 0.42685
Epoch 112: | Loss: 0.43026
Epoch 113: | Loss: 0.43061
Epoch 114: | Loss: 0.43055
Epoch 115: | Loss: 0.42289
Epoch 116: | Loss: 0.42518
Epoch 117: | Loss: 0.42338
Epoch 118: | Loss: 0.42685
Epoch 119: | Loss: 0.42414
Epoch 120: | Loss: 0.42408
Epoch 121: | Loss: 0.42094
Epoch 122: | Loss: 0.42388
Epoch 123: | Loss: 0.41943
Epoch 124: | Loss: 0.42304
Epoch 125: | Loss: 0.41607
Epoch 126: | Loss: 0.42080
Epoch 127: | Loss: 0.41925
Epoch 128: | Loss: 0.41612
Epoch 129: | Loss: 0.41804
Epoch 130: | Loss: 0.41932
Epoch 131: | Loss: 0.41673
Epoch 132: | Loss: 0.41667
Epoch 133: | Loss: 0.41677
Epoch 134: | Loss: 0.41550
Epoch 135: | Loss: 0.41249
Epoch 136: | Loss: 0.41325
Epoch 137: | Loss: 0.41267
Epoch 138: | Loss: 0.41092
Epoch 139: | Loss: 0.41102
Epoch 140: | Loss: 0.40942
Epoch 141: | Loss: 0.40863
Epoch 142: | Loss: 0.41002
Epoch 143: | Loss: 0.41104
Epoch 144: | Loss: 0.40801
Epoch 145: | Loss: 0.40959
Epoch 146: | Loss: 0.41669
Epoch 147: | Loss: 0.40938
Epoch 148: | Loss: 0.40765
Epoch 149: | Loss: 0.40840
Epoch 150: | Loss: 0.40725
Epoch 151: | Loss: 0.40381
Epoch 152: | Loss: 0.40661
Epoch 153: | Loss: 0.40639
Epoch 154: | Loss: 0.40885
Epoch 155: | Loss: 0.40787
Epoch 156: | Loss: 0.40528
Epoch 157: | Loss: 0.40658
Epoch 158: | Loss: 0.40466
Epoch 159: | Loss: 0.40502
Epoch 160: | Loss: 0.40363
Epoch 161: | Loss: 0.40507
Epoch 162: | Loss: 0.40253
Epoch 163: | Loss: 0.40484
Epoch 164: | Loss: 0.40430
Epoch 165: | Loss: 0.40273
Epoch 166: | Loss: 0.40163
Epoch 167: | Loss: 0.40698
Epoch 168: | Loss: 0.40678
Epoch 169: | Loss: 0.40229
Epoch 170: | Loss: 0.40107
Epoch 171: | Loss: 0.40428
Epoch 172: | Loss: 0.40107
Epoch 173: | Loss: 0.39981
Epoch 174: | Loss: 0.39745
Epoch 175: | Loss: 0.40385
Epoch 176: | Loss: 0.40155
Epoch 177: | Loss: 0.40199
Epoch 178: | Loss: 0.39787
Epoch 179: | Loss: 0.40054
Epoch 180: | Loss: 0.39914
Epoch 181: | Loss: 0.39755
Epoch 182: | Loss: 0.39737
Epoch 183: | Loss: 0.39799
Epoch 184: | Loss: 0.40016
Epoch 185: | Loss: 0.39547
Epoch 186: | Loss: 0.39179
Epoch 187: | Loss: 0.39647
Epoch 188: | Loss: 0.39443
Epoch 189: | Loss: 0.39041
Epoch 190: | Loss: 0.39185
Epoch 191: | Loss: 0.39757
Epoch 192: | Loss: 0.39616
Epoch 193: | Loss: 0.39428
Epoch 194: | Loss: 0.39292
Epoch 195: | Loss: 0.39321
Epoch 196: | Loss: 0.39206
Epoch 197: | Loss: 0.38965
Epoch 198: | Loss: 0.39441
Epoch 199: | Loss: 0.38893
Accuracy: 0.8388141025641026
Epoch 000: | Loss: 1.54115
Epoch 001: | Loss: 1.48924
Epoch 002: | Loss: 1.33812
Epoch 003: | Loss: 1.21105
Epoch 004: | Loss: 1.10703
Epoch 005: | Loss: 1.04515
Epoch 006: | Loss: 0.98088
Epoch 007: | Loss: 0.91479
Epoch 008: | Loss: 0.86663
Epoch 009: | Loss: 0.83453
Epoch 010: | Loss: 0.81490
Epoch 011: | Loss: 0.79997
Epoch 012: | Loss: 0.78361
Epoch 013: | Loss: 0.76710
Epoch 014: | Loss: 0.75713
Epoch 015: | Loss: 0.74475
Epoch 016: | Loss: 0.73798
Epoch 017: | Loss: 0.73034
Epoch 018: | Loss: 0.72276
Epoch 019: | Loss: 0.71529
Epoch 020: | Loss: 0.71235
Epoch 021: | Loss: 0.70508
Epoch 022: | Loss: 0.69542
Epoch 023: | Loss: 0.69755
Epoch 024: | Loss: 0.68864
Epoch 025: | Loss: 0.68283
Epoch 026: | Loss: 0.68356
Epoch 027: | Loss: 0.67349
Epoch 028: | Loss: 0.67555
Epoch 029: | Loss: 0.67418
Epoch 030: | Loss: 0.66822
Epoch 031: | Loss: 0.67062
Epoch 032: | Loss: 0.66502
Epoch 033: | Loss: 0.66501
Epoch 034: | Loss: 0.66325
Epoch 035: | Loss: 0.66117
Epoch 036: | Loss: 0.65814
Epoch 037: | Loss: 0.65687
Epoch 038: | Loss: 0.65501
Epoch 039: | Loss: 0.65517
Epoch 040: | Loss: 0.65574
Epoch 041: | Loss: 0.65009
Epoch 042: | Loss: 0.65096
Epoch 043: | Loss: 0.65250
Epoch 044: | Loss: 0.65053
Epoch 045: | Loss: 0.64625
Epoch 046: | Loss: 0.64646
Epoch 047: | Loss: 0.64348
Epoch 048: | Loss: 0.64443
Epoch 049: | Loss: 0.64128
Epoch 050: | Loss: 0.64129
Epoch 051: | Loss: 0.64478
Epoch 052: | Loss: 0.63928
Epoch 053: | Loss: 0.63774
Epoch 054: | Loss: 0.63990
Epoch 055: | Loss: 0.64159
Epoch 056: | Loss: 0.63868
Epoch 057: | Loss: 0.63857
Epoch 058: | Loss: 0.63833
Epoch 059: | Loss: 0.63580
Epoch 060: | Loss: 0.63675
Epoch 061: | Loss: 0.63542
Epoch 062: | Loss: 0.63391
Epoch 063: | Loss: 0.63444
Epoch 064: | Loss: 0.62840
Epoch 065: | Loss: 0.63770
Epoch 066: | Loss: 0.63494
Epoch 067: | Loss: 0.62998
Epoch 068: | Loss: 0.63163
Epoch 069: | Loss: 0.63173
Epoch 070: | Loss: 0.62820
Epoch 071: | Loss: 0.62797
Epoch 072: | Loss: 0.63060
Epoch 073: | Loss: 0.63524
Epoch 074: | Loss: 0.62911
Epoch 075: | Loss: 0.62870
Epoch 076: | Loss: 0.62943
Epoch 077: | Loss: 0.62753
Epoch 078: | Loss: 0.62853
Epoch 079: | Loss: 0.62768
Epoch 080: | Loss: 0.62816
Epoch 081: | Loss: 0.63051
Epoch 082: | Loss: 0.62697
Epoch 083: | Loss: 0.62735
Epoch 084: | Loss: 0.62595
Epoch 085: | Loss: 0.62796
Epoch 086: | Loss: 0.62478
Epoch 087: | Loss: 0.62670
Epoch 088: | Loss: 0.62614
Epoch 089: | Loss: 0.62679
Epoch 090: | Loss: 0.62988
Epoch 091: | Loss: 0.62458
Epoch 092: | Loss: 0.62561
Epoch 093: | Loss: 0.62569
Epoch 094: | Loss: 0.62288
Epoch 095: | Loss: 0.62329
Epoch 096: | Loss: 0.62421
Epoch 097: | Loss: 0.62622
Epoch 098: | Loss: 0.62573
Epoch 099: | Loss: 0.62740
Epoch 100: | Loss: 0.62656
Epoch 101: | Loss: 0.62639
Epoch 102: | Loss: 0.62381
Epoch 103: | Loss: 0.62558
Epoch 104: | Loss: 0.62554
Epoch 105: | Loss: 0.62225
Epoch 106: | Loss: 0.61978
Epoch 107: | Loss: 0.62268
Epoch 108: | Loss: 0.62255
Epoch 109: | Loss: 0.62697
Epoch 110: | Loss: 0.62498
Epoch 111: | Loss: 0.62525
Epoch 112: | Loss: 0.62447
Epoch 113: | Loss: 0.62307
Epoch 114: | Loss: 0.62431
Epoch 115: | Loss: 0.62637
Epoch 116: | Loss: 0.62236
Epoch 117: | Loss: 0.62066
Epoch 118: | Loss: 0.62398
Epoch 119: | Loss: 0.62494
Epoch 120: | Loss: 0.62130
Epoch 121: | Loss: 0.62060
Epoch 122: | Loss: 0.62147
Epoch 123: | Loss: 0.62005
Epoch 124: | Loss: 0.62202
Epoch 125: | Loss: 0.62093
Epoch 126: | Loss: 0.61942
Epoch 127: | Loss: 0.62291
Epoch 128: | Loss: 0.62143
Epoch 129: | Loss: 0.62150
Epoch 130: | Loss: 0.61885
Epoch 131: | Loss: 0.61982
Epoch 132: | Loss: 0.62295
Epoch 133: | Loss: 0.62034
Epoch 134: | Loss: 0.61909
Epoch 135: | Loss: 0.62314
Epoch 136: | Loss: 0.61882
Epoch 137: | Loss: 0.62184
Epoch 138: | Loss: 0.61896
Epoch 139: | Loss: 0.62195
Epoch 140: | Loss: 0.62119
Epoch 141: | Loss: 0.61511
Epoch 142: | Loss: 0.61507
Epoch 143: | Loss: 0.61441
Epoch 144: | Loss: 0.62144
Epoch 145: | Loss: 0.61911
Epoch 146: | Loss: 0.61740
Epoch 147: | Loss: 0.61693
Epoch 148: | Loss: 0.61759
Epoch 149: | Loss: 0.61588
Epoch 150: | Loss: 0.61638
Epoch 151: | Loss: 0.61383
Epoch 152: | Loss: 0.61785
Epoch 153: | Loss: 0.61271
Epoch 154: | Loss: 0.61392
Epoch 155: | Loss: 0.61348
Epoch 156: | Loss: 0.61712
Epoch 157: | Loss: 0.61485
Epoch 158: | Loss: 0.61344
Epoch 159: | Loss: 0.61476
Epoch 160: | Loss: 0.61613
Epoch 161: | Loss: 0.61271
Epoch 162: | Loss: 0.61211
Epoch 163: | Loss: 0.60988
Epoch 164: | Loss: 0.61278
Epoch 165: | Loss: 0.61359
Epoch 166: | Loss: 0.60619
Epoch 167: | Loss: 0.60642
Epoch 168: | Loss: 0.60824
Epoch 169: | Loss: 0.61067
Epoch 170: | Loss: 0.60883
Epoch 171: | Loss: 0.60697
Epoch 172: | Loss: 0.60711
Epoch 173: | Loss: 0.60572
Epoch 174: | Loss: 0.60499
Epoch 175: | Loss: 0.60610
Epoch 176: | Loss: 0.60885
Epoch 177: | Loss: 0.60714
Epoch 178: | Loss: 0.60448
Epoch 179: | Loss: 0.60534
Epoch 180: | Loss: 0.60378
Epoch 181: | Loss: 0.60207
Epoch 182: | Loss: 0.60396
Epoch 183: | Loss: 0.60179
Epoch 184: | Loss: 0.60105
Epoch 185: | Loss: 0.60282
Epoch 186: | Loss: 0.59927
Epoch 187: | Loss: 0.59747
Epoch 188: | Loss: 0.60168
Epoch 189: | Loss: 0.60359
Epoch 190: | Loss: 0.59784
Epoch 191: | Loss: 0.59786
Epoch 192: | Loss: 0.59680
Epoch 193: | Loss: 0.59656
Epoch 194: | Loss: 0.59484
Epoch 195: | Loss: 0.59671
Epoch 196: | Loss: 0.59851
Epoch 197: | Loss: 0.59709
Epoch 198: | Loss: 0.59462
Epoch 199: | Loss: 0.59251
Accuracy: 0.7842654914529914
Epoch 000: | Loss: 1.53619
Epoch 001: | Loss: 1.52574
Epoch 002: | Loss: 1.52022
Epoch 003: | Loss: 1.50486
Epoch 004: | Loss: 1.49823
Epoch 005: | Loss: 1.49995
Epoch 006: | Loss: 1.49098
Epoch 007: | Loss: 1.48527
Epoch 008: | Loss: 1.47828
Epoch 009: | Loss: 1.47738
Epoch 010: | Loss: 1.47406
Epoch 011: | Loss: 1.46839
Epoch 012: | Loss: 1.46361
Epoch 013: | Loss: 1.45413
Epoch 014: | Loss: 1.44482
Epoch 015: | Loss: 1.44537
Epoch 016: | Loss: 1.43635
Epoch 017: | Loss: 1.43300
Epoch 018: | Loss: 1.42051
Epoch 019: | Loss: 1.41101
Epoch 020: | Loss: 1.40643
Epoch 021: | Loss: 1.39689
Epoch 022: | Loss: 1.38381
Epoch 023: | Loss: 1.37903
Epoch 024: | Loss: 1.36862
Epoch 025: | Loss: 1.36129
Epoch 026: | Loss: 1.34964
Epoch 027: | Loss: 1.33932
Epoch 028: | Loss: 1.33349
Epoch 029: | Loss: 1.32569
Epoch 030: | Loss: 1.32115
Epoch 031: | Loss: 1.31345
Epoch 032: | Loss: 1.30936
Epoch 033: | Loss: 1.30858
Epoch 034: | Loss: 1.30160
Epoch 035: | Loss: 1.29770
Epoch 036: | Loss: 1.29285
Epoch 037: | Loss: 1.29430
Epoch 038: | Loss: 1.29026
Epoch 039: | Loss: 1.28643
Epoch 040: | Loss: 1.28524
Epoch 041: | Loss: 1.28812
Epoch 042: | Loss: 1.28401
Epoch 043: | Loss: 1.28306
Epoch 044: | Loss: 1.28594
Epoch 045: | Loss: 1.28216
Epoch 046: | Loss: 1.28606
Epoch 047: | Loss: 1.28898
Epoch 048: | Loss: 1.28190
Epoch 049: | Loss: 1.28049
Epoch 050: | Loss: 1.28096
Epoch 051: | Loss: 1.28570
Epoch 052: | Loss: 1.28298
Epoch 053: | Loss: 1.28113
Epoch 054: | Loss: 1.28233
Epoch 055: | Loss: 1.27990
Epoch 056: | Loss: 1.28576
Epoch 057: | Loss: 1.28397
Epoch 058: | Loss: 1.27879
Epoch 059: | Loss: 1.28173
Epoch 060: | Loss: 1.28270
Epoch 061: | Loss: 1.27855
Epoch 062: | Loss: 1.28061
Epoch 063: | Loss: 1.27476
Epoch 064: | Loss: 1.27551
Epoch 065: | Loss: 1.27165
Epoch 066: | Loss: 1.26782
Epoch 067: | Loss: 1.26618
Epoch 068: | Loss: 1.26150
Epoch 069: | Loss: 1.25853
Epoch 070: | Loss: 1.25367
Epoch 071: | Loss: 1.25065
Epoch 072: | Loss: 1.24667
Epoch 073: | Loss: 1.23777
Epoch 074: | Loss: 1.23569
Epoch 075: | Loss: 1.23438
Epoch 076: | Loss: 1.22541
Epoch 077: | Loss: 1.22092
Epoch 078: | Loss: 1.21575
Epoch 079: | Loss: 1.21538
Epoch 080: | Loss: 1.20960
Epoch 081: | Loss: 1.20214
Epoch 082: | Loss: 1.19393
Epoch 083: | Loss: 1.19082
Epoch 084: | Loss: 1.18715
Epoch 085: | Loss: 1.18346
Epoch 086: | Loss: 1.17337
Epoch 087: | Loss: 1.17202
Epoch 088: | Loss: 1.16650
Epoch 089: | Loss: 1.15698
Epoch 090: | Loss: 1.14876
Epoch 091: | Loss: 1.14622
Epoch 092: | Loss: 1.14000
Epoch 093: | Loss: 1.13700
Epoch 094: | Loss: 1.13087
Epoch 095: | Loss: 1.11707
Epoch 096: | Loss: 1.11854
Epoch 097: | Loss: 1.10932
Epoch 098: | Loss: 1.10681
Epoch 099: | Loss: 1.10030
Epoch 100: | Loss: 1.09607
Epoch 101: | Loss: 1.08991
Epoch 102: | Loss: 1.08289
Epoch 103: | Loss: 1.07569
Epoch 104: | Loss: 1.06902
Epoch 105: | Loss: 1.06438
Epoch 106: | Loss: 1.06399
Epoch 107: | Loss: 1.05200
Epoch 108: | Loss: 1.04916
Epoch 109: | Loss: 1.04394
Epoch 110: | Loss: 1.03895
Epoch 111: | Loss: 1.03487
Epoch 112: | Loss: 1.03174
Epoch 113: | Loss: 1.02582
Epoch 114: | Loss: 1.01754
Epoch 115: | Loss: 1.01193
Epoch 116: | Loss: 1.01181
Epoch 117: | Loss: 1.00360
Epoch 118: | Loss: 1.00607
Epoch 119: | Loss: 1.00126
Epoch 120: | Loss: 0.99882
Epoch 121: | Loss: 0.99483
Epoch 122: | Loss: 0.98375
Epoch 123: | Loss: 0.98030
Epoch 124: | Loss: 0.98195
Epoch 125: | Loss: 0.97920
Epoch 126: | Loss: 0.97476
Epoch 127: | Loss: 0.96616
Epoch 128: | Loss: 0.97344
Epoch 129: | Loss: 0.96786
Epoch 130: | Loss: 0.96565
Epoch 131: | Loss: 0.96361
Epoch 132: | Loss: 0.95922
Epoch 133: | Loss: 0.95594
Epoch 134: | Loss: 0.95915
Epoch 135: | Loss: 0.95852
Epoch 136: | Loss: 0.95208
Epoch 137: | Loss: 0.95621
Epoch 138: | Loss: 0.95378
Epoch 139: | Loss: 0.95232
Epoch 140: | Loss: 0.95294
Epoch 141: | Loss: 0.95423
Epoch 142: | Loss: 0.94821
Epoch 143: | Loss: 0.95250
Epoch 144: | Loss: 0.95254
Epoch 145: | Loss: 0.95187
Epoch 146: | Loss: 0.94694
Epoch 147: | Loss: 0.94962
Epoch 148: | Loss: 0.94891
Epoch 149: | Loss: 0.94372
Epoch 150: | Loss: 0.94939
Epoch 151: | Loss: 0.94999
Epoch 152: | Loss: 0.94773
Epoch 153: | Loss: 0.94165
Epoch 154: | Loss: 0.94259
Epoch 155: | Loss: 0.95212
Epoch 156: | Loss: 0.95242
Epoch 157: | Loss: 0.94867
Epoch 158: | Loss: 0.95300
Epoch 159: | Loss: 0.94245
Epoch 160: | Loss: 0.94333
Epoch 161: | Loss: 0.94452
Epoch 162: | Loss: 0.95490
Epoch 163: | Loss: 0.94408
Epoch 164: | Loss: 0.94370
Epoch 165: | Loss: 0.94275
Epoch 166: | Loss: 0.94294
Epoch 167: | Loss: 0.93696
Epoch 168: | Loss: 0.93411
Epoch 169: | Loss: 0.93701
Epoch 170: | Loss: 0.93400
Epoch 171: | Loss: 0.93233
Epoch 172: | Loss: 0.92807
Epoch 173: | Loss: 0.93003
Epoch 174: | Loss: 0.92586
Epoch 175: | Loss: 0.92472
Epoch 176: | Loss: 0.92316
Epoch 177: | Loss: 0.91561
Epoch 178: | Loss: 0.91910
Epoch 179: | Loss: 0.91048
Epoch 180: | Loss: 0.91058
Epoch 181: | Loss: 0.91219
Epoch 182: | Loss: 0.89887
Epoch 183: | Loss: 0.89888
Epoch 184: | Loss: 0.89984
Epoch 185: | Loss: 0.89088
Epoch 186: | Loss: 0.88703
Epoch 187: | Loss: 0.88418
Epoch 188: | Loss: 0.88053
Epoch 189: | Loss: 0.88049
Epoch 190: | Loss: 0.87626
Epoch 191: | Loss: 0.87122
Epoch 192: | Loss: 0.87309
Epoch 193: | Loss: 0.86633
Epoch 194: | Loss: 0.86082
Epoch 195: | Loss: 0.86538
Epoch 196: | Loss: 0.85443
Epoch 197: | Loss: 0.85247
Epoch 198: | Loss: 0.85197
Epoch 199: | Loss: 0.85317
Accuracy: 0.7202136752136752
Epoch 000: | Loss: 1.32500
Epoch 001: | Loss: 0.81863
Epoch 002: | Loss: 0.74766
Epoch 003: | Loss: 0.73994
Epoch 004: | Loss: 0.70319
Epoch 005: | Loss: 0.66437
Epoch 006: | Loss: 0.62167
Epoch 007: | Loss: 0.60021
Epoch 008: | Loss: 0.57646
Epoch 009: | Loss: 0.57238
Epoch 010: | Loss: 0.53780
Epoch 011: | Loss: 0.53001
Epoch 012: | Loss: 0.52790
Epoch 013: | Loss: 0.50314
Epoch 014: | Loss: 0.49015
Epoch 015: | Loss: 0.47724
Epoch 016: | Loss: 0.47381
Epoch 017: | Loss: 0.46251
Epoch 018: | Loss: 0.45814
Epoch 019: | Loss: 0.43687
Epoch 020: | Loss: 0.43100
Epoch 021: | Loss: 0.42649
Epoch 022: | Loss: 0.42066
Epoch 023: | Loss: 0.40782
Epoch 024: | Loss: 0.40919
Epoch 025: | Loss: 0.38213
Epoch 026: | Loss: 0.38373
Epoch 027: | Loss: 0.37187
Epoch 028: | Loss: 0.36497
Epoch 029: | Loss: 0.35315
Epoch 030: | Loss: 0.34060
Epoch 031: | Loss: 0.34342
Epoch 032: | Loss: 0.32413
Epoch 033: | Loss: 0.32041
Epoch 034: | Loss: 0.30798
Epoch 035: | Loss: 0.30254
Epoch 036: | Loss: 0.30031
Epoch 037: | Loss: 0.29356
Epoch 038: | Loss: 0.28853
Epoch 039: | Loss: 0.28349
Epoch 040: | Loss: 0.27909
Epoch 041: | Loss: 0.27320
Epoch 042: | Loss: 0.27197
Epoch 043: | Loss: 0.26708
Epoch 044: | Loss: 0.26830
Epoch 045: | Loss: 0.26267
Epoch 046: | Loss: 0.25992
Epoch 047: | Loss: 0.25646
Epoch 048: | Loss: 0.25681
Epoch 049: | Loss: 0.25686
Epoch 050: | Loss: 0.25853
Epoch 051: | Loss: 0.25862
Epoch 052: | Loss: 0.25558
Epoch 053: | Loss: 0.25471
Epoch 054: | Loss: 0.25712
Epoch 055: | Loss: 0.26064
Epoch 056: | Loss: 0.25779
Epoch 057: | Loss: 0.26090
Epoch 058: | Loss: 0.25812
Epoch 059: | Loss: 0.26318
Epoch 060: | Loss: 0.26629
Epoch 061: | Loss: 0.26943
Epoch 062: | Loss: 0.26774
Epoch 063: | Loss: 0.26658
Epoch 064: | Loss: 0.27137
Epoch 065: | Loss: 0.27191
Epoch 066: | Loss: 0.26938
Epoch 067: | Loss: 0.26975
Epoch 068: | Loss: 0.26932
Epoch 069: | Loss: 0.27740
Epoch 070: | Loss: 0.27683
Epoch 071: | Loss: 0.27757
Epoch 072: | Loss: 0.27723
Epoch 073: | Loss: 0.27316
Epoch 074: | Loss: 0.27306
Epoch 075: | Loss: 0.27910
Epoch 076: | Loss: 0.27641
Epoch 077: | Loss: 0.27307
Epoch 078: | Loss: 0.28546
Epoch 079: | Loss: 0.28405
Epoch 080: | Loss: 0.27791
Epoch 081: | Loss: 0.28028
Epoch 082: | Loss: 0.27226
Epoch 083: | Loss: 0.26970
Epoch 084: | Loss: 0.27182
Epoch 085: | Loss: 0.26106
Epoch 086: | Loss: 0.27001
Epoch 087: | Loss: 0.25432
Epoch 088: | Loss: 0.26432
Epoch 089: | Loss: 0.26252
Epoch 090: | Loss: 0.27269
Epoch 091: | Loss: 0.26391
Epoch 092: | Loss: 0.26547
Epoch 093: | Loss: 0.25150
Epoch 094: | Loss: 0.24532
Epoch 095: | Loss: 0.25021
Epoch 096: | Loss: 0.25230
Epoch 097: | Loss: 0.24313
Epoch 098: | Loss: 0.23935
Epoch 099: | Loss: 0.23948
Epoch 100: | Loss: 0.23250
Epoch 101: | Loss: 0.23847
Epoch 102: | Loss: 0.22489
Epoch 103: | Loss: 0.22548
Epoch 104: | Loss: 0.22211
Epoch 105: | Loss: 0.21179
Epoch 106: | Loss: 0.20403
Epoch 107: | Loss: 0.20666
Epoch 108: | Loss: 0.19817
Epoch 109: | Loss: 0.19925
Epoch 110: | Loss: 0.19202
Epoch 111: | Loss: 0.19068
Epoch 112: | Loss: 0.19465
Epoch 113: | Loss: 0.17541
Epoch 114: | Loss: 0.17786
Epoch 115: | Loss: 0.17035
Epoch 116: | Loss: 0.16529
Epoch 117: | Loss: 0.16065
Epoch 118: | Loss: 0.14722
Epoch 119: | Loss: 0.14504
Epoch 120: | Loss: 0.14579
Epoch 121: | Loss: 0.14015
Epoch 122: | Loss: 0.13264
Epoch 123: | Loss: 0.12228
Epoch 124: | Loss: 0.11467
Epoch 125: | Loss: 0.12053
Epoch 126: | Loss: 0.11045
Epoch 127: | Loss: 0.10881
Epoch 128: | Loss: 0.10643
Epoch 129: | Loss: 0.09317
Epoch 130: | Loss: 0.08597
Epoch 131: | Loss: 0.08201
Epoch 132: | Loss: 0.08048
Epoch 133: | Loss: 0.07570
Epoch 134: | Loss: 0.07263
Epoch 135: | Loss: 0.06837
Epoch 136: | Loss: 0.06231
Epoch 137: | Loss: 0.06212
Epoch 138: | Loss: 0.05788
Epoch 139: | Loss: 0.05516
Epoch 140: | Loss: 0.05354
Epoch 141: | Loss: 0.05108
Epoch 142: | Loss: 0.04634
Epoch 143: | Loss: 0.04743
Epoch 144: | Loss: 0.04431
Epoch 145: | Loss: 0.04503
Epoch 146: | Loss: 0.04348
Epoch 147: | Loss: 0.04174
Epoch 148: | Loss: 0.04121
Epoch 149: | Loss: 0.03972
Epoch 150: | Loss: 0.04155
Epoch 151: | Loss: 0.04076
Epoch 152: | Loss: 0.04198
Epoch 153: | Loss: 0.04088
Epoch 154: | Loss: 0.04099
Epoch 155: | Loss: 0.04098
Epoch 156: | Loss: 0.04260
Epoch 157: | Loss: 0.04420
Epoch 158: | Loss: 0.04332
Epoch 159: | Loss: 0.04511
Epoch 160: | Loss: 0.04688
Epoch 161: | Loss: 0.04827
Epoch 162: | Loss: 0.04901
Epoch 163: | Loss: 0.04571
Epoch 164: | Loss: 0.05193
Epoch 165: | Loss: 0.05703
Epoch 166: | Loss: 0.06306
Epoch 167: | Loss: 0.06051
Epoch 168: | Loss: 0.06099
Epoch 169: | Loss: 0.07142
Epoch 170: | Loss: 0.07278
Epoch 171: | Loss: 0.06692
Epoch 172: | Loss: 0.07593
Epoch 173: | Loss: 0.07492
Epoch 174: | Loss: 0.07933
Epoch 175: | Loss: 0.08590
Epoch 176: | Loss: 0.07981
Epoch 177: | Loss: 0.09356
Epoch 178: | Loss: 0.09096
Epoch 179: | Loss: 0.09358
Epoch 180: | Loss: 0.09651
Epoch 181: | Loss: 0.10096
Epoch 182: | Loss: 0.10641
Epoch 183: | Loss: 0.11403
early stopping at epoch 184 with loss 0.09790
Accuracy: 0.9334508547008546
Epoch 000: | Loss: 1.26577
Epoch 001: | Loss: 0.80349
Epoch 002: | Loss: 0.67649
Epoch 003: | Loss: 0.61898
Epoch 004: | Loss: 0.57940
Epoch 005: | Loss: 0.55131
Epoch 006: | Loss: 0.54060
Epoch 007: | Loss: 0.50991
Epoch 008: | Loss: 0.48584
Epoch 009: | Loss: 0.46221
Epoch 010: | Loss: 0.44635
Epoch 011: | Loss: 0.42753
Epoch 012: | Loss: 0.41869
Epoch 013: | Loss: 0.39843
Epoch 014: | Loss: 0.36871
Epoch 015: | Loss: 0.35256
Epoch 016: | Loss: 0.33692
Epoch 017: | Loss: 0.31890
Epoch 018: | Loss: 0.31168
Epoch 019: | Loss: 0.30508
Epoch 020: | Loss: 0.30055
Epoch 021: | Loss: 0.27927
Epoch 022: | Loss: 0.25839
Epoch 023: | Loss: 0.25166
Epoch 024: | Loss: 0.23417
Epoch 025: | Loss: 0.22597
Epoch 026: | Loss: 0.22229
Epoch 027: | Loss: 0.20367
Epoch 028: | Loss: 0.19517
Epoch 029: | Loss: 0.18823
Epoch 030: | Loss: 0.18405
Epoch 031: | Loss: 0.17185
Epoch 032: | Loss: 0.17279
Epoch 033: | Loss: 0.16245
Epoch 034: | Loss: 0.15312
Epoch 035: | Loss: 0.14394
Epoch 036: | Loss: 0.13993
Epoch 037: | Loss: 0.13433
Epoch 038: | Loss: 0.12828
Epoch 039: | Loss: 0.12301
Epoch 040: | Loss: 0.12170
Epoch 041: | Loss: 0.11810
Epoch 042: | Loss: 0.11411
Epoch 043: | Loss: 0.10952
Epoch 044: | Loss: 0.10783
Epoch 045: | Loss: 0.10513
Epoch 046: | Loss: 0.10034
Epoch 047: | Loss: 0.10159
Epoch 048: | Loss: 0.10041
Epoch 049: | Loss: 0.10285
Epoch 050: | Loss: 0.09935
Epoch 051: | Loss: 0.09707
Epoch 052: | Loss: 0.09784
Epoch 053: | Loss: 0.09990
Epoch 054: | Loss: 0.10013
Epoch 055: | Loss: 0.10231
Epoch 056: | Loss: 0.10617
early stopping at epoch 57 with loss 0.10532
Accuracy: 0.9401629273504273
Epoch 000: | Loss: 1.37875
Epoch 001: | Loss: 0.98442
Epoch 002: | Loss: 0.74367
Epoch 003: | Loss: 0.67457
Epoch 004: | Loss: 0.62227
Epoch 005: | Loss: 0.60010
Epoch 006: | Loss: 0.57569
Epoch 007: | Loss: 0.56353
Epoch 008: | Loss: 0.55524
Epoch 009: | Loss: 0.52948
Epoch 010: | Loss: 0.51883
Epoch 011: | Loss: 0.51983
Epoch 012: | Loss: 0.49766
Epoch 013: | Loss: 0.49663
Epoch 014: | Loss: 0.47384
Epoch 015: | Loss: 0.47247
Epoch 016: | Loss: 0.45648
Epoch 017: | Loss: 0.44771
Epoch 018: | Loss: 0.43831
Epoch 019: | Loss: 0.43632
Epoch 020: | Loss: 0.42072
Epoch 021: | Loss: 0.41403
Epoch 022: | Loss: 0.39698
Epoch 023: | Loss: 0.37931
Epoch 024: | Loss: 0.37461
Epoch 025: | Loss: 0.37460
Epoch 026: | Loss: 0.35690
Epoch 027: | Loss: 0.35624
Epoch 028: | Loss: 0.33968
Epoch 029: | Loss: 0.33119
Epoch 030: | Loss: 0.32219
Epoch 031: | Loss: 0.32122
Epoch 032: | Loss: 0.31819
Epoch 033: | Loss: 0.29934
Epoch 034: | Loss: 0.29784
Epoch 035: | Loss: 0.29988
Epoch 036: | Loss: 0.28992
Epoch 037: | Loss: 0.28068
Epoch 038: | Loss: 0.27877
Epoch 039: | Loss: 0.27289
Epoch 040: | Loss: 0.26425
Epoch 041: | Loss: 0.26336
Epoch 042: | Loss: 0.26021
Epoch 043: | Loss: 0.25729
Epoch 044: | Loss: 0.25299
Epoch 045: | Loss: 0.25202
Epoch 046: | Loss: 0.25010
Epoch 047: | Loss: 0.24859
Epoch 048: | Loss: 0.24431
Epoch 049: | Loss: 0.24621
Epoch 050: | Loss: 0.24199
Epoch 051: | Loss: 0.24529
Epoch 052: | Loss: 0.24593
Epoch 053: | Loss: 0.25174
Epoch 054: | Loss: 0.24789
Epoch 055: | Loss: 0.24690
Epoch 056: | Loss: 0.24632
Epoch 057: | Loss: 0.25194
Epoch 058: | Loss: 0.24994
Epoch 059: | Loss: 0.25091
Epoch 060: | Loss: 0.25452
Epoch 061: | Loss: 0.25594
Epoch 062: | Loss: 0.25371
Epoch 063: | Loss: 0.26090
Epoch 064: | Loss: 0.25818
Epoch 065: | Loss: 0.25970
Epoch 066: | Loss: 0.26327
Epoch 067: | Loss: 0.26694
Epoch 068: | Loss: 0.26734
Epoch 069: | Loss: 0.26890
early stopping at epoch 70 with loss 0.26465
Accuracy: 0.11110309829059828
Epoch 000: | Loss: 1.26745
Epoch 001: | Loss: 0.73041
Epoch 002: | Loss: 0.62786
Epoch 003: | Loss: 0.57627
Epoch 004: | Loss: 0.55714
Epoch 005: | Loss: 0.54790
Epoch 006: | Loss: 0.51586
Epoch 007: | Loss: 0.50102
Epoch 008: | Loss: 0.48234
Epoch 009: | Loss: 0.47083
Epoch 010: | Loss: 0.46282
Epoch 011: | Loss: 0.44483
Epoch 012: | Loss: 0.44497
Epoch 013: | Loss: 0.41911
Epoch 014: | Loss: 0.40826
Epoch 015: | Loss: 0.39169
Epoch 016: | Loss: 0.37646
Epoch 017: | Loss: 0.37027
Epoch 018: | Loss: 0.35697
Epoch 019: | Loss: 0.32053
Epoch 020: | Loss: 0.32104
Epoch 021: | Loss: 0.29242
Epoch 022: | Loss: 0.28273
Epoch 023: | Loss: 0.27078
Epoch 024: | Loss: 0.25390
Epoch 025: | Loss: 0.23640
Epoch 026: | Loss: 0.22446
Epoch 027: | Loss: 0.21131
Epoch 028: | Loss: 0.20389
Epoch 029: | Loss: 0.19180
Epoch 030: | Loss: 0.17456
Epoch 031: | Loss: 0.16543
Epoch 032: | Loss: 0.14994
Epoch 033: | Loss: 0.14282
Epoch 034: | Loss: 0.12689
Epoch 035: | Loss: 0.11877
Epoch 036: | Loss: 0.11401
Epoch 037: | Loss: 0.10281
Epoch 038: | Loss: 0.09495
Epoch 039: | Loss: 0.08655
Epoch 040: | Loss: 0.08342
Epoch 041: | Loss: 0.07599
Epoch 042: | Loss: 0.07346
Epoch 043: | Loss: 0.06976
Epoch 044: | Loss: 0.06320
Epoch 045: | Loss: 0.06292
Epoch 046: | Loss: 0.06155
Epoch 047: | Loss: 0.05977
Epoch 048: | Loss: 0.06200
Epoch 049: | Loss: 0.05801
Epoch 050: | Loss: 0.05796
Epoch 051: | Loss: 0.05734
Epoch 052: | Loss: 0.06021
Epoch 053: | Loss: 0.05946
Epoch 054: | Loss: 0.05889
Epoch 055: | Loss: 0.05646
Epoch 056: | Loss: 0.05677
Epoch 057: | Loss: 0.05861
Epoch 058: | Loss: 0.06160
Epoch 059: | Loss: 0.06116
Epoch 060: | Loss: 0.06532
Epoch 061: | Loss: 0.06388
Epoch 062: | Loss: 0.06672
Epoch 063: | Loss: 0.07379
Epoch 064: | Loss: 0.06906
Epoch 065: | Loss: 0.06942
Epoch 066: | Loss: 0.07648
Epoch 067: | Loss: 0.07043
Epoch 068: | Loss: 0.07593
Epoch 069: | Loss: 0.07222
Epoch 070: | Loss: 0.07955
Epoch 071: | Loss: 0.07615
Epoch 072: | Loss: 0.07800
Epoch 073: | Loss: 0.08466
Epoch 074: | Loss: 0.07221
Epoch 075: | Loss: 0.07823
Epoch 076: | Loss: 0.09468
Epoch 077: | Loss: 0.08832
Epoch 078: | Loss: 0.06840
Epoch 079: | Loss: 0.07064
Epoch 080: | Loss: 0.07620
Epoch 081: | Loss: 0.05635
Epoch 082: | Loss: 0.08548
Epoch 083: | Loss: 0.10780
Epoch 084: | Loss: 0.07454
Epoch 085: | Loss: 0.06814
Epoch 086: | Loss: 0.07377
Epoch 087: | Loss: 0.08455
Epoch 088: | Loss: 0.05915
Epoch 089: | Loss: 0.07039
Epoch 090: | Loss: 0.06583
Epoch 091: | Loss: 0.05540
Epoch 092: | Loss: 0.06431
Epoch 093: | Loss: 0.05470
Epoch 094: | Loss: 0.05001
Epoch 095: | Loss: 0.05893
Epoch 096: | Loss: 0.04886
Epoch 097: | Loss: 0.04476
Epoch 098: | Loss: 0.04440
Epoch 099: | Loss: 0.06138
Epoch 100: | Loss: 0.04227
Epoch 101: | Loss: 0.05041
Epoch 102: | Loss: 0.04559
Epoch 103: | Loss: 0.04332
Epoch 104: | Loss: 0.03513
Epoch 105: | Loss: 0.03130
Epoch 106: | Loss: 0.05300
Epoch 107: | Loss: 0.03630
Epoch 108: | Loss: 0.02030
Epoch 109: | Loss: 0.02939
Epoch 110: | Loss: 0.04049
Epoch 111: | Loss: 0.02091
Epoch 112: | Loss: 0.03023
Epoch 113: | Loss: 0.01726
Epoch 114: | Loss: 0.01993
Epoch 115: | Loss: 0.02490
Epoch 116: | Loss: 0.01710
Epoch 117: | Loss: 0.01900
Epoch 118: | Loss: 0.01393
Epoch 119: | Loss: 0.00751
Epoch 120: | Loss: 0.01070
Epoch 121: | Loss: 0.00505
Epoch 122: | Loss: 0.01019
Epoch 123: | Loss: 0.01270
Epoch 124: | Loss: 0.00849
Epoch 125: | Loss: 0.00571
Epoch 126: | Loss: 0.00484
Epoch 127: | Loss: 0.00375
Epoch 128: | Loss: 0.00223
Epoch 129: | Loss: 0.00238
Epoch 130: | Loss: 0.00212
Epoch 131: | Loss: 0.00224
Epoch 132: | Loss: 0.00200
Epoch 133: | Loss: 0.00157
Epoch 134: | Loss: 0.00166
Epoch 135: | Loss: 0.00236
Epoch 136: | Loss: 0.00213
Epoch 137: | Loss: 0.00236
Epoch 138: | Loss: 0.00183
Epoch 139: | Loss: 0.00130
Epoch 140: | Loss: 0.00125
Epoch 141: | Loss: 0.00159
Epoch 142: | Loss: 0.00134
Epoch 143: | Loss: 0.00136
Epoch 144: | Loss: 0.00122
Epoch 145: | Loss: 0.00140
Epoch 146: | Loss: 0.00130
Epoch 147: | Loss: 0.00122
Epoch 148: | Loss: 0.00104
Epoch 149: | Loss: 0.00162
Epoch 150: | Loss: 0.00116
Epoch 151: | Loss: 0.00113
Epoch 152: | Loss: 0.00113
Epoch 153: | Loss: 0.00112
Epoch 154: | Loss: 0.00147
Epoch 155: | Loss: 0.00127
Epoch 156: | Loss: 0.00108
Epoch 157: | Loss: 0.00114
Epoch 158: | Loss: 0.00177
Epoch 159: | Loss: 0.00177
Epoch 160: | Loss: 0.00208
Epoch 161: | Loss: 0.00450
Epoch 162: | Loss: 0.00192
Epoch 163: | Loss: 0.00347
Epoch 164: | Loss: 0.00428
Epoch 165: | Loss: 0.00384
Epoch 166: | Loss: 0.00361
Epoch 167: | Loss: 0.01209
Epoch 168: | Loss: 0.01057
Epoch 169: | Loss: 0.01116
Epoch 170: | Loss: 0.00552
Epoch 171: | Loss: 0.01549
Epoch 172: | Loss: 0.00578
Epoch 173: | Loss: 0.01256
Epoch 174: | Loss: 0.02751
Epoch 175: | Loss: 0.00976
Epoch 176: | Loss: 0.01198
Epoch 177: | Loss: 0.00564
Epoch 178: | Loss: 0.00958
Epoch 179: | Loss: 0.01995
Epoch 180: | Loss: 0.02307
Epoch 181: | Loss: 0.01324
Epoch 182: | Loss: 0.02511
Epoch 183: | Loss: 0.01714
Epoch 184: | Loss: 0.02061
Epoch 185: | Loss: 0.01483
Epoch 186: | Loss: 0.01964
Epoch 187: | Loss: 0.02288
Epoch 188: | Loss: 0.02204
Epoch 189: | Loss: 0.01522
Epoch 190: | Loss: 0.03378
Epoch 191: | Loss: 0.03014
Epoch 192: | Loss: 0.01992
Epoch 193: | Loss: 0.01241
Epoch 194: | Loss: 0.01274
Epoch 195: | Loss: 0.02183
Epoch 196: | Loss: 0.02404
Epoch 197: | Loss: 0.02716
Epoch 198: | Loss: 0.01861
Epoch 199: | Loss: 0.01904
Accuracy: 0.923392094017094
Epoch 000: | Loss: 1.50562
Epoch 001: | Loss: 1.29310
Epoch 002: | Loss: 0.91962
Epoch 003: | Loss: 0.78156
Epoch 004: | Loss: 0.71655
Epoch 005: | Loss: 0.70782
Epoch 006: | Loss: 0.68586
Epoch 007: | Loss: 0.66753
Epoch 008: | Loss: 0.65536
Epoch 009: | Loss: 0.63518
Epoch 010: | Loss: 0.63287
Epoch 011: | Loss: 0.61344
Epoch 012: | Loss: 0.59468
Epoch 013: | Loss: 0.58837
Epoch 014: | Loss: 0.57517
Epoch 015: | Loss: 0.56884
Epoch 016: | Loss: 0.55643
Epoch 017: | Loss: 0.54700
Epoch 018: | Loss: 0.54139
Epoch 019: | Loss: 0.54173
Epoch 020: | Loss: 0.53422
Epoch 021: | Loss: 0.52995
Epoch 022: | Loss: 0.52809
Epoch 023: | Loss: 0.52183
Epoch 024: | Loss: 0.51337
Epoch 025: | Loss: 0.52110
Epoch 026: | Loss: 0.51520
Epoch 027: | Loss: 0.51489
Epoch 028: | Loss: 0.51125
Epoch 029: | Loss: 0.51057
Epoch 030: | Loss: 0.50976
Epoch 031: | Loss: 0.50083
Epoch 032: | Loss: 0.50108
Epoch 033: | Loss: 0.49976
Epoch 034: | Loss: 0.49975
Epoch 035: | Loss: 0.49390
Epoch 036: | Loss: 0.49484
Epoch 037: | Loss: 0.49384
Epoch 038: | Loss: 0.49258
Epoch 039: | Loss: 0.49015
Epoch 040: | Loss: 0.48800
Epoch 041: | Loss: 0.48528
Epoch 042: | Loss: 0.48691
Epoch 043: | Loss: 0.48961
Epoch 044: | Loss: 0.48499
Epoch 045: | Loss: 0.48335
Epoch 046: | Loss: 0.47994
Epoch 047: | Loss: 0.48421
Epoch 048: | Loss: 0.47976
Epoch 049: | Loss: 0.48169
Epoch 050: | Loss: 0.48109
Epoch 051: | Loss: 0.48488
Epoch 052: | Loss: 0.48223
Epoch 053: | Loss: 0.47965
Epoch 054: | Loss: 0.48071
Epoch 055: | Loss: 0.47904
Epoch 056: | Loss: 0.47884
Epoch 057: | Loss: 0.48235
Epoch 058: | Loss: 0.47981
Epoch 059: | Loss: 0.47825
Epoch 060: | Loss: 0.48275
Epoch 061: | Loss: 0.47783
Epoch 062: | Loss: 0.47543
Epoch 063: | Loss: 0.47645
Epoch 064: | Loss: 0.47668
Epoch 065: | Loss: 0.47864
Epoch 066: | Loss: 0.47682
Epoch 067: | Loss: 0.47401
Epoch 068: | Loss: 0.47432
Epoch 069: | Loss: 0.47238
Epoch 070: | Loss: 0.46899
Epoch 071: | Loss: 0.47228
Epoch 072: | Loss: 0.47297
Epoch 073: | Loss: 0.46988
Epoch 074: | Loss: 0.47122
Epoch 075: | Loss: 0.47126
Epoch 076: | Loss: 0.46808
Epoch 077: | Loss: 0.46701
Epoch 078: | Loss: 0.46648
Epoch 079: | Loss: 0.46206
Epoch 080: | Loss: 0.46506
Epoch 081: | Loss: 0.45875
Epoch 082: | Loss: 0.45970
Epoch 083: | Loss: 0.45812
Epoch 084: | Loss: 0.45266
Epoch 085: | Loss: 0.45629
Epoch 086: | Loss: 0.45011
Epoch 087: | Loss: 0.45218
Epoch 088: | Loss: 0.46017
Epoch 089: | Loss: 0.44288
Epoch 090: | Loss: 0.44327
Epoch 091: | Loss: 0.44220
Epoch 092: | Loss: 0.44631
Epoch 093: | Loss: 0.43831
Epoch 094: | Loss: 0.43489
Epoch 095: | Loss: 0.43830
Epoch 096: | Loss: 0.43439
Epoch 097: | Loss: 0.42882
Epoch 098: | Loss: 0.42215
Epoch 099: | Loss: 0.42979
Epoch 100: | Loss: 0.42434
Epoch 101: | Loss: 0.41455
Epoch 102: | Loss: 0.41325
Epoch 103: | Loss: 0.41122
Epoch 104: | Loss: 0.40421
Epoch 105: | Loss: 0.40277
Epoch 106: | Loss: 0.40565
Epoch 107: | Loss: 0.40324
Epoch 108: | Loss: 0.39471
Epoch 109: | Loss: 0.39279
Epoch 110: | Loss: 0.39251
Epoch 111: | Loss: 0.38959
Epoch 112: | Loss: 0.38735
Epoch 113: | Loss: 0.38686
Epoch 114: | Loss: 0.37965
Epoch 115: | Loss: 0.37900
Epoch 116: | Loss: 0.38052
Epoch 117: | Loss: 0.37386
Epoch 118: | Loss: 0.37380
Epoch 119: | Loss: 0.37109
Epoch 120: | Loss: 0.36496
Epoch 121: | Loss: 0.35907
Epoch 122: | Loss: 0.35540
Epoch 123: | Loss: 0.35636
Epoch 124: | Loss: 0.35147
Epoch 125: | Loss: 0.34576
Epoch 126: | Loss: 0.34545
Epoch 127: | Loss: 0.34525
Epoch 128: | Loss: 0.34435
Epoch 129: | Loss: 0.33585
Epoch 130: | Loss: 0.34247
Epoch 131: | Loss: 0.33784
Epoch 132: | Loss: 0.33652
Epoch 133: | Loss: 0.33133
Epoch 134: | Loss: 0.33489
Epoch 135: | Loss: 0.33149
Epoch 136: | Loss: 0.32632
Epoch 137: | Loss: 0.32954
Epoch 138: | Loss: 0.32680
Epoch 139: | Loss: 0.32581
Epoch 140: | Loss: 0.32781
Epoch 141: | Loss: 0.32589
Epoch 142: | Loss: 0.32028
Epoch 143: | Loss: 0.32684
Epoch 144: | Loss: 0.32101
Epoch 145: | Loss: 0.32011
Epoch 146: | Loss: 0.32085
Epoch 147: | Loss: 0.31448
Epoch 148: | Loss: 0.32043
Epoch 149: | Loss: 0.31789
Epoch 150: | Loss: 0.31776
Epoch 151: | Loss: 0.31555
Epoch 152: | Loss: 0.31678
Epoch 153: | Loss: 0.31709
Epoch 154: | Loss: 0.31473
Epoch 155: | Loss: 0.31973
Epoch 156: | Loss: 0.31318
Epoch 157: | Loss: 0.31434
Epoch 158: | Loss: 0.31773
Epoch 159: | Loss: 0.31518
Epoch 160: | Loss: 0.31273
Epoch 161: | Loss: 0.31496
Epoch 162: | Loss: 0.31299
Epoch 163: | Loss: 0.31589
Epoch 164: | Loss: 0.31099
Epoch 165: | Loss: 0.31030
Epoch 166: | Loss: 0.30803
Epoch 167: | Loss: 0.31504
Epoch 168: | Loss: 0.31133
Epoch 169: | Loss: 0.30723
Epoch 170: | Loss: 0.30647
Epoch 171: | Loss: 0.31370
Epoch 172: | Loss: 0.30862
Epoch 173: | Loss: 0.30856
Epoch 174: | Loss: 0.30415
Epoch 175: | Loss: 0.30342
Epoch 176: | Loss: 0.30516
Epoch 177: | Loss: 0.30899
Epoch 178: | Loss: 0.29520
Epoch 179: | Loss: 0.29547
Epoch 180: | Loss: 0.29824
Epoch 181: | Loss: 0.29376
Epoch 182: | Loss: 0.28895
Epoch 183: | Loss: 0.28601
Epoch 184: | Loss: 0.29501
Epoch 185: | Loss: 0.29537
Epoch 186: | Loss: 0.28570
Epoch 187: | Loss: 0.28007
Epoch 188: | Loss: 0.28541
Epoch 189: | Loss: 0.27991
Epoch 190: | Loss: 0.27779
Epoch 191: | Loss: 0.26948
Epoch 192: | Loss: 0.26487
Epoch 193: | Loss: 0.27379
Epoch 194: | Loss: 0.25891
Epoch 195: | Loss: 0.26465
Epoch 196: | Loss: 0.26044
Epoch 197: | Loss: 0.25963
Epoch 198: | Loss: 0.25404
Epoch 199: | Loss: 0.25288
Accuracy: 0.877275641025641
Epoch 000: | Loss: 1.23042
Epoch 001: | Loss: 0.80380
Epoch 002: | Loss: 0.72671
Epoch 003: | Loss: 0.67486
Epoch 004: | Loss: 0.61580
Epoch 005: | Loss: 0.60236
Epoch 006: | Loss: 0.58370
Epoch 007: | Loss: 0.55269
Epoch 008: | Loss: 0.53323
Epoch 009: | Loss: 0.51882
Epoch 010: | Loss: 0.50653
Epoch 011: | Loss: 0.49550
Epoch 012: | Loss: 0.47374
Epoch 013: | Loss: 0.47185
Epoch 014: | Loss: 0.45104
Epoch 015: | Loss: 0.43817
Epoch 016: | Loss: 0.43085
Epoch 017: | Loss: 0.41557
Epoch 018: | Loss: 0.41542
Epoch 019: | Loss: 0.39124
Epoch 020: | Loss: 0.38399
Epoch 021: | Loss: 0.37071
Epoch 022: | Loss: 0.36178
Epoch 023: | Loss: 0.35321
Epoch 024: | Loss: 0.33998
Epoch 025: | Loss: 0.32408
Epoch 026: | Loss: 0.31483
Epoch 027: | Loss: 0.30436
Epoch 028: | Loss: 0.29327
Epoch 029: | Loss: 0.29097
Epoch 030: | Loss: 0.28364
Epoch 031: | Loss: 0.27177
Epoch 032: | Loss: 0.25937
Epoch 033: | Loss: 0.25210
Epoch 034: | Loss: 0.24124
Epoch 035: | Loss: 0.24169
Epoch 036: | Loss: 0.23288
Epoch 037: | Loss: 0.22423
Epoch 038: | Loss: 0.21803
Epoch 039: | Loss: 0.21618
Epoch 040: | Loss: 0.21111
Epoch 041: | Loss: 0.20325
Epoch 042: | Loss: 0.19903
Epoch 043: | Loss: 0.19473
Epoch 044: | Loss: 0.19418
Epoch 045: | Loss: 0.18885
Epoch 046: | Loss: 0.19176
Epoch 047: | Loss: 0.18195
Epoch 048: | Loss: 0.18548
Epoch 049: | Loss: 0.18209
Epoch 050: | Loss: 0.18259
Epoch 051: | Loss: 0.18139
Epoch 052: | Loss: 0.17959
Epoch 053: | Loss: 0.18298
Epoch 054: | Loss: 0.18416
Epoch 055: | Loss: 0.18340
Epoch 056: | Loss: 0.18816
Epoch 057: | Loss: 0.18391
Epoch 058: | Loss: 0.18753
Epoch 059: | Loss: 0.18871
Epoch 060: | Loss: 0.18883
Epoch 061: | Loss: 0.19164
Epoch 062: | Loss: 0.18753
Epoch 063: | Loss: 0.19935
Epoch 064: | Loss: 0.19435
Epoch 065: | Loss: 0.19729
Epoch 066: | Loss: 0.20051
Epoch 067: | Loss: 0.20254
Epoch 068: | Loss: 0.19902
Epoch 069: | Loss: 0.20862
Epoch 070: | Loss: 0.19803
Epoch 071: | Loss: 0.20045
Epoch 072: | Loss: 0.21182
Epoch 073: | Loss: 0.21429
Epoch 074: | Loss: 0.20174
Epoch 075: | Loss: 0.21238
Epoch 076: | Loss: 0.20654
Epoch 077: | Loss: 0.21422
Epoch 078: | Loss: 0.20356
Epoch 079: | Loss: 0.20236
Epoch 080: | Loss: 0.20164
Epoch 081: | Loss: 0.20649
Epoch 082: | Loss: 0.21951
Epoch 083: | Loss: 0.20476
Epoch 084: | Loss: 0.20187
Epoch 085: | Loss: 0.19615
Epoch 086: | Loss: 0.19364
Epoch 087: | Loss: 0.20114
Epoch 088: | Loss: 0.20514
Epoch 089: | Loss: 0.20351
Epoch 090: | Loss: 0.20078
Epoch 091: | Loss: 0.19007
Epoch 092: | Loss: 0.19103
Epoch 093: | Loss: 0.18154
Epoch 094: | Loss: 0.19628
Epoch 095: | Loss: 0.17629
Epoch 096: | Loss: 0.17317
Epoch 097: | Loss: 0.17689
Epoch 098: | Loss: 0.17248
Epoch 099: | Loss: 0.16707
Epoch 100: | Loss: 0.17402
Epoch 101: | Loss: 0.15642
Epoch 102: | Loss: 0.15538
Epoch 103: | Loss: 0.15556
Epoch 104: | Loss: 0.16024
Epoch 105: | Loss: 0.16567
Epoch 106: | Loss: 0.15146
Epoch 107: | Loss: 0.13539
Epoch 108: | Loss: 0.13205
Epoch 109: | Loss: 0.12684
Epoch 110: | Loss: 0.12891
Epoch 111: | Loss: 0.12015
Epoch 112: | Loss: 0.11495
Epoch 113: | Loss: 0.10756
Epoch 114: | Loss: 0.11692
Epoch 115: | Loss: 0.09903
Epoch 116: | Loss: 0.09409
Epoch 117: | Loss: 0.09722
Epoch 118: | Loss: 0.09329
Epoch 119: | Loss: 0.08987
Epoch 120: | Loss: 0.07694
Epoch 121: | Loss: 0.07022
Epoch 122: | Loss: 0.07186
Epoch 123: | Loss: 0.06763
Epoch 124: | Loss: 0.06257
Epoch 125: | Loss: 0.06005
Epoch 126: | Loss: 0.05209
Epoch 127: | Loss: 0.05112
Epoch 128: | Loss: 0.04690
Epoch 129: | Loss: 0.04501
Epoch 130: | Loss: 0.04650
Epoch 131: | Loss: 0.03261
Epoch 132: | Loss: 0.03064
Epoch 133: | Loss: 0.02928
Epoch 134: | Loss: 0.02653
Epoch 135: | Loss: 0.02534
Epoch 136: | Loss: 0.02122
Epoch 137: | Loss: 0.02189
Epoch 138: | Loss: 0.02038
Epoch 139: | Loss: 0.01825
Epoch 140: | Loss: 0.01740
Epoch 141: | Loss: 0.01467
Epoch 142: | Loss: 0.01399
Epoch 143: | Loss: 0.01334
Epoch 144: | Loss: 0.01219
Epoch 145: | Loss: 0.01242
Epoch 146: | Loss: 0.01190
Epoch 147: | Loss: 0.01156
Epoch 148: | Loss: 0.01084
Epoch 149: | Loss: 0.01084
Epoch 150: | Loss: 0.01161
Epoch 151: | Loss: 0.01139
Epoch 152: | Loss: 0.01082
Epoch 153: | Loss: 0.01139
Epoch 154: | Loss: 0.01125
Epoch 155: | Loss: 0.01227
Epoch 156: | Loss: 0.01275
Epoch 157: | Loss: 0.01310
Epoch 158: | Loss: 0.01340
Epoch 159: | Loss: 0.01536
early stopping at epoch 160 with loss 0.01444
Accuracy: 0.9451095085470086
Epoch 000: | Loss: 1.31775
Epoch 001: | Loss: 0.84840
Epoch 002: | Loss: 0.70742
Epoch 003: | Loss: 0.65414
Epoch 004: | Loss: 0.61137
Epoch 005: | Loss: 0.59872
Epoch 006: | Loss: 0.58650
Epoch 007: | Loss: 0.58338
Epoch 008: | Loss: 0.56945
Epoch 009: | Loss: 0.55080
Epoch 010: | Loss: 0.54899
Epoch 011: | Loss: 0.53573
Epoch 012: | Loss: 0.52070
Epoch 013: | Loss: 0.50731
Epoch 014: | Loss: 0.49826
Epoch 015: | Loss: 0.48275
Epoch 016: | Loss: 0.47199
Epoch 017: | Loss: 0.47576
Epoch 018: | Loss: 0.45531
Epoch 019: | Loss: 0.45525
Epoch 020: | Loss: 0.44232
Epoch 021: | Loss: 0.43500
Epoch 022: | Loss: 0.42049
Epoch 023: | Loss: 0.42542
Epoch 024: | Loss: 0.40098
Epoch 025: | Loss: 0.40590
Epoch 026: | Loss: 0.38683
Epoch 027: | Loss: 0.37614
Epoch 028: | Loss: 0.37325
Epoch 029: | Loss: 0.35922
Epoch 030: | Loss: 0.35676
Epoch 031: | Loss: 0.34337
Epoch 032: | Loss: 0.33794
Epoch 033: | Loss: 0.33658
Epoch 034: | Loss: 0.32592
Epoch 035: | Loss: 0.32006
Epoch 036: | Loss: 0.31082
Epoch 037: | Loss: 0.30285
Epoch 038: | Loss: 0.29616
Epoch 039: | Loss: 0.29530
Epoch 040: | Loss: 0.28655
Epoch 041: | Loss: 0.27992
Epoch 042: | Loss: 0.27879
Epoch 043: | Loss: 0.27779
Epoch 044: | Loss: 0.27300
Epoch 045: | Loss: 0.27281
Epoch 046: | Loss: 0.27000
Epoch 047: | Loss: 0.26685
Epoch 048: | Loss: 0.26387
Epoch 049: | Loss: 0.26480
Epoch 050: | Loss: 0.26271
Epoch 051: | Loss: 0.26342
Epoch 052: | Loss: 0.26173
Epoch 053: | Loss: 0.26186
Epoch 054: | Loss: 0.26393
Epoch 055: | Loss: 0.26344
Epoch 056: | Loss: 0.26590
Epoch 057: | Loss: 0.26737
Epoch 058: | Loss: 0.26514
Epoch 059: | Loss: 0.27112
Epoch 060: | Loss: 0.26911
Epoch 061: | Loss: 0.26693
Epoch 062: | Loss: 0.27184
Epoch 063: | Loss: 0.26943
Epoch 064: | Loss: 0.26959
Epoch 065: | Loss: 0.27170
Epoch 066: | Loss: 0.27744
Epoch 067: | Loss: 0.27430
Epoch 068: | Loss: 0.27745
Epoch 069: | Loss: 0.27517
Epoch 070: | Loss: 0.27980
Epoch 071: | Loss: 0.27068
Epoch 072: | Loss: 0.27755
Epoch 073: | Loss: 0.28666
Epoch 074: | Loss: 0.28485
Epoch 075: | Loss: 0.27151
Epoch 076: | Loss: 0.27211
Epoch 077: | Loss: 0.28588
Epoch 078: | Loss: 0.27042
Epoch 079: | Loss: 0.27241
Epoch 080: | Loss: 0.28565
Epoch 081: | Loss: 0.27201
Epoch 082: | Loss: 0.26644
Epoch 083: | Loss: 0.27759
Epoch 084: | Loss: 0.26449
Epoch 085: | Loss: 0.27021
Epoch 086: | Loss: 0.26460
Epoch 087: | Loss: 0.27156
Epoch 088: | Loss: 0.26732
Epoch 089: | Loss: 0.24966
Epoch 090: | Loss: 0.25575
Epoch 091: | Loss: 0.24824
Epoch 092: | Loss: 0.24987
Epoch 093: | Loss: 0.26143
Epoch 094: | Loss: 0.24434
Epoch 095: | Loss: 0.23501
Epoch 096: | Loss: 0.23694
Epoch 097: | Loss: 0.23567
Epoch 098: | Loss: 0.22551
Epoch 099: | Loss: 0.23074
Epoch 100: | Loss: 0.22336
Epoch 101: | Loss: 0.22625
Epoch 102: | Loss: 0.23254
Epoch 103: | Loss: 0.21405
Epoch 104: | Loss: 0.20998
Epoch 105: | Loss: 0.20165
Epoch 106: | Loss: 0.19235
Epoch 107: | Loss: 0.18934
Epoch 108: | Loss: 0.18854
Epoch 109: | Loss: 0.17359
Epoch 110: | Loss: 0.17248
Epoch 111: | Loss: 0.16406
Epoch 112: | Loss: 0.16399
Epoch 113: | Loss: 0.15653
Epoch 114: | Loss: 0.15397
Epoch 115: | Loss: 0.14121
Epoch 116: | Loss: 0.13508
Epoch 117: | Loss: 0.13234
Epoch 118: | Loss: 0.14115
Epoch 119: | Loss: 0.12346
Epoch 120: | Loss: 0.11011
Epoch 121: | Loss: 0.11717
Epoch 122: | Loss: 0.10168
Epoch 123: | Loss: 0.10010
Epoch 124: | Loss: 0.09738
Epoch 125: | Loss: 0.08894
Epoch 126: | Loss: 0.08015
Epoch 127: | Loss: 0.07636
Epoch 128: | Loss: 0.06959
Epoch 129: | Loss: 0.06551
Epoch 130: | Loss: 0.06068
Epoch 131: | Loss: 0.05798
Epoch 132: | Loss: 0.05474
Epoch 133: | Loss: 0.04823
Epoch 134: | Loss: 0.04933
Epoch 135: | Loss: 0.04642
Epoch 136: | Loss: 0.03929
Epoch 137: | Loss: 0.03507
Epoch 138: | Loss: 0.03417
Epoch 139: | Loss: 0.03146
Epoch 140: | Loss: 0.03145
Epoch 141: | Loss: 0.02625
Epoch 142: | Loss: 0.02539
Epoch 143: | Loss: 0.02447
Epoch 144: | Loss: 0.02307
Epoch 145: | Loss: 0.02280
Epoch 146: | Loss: 0.02315
Epoch 147: | Loss: 0.02030
Epoch 148: | Loss: 0.02016
Epoch 149: | Loss: 0.02029
Epoch 150: | Loss: 0.02001
Epoch 151: | Loss: 0.02081
Epoch 152: | Loss: 0.02106
Epoch 153: | Loss: 0.02162
Epoch 154: | Loss: 0.02049
Epoch 155: | Loss: 0.02039
Epoch 156: | Loss: 0.02190
Epoch 157: | Loss: 0.02376
Epoch 158: | Loss: 0.02252
Epoch 159: | Loss: 0.02426
Epoch 160: | Loss: 0.02484
Epoch 161: | Loss: 0.02764
Epoch 162: | Loss: 0.02895
Epoch 163: | Loss: 0.02678
Epoch 164: | Loss: 0.03759
Epoch 165: | Loss: 0.03807
Epoch 166: | Loss: 0.03806
Epoch 167: | Loss: 0.03953
Epoch 168: | Loss: 0.04720
Epoch 169: | Loss: 0.04782
Epoch 170: | Loss: 0.05397
Epoch 171: | Loss: 0.05283
Epoch 172: | Loss: 0.04799
Epoch 173: | Loss: 0.05420
Epoch 174: | Loss: 0.05582
Epoch 175: | Loss: 0.07517
Epoch 176: | Loss: 0.07503
Epoch 177: | Loss: 0.05396
Epoch 178: | Loss: 0.06623
Epoch 179: | Loss: 0.07455
Epoch 180: | Loss: 0.05883
Epoch 181: | Loss: 0.07069
Epoch 182: | Loss: 0.07154
Epoch 183: | Loss: 0.07037
Epoch 184: | Loss: 0.08717
Epoch 185: | Loss: 0.07723
Epoch 186: | Loss: 0.08137
Epoch 187: | Loss: 0.07547
Epoch 188: | Loss: 0.08201
Epoch 189: | Loss: 0.09971
Epoch 190: | Loss: 0.07601
Epoch 191: | Loss: 0.08344
Epoch 192: | Loss: 0.09933
Epoch 193: | Loss: 0.08415
Epoch 194: | Loss: 0.08627
Epoch 195: | Loss: 0.09214
Epoch 196: | Loss: 0.12642
Epoch 197: | Loss: 0.08336
Epoch 198: | Loss: 0.08244
Epoch 199: | Loss: 0.10122
Accuracy: 0.9501201923076923
Epoch 000: | Loss: 1.39272
Epoch 001: | Loss: 0.98746
Epoch 002: | Loss: 0.73624
Epoch 003: | Loss: 0.66882
Epoch 004: | Loss: 0.62024
Epoch 005: | Loss: 0.60196
Epoch 006: | Loss: 0.56678
Epoch 007: | Loss: 0.55413
Epoch 008: | Loss: 0.52831
Epoch 009: | Loss: 0.50200
Epoch 010: | Loss: 0.49146
Epoch 011: | Loss: 0.47338
Epoch 012: | Loss: 0.47132
Epoch 013: | Loss: 0.44831
Epoch 014: | Loss: 0.43569
Epoch 015: | Loss: 0.42301
Epoch 016: | Loss: 0.41851
Epoch 017: | Loss: 0.40363
Epoch 018: | Loss: 0.38703
Epoch 019: | Loss: 0.37599
Epoch 020: | Loss: 0.37489
Epoch 021: | Loss: 0.35060
Epoch 022: | Loss: 0.34111
Epoch 023: | Loss: 0.33198
Epoch 024: | Loss: 0.32918
Epoch 025: | Loss: 0.32009
Epoch 026: | Loss: 0.30697
Epoch 027: | Loss: 0.30289
Epoch 028: | Loss: 0.29215
Epoch 029: | Loss: 0.28443
Epoch 030: | Loss: 0.27795
Epoch 031: | Loss: 0.27018
Epoch 032: | Loss: 0.26809
Epoch 033: | Loss: 0.25415
Epoch 034: | Loss: 0.25368
Epoch 035: | Loss: 0.24391
Epoch 036: | Loss: 0.24041
Epoch 037: | Loss: 0.23590
Epoch 038: | Loss: 0.22672
Epoch 039: | Loss: 0.22558
Epoch 040: | Loss: 0.21868
Epoch 041: | Loss: 0.21581
Epoch 042: | Loss: 0.21070
Epoch 043: | Loss: 0.21144
Epoch 044: | Loss: 0.20603
Epoch 045: | Loss: 0.20306
Epoch 046: | Loss: 0.20388
Epoch 047: | Loss: 0.20078
Epoch 048: | Loss: 0.19800
Epoch 049: | Loss: 0.19884
Epoch 050: | Loss: 0.19814
Epoch 051: | Loss: 0.19775
Epoch 052: | Loss: 0.19695
Epoch 053: | Loss: 0.19547
Epoch 054: | Loss: 0.19799
Epoch 055: | Loss: 0.20052
Epoch 056: | Loss: 0.20227
Epoch 057: | Loss: 0.20239
Epoch 058: | Loss: 0.20200
Epoch 059: | Loss: 0.20334
Epoch 060: | Loss: 0.20493
Epoch 061: | Loss: 0.20119
Epoch 062: | Loss: 0.20732
Epoch 063: | Loss: 0.20979
Epoch 064: | Loss: 0.21258
Epoch 065: | Loss: 0.21020
Epoch 066: | Loss: 0.21384
Epoch 067: | Loss: 0.21762
Epoch 068: | Loss: 0.21796
Epoch 069: | Loss: 0.22084
Epoch 070: | Loss: 0.22590
early stopping at epoch 71 with loss 0.22658
Accuracy: 0.9131757478632478
Epoch 000: | Loss: 1.13506
Epoch 001: | Loss: 0.87143
Epoch 002: | Loss: 0.80404
Epoch 003: | Loss: 0.76749
Epoch 004: | Loss: 0.73759
Epoch 005: | Loss: 0.71026
Epoch 006: | Loss: 0.68752
Epoch 007: | Loss: 0.67118
Epoch 008: | Loss: 0.63123
Epoch 009: | Loss: 0.62495
Epoch 010: | Loss: 0.61183
Epoch 011: | Loss: 0.59869
Epoch 012: | Loss: 0.58318
Epoch 013: | Loss: 0.57529
Epoch 014: | Loss: 0.56481
Epoch 015: | Loss: 0.54821
Epoch 016: | Loss: 0.54205
Epoch 017: | Loss: 0.53589
Epoch 018: | Loss: 0.52241
Epoch 019: | Loss: 0.50096
Epoch 020: | Loss: 0.50039
Epoch 021: | Loss: 0.48738
Epoch 022: | Loss: 0.46907
Epoch 023: | Loss: 0.45660
Epoch 024: | Loss: 0.44331
Epoch 025: | Loss: 0.44254
Epoch 026: | Loss: 0.43265
Epoch 027: | Loss: 0.42346
Epoch 028: | Loss: 0.41397
Epoch 029: | Loss: 0.40207
Epoch 030: | Loss: 0.38883
Epoch 031: | Loss: 0.38526
Epoch 032: | Loss: 0.38371
Epoch 033: | Loss: 0.37330
Epoch 034: | Loss: 0.36732
Epoch 035: | Loss: 0.35717
Epoch 036: | Loss: 0.35111
Epoch 037: | Loss: 0.34565
Epoch 038: | Loss: 0.34538
Epoch 039: | Loss: 0.33924
Epoch 040: | Loss: 0.32858
Epoch 041: | Loss: 0.33144
Epoch 042: | Loss: 0.32114
Epoch 043: | Loss: 0.32064
Epoch 044: | Loss: 0.31963
Epoch 045: | Loss: 0.31504
Epoch 046: | Loss: 0.31547
Epoch 047: | Loss: 0.31331
Epoch 048: | Loss: 0.31049
Epoch 049: | Loss: 0.30797
Epoch 050: | Loss: 0.30774
Epoch 051: | Loss: 0.30927
Epoch 052: | Loss: 0.30780
Epoch 053: | Loss: 0.30997
Epoch 054: | Loss: 0.31250
Epoch 055: | Loss: 0.30867
Epoch 056: | Loss: 0.30977
Epoch 057: | Loss: 0.30784
Epoch 058: | Loss: 0.31256
Epoch 059: | Loss: 0.31380
Epoch 060: | Loss: 0.31444
Epoch 061: | Loss: 0.31692
Epoch 062: | Loss: 0.31416
Epoch 063: | Loss: 0.31683
Epoch 064: | Loss: 0.31596
Epoch 065: | Loss: 0.31735
Epoch 066: | Loss: 0.32227
Epoch 067: | Loss: 0.31856
Epoch 068: | Loss: 0.32210
Epoch 069: | Loss: 0.31651
Epoch 070: | Loss: 0.32513
Epoch 071: | Loss: 0.31891
Epoch 072: | Loss: 0.32320
Epoch 073: | Loss: 0.31591
Epoch 074: | Loss: 0.31508
Epoch 075: | Loss: 0.32896
Epoch 076: | Loss: 0.32461
Epoch 077: | Loss: 0.32159
Epoch 078: | Loss: 0.31477
Epoch 079: | Loss: 0.32814
Epoch 080: | Loss: 0.31567
Epoch 081: | Loss: 0.31355
Epoch 082: | Loss: 0.31742
Epoch 083: | Loss: 0.31228
Epoch 084: | Loss: 0.30285
Epoch 085: | Loss: 0.30363
Epoch 086: | Loss: 0.30130
Epoch 087: | Loss: 0.29818
Epoch 088: | Loss: 0.29727
Epoch 089: | Loss: 0.30097
Epoch 090: | Loss: 0.29806
Epoch 091: | Loss: 0.28635
Epoch 092: | Loss: 0.29718
Epoch 093: | Loss: 0.28578
Epoch 094: | Loss: 0.29879
Epoch 095: | Loss: 0.28947
Epoch 096: | Loss: 0.29287
Epoch 097: | Loss: 0.27158
Epoch 098: | Loss: 0.27310
Epoch 099: | Loss: 0.26391
Epoch 100: | Loss: 0.26001
Epoch 101: | Loss: 0.26562
Epoch 102: | Loss: 0.24886
Epoch 103: | Loss: 0.25277
Epoch 104: | Loss: 0.26508
Epoch 105: | Loss: 0.23807
Epoch 106: | Loss: 0.23708
Epoch 107: | Loss: 0.22991
Epoch 108: | Loss: 0.22777
Epoch 109: | Loss: 0.22312
Epoch 110: | Loss: 0.21390
Epoch 111: | Loss: 0.21289
Epoch 112: | Loss: 0.20787
Epoch 113: | Loss: 0.20753
Epoch 114: | Loss: 0.19782
Epoch 115: | Loss: 0.18413
Epoch 116: | Loss: 0.18224
Epoch 117: | Loss: 0.17719
Epoch 118: | Loss: 0.16387
Epoch 119: | Loss: 0.15575
Epoch 120: | Loss: 0.15156
Epoch 121: | Loss: 0.14514
Epoch 122: | Loss: 0.13878
Epoch 123: | Loss: 0.12589
Epoch 124: | Loss: 0.12726
Epoch 125: | Loss: 0.11360
Epoch 126: | Loss: 0.11949
Epoch 127: | Loss: 0.10227
Epoch 128: | Loss: 0.09910
Epoch 129: | Loss: 0.09271
Epoch 130: | Loss: 0.08269
Epoch 131: | Loss: 0.07425
Epoch 132: | Loss: 0.06927
Epoch 133: | Loss: 0.06169
Epoch 134: | Loss: 0.05965
Epoch 135: | Loss: 0.05655
Epoch 136: | Loss: 0.05121
Epoch 137: | Loss: 0.04688
Epoch 138: | Loss: 0.04281
Epoch 139: | Loss: 0.03918
Epoch 140: | Loss: 0.03882
Epoch 141: | Loss: 0.03770
Epoch 142: | Loss: 0.03363
Epoch 143: | Loss: 0.03189
Epoch 144: | Loss: 0.03253
Epoch 145: | Loss: 0.03160
Epoch 146: | Loss: 0.02915
Epoch 147: | Loss: 0.02835
Epoch 148: | Loss: 0.02795
Epoch 149: | Loss: 0.02793
Epoch 150: | Loss: 0.02701
Epoch 151: | Loss: 0.02805
Epoch 152: | Loss: 0.02654
Epoch 153: | Loss: 0.02812
Epoch 154: | Loss: 0.02719
Epoch 155: | Loss: 0.02862
Epoch 156: | Loss: 0.02848
Epoch 157: | Loss: 0.03001
Epoch 158: | Loss: 0.03134
Epoch 159: | Loss: 0.03032
Epoch 160: | Loss: 0.03248
Epoch 161: | Loss: 0.03428
Epoch 162: | Loss: 0.03593
Epoch 163: | Loss: 0.03842
Epoch 164: | Loss: 0.03623
Epoch 165: | Loss: 0.04630
Epoch 166: | Loss: 0.04509
Epoch 167: | Loss: 0.04341
Epoch 168: | Loss: 0.05857
Epoch 169: | Loss: 0.04450
Epoch 170: | Loss: 0.05749
Epoch 171: | Loss: 0.05476
Epoch 172: | Loss: 0.04576
Epoch 173: | Loss: 0.06040
Epoch 174: | Loss: 0.06615
Epoch 175: | Loss: 0.06845
Epoch 176: | Loss: 0.07100
Epoch 177: | Loss: 0.08113
early stopping at epoch 178 with loss 0.07656
Accuracy: 0.8966452991452991
Epoch 000: | Loss: 1.55486
Epoch 001: | Loss: 0.77666
Epoch 002: | Loss: 0.59715
Epoch 003: | Loss: 0.58837
Epoch 004: | Loss: 0.53896
Epoch 005: | Loss: 0.53474
Epoch 006: | Loss: 0.51081
Epoch 007: | Loss: 0.56734
Epoch 008: | Loss: 0.51477
Epoch 009: | Loss: 0.48973
Epoch 010: | Loss: 0.46790
Epoch 011: | Loss: 0.45339
Epoch 012: | Loss: 0.43004
Epoch 013: | Loss: 0.40912
Epoch 014: | Loss: 0.39709
Epoch 015: | Loss: 0.37086
Epoch 016: | Loss: 0.36585
Epoch 017: | Loss: 0.34273
Epoch 018: | Loss: 0.33176
Epoch 019: | Loss: 0.32434
Epoch 020: | Loss: 0.31224
Epoch 021: | Loss: 0.29486
Epoch 022: | Loss: 0.28396
Epoch 023: | Loss: 0.27055
Epoch 024: | Loss: 0.26145
Epoch 025: | Loss: 0.24411
Epoch 026: | Loss: 0.24112
Epoch 027: | Loss: 0.22773
Epoch 028: | Loss: 0.21613
Epoch 029: | Loss: 0.20854
Epoch 030: | Loss: 0.19700
Epoch 031: | Loss: 0.19528
Epoch 032: | Loss: 0.18957
Epoch 033: | Loss: 0.17478
Epoch 034: | Loss: 0.17676
Epoch 035: | Loss: 0.16195
Epoch 036: | Loss: 0.16064
Epoch 037: | Loss: 0.15016
Epoch 038: | Loss: 0.14720
Epoch 039: | Loss: 0.13825
Epoch 040: | Loss: 0.13131
Epoch 041: | Loss: 0.13462
Epoch 042: | Loss: 0.12874
Epoch 043: | Loss: 0.12344
Epoch 044: | Loss: 0.11934
Epoch 045: | Loss: 0.11802
Epoch 046: | Loss: 0.11537
Epoch 047: | Loss: 0.11392
Epoch 048: | Loss: 0.11079
Epoch 049: | Loss: 0.11032
Epoch 050: | Loss: 0.11387
Epoch 051: | Loss: 0.11240
Epoch 052: | Loss: 0.11269
Epoch 053: | Loss: 0.11578
Epoch 054: | Loss: 0.11157
Epoch 055: | Loss: 0.11567
Epoch 056: | Loss: 0.11354
Epoch 057: | Loss: 0.11375
Epoch 058: | Loss: 0.11458
Epoch 059: | Loss: 0.11923
Epoch 060: | Loss: 0.11945
Epoch 061: | Loss: 0.12248
early stopping at epoch 62 with loss 0.12499
Accuracy: 0.04252938034188034
Epoch 000: | Loss: 1.32023
Epoch 001: | Loss: 0.87407
Epoch 002: | Loss: 0.74079
Epoch 003: | Loss: 0.68937
Epoch 004: | Loss: 0.63910
Epoch 005: | Loss: 0.61258
Epoch 006: | Loss: 0.60881
Epoch 007: | Loss: 0.58183
Epoch 008: | Loss: 0.56421
Epoch 009: | Loss: 0.55367
Epoch 010: | Loss: 0.54685
Epoch 011: | Loss: 0.51770
Epoch 012: | Loss: 0.50694
Epoch 013: | Loss: 0.48827
Epoch 014: | Loss: 0.48702
Epoch 015: | Loss: 0.46791
Epoch 016: | Loss: 0.44674
Epoch 017: | Loss: 0.44517
Epoch 018: | Loss: 0.42467
Epoch 019: | Loss: 0.41685
Epoch 020: | Loss: 0.40079
Epoch 021: | Loss: 0.38385
Epoch 022: | Loss: 0.38170
Epoch 023: | Loss: 0.36812
Epoch 024: | Loss: 0.36347
Epoch 025: | Loss: 0.35075
Epoch 026: | Loss: 0.34419
Epoch 027: | Loss: 0.33222
Epoch 028: | Loss: 0.32590
Epoch 029: | Loss: 0.31984
Epoch 030: | Loss: 0.31033
Epoch 031: | Loss: 0.30028
Epoch 032: | Loss: 0.29140
Epoch 033: | Loss: 0.28514
Epoch 034: | Loss: 0.27998
Epoch 035: | Loss: 0.27202
Epoch 036: | Loss: 0.26703
Epoch 037: | Loss: 0.26119
Epoch 038: | Loss: 0.25347
Epoch 039: | Loss: 0.25186
Epoch 040: | Loss: 0.24241
Epoch 041: | Loss: 0.23987
Epoch 042: | Loss: 0.23508
Epoch 043: | Loss: 0.22892
Epoch 044: | Loss: 0.22820
Epoch 045: | Loss: 0.22767
Epoch 046: | Loss: 0.22769
Epoch 047: | Loss: 0.22387
Epoch 048: | Loss: 0.22149
Epoch 049: | Loss: 0.22338
Epoch 050: | Loss: 0.21811
Epoch 051: | Loss: 0.22110
Epoch 052: | Loss: 0.22081
Epoch 053: | Loss: 0.22368
Epoch 054: | Loss: 0.22138
Epoch 055: | Loss: 0.22234
Epoch 056: | Loss: 0.22098
Epoch 057: | Loss: 0.22438
Epoch 058: | Loss: 0.22471
Epoch 059: | Loss: 0.22510
Epoch 060: | Loss: 0.22764
Epoch 061: | Loss: 0.22784
early stopping at epoch 62 with loss 0.23104
Accuracy: 0.3136992521367521
Epoch 000: | Loss: 1.33897
Epoch 001: | Loss: 0.72881
Epoch 002: | Loss: 0.64262
Epoch 003: | Loss: 0.60638
Epoch 004: | Loss: 0.58474
Epoch 005: | Loss: 0.56816
Epoch 006: | Loss: 0.54516
Epoch 007: | Loss: 0.51229
Epoch 008: | Loss: 0.50184
Epoch 009: | Loss: 0.49366
Epoch 010: | Loss: 0.48489
Epoch 011: | Loss: 0.46041
Epoch 012: | Loss: 0.45427
Epoch 013: | Loss: 0.44446
Epoch 014: | Loss: 0.43751
Epoch 015: | Loss: 0.43261
Epoch 016: | Loss: 0.42032
Epoch 017: | Loss: 0.40940
Epoch 018: | Loss: 0.39489
Epoch 019: | Loss: 0.38404
Epoch 020: | Loss: 0.37849
Epoch 021: | Loss: 0.37423
Epoch 022: | Loss: 0.36374
Epoch 023: | Loss: 0.36397
Epoch 024: | Loss: 0.33997
Epoch 025: | Loss: 0.33404
Epoch 026: | Loss: 0.33395
Epoch 027: | Loss: 0.32654
Epoch 028: | Loss: 0.31524
Epoch 029: | Loss: 0.30641
Epoch 030: | Loss: 0.30072
Epoch 031: | Loss: 0.29262
Epoch 032: | Loss: 0.28542
Epoch 033: | Loss: 0.28221
Epoch 034: | Loss: 0.27737
Epoch 035: | Loss: 0.26760
Epoch 036: | Loss: 0.26538
Epoch 037: | Loss: 0.25683
Epoch 038: | Loss: 0.25616
Epoch 039: | Loss: 0.24754
Epoch 040: | Loss: 0.24672
Epoch 041: | Loss: 0.24137
Epoch 042: | Loss: 0.23574
Epoch 043: | Loss: 0.23472
Epoch 044: | Loss: 0.23551
Epoch 045: | Loss: 0.23160
Epoch 046: | Loss: 0.22786
Epoch 047: | Loss: 0.22795
Epoch 048: | Loss: 0.22366
Epoch 049: | Loss: 0.22466
Epoch 050: | Loss: 0.22593
Epoch 051: | Loss: 0.22281
Epoch 052: | Loss: 0.22312
Epoch 053: | Loss: 0.22360
Epoch 054: | Loss: 0.22656
Epoch 055: | Loss: 0.22373
Epoch 056: | Loss: 0.22351
Epoch 057: | Loss: 0.22825
Epoch 058: | Loss: 0.22800
Epoch 059: | Loss: 0.22789
Epoch 060: | Loss: 0.23216
Epoch 061: | Loss: 0.23104
Epoch 062: | Loss: 0.23434
Epoch 063: | Loss: 0.22953
Epoch 064: | Loss: 0.23453
Epoch 065: | Loss: 0.24391
Epoch 066: | Loss: 0.24304
Epoch 067: | Loss: 0.25333
Epoch 068: | Loss: 0.24235
Epoch 069: | Loss: 0.23981
Epoch 070: | Loss: 0.24790
Epoch 071: | Loss: 0.24192
Epoch 072: | Loss: 0.24089
Epoch 073: | Loss: 0.24770
Epoch 074: | Loss: 0.24853
Epoch 075: | Loss: 0.24976
Epoch 076: | Loss: 0.24826
Epoch 077: | Loss: 0.24340
Epoch 078: | Loss: 0.24666
Epoch 079: | Loss: 0.24280
Epoch 080: | Loss: 0.24283
Epoch 081: | Loss: 0.24798
Epoch 082: | Loss: 0.23770
Epoch 083: | Loss: 0.25847
Epoch 084: | Loss: 0.23638
Epoch 085: | Loss: 0.23340
Epoch 086: | Loss: 0.23628
Epoch 087: | Loss: 0.23355
Epoch 088: | Loss: 0.23093
Epoch 089: | Loss: 0.23379
Epoch 090: | Loss: 0.22019
Epoch 091: | Loss: 0.21723
Epoch 092: | Loss: 0.22028
Epoch 093: | Loss: 0.22077
Epoch 094: | Loss: 0.20877
Epoch 095: | Loss: 0.20883
Epoch 096: | Loss: 0.20569
Epoch 097: | Loss: 0.20901
Epoch 098: | Loss: 0.21197
Epoch 099: | Loss: 0.21136
Epoch 100: | Loss: 0.18142
Epoch 101: | Loss: 0.23693
Epoch 102: | Loss: 0.19474
Epoch 103: | Loss: 0.19279
Epoch 104: | Loss: 0.17448
Epoch 105: | Loss: 0.17217
Epoch 106: | Loss: 0.17789
Epoch 107: | Loss: 0.17099
Epoch 108: | Loss: 0.15965
Epoch 109: | Loss: 0.15698
Epoch 110: | Loss: 0.14948
Epoch 111: | Loss: 0.14551
Epoch 112: | Loss: 0.14583
Epoch 113: | Loss: 0.13381
Epoch 114: | Loss: 0.12875
Epoch 115: | Loss: 0.12813
Epoch 116: | Loss: 0.12098
Epoch 117: | Loss: 0.11057
Epoch 118: | Loss: 0.10952
Epoch 119: | Loss: 0.10388
Epoch 120: | Loss: 0.10217
Epoch 121: | Loss: 0.08781
Epoch 122: | Loss: 0.09509
Epoch 123: | Loss: 0.08378
Epoch 124: | Loss: 0.07421
Epoch 125: | Loss: 0.07224
Epoch 126: | Loss: 0.06846
Epoch 127: | Loss: 0.06860
Epoch 128: | Loss: 0.06976
Epoch 129: | Loss: 0.05808
Epoch 130: | Loss: 0.04981
Epoch 131: | Loss: 0.05116
Epoch 132: | Loss: 0.04088
Epoch 133: | Loss: 0.04261
Epoch 134: | Loss: 0.03619
Epoch 135: | Loss: 0.03373
Epoch 136: | Loss: 0.03188
Epoch 137: | Loss: 0.02985
Epoch 138: | Loss: 0.02646
Epoch 139: | Loss: 0.02640
Epoch 140: | Loss: 0.02454
Epoch 141: | Loss: 0.02336
Epoch 142: | Loss: 0.02303
Epoch 143: | Loss: 0.02157
Epoch 144: | Loss: 0.02079
Epoch 145: | Loss: 0.01994
Epoch 146: | Loss: 0.01921
Epoch 147: | Loss: 0.01770
Epoch 148: | Loss: 0.01736
Epoch 149: | Loss: 0.01898
Epoch 150: | Loss: 0.01750
Epoch 151: | Loss: 0.01791
Epoch 152: | Loss: 0.01740
Epoch 153: | Loss: 0.01774
Epoch 154: | Loss: 0.01737
Epoch 155: | Loss: 0.01906
Epoch 156: | Loss: 0.01951
Epoch 157: | Loss: 0.01983
Epoch 158: | Loss: 0.02035
Epoch 159: | Loss: 0.02010
Epoch 160: | Loss: 0.02097
Epoch 161: | Loss: 0.02320
Epoch 162: | Loss: 0.02690
Epoch 163: | Loss: 0.02847
Epoch 164: | Loss: 0.03224
early stopping at epoch 165 with loss 0.03467
Accuracy: 0.9522836538461539
FrozenTrial(number=22, state=TrialState.COMPLETE, values=[0.9534855769230769], datetime_start=datetime.datetime(2023, 9, 4, 23, 35, 49, 517872), datetime_complete=datetime.datetime(2023, 9, 4, 23, 48, 41, 426254), params={'lr': 0.0001, 'beta1': 0.9, 'beta2': 0.999, 'eps': 1e-06, 'T_max': 150, 'eta_min': 1e-05, 'hidden_dim': 128, 'hidden_ch': 15, 'depth': 8, 'heads': 5, 'mlp_dim': 256, 'dropout': 0.1, 'emb_dropout': 0.1}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'lr': CategoricalDistribution(choices=(1e-06, 1e-05, 0.0001, 0.001)), 'beta1': CategoricalDistribution(choices=(0.9, 0.95, 0.99, 0.999)), 'beta2': CategoricalDistribution(choices=(0.9, 0.95, 0.99, 0.999)), 'eps': CategoricalDistribution(choices=(1e-09, 1e-08, 1e-07, 1e-06)), 'T_max': CategoricalDistribution(choices=(50, 100, 150, 200)), 'eta_min': CategoricalDistribution(choices=(0, 1e-08, 1e-07, 1e-06, 1e-05)), 'hidden_dim': CategoricalDistribution(choices=(64, 128, 256, 512, 1024)), 'hidden_ch': CategoricalDistribution(choices=(3, 5, 7, 8, 10, 15)), 'depth': CategoricalDistribution(choices=(3, 5, 6, 8)), 'heads': CategoricalDistribution(choices=(3, 5, 6, 8, 10)), 'mlp_dim': CategoricalDistribution(choices=(256, 512, 1024, 2048)), 'dropout': CategoricalDistribution(choices=(0.01, 0.1, 0.25, 0.5, 0.8)), 'emb_dropout': CategoricalDistribution(choices=(0.01, 0.1, 0.25, 0.5, 0.8))}, trial_id=22, value=None)
Epoch 001: | Loss: 1.31844
Epoch 002: | Loss: 0.91279
Epoch 003: | Loss: 0.76380
Epoch 004: | Loss: 0.69440
Epoch 005: | Loss: 0.65287
Epoch 006: | Loss: 0.62864
Epoch 007: | Loss: 0.60655
Epoch 008: | Loss: 0.58968
Epoch 009: | Loss: 0.57971
Epoch 010: | Loss: 0.56339
Epoch 011: | Loss: 0.55118
Epoch 012: | Loss: 0.54529
Epoch 013: | Loss: 0.53325
Epoch 014: | Loss: 0.52495
Epoch 015: | Loss: 0.51840
Epoch 016: | Loss: 0.50663
Epoch 017: | Loss: 0.49179
Epoch 018: | Loss: 0.47691
Epoch 019: | Loss: 0.46916
Epoch 020: | Loss: 0.45164
Epoch 021: | Loss: 0.43612
Epoch 022: | Loss: 0.42371
Epoch 023: | Loss: 0.41016
Epoch 024: | Loss: 0.40026
Epoch 025: | Loss: 0.39235
Epoch 026: | Loss: 0.38373
Epoch 027: | Loss: 0.37402
Epoch 028: | Loss: 0.36332
Epoch 029: | Loss: 0.35441
Epoch 030: | Loss: 0.34576
Epoch 031: | Loss: 0.33717
Epoch 032: | Loss: 0.32687
Epoch 033: | Loss: 0.32557
Epoch 034: | Loss: 0.31980
Epoch 035: | Loss: 0.31433
Epoch 036: | Loss: 0.30352
Epoch 037: | Loss: 0.29635
Epoch 038: | Loss: 0.29237
Epoch 039: | Loss: 0.28250
Epoch 040: | Loss: 0.28516
Epoch 041: | Loss: 0.27104
Epoch 042: | Loss: 0.26729
Epoch 043: | Loss: 0.25879
Epoch 044: | Loss: 0.25553
Epoch 045: | Loss: 0.24796
Epoch 046: | Loss: 0.25052
Epoch 047: | Loss: 0.23981
Epoch 048: | Loss: 0.23438
Epoch 049: | Loss: 0.23541
Epoch 050: | Loss: 0.22866
Epoch 051: | Loss: 0.22442
Epoch 052: | Loss: 0.21685
Epoch 053: | Loss: 0.21547
Epoch 054: | Loss: 0.21260
Epoch 055: | Loss: 0.20940
Epoch 056: | Loss: 0.20812
Epoch 057: | Loss: 0.20129
Epoch 058: | Loss: 0.19947
Epoch 059: | Loss: 0.19976
Epoch 060: | Loss: 0.19518
Epoch 061: | Loss: 0.19282
Epoch 062: | Loss: 0.18711
Epoch 063: | Loss: 0.18137
Epoch 064: | Loss: 0.18027
Epoch 065: | Loss: 0.17696
Epoch 066: | Loss: 0.17555
Epoch 067: | Loss: 0.17373
Epoch 068: | Loss: 0.16889
Epoch 069: | Loss: 0.17118
Epoch 070: | Loss: 0.16718
Epoch 071: | Loss: 0.16653
Epoch 072: | Loss: 0.16354
Epoch 073: | Loss: 0.16090
Epoch 074: | Loss: 0.15973
Epoch 075: | Loss: 0.15767
Epoch 076: | Loss: 0.15253
Epoch 077: | Loss: 0.15509
Epoch 078: | Loss: 0.14920
Epoch 079: | Loss: 0.14525
Epoch 080: | Loss: 0.14579
Epoch 081: | Loss: 0.14391
Epoch 082: | Loss: 0.14495
Epoch 083: | Loss: 0.14001
Epoch 084: | Loss: 0.14085
Epoch 085: | Loss: 0.13926
Epoch 086: | Loss: 0.13826
Epoch 087: | Loss: 0.13876
Epoch 088: | Loss: 0.13464
Epoch 089: | Loss: 0.12802
Epoch 090: | Loss: 0.12772
Epoch 091: | Loss: 0.12861
Epoch 092: | Loss: 0.12618
Epoch 093: | Loss: 0.12367
Epoch 094: | Loss: 0.12440
Epoch 095: | Loss: 0.12455
Epoch 096: | Loss: 0.12073
Epoch 097: | Loss: 0.12062
Epoch 098: | Loss: 0.12148
Epoch 099: | Loss: 0.11626
Epoch 100: | Loss: 0.11497
Epoch 101: | Loss: 0.11440
Epoch 102: | Loss: 0.11272
Epoch 103: | Loss: 0.11342
Epoch 104: | Loss: 0.11254
Epoch 105: | Loss: 0.11432
Epoch 106: | Loss: 0.11219
Epoch 107: | Loss: 0.10693
Epoch 108: | Loss: 0.10623
Epoch 109: | Loss: 0.11072
Epoch 110: | Loss: 0.11179
Epoch 111: | Loss: 0.10525
Epoch 112: | Loss: 0.10823
Epoch 113: | Loss: 0.10495
Epoch 114: | Loss: 0.10387
Epoch 115: | Loss: 0.10293
Epoch 116: | Loss: 0.09840
Epoch 117: | Loss: 0.10695
Epoch 118: | Loss: 0.10097
Epoch 119: | Loss: 0.10146
Epoch 120: | Loss: 0.09929
Epoch 121: | Loss: 0.10165
Epoch 122: | Loss: 0.09656
Epoch 123: | Loss: 0.09622
Epoch 124: | Loss: 0.09535
Epoch 125: | Loss: 0.09298
Epoch 126: | Loss: 0.09834
Epoch 127: | Loss: 0.09469
Epoch 128: | Loss: 0.09731
Epoch 129: | Loss: 0.09456
Epoch 130: | Loss: 0.09425
Epoch 131: | Loss: 0.09332
Epoch 132: | Loss: 0.08905
Epoch 133: | Loss: 0.09064
Epoch 134: | Loss: 0.09049
Epoch 135: | Loss: 0.08722
Epoch 136: | Loss: 0.08989
Epoch 137: | Loss: 0.09104
Epoch 138: | Loss: 0.08991
Epoch 139: | Loss: 0.08758
Epoch 140: | Loss: 0.09273
Epoch 141: | Loss: 0.08674
Epoch 142: | Loss: 0.08752
Epoch 143: | Loss: 0.09212
Epoch 144: | Loss: 0.09013
Epoch 145: | Loss: 0.08608
Epoch 146: | Loss: 0.08435
Epoch 147: | Loss: 0.08711
Epoch 148: | Loss: 0.08705
Epoch 149: | Loss: 0.09007
Epoch 150: | Loss: 0.08527
Epoch 151: | Loss: 0.08821
Epoch 152: | Loss: 0.08401
Epoch 153: | Loss: 0.08832
Epoch 154: | Loss: 0.08226
Epoch 155: | Loss: 0.08557
Epoch 156: | Loss: 0.08444
Epoch 157: | Loss: 0.08489
Epoch 158: | Loss: 0.08218
Epoch 159: | Loss: 0.08659
Epoch 160: | Loss: 0.08469
Epoch 161: | Loss: 0.08624
Epoch 162: | Loss: 0.08162
Epoch 163: | Loss: 0.08115
Epoch 164: | Loss: 0.08269
Epoch 165: | Loss: 0.08203
Epoch 166: | Loss: 0.08571
Epoch 167: | Loss: 0.08573
Epoch 168: | Loss: 0.08140
Epoch 169: | Loss: 0.08437
Epoch 170: | Loss: 0.08166
Epoch 171: | Loss: 0.08053
Epoch 172: | Loss: 0.08204
Epoch 173: | Loss: 0.08223
Epoch 174: | Loss: 0.07967
Epoch 175: | Loss: 0.08218
Epoch 176: | Loss: 0.08216
Epoch 177: | Loss: 0.08027
Epoch 178: | Loss: 0.08282
Epoch 179: | Loss: 0.07933
Epoch 180: | Loss: 0.08182
Epoch 181: | Loss: 0.08129
Epoch 182: | Loss: 0.08179
Epoch 183: | Loss: 0.08354
Epoch 184: | Loss: 0.08273
Epoch 185: | Loss: 0.07714
Epoch 186: | Loss: 0.07733
Epoch 187: | Loss: 0.08097
Epoch 188: | Loss: 0.08141
Epoch 189: | Loss: 0.08059
Epoch 190: | Loss: 0.07768
Epoch 191: | Loss: 0.07524
Epoch 192: | Loss: 0.07692
Epoch 193: | Loss: 0.07997
Epoch 194: | Loss: 0.07780
Epoch 195: | Loss: 0.07712
Epoch 196: | Loss: 0.07824
Epoch 197: | Loss: 0.07886
Epoch 198: | Loss: 0.07681
Epoch 199: | Loss: 0.07832
Epoch 200: | Loss: 0.07514
Model's state_dict:
pos_embedding 	 torch.Size([1, 16, 128])
cls_token 	 torch.Size([128])
convbackbone.input_proj.0.weight 	 torch.Size([15, 3, 1])
convbackbone.input_proj.0.bias 	 torch.Size([15])
convbackbone.input_proj.2.weight 	 torch.Size([15, 15, 1])
convbackbone.input_proj.2.bias 	 torch.Size([15])
convbackbone.input_proj.4.weight 	 torch.Size([15, 15, 1])
convbackbone.input_proj.4.bias 	 torch.Size([15])
convbackbone.input_proj.6.weight 	 torch.Size([15, 15, 1])
convbackbone.input_proj.6.bias 	 torch.Size([15])
to_embedding.weight 	 torch.Size([128, 80])
transformer.layers.0.0.norm.weight 	 torch.Size([128])
transformer.layers.0.0.norm.bias 	 torch.Size([128])
transformer.layers.0.0.fn.to_qkv.weight 	 torch.Size([960, 128])
transformer.layers.0.0.fn.to_out.0.weight 	 torch.Size([128, 320])
transformer.layers.0.0.fn.to_out.0.bias 	 torch.Size([128])
transformer.layers.0.1.norm.weight 	 torch.Size([128])
transformer.layers.0.1.norm.bias 	 torch.Size([128])
transformer.layers.0.1.fn.net.0.weight 	 torch.Size([256, 128])
transformer.layers.0.1.fn.net.0.bias 	 torch.Size([256])
transformer.layers.0.1.fn.net.3.weight 	 torch.Size([128, 256])
transformer.layers.0.1.fn.net.3.bias 	 torch.Size([128])
transformer.layers.1.0.norm.weight 	 torch.Size([128])
transformer.layers.1.0.norm.bias 	 torch.Size([128])
transformer.layers.1.0.fn.to_qkv.weight 	 torch.Size([960, 128])
transformer.layers.1.0.fn.to_out.0.weight 	 torch.Size([128, 320])
transformer.layers.1.0.fn.to_out.0.bias 	 torch.Size([128])
transformer.layers.1.1.norm.weight 	 torch.Size([128])
transformer.layers.1.1.norm.bias 	 torch.Size([128])
transformer.layers.1.1.fn.net.0.weight 	 torch.Size([256, 128])
transformer.layers.1.1.fn.net.0.bias 	 torch.Size([256])
transformer.layers.1.1.fn.net.3.weight 	 torch.Size([128, 256])
transformer.layers.1.1.fn.net.3.bias 	 torch.Size([128])
transformer.layers.2.0.norm.weight 	 torch.Size([128])
transformer.layers.2.0.norm.bias 	 torch.Size([128])
transformer.layers.2.0.fn.to_qkv.weight 	 torch.Size([960, 128])
transformer.layers.2.0.fn.to_out.0.weight 	 torch.Size([128, 320])
transformer.layers.2.0.fn.to_out.0.bias 	 torch.Size([128])
transformer.layers.2.1.norm.weight 	 torch.Size([128])
transformer.layers.2.1.norm.bias 	 torch.Size([128])
transformer.layers.2.1.fn.net.0.weight 	 torch.Size([256, 128])
transformer.layers.2.1.fn.net.0.bias 	 torch.Size([256])
transformer.layers.2.1.fn.net.3.weight 	 torch.Size([128, 256])
transformer.layers.2.1.fn.net.3.bias 	 torch.Size([128])
transformer.layers.3.0.norm.weight 	 torch.Size([128])
transformer.layers.3.0.norm.bias 	 torch.Size([128])
transformer.layers.3.0.fn.to_qkv.weight 	 torch.Size([960, 128])
transformer.layers.3.0.fn.to_out.0.weight 	 torch.Size([128, 320])
transformer.layers.3.0.fn.to_out.0.bias 	 torch.Size([128])
transformer.layers.3.1.norm.weight 	 torch.Size([128])
transformer.layers.3.1.norm.bias 	 torch.Size([128])
transformer.layers.3.1.fn.net.0.weight 	 torch.Size([256, 128])
transformer.layers.3.1.fn.net.0.bias 	 torch.Size([256])
transformer.layers.3.1.fn.net.3.weight 	 torch.Size([128, 256])
transformer.layers.3.1.fn.net.3.bias 	 torch.Size([128])
transformer.layers.4.0.norm.weight 	 torch.Size([128])
transformer.layers.4.0.norm.bias 	 torch.Size([128])
transformer.layers.4.0.fn.to_qkv.weight 	 torch.Size([960, 128])
transformer.layers.4.0.fn.to_out.0.weight 	 torch.Size([128, 320])
transformer.layers.4.0.fn.to_out.0.bias 	 torch.Size([128])
transformer.layers.4.1.norm.weight 	 torch.Size([128])
transformer.layers.4.1.norm.bias 	 torch.Size([128])
transformer.layers.4.1.fn.net.0.weight 	 torch.Size([256, 128])
transformer.layers.4.1.fn.net.0.bias 	 torch.Size([256])
transformer.layers.4.1.fn.net.3.weight 	 torch.Size([128, 256])
transformer.layers.4.1.fn.net.3.bias 	 torch.Size([128])
transformer.layers.5.0.norm.weight 	 torch.Size([128])
transformer.layers.5.0.norm.bias 	 torch.Size([128])
transformer.layers.5.0.fn.to_qkv.weight 	 torch.Size([960, 128])
transformer.layers.5.0.fn.to_out.0.weight 	 torch.Size([128, 320])
transformer.layers.5.0.fn.to_out.0.bias 	 torch.Size([128])
transformer.layers.5.1.norm.weight 	 torch.Size([128])
transformer.layers.5.1.norm.bias 	 torch.Size([128])
transformer.layers.5.1.fn.net.0.weight 	 torch.Size([256, 128])
transformer.layers.5.1.fn.net.0.bias 	 torch.Size([256])
transformer.layers.5.1.fn.net.3.weight 	 torch.Size([128, 256])
transformer.layers.5.1.fn.net.3.bias 	 torch.Size([128])
transformer.layers.6.0.norm.weight 	 torch.Size([128])
transformer.layers.6.0.norm.bias 	 torch.Size([128])
transformer.layers.6.0.fn.to_qkv.weight 	 torch.Size([960, 128])
transformer.layers.6.0.fn.to_out.0.weight 	 torch.Size([128, 320])
transformer.layers.6.0.fn.to_out.0.bias 	 torch.Size([128])
transformer.layers.6.1.norm.weight 	 torch.Size([128])
transformer.layers.6.1.norm.bias 	 torch.Size([128])
transformer.layers.6.1.fn.net.0.weight 	 torch.Size([256, 128])
transformer.layers.6.1.fn.net.0.bias 	 torch.Size([256])
transformer.layers.6.1.fn.net.3.weight 	 torch.Size([128, 256])
transformer.layers.6.1.fn.net.3.bias 	 torch.Size([128])
transformer.layers.7.0.norm.weight 	 torch.Size([128])
transformer.layers.7.0.norm.bias 	 torch.Size([128])
transformer.layers.7.0.fn.to_qkv.weight 	 torch.Size([960, 128])
transformer.layers.7.0.fn.to_out.0.weight 	 torch.Size([128, 320])
transformer.layers.7.0.fn.to_out.0.bias 	 torch.Size([128])
transformer.layers.7.1.norm.weight 	 torch.Size([128])
transformer.layers.7.1.norm.bias 	 torch.Size([128])
transformer.layers.7.1.fn.net.0.weight 	 torch.Size([256, 128])
transformer.layers.7.1.fn.net.0.bias 	 torch.Size([256])
transformer.layers.7.1.fn.net.3.weight 	 torch.Size([128, 256])
transformer.layers.7.1.fn.net.3.bias 	 torch.Size([128])
mlp_head.0.weight 	 torch.Size([128])
mlp_head.0.bias 	 torch.Size([128])
mlp_head.1.weight 	 torch.Size([6, 128])
mlp_head.1.bias 	 torch.Size([6])
Optimizer's state_dict:
state 	 {0: {'step': tensor(30200.), 'exp_avg': tensor([[[ 1.3777e-04, -2.2750e-04,  1.0962e-04,  ...,  5.7840e-06,
          -3.1296e-04,  7.1835e-05],
         [-9.4764e-04, -1.0999e-03,  2.8164e-05,  ...,  4.3642e-04,
           2.9723e-04, -4.4776e-04],
         [-5.0430e-05,  4.8310e-06,  1.9825e-04,  ...,  9.7259e-05,
           1.7409e-04,  1.9618e-04],
         ...,
         [ 1.1392e-03,  8.2342e-04,  6.4731e-04,  ..., -4.1187e-04,
          -2.1179e-04, -2.8357e-04],
         [-3.7431e-05, -5.1915e-04,  7.2608e-04,  ..., -1.8882e-04,
           2.1122e-04, -6.6128e-06],
         [ 5.2988e-04, -1.2249e-04, -8.2605e-05,  ..., -1.6343e-04,
          -3.6894e-04, -1.5872e-04]]], device='cuda:0'), 'exp_avg_sq': tensor([[[1.0392e-06, 2.6157e-06, 1.1229e-06,  ..., 1.4442e-06,
          1.3134e-06, 9.2441e-07],
         [4.8925e-06, 1.9500e-05, 1.5746e-05,  ..., 3.3282e-06,
          1.0508e-05, 2.5711e-05],
         [1.0683e-06, 8.1521e-07, 8.4844e-07,  ..., 3.7739e-07,
          4.4742e-07, 1.0626e-06],
         ...,
         [1.0849e-05, 1.1703e-05, 1.6944e-05,  ..., 1.2451e-05,
          7.8487e-06, 1.6463e-05],
         [1.0414e-06, 1.3669e-06, 2.7621e-06,  ..., 7.0227e-07,
          1.4084e-06, 1.6759e-06],
         [5.6934e-06, 3.6596e-06, 2.0597e-06,  ..., 1.2208e-06,
          3.0685e-06, 6.2495e-06]]], device='cuda:0')}, 1: {'step': tensor(30200.), 'exp_avg': tensor([ 1.3777e-04, -2.2750e-04,  1.0962e-04,  1.6906e-04, -9.7786e-05,
        -4.4700e-05,  4.9363e-04,  2.9006e-04,  1.8764e-05, -3.1324e-04,
         7.8671e-05,  3.2156e-04,  2.1924e-04,  2.0509e-05, -3.1608e-06,
        -2.9167e-06,  4.9342e-05,  8.1227e-05, -1.9239e-04, -1.6162e-04,
         2.9632e-04, -1.9525e-04,  4.0461e-04,  1.6255e-04,  2.0922e-04,
        -6.0542e-05,  9.6835e-05, -3.2579e-04,  4.5892e-04,  5.1198e-05,
        -1.7153e-04, -7.4965e-05, -6.1315e-05,  3.9655e-05,  1.1995e-04,
        -2.1137e-04,  1.2914e-04,  9.4712e-05, -3.3687e-04, -7.8278e-05,
        -8.1231e-05,  4.7508e-04,  6.6214e-05,  6.1629e-05,  5.1395e-04,
        -3.2957e-04, -6.6510e-05,  6.8581e-04, -1.5593e-05,  2.6195e-04,
        -3.5923e-04, -2.0411e-04, -3.8452e-04, -4.1212e-04, -2.6989e-04,
        -4.0751e-05, -4.5980e-05, -2.6947e-04, -1.1591e-04,  1.2180e-05,
        -2.5784e-04, -1.5338e-04,  3.6030e-05,  1.7256e-04, -7.7095e-06,
        -1.0241e-04, -2.5227e-04, -3.2493e-04, -1.5609e-04, -3.6617e-04,
        -2.6259e-04, -3.6685e-05, -1.7744e-04, -1.6633e-04,  6.9678e-06,
        -1.0467e-04, -5.5349e-05, -1.1326e-04,  1.5087e-05,  2.0565e-05,
        -2.3514e-04, -4.0495e-05,  1.3585e-04,  1.5354e-04, -1.1309e-04,
        -1.5147e-04,  4.3710e-05,  4.8441e-05, -1.9045e-05,  3.3112e-04,
        -2.3297e-04, -4.8890e-04,  2.0324e-04, -2.5768e-04, -2.6883e-05,
         1.1019e-04,  1.6928e-05, -9.1650e-05, -2.5111e-04,  1.8291e-05,
         8.6542e-05,  5.7880e-06,  1.9016e-05,  1.4282e-05,  9.3064e-05,
         3.6798e-04, -8.0016e-06,  3.0688e-04, -6.6987e-06, -3.4264e-04,
        -4.5538e-05,  8.7778e-05,  2.8509e-04,  1.8389e-04,  5.0494e-04,
         2.0758e-04,  1.6090e-04, -3.4939e-04, -3.0551e-04,  3.0985e-05,
        -1.8326e-04, -6.1133e-05, -1.0202e-04,  5.9111e-05,  4.6070e-05,
         5.7840e-06, -3.1296e-04,  7.1835e-05], device='cuda:0'), 'exp_avg_sq': tensor([1.0392e-06, 2.6157e-06, 1.1229e-06, 7.7268e-07, 1.1770e-06, 6.6310e-07,
        1.1036e-06, 1.1307e-06, 1.7740e-06, 7.5205e-07, 6.4938e-07, 8.8171e-07,
        1.6572e-06, 1.7130e-06, 2.2404e-06, 1.3403e-06, 1.3914e-06, 8.4288e-07,
        1.0525e-06, 8.9554e-07, 1.3966e-06, 1.1858e-06, 2.5654e-06, 1.7471e-06,
        1.8434e-06, 1.0949e-06, 1.7110e-06, 1.0649e-06, 7.6929e-07, 1.8433e-06,
        2.2204e-06, 1.2446e-06, 8.4131e-07, 1.3772e-06, 8.0202e-07, 1.9629e-06,
        1.2171e-06, 1.7557e-06, 1.5698e-06, 1.5320e-06, 9.9968e-07, 1.2612e-06,
        8.1666e-07, 6.6835e-07, 9.3264e-07, 8.5769e-07, 9.8398e-07, 1.0363e-06,
        1.5645e-06, 1.5271e-06, 2.0247e-06, 2.0382e-06, 2.7403e-06, 1.3928e-06,
        9.0635e-07, 6.9009e-07, 1.8980e-06, 1.8757e-06, 1.4556e-06, 9.6023e-07,
        2.4142e-06, 7.0912e-07, 1.3380e-06, 9.0097e-07, 1.7326e-06, 1.7102e-06,
        1.0540e-06, 1.1099e-06, 7.3538e-07, 1.2804e-06, 8.6073e-07, 7.3968e-07,
        1.5032e-06, 8.5129e-07, 6.8419e-07, 5.4481e-07, 4.6560e-07, 1.8134e-06,
        1.2464e-06, 9.9014e-07, 1.2245e-06, 1.0881e-06, 2.4140e-06, 1.3576e-06,
        1.4468e-06, 1.2236e-06, 1.2340e-06, 2.7674e-06, 2.4279e-06, 2.7969e-06,
        1.2668e-06, 1.2590e-06, 1.4219e-06, 6.1976e-07, 1.2028e-06, 2.1410e-06,
        8.0865e-07, 1.2579e-06, 1.9563e-06, 2.4573e-06, 8.9770e-07, 1.4054e-06,
        1.0276e-06, 7.2350e-07, 2.8075e-06, 9.5807e-07, 1.0090e-06, 1.5583e-06,
        1.1462e-06, 9.8337e-07, 1.9043e-06, 1.2495e-06, 1.4932e-06, 1.4533e-06,
        2.1918e-06, 1.0758e-06, 6.0757e-07, 1.0503e-06, 1.7804e-06, 2.1880e-06,
        2.0989e-06, 5.7973e-07, 1.3005e-06, 1.1657e-06, 2.1463e-06, 1.4442e-06,
        1.3134e-06, 9.2441e-07], device='cuda:0')}, 2: {'step': tensor(30200.), 'exp_avg': tensor([[[ 0.0008],
         [-0.0112],
         [-0.0044]],

        [[ 0.0021],
         [ 0.0055],
         [ 0.0125]],

        [[ 0.0038],
         [-0.0013],
         [-0.0020]],

        [[-0.0107],
         [-0.0081],
         [-0.0027]],

        [[-0.0184],
         [-0.0201],
         [-0.0232]],

        [[ 0.0058],
         [-0.0049],
         [-0.0074]],

        [[ 0.0035],
         [ 0.0021],
         [ 0.0004]],

        [[-0.0166],
         [-0.0053],
         [-0.0081]],

        [[ 0.0154],
         [-0.0067],
         [-0.0189]],

        [[-0.0079],
         [-0.0033],
         [ 0.0061]],

        [[-0.0165],
         [-0.0140],
         [ 0.0151]],

        [[-0.0047],
         [-0.0045],
         [-0.0011]],

        [[-0.0069],
         [-0.0110],
         [ 0.0078]],

        [[-0.0014],
         [ 0.0070],
         [ 0.0121]],

        [[-0.0124],
         [ 0.0015],
         [-0.0014]]], device='cuda:0'), 'exp_avg_sq': tensor([[[0.0038],
         [0.0069],
         [0.0044]],

        [[0.0062],
         [0.0103],
         [0.0172]],

        [[0.0054],
         [0.0036],
         [0.0021]],

        [[0.0274],
         [0.0608],
         [0.0512]],

        [[0.0389],
         [0.0280],
         [0.0139]],

        [[0.0017],
         [0.0019],
         [0.0039]],

        [[0.0014],
         [0.0009],
         [0.0013]],

        [[0.0315],
         [0.0253],
         [0.0190]],

        [[0.0089],
         [0.0049],
         [0.0061]],

        [[0.0093],
         [0.0101],
         [0.0120]],

        [[0.0201],
         [0.0330],
         [0.0586]],

        [[0.0022],
         [0.0025],
         [0.0017]],

        [[0.0156],
         [0.0097],
         [0.0208]],

        [[0.0022],
         [0.0026],
         [0.0050]],

        [[0.0142],
         [0.0126],
         [0.0112]]], device='cuda:0')}, 3: {'step': tensor(30200.), 'exp_avg': tensor([ 0.0044,  0.0054, -0.0026,  0.0127,  0.0027, -0.0039, -0.0019,  0.0056,
         0.0072,  0.0063,  0.0137, -0.0015,  0.0079,  0.0017,  0.0037],
       device='cuda:0'), 'exp_avg_sq': tensor([1.1117e-03, 4.2937e-04, 9.5265e-04, 1.7208e-03, 5.5378e-04, 8.2157e-04,
        1.6891e-04, 7.5967e-04, 5.8723e-04, 5.8178e-04, 1.4766e-03, 5.0200e-04,
        6.6228e-04, 9.4352e-05, 1.9490e-03], device='cuda:0')}, 4: {'step': tensor(30200.), 'exp_avg': tensor([[[ 7.7240e-03],
         [-2.2680e-03],
         [ 2.1032e-03],
         [ 3.6866e-03],
         [-6.7476e-03],
         [ 8.7386e-04],
         [-5.5726e-04],
         [-8.8475e-03],
         [-6.0238e-03],
         [-1.9040e-02],
         [ 1.3784e-02],
         [ 1.0041e-02],
         [ 3.6512e-03],
         [-4.4804e-03],
         [-1.9550e-03]],

        [[ 4.1067e-03],
         [ 1.1967e-03],
         [ 7.0157e-03],
         [-1.9195e-03],
         [-2.0012e-03],
         [ 3.4716e-03],
         [ 4.4697e-03],
         [ 1.1830e-03],
         [-1.1876e-03],
         [ 8.7629e-03],
         [ 1.1616e-02],
         [ 1.1727e-02],
         [ 1.5315e-03],
         [ 2.7363e-03],
         [ 1.8558e-03]],

        [[ 1.2838e-02],
         [-1.1731e-02],
         [ 7.2626e-03],
         [ 2.4301e-03],
         [ 7.3572e-03],
         [ 1.1831e-02],
         [ 1.0825e-02],
         [-9.2810e-03],
         [ 1.1215e-02],
         [-2.7867e-02],
         [ 4.1098e-03],
         [ 1.1511e-02],
         [ 8.4317e-03],
         [-1.4411e-02],
         [ 5.0912e-03]],

        [[-2.8848e-03],
         [ 9.0708e-03],
         [-8.0405e-04],
         [ 2.8220e-03],
         [-1.4750e-03],
         [ 1.0623e-03],
         [ 7.4661e-04],
         [ 1.6295e-02],
         [-2.1913e-03],
         [ 2.6879e-02],
         [ 4.6647e-03],
         [-9.9522e-04],
         [-2.0032e-03],
         [ 1.2185e-02],
         [-6.5225e-04]],

        [[ 3.6477e-03],
         [ 8.2618e-03],
         [ 2.8349e-03],
         [ 9.7916e-03],
         [-1.7596e-03],
         [ 1.1272e-03],
         [-1.4346e-03],
         [ 1.4838e-02],
         [-2.6580e-03],
         [ 2.0783e-02],
         [ 1.2918e-02],
         [ 5.1136e-03],
         [ 3.6500e-03],
         [ 9.1302e-03],
         [-2.7249e-03]],

        [[-6.6130e-03],
         [-3.2695e-03],
         [-4.5612e-03],
         [-7.9701e-03],
         [ 2.0602e-03],
         [-6.9688e-04],
         [ 1.8487e-03],
         [-6.8406e-03],
         [ 4.8413e-03],
         [-6.2689e-03],
         [-1.1677e-02],
         [-1.0157e-02],
         [-6.0885e-03],
         [-2.6339e-03],
         [ 3.2978e-03]],

        [[-1.9365e-03],
         [-4.7636e-03],
         [-2.0099e-03],
         [-1.4353e-03],
         [-7.1604e-03],
         [-1.6349e-04],
         [-1.3861e-03],
         [-1.5585e-02],
         [-6.2960e-03],
         [-2.3134e-02],
         [ 4.2713e-03],
         [ 5.6732e-04],
         [-1.9400e-03],
         [-6.1707e-03],
         [-1.5479e-03]],

        [[ 1.4980e-02],
         [ 2.3213e-04],
         [ 1.5582e-02],
         [ 6.0416e-03],
         [ 1.5721e-02],
         [ 1.7830e-02],
         [ 1.6678e-02],
         [ 2.9562e-02],
         [ 1.9143e-02],
         [ 2.2820e-02],
         [-1.6194e-03],
         [ 1.8029e-02],
         [ 5.7881e-03],
         [ 1.6420e-03],
         [ 8.7462e-03]],

        [[ 2.7058e-03],
         [ 6.2654e-04],
         [ 5.0695e-03],
         [ 2.0441e-03],
         [ 6.5181e-03],
         [ 7.7889e-03],
         [ 7.6319e-03],
         [ 1.2118e-02],
         [ 6.3347e-03],
         [ 1.1237e-02],
         [-8.7270e-04],
         [ 4.8740e-03],
         [ 3.9562e-04],
         [ 1.9082e-03],
         [ 4.1442e-03]],

        [[-1.2774e-03],
         [-7.7124e-04],
         [-9.6366e-04],
         [-3.2577e-03],
         [-9.2193e-03],
         [ 1.2594e-03],
         [ 6.4123e-05],
         [-1.5253e-02],
         [-9.4519e-03],
         [-1.2587e-02],
         [ 1.1974e-02],
         [ 3.2698e-03],
         [-2.5633e-03],
         [-7.0222e-04],
         [-1.7096e-03]],

        [[ 2.1293e-02],
         [-5.2752e-03],
         [ 8.8417e-03],
         [ 3.0026e-03],
         [-3.4708e-03],
         [ 1.1983e-02],
         [ 8.6476e-03],
         [-1.1312e-03],
         [ 7.7435e-04],
         [-1.3502e-02],
         [ 1.5014e-02],
         [ 2.3915e-02],
         [ 1.2744e-02],
         [-6.3816e-03],
         [ 1.3776e-03]],

        [[ 7.6914e-03],
         [ 8.0423e-04],
         [ 1.5462e-03],
         [-3.8871e-03],
         [-4.1680e-03],
         [-1.3287e-03],
         [-5.0742e-04],
         [-3.2642e-03],
         [-3.6671e-03],
         [ 2.7567e-03],
         [ 1.8911e-02],
         [ 9.7630e-03],
         [ 2.0417e-03],
         [ 1.4422e-03],
         [-2.0739e-03]],

        [[ 4.4604e-03],
         [ 4.3803e-03],
         [ 5.5353e-03],
         [ 7.6763e-03],
         [ 3.5087e-03],
         [ 2.6995e-03],
         [ 1.8654e-03],
         [ 1.6341e-03],
         [ 5.9467e-03],
         [ 2.8568e-03],
         [ 3.6141e-03],
         [ 3.2286e-03],
         [ 4.3903e-03],
         [ 1.9168e-03],
         [ 1.4379e-03]],

        [[-7.1189e-04],
         [ 4.8433e-03],
         [ 2.7824e-04],
         [ 2.4587e-04],
         [ 3.1499e-03],
         [-6.3031e-04],
         [ 1.8844e-04],
         [ 7.7924e-03],
         [-2.8075e-04],
         [ 1.8356e-02],
         [ 4.3832e-03],
         [ 9.3456e-05],
         [ 1.6677e-03],
         [ 7.0240e-03],
         [ 2.7832e-04]],

        [[-3.2124e-03],
         [-4.5268e-04],
         [ 3.2044e-03],
         [-3.6908e-03],
         [ 4.9931e-03],
         [ 8.6384e-03],
         [ 1.0574e-02],
         [ 2.1151e-03],
         [ 6.3056e-03],
         [ 1.6460e-03],
         [-8.6007e-03],
         [ 2.2728e-04],
         [-6.5968e-03],
         [ 1.1290e-03],
         [ 7.4128e-03]]], device='cuda:0'), 'exp_avg_sq': tensor([[[2.1176e-03],
         [8.2171e-03],
         [8.3103e-04],
         [8.9433e-04],
         [8.2637e-04],
         [6.4431e-04],
         [6.0763e-04],
         [3.3605e-02],
         [3.5868e-04],
         [1.0861e-01],
         [2.8669e-03],
         [2.5883e-03],
         [1.3810e-03],
         [1.5620e-02],
         [1.3264e-04]],

        [[1.3512e-03],
         [3.3111e-03],
         [2.0889e-03],
         [1.0199e-03],
         [6.8899e-05],
         [7.4752e-04],
         [1.2267e-03],
         [5.7206e-03],
         [1.6808e-05],
         [2.4380e-02],
         [3.9092e-03],
         [4.4220e-03],
         [8.7335e-04],
         [4.6960e-03],
         [4.3143e-04]],

        [[2.5620e-03],
         [3.5321e-03],
         [1.3260e-03],
         [5.7692e-04],
         [1.7986e-03],
         [2.8163e-03],
         [2.3522e-03],
         [1.8655e-02],
         [1.3129e-03],
         [5.2378e-02],
         [1.7375e-03],
         [3.1222e-03],
         [1.3790e-03],
         [6.9983e-03],
         [4.5819e-04]],

        [[4.8669e-04],
         [1.3051e-03],
         [1.9509e-04],
         [6.8296e-04],
         [2.9102e-04],
         [4.1128e-04],
         [1.5795e-04],
         [5.6225e-03],
         [1.3116e-04],
         [1.6243e-02],
         [5.6316e-04],
         [2.5873e-04],
         [4.0234e-04],
         [2.3731e-03],
         [6.4327e-05]],

        [[3.0461e-03],
         [3.3916e-03],
         [5.7561e-03],
         [1.4120e-03],
         [4.9673e-04],
         [5.9216e-03],
         [5.7162e-03],
         [1.4097e-02],
         [7.1390e-04],
         [4.3773e-02],
         [3.3007e-03],
         [1.0227e-02],
         [8.6389e-04],
         [6.3981e-03],
         [1.2277e-03]],

        [[9.6097e-03],
         [4.8975e-04],
         [1.1321e-02],
         [1.6532e-03],
         [6.6144e-04],
         [1.2347e-02],
         [1.1796e-02],
         [3.1854e-03],
         [1.7274e-03],
         [6.2646e-03],
         [5.6425e-03],
         [2.3731e-02],
         [2.6745e-03],
         [7.8645e-04],
         [2.3278e-03]],

        [[3.1388e-04],
         [6.6922e-03],
         [1.1295e-04],
         [1.2290e-03],
         [2.3075e-03],
         [8.1975e-04],
         [1.9729e-04],
         [4.1074e-02],
         [7.2369e-04],
         [1.0253e-01],
         [3.3150e-04],
         [3.8830e-05],
         [2.5155e-04],
         [1.3724e-02],
         [1.6615e-05]],

        [[5.7159e-03],
         [5.0686e-03],
         [5.0810e-03],
         [4.1017e-03],
         [2.7091e-03],
         [5.9295e-03],
         [5.2120e-03],
         [9.6426e-03],
         [2.1865e-03],
         [2.0047e-02],
         [1.0286e-02],
         [1.0752e-02],
         [3.1997e-03],
         [5.0541e-03],
         [1.1602e-03]],

        [[8.2139e-04],
         [4.0358e-05],
         [5.8951e-04],
         [2.2039e-04],
         [8.5201e-04],
         [1.5838e-03],
         [1.2692e-03],
         [2.5533e-03],
         [7.8321e-04],
         [1.3668e-03],
         [2.8482e-05],
         [9.7556e-04],
         [2.6115e-04],
         [6.0193e-05],
         [2.5390e-04]],

        [[2.1304e-03],
         [1.7673e-02],
         [3.7321e-04],
         [2.6492e-03],
         [2.7324e-03],
         [9.3457e-04],
         [2.8092e-04],
         [7.2286e-02],
         [9.7268e-04],
         [2.2227e-01],
         [4.7765e-03],
         [1.2132e-03],
         [2.0199e-03],
         [3.2712e-02],
         [3.4666e-05]],

        [[6.8257e-03],
         [8.9856e-03],
         [4.7873e-03],
         [1.2209e-03],
         [2.3162e-03],
         [6.0867e-03],
         [5.3250e-03],
         [5.1736e-02],
         [1.4673e-03],
         [1.4236e-01],
         [3.5289e-03],
         [1.1641e-02],
         [2.6584e-03],
         [1.8743e-02],
         [9.6985e-04]],

        [[3.0660e-03],
         [2.6140e-02],
         [6.3637e-04],
         [3.3338e-03],
         [1.1590e-04],
         [3.2734e-05],
         [3.7461e-05],
         [4.7363e-02],
         [7.3809e-05],
         [2.2454e-01],
         [1.1413e-02],
         [2.8891e-03],
         [3.6533e-03],
         [4.0299e-02],
         [4.0166e-05]],

        [[3.6559e-03],
         [3.1480e-04],
         [5.0923e-03],
         [9.6621e-04],
         [9.5554e-04],
         [5.8424e-03],
         [5.6275e-03],
         [3.1356e-03],
         [1.0360e-03],
         [3.1144e-03],
         [2.5273e-03],
         [1.0033e-02],
         [1.1598e-03],
         [4.2696e-04],
         [1.2165e-03]],

        [[1.1640e-04],
         [2.4344e-03],
         [9.9356e-05],
         [3.1163e-04],
         [2.4800e-04],
         [1.6559e-05],
         [1.7720e-05],
         [1.0262e-02],
         [8.0817e-06],
         [3.0600e-02],
         [7.8659e-04],
         [3.1557e-04],
         [1.0944e-04],
         [4.4484e-03],
         [5.1106e-06]],

        [[9.4055e-03],
         [1.0539e-04],
         [1.1656e-02],
         [3.0233e-03],
         [2.0916e-03],
         [1.9176e-02],
         [1.5859e-02],
         [6.2824e-03],
         [3.4073e-03],
         [2.0538e-03],
         [2.2089e-03],
         [2.0311e-02],
         [2.0583e-03],
         [1.5321e-04],
         [2.8787e-03]]], device='cuda:0')}, 5: {'step': tensor(30200.), 'exp_avg': tensor([ 0.0139,  0.0111,  0.0052,  0.0100,  0.0165, -0.0127,  0.0046,  0.0079,
         0.0025,  0.0108,  0.0203,  0.0156, -0.0020,  0.0012, -0.0075],
       device='cuda:0'), 'exp_avg_sq': tensor([0.0035, 0.0015, 0.0020, 0.0019, 0.0040, 0.0076, 0.0018, 0.0040, 0.0004,
        0.0051, 0.0061, 0.0047, 0.0026, 0.0005, 0.0087], device='cuda:0')}, 6: {'step': tensor(30200.), 'exp_avg': tensor([[[ 8.6885e-03],
         [ 1.3271e-02],
         [ 2.0256e-02],
         [-1.5317e-02],
         [ 2.8813e-03],
         [ 3.2402e-02],
         [ 6.0533e-03],
         [ 2.3655e-02],
         [ 1.2873e-02],
         [ 7.5758e-03],
         [ 2.5814e-02],
         [ 6.5727e-05],
         [ 2.1676e-02],
         [-1.8449e-03],
         [ 4.8164e-03]],

        [[ 1.6380e-03],
         [-4.0590e-04],
         [ 9.8990e-04],
         [ 1.3305e-03],
         [ 7.7788e-04],
         [-1.2792e-03],
         [ 8.3690e-04],
         [-6.2403e-04],
         [ 2.8923e-04],
         [ 7.0119e-04],
         [ 6.8268e-04],
         [ 1.7197e-04],
         [-1.3916e-03],
         [ 4.4534e-04],
         [-3.0988e-04]],

        [[-1.3525e-02],
         [-1.9546e-02],
         [-1.1189e-02],
         [ 4.6014e-03],
         [ 4.5128e-03],
         [-1.0116e-02],
         [-8.9293e-04],
         [-2.7917e-03],
         [ 3.4598e-03],
         [-5.7946e-03],
         [-2.6190e-03],
         [-3.8919e-03],
         [ 5.4054e-04],
         [-5.2148e-03],
         [-4.1865e-03]],

        [[-1.8142e-02],
         [ 8.7111e-03],
         [-1.3574e-02],
         [-8.5387e-03],
         [-1.9603e-02],
         [ 5.3970e-03],
         [-9.0401e-03],
         [ 6.6670e-03],
         [-3.0152e-03],
         [-7.3604e-03],
         [-1.4376e-02],
         [-1.7026e-03],
         [ 8.0707e-03],
         [ 8.3199e-03],
         [ 2.3740e-03]],

        [[-1.2509e-02],
         [-1.1408e-02],
         [-8.8740e-03],
         [-1.5440e-03],
         [-3.9553e-04],
         [-1.5656e-04],
         [-3.5550e-03],
         [-2.0161e-03],
         [ 1.2139e-04],
         [-5.7813e-03],
         [-4.3857e-03],
         [-4.1375e-03],
         [ 5.8702e-03],
         [-5.3099e-03],
         [-6.7169e-04]],

        [[ 2.2185e-02],
         [ 3.9037e-03],
         [ 2.1133e-02],
         [ 2.1869e-03],
         [ 1.1378e-02],
         [ 5.0124e-03],
         [ 1.2483e-02],
         [ 2.2813e-03],
         [ 5.2892e-03],
         [ 1.2581e-02],
         [ 2.0984e-02],
         [ 3.5177e-03],
         [-2.8198e-03],
         [-1.9807e-03],
         [-5.2887e-04]],

        [[ 1.9901e-02],
         [ 1.8570e-02],
         [ 8.4391e-03],
         [ 1.5113e-02],
         [ 1.6831e-02],
         [ 1.5041e-02],
         [-5.2944e-03],
         [ 7.5863e-03],
         [-8.2894e-03],
         [ 1.5761e-03],
         [-8.3827e-03],
         [ 8.6585e-03],
         [ 1.2982e-02],
         [ 2.2604e-02],
         [ 9.7025e-04]],

        [[ 2.8217e-02],
         [ 2.5200e-02],
         [ 2.7473e-02],
         [ 1.7183e-03],
         [ 1.4716e-02],
         [ 3.2108e-02],
         [ 5.5986e-03],
         [ 2.1049e-02],
         [ 5.1780e-03],
         [ 1.1419e-02],
         [ 1.7005e-02],
         [ 7.0923e-03],
         [ 1.9804e-02],
         [ 1.4934e-02],
         [ 4.8029e-03]],

        [[ 5.4779e-03],
         [ 1.9233e-03],
         [ 1.5007e-02],
         [-3.8332e-03],
         [ 6.8662e-03],
         [ 2.1514e-02],
         [ 2.9977e-03],
         [ 1.3163e-02],
         [ 1.1165e-02],
         [ 4.3589e-03],
         [ 1.5806e-02],
         [-2.3341e-04],
         [ 1.8086e-02],
         [-6.2867e-04],
         [ 3.7406e-03]],

        [[-1.4691e-02],
         [ 8.1079e-03],
         [-1.3170e-02],
         [-1.2197e-02],
         [-7.5258e-03],
         [ 2.0825e-03],
         [-5.8362e-03],
         [ 6.4185e-03],
         [-4.1794e-03],
         [-5.3100e-03],
         [-9.9821e-03],
         [ 5.3283e-03],
         [ 5.3253e-03],
         [ 4.4182e-03],
         [ 6.1275e-05]],

        [[-1.9778e-02],
         [-1.0116e-02],
         [-2.0057e-02],
         [-1.6937e-03],
         [-1.0913e-02],
         [-2.6536e-02],
         [-6.1328e-03],
         [-1.8250e-02],
         [-6.9429e-03],
         [-7.1473e-03],
         [-2.0385e-02],
         [ 1.6946e-03],
         [-1.8149e-02],
         [-1.2700e-03],
         [-3.8076e-03]],

        [[ 1.7652e-03],
         [ 5.3511e-04],
         [ 6.6301e-03],
         [-3.1267e-03],
         [-7.2313e-04],
         [ 3.7092e-03],
         [ 3.6083e-03],
         [ 3.2626e-03],
         [ 5.2263e-03],
         [ 2.9051e-03],
         [ 8.9087e-03],
         [-1.7441e-03],
         [ 3.7346e-04],
         [-2.6356e-03],
         [ 1.0623e-03]],

        [[ 7.5802e-05],
         [ 6.7572e-03],
         [-1.2653e-03],
         [ 3.3634e-03],
         [ 5.5229e-03],
         [ 5.4108e-03],
         [-7.8684e-03],
         [ 6.2000e-04],
         [-5.4343e-03],
         [-3.1671e-03],
         [-9.9870e-03],
         [ 4.6575e-03],
         [ 5.7370e-03],
         [ 9.3861e-03],
         [-2.5500e-04]],

        [[-9.7497e-03],
         [ 9.6922e-03],
         [-3.0790e-03],
         [-1.5261e-02],
         [-9.5374e-03],
         [ 1.5595e-02],
         [-5.1809e-03],
         [ 8.5192e-03],
         [-6.1783e-04],
         [-3.2283e-03],
         [-1.6943e-05],
         [ 2.3825e-03],
         [ 1.3857e-02],
         [ 7.0407e-06],
         [ 2.2425e-03]],

        [[ 1.1446e-02],
         [ 9.5412e-03],
         [ 1.9280e-02],
         [-6.1812e-03],
         [ 5.4999e-03],
         [ 3.3827e-02],
         [ 3.8878e-03],
         [ 2.4608e-02],
         [ 1.1272e-02],
         [ 5.0999e-03],
         [ 2.4826e-02],
         [-3.6858e-03],
         [ 2.4815e-02],
         [ 9.6475e-06],
         [ 4.1092e-03]]], device='cuda:0'), 'exp_avg_sq': tensor([[[4.5851e-02],
         [5.4655e-03],
         [2.1408e-02],
         [1.2964e-02],
         [2.6689e-02],
         [1.2228e-02],
         [3.1332e-03],
         [7.7478e-03],
         [1.2869e-03],
         [6.0520e-03],
         [7.6387e-03],
         [2.9907e-03],
         [7.7265e-03],
         [4.1479e-03],
         [3.5955e-04]],

        [[8.1259e-05],
         [6.0565e-06],
         [3.1345e-05],
         [5.6738e-05],
         [5.4454e-05],
         [6.4492e-05],
         [5.0668e-06],
         [3.5859e-05],
         [1.0183e-05],
         [6.5654e-06],
         [9.3130e-06],
         [3.0304e-06],
         [7.9934e-05],
         [8.0453e-06],
         [7.9183e-06]],

        [[1.8472e-02],
         [1.5646e-02],
         [2.3234e-02],
         [5.1119e-04],
         [1.5880e-02],
         [1.0226e-01],
         [5.0889e-04],
         [5.7070e-02],
         [5.8958e-03],
         [2.2495e-03],
         [1.8532e-02],
         [1.0069e-03],
         [8.1095e-02],
         [2.7892e-03],
         [2.3897e-03]],

        [[6.7296e-02],
         [3.1123e-03],
         [2.9413e-02],
         [2.5915e-02],
         [3.9472e-02],
         [2.8184e-03],
         [3.2833e-03],
         [4.7772e-04],
         [1.7039e-04],
         [6.7701e-03],
         [6.2057e-03],
         [2.9801e-03],
         [3.8698e-04],
         [6.8912e-03],
         [7.7396e-05]],

        [[5.5319e-03],
         [3.9976e-03],
         [3.2409e-03],
         [2.8751e-04],
         [4.0558e-03],
         [9.7858e-03],
         [2.3335e-04],
         [6.9252e-03],
         [3.7552e-04],
         [8.4436e-04],
         [1.8412e-03],
         [1.1072e-03],
         [7.2444e-03],
         [1.2910e-03],
         [2.0228e-04]],

        [[5.3555e-02],
         [2.0468e-03],
         [2.5224e-02],
         [2.6133e-02],
         [3.1617e-02],
         [1.7715e-02],
         [2.9507e-03],
         [9.0260e-03],
         [1.5865e-03],
         [4.5117e-03],
         [9.2180e-03],
         [3.5189e-04],
         [1.3159e-02],
         [4.6824e-03],
         [4.3187e-04]],

        [[6.0027e-02],
         [5.2923e-03],
         [2.8017e-02],
         [2.3356e-02],
         [3.3269e-02],
         [6.5073e-03],
         [3.4763e-03],
         [3.3704e-03],
         [7.7177e-04],
         [6.5568e-03],
         [7.8101e-03],
         [2.0287e-03],
         [1.9145e-03],
         [6.7360e-03],
         [1.9802e-04]],

        [[2.2619e-02],
         [4.5489e-03],
         [1.2831e-02],
         [9.1753e-03],
         [1.4209e-02],
         [2.3211e-02],
         [1.2816e-03],
         [1.2851e-02],
         [1.5431e-03],
         [2.5219e-03],
         [5.6080e-03],
         [9.0115e-04],
         [1.8297e-02],
         [2.7489e-03],
         [6.5246e-04]],

        [[5.4854e-03],
         [7.0944e-05],
         [4.5726e-03],
         [1.4429e-03],
         [2.3052e-03],
         [2.6824e-03],
         [9.0015e-04],
         [1.2368e-03],
         [1.0342e-03],
         [8.5213e-04],
         [3.3943e-03],
         [4.7278e-05],
         [2.0048e-03],
         [1.2156e-04],
         [1.1946e-04]],

        [[6.8356e-02],
         [5.8200e-03],
         [3.6456e-02],
         [2.3513e-02],
         [3.9249e-02],
         [2.0086e-02],
         [4.6101e-03],
         [1.1072e-02],
         [2.9224e-03],
         [8.4690e-03],
         [1.3085e-02],
         [2.4382e-03],
         [1.2510e-02],
         [6.7716e-03],
         [7.1188e-04]],

        [[2.2323e-02],
         [3.8802e-03],
         [1.2625e-02],
         [8.5086e-03],
         [1.3033e-02],
         [1.3863e-02],
         [1.2986e-03],
         [7.6192e-03],
         [1.0691e-03],
         [2.5848e-03],
         [4.9349e-03],
         [6.2513e-04],
         [9.0426e-03],
         [2.6716e-03],
         [4.5332e-04]],

        [[1.0901e-02],
         [1.1929e-03],
         [5.5664e-03],
         [3.7569e-03],
         [6.5149e-03],
         [2.6728e-03],
         [7.3870e-04],
         [2.0316e-03],
         [5.7705e-04],
         [1.4550e-03],
         [2.0413e-03],
         [5.3178e-04],
         [1.6949e-03],
         [1.0546e-03],
         [9.9960e-05]],

        [[3.5195e-02],
         [2.3673e-03],
         [1.4665e-02],
         [1.5084e-02],
         [2.0711e-02],
         [1.5940e-03],
         [2.2804e-03],
         [1.3087e-03],
         [3.7770e-04],
         [3.8444e-03],
         [3.4436e-03],
         [1.2913e-03],
         [3.7556e-04],
         [3.9198e-03],
         [1.2210e-04]],

        [[1.8280e-02],
         [2.1535e-03],
         [9.2738e-03],
         [6.4251e-03],
         [9.9754e-03],
         [7.3058e-03],
         [1.2343e-03],
         [4.3305e-03],
         [6.9513e-04],
         [2.1324e-03],
         [3.6420e-03],
         [6.5682e-04],
         [4.9876e-03],
         [1.8070e-03],
         [2.0428e-04]],

        [[1.0651e-02],
         [2.4737e-03],
         [7.1364e-03],
         [2.2271e-03],
         [6.2457e-03],
         [7.1407e-03],
         [6.0915e-04],
         [4.2917e-03],
         [7.7417e-04],
         [1.5899e-03],
         [3.4821e-03],
         [7.4357e-04],
         [4.1982e-03],
         [1.0507e-03],
         [1.6946e-04]]], device='cuda:0')}, 7: {'step': tensor(30200.), 'exp_avg': tensor([ 0.0169, -0.0011, -0.0213,  0.0129, -0.0036, -0.0028,  0.0368,  0.0385,
         0.0140,  0.0093, -0.0131, -0.0007,  0.0199,  0.0140,  0.0142],
       device='cuda:0'), 'exp_avg_sq': tensor([8.7972e-03, 6.4475e-05, 4.5420e-02, 9.3280e-03, 5.8690e-03, 1.3204e-02,
        1.2984e-02, 1.4158e-02, 1.3999e-03, 1.9489e-02, 1.1783e-02, 2.1967e-03,
        5.5922e-03, 5.0079e-03, 4.8289e-03], device='cuda:0')}, 8: {'step': tensor(30200.), 'exp_avg': tensor([[[-4.3382e-02],
         [ 1.0370e-02],
         [-4.2362e-02],
         [ 4.4488e-03],
         [-1.8970e-02],
         [-1.0122e-02],
         [-1.0656e-02],
         [-4.4206e-02],
         [ 5.3017e-03],
         [-1.8541e-02],
         [-5.1237e-02],
         [-7.4722e-03],
         [ 5.9920e-03],
         [-1.5291e-02],
         [-5.9057e-02]],

        [[-1.5434e-03],
         [-3.1359e-04],
         [ 3.5380e-04],
         [ 2.0093e-03],
         [ 3.3675e-06],
         [-9.2386e-04],
         [ 1.7280e-03],
         [ 6.9969e-04],
         [-6.7050e-04],
         [ 1.8357e-04],
         [ 1.4438e-03],
         [-9.0646e-04],
         [-3.0090e-04],
         [-3.4151e-04],
         [ 9.8810e-04]],

        [[-6.4025e-03],
         [-4.2057e-03],
         [ 8.3574e-03],
         [-1.7296e-02],
         [ 1.0752e-02],
         [-3.1130e-03],
         [-1.9466e-02],
         [-3.8194e-02],
         [-1.8018e-02],
         [-2.3384e-02],
         [-2.2459e-02],
         [-1.2871e-02],
         [-8.0536e-03],
         [-2.6446e-02],
         [-1.5202e-03]],

        [[-1.1469e-02],
         [ 6.2249e-04],
         [-4.3085e-03],
         [ 1.2476e-04],
         [-7.9484e-03],
         [ 1.6511e-03],
         [-6.4694e-03],
         [-1.4059e-02],
         [-2.9385e-03],
         [-6.6039e-03],
         [-7.9397e-03],
         [-1.6156e-03],
         [-3.4163e-03],
         [-1.3555e-02],
         [-4.2508e-03]],

        [[-1.3355e-03],
         [ 2.1718e-03],
         [-6.5730e-03],
         [ 1.1837e-03],
         [-3.4852e-03],
         [ 4.3679e-03],
         [-1.4961e-03],
         [ 1.2128e-04],
         [ 1.3100e-03],
         [-4.9767e-04],
         [-2.4809e-03],
         [ 4.5123e-03],
         [ 1.7989e-03],
         [-1.6007e-03],
         [-2.3611e-03]],

        [[ 9.1399e-03],
         [-4.3523e-03],
         [ 3.5152e-03],
         [ 3.0432e-03],
         [ 8.1304e-03],
         [ 3.9950e-03],
         [ 2.0718e-02],
         [ 1.5919e-02],
         [-4.4427e-03],
         [ 6.4783e-03],
         [ 9.5909e-03],
         [ 2.7670e-03],
         [ 1.8479e-03],
         [ 3.3006e-03],
         [ 3.3759e-03]],

        [[-3.4573e-03],
         [ 1.6781e-04],
         [-2.7609e-04],
         [-1.1793e-04],
         [-4.5652e-03],
         [ 1.6580e-03],
         [-3.6647e-03],
         [-2.9035e-03],
         [ 5.8809e-04],
         [-3.8080e-04],
         [-4.3914e-04],
         [ 3.3589e-04],
         [-1.3503e-03],
         [-3.7484e-03],
         [-2.1796e-04]],

        [[ 2.4498e-02],
         [-7.1332e-03],
         [ 2.4972e-02],
         [-8.4986e-03],
         [ 2.0760e-02],
         [ 9.4581e-03],
         [ 9.3439e-04],
         [ 1.3653e-02],
         [-8.1753e-03],
         [ 2.0271e-03],
         [ 2.1205e-02],
         [ 3.1620e-03],
         [-5.3409e-03],
         [-2.5132e-03],
         [ 3.4727e-02]],

        [[-4.0234e-03],
         [ 1.1299e-04],
         [ 1.3323e-03],
         [-1.3655e-02],
         [ 4.3164e-03],
         [-1.4672e-02],
         [-2.7972e-02],
         [-2.6888e-02],
         [ 2.9185e-03],
         [-5.1704e-03],
         [-1.8330e-02],
         [-6.7421e-03],
         [-3.7494e-03],
         [-4.7586e-03],
         [-9.8085e-04]],

        [[-6.5947e-03],
         [ 1.7945e-04],
         [-1.9668e-03],
         [-2.3647e-03],
         [-1.2165e-03],
         [-3.0980e-03],
         [-7.5097e-03],
         [-1.3135e-02],
         [-3.5615e-03],
         [-8.0936e-03],
         [-9.4314e-03],
         [-5.5436e-03],
         [-1.4625e-03],
         [-6.1888e-03],
         [-6.0313e-03]],

        [[-2.3337e-04],
         [ 1.1425e-03],
         [-3.0926e-04],
         [-5.9443e-04],
         [-1.0946e-03],
         [-6.2375e-05],
         [-2.4082e-03],
         [-7.7244e-04],
         [ 1.1021e-03],
         [-7.5278e-04],
         [-1.0629e-04],
         [ 6.5463e-04],
         [-1.9653e-04],
         [ 2.2956e-04],
         [ 2.3787e-04]],

        [[ 7.7848e-04],
         [ 2.5322e-04],
         [ 3.2106e-05],
         [ 4.7170e-04],
         [ 1.8714e-04],
         [ 2.1176e-04],
         [ 1.1722e-03],
         [ 1.5451e-03],
         [ 1.9675e-04],
         [ 2.4222e-04],
         [ 1.2131e-03],
         [ 3.7674e-04],
         [ 2.8730e-04],
         [ 1.0496e-03],
         [ 4.1025e-04]],

        [[ 4.8754e-02],
         [-6.5285e-03],
         [ 3.2258e-02],
         [ 7.6754e-05],
         [ 1.2145e-02],
         [ 1.1342e-02],
         [-1.3637e-03],
         [ 5.6570e-02],
         [ 1.2436e-02],
         [ 3.2236e-02],
         [ 5.4295e-02],
         [ 1.9429e-02],
         [-1.8841e-03],
         [ 2.8650e-02],
         [ 6.4413e-02]],

        [[ 2.7592e-03],
         [ 2.3809e-04],
         [ 8.9915e-03],
         [-1.7401e-02],
         [ 1.5958e-03],
         [-8.7256e-03],
         [-4.0952e-02],
         [-2.4247e-02],
         [ 4.4877e-03],
         [-4.5442e-03],
         [-1.1425e-02],
         [-1.9840e-03],
         [-7.0597e-03],
         [-6.9638e-03],
         [ 1.3390e-02]],

        [[ 2.1988e-03],
         [-2.2406e-03],
         [-6.4104e-03],
         [ 1.5545e-02],
         [ 4.4566e-03],
         [ 4.4466e-03],
         [ 3.6513e-02],
         [ 2.3298e-02],
         [-6.2530e-03],
         [ 6.8448e-03],
         [ 1.2808e-02],
         [ 2.4805e-03],
         [ 6.7442e-03],
         [ 6.6106e-03],
         [-3.5465e-03]]], device='cuda:0'), 'exp_avg_sq': tensor([[[4.9138e-02],
         [2.1453e-03],
         [3.7271e-02],
         [7.9476e-04],
         [6.5946e-03],
         [7.3804e-03],
         [4.2433e-03],
         [5.6051e-02],
         [4.9822e-04],
         [1.2229e-02],
         [6.9293e-02],
         [7.2234e-03],
         [6.5517e-04],
         [3.8725e-03],
         [9.1949e-02]],

        [[2.6047e-03],
         [3.0519e-05],
         [6.8592e-04],
         [6.6243e-04],
         [3.7385e-04],
         [5.4316e-04],
         [2.8812e-03],
         [6.3463e-03],
         [1.6234e-04],
         [1.6384e-03],
         [3.7133e-03],
         [8.5283e-04],
         [1.4691e-04],
         [1.5242e-03],
         [2.9970e-03]],

        [[2.2873e-02],
         [7.7018e-04],
         [5.2732e-03],
         [1.4546e-02],
         [5.3277e-03],
         [7.2582e-03],
         [8.3404e-02],
         [1.0996e-01],
         [1.0251e-03],
         [2.0586e-02],
         [5.7198e-02],
         [5.0123e-03],
         [2.2531e-03],
         [2.2371e-02],
         [1.5847e-02]],

        [[6.3771e-03],
         [7.4819e-05],
         [2.0279e-03],
         [3.6336e-04],
         [1.2113e-03],
         [9.1622e-04],
         [4.3765e-03],
         [9.9196e-03],
         [4.8153e-05],
         [1.1832e-03],
         [7.5373e-03],
         [1.4737e-03],
         [2.6240e-04],
         [1.7124e-03],
         [8.3846e-03]],

        [[7.6833e-03],
         [1.8044e-04],
         [4.4405e-03],
         [9.5234e-05],
         [5.4381e-04],
         [2.1575e-03],
         [4.9418e-04],
         [9.7018e-03],
         [1.7160e-04],
         [2.1215e-03],
         [1.0625e-02],
         [2.6181e-03],
         [8.8249e-05],
         [6.4398e-04],
         [1.5115e-02]],

        [[6.5940e-03],
         [4.7256e-04],
         [2.4351e-03],
         [5.5110e-03],
         [1.1518e-03],
         [6.0605e-03],
         [2.8978e-02],
         [3.1256e-02],
         [3.9335e-04],
         [3.6708e-03],
         [1.8578e-02],
         [2.5367e-03],
         [4.3973e-04],
         [2.7293e-03],
         [9.5727e-03]],

        [[9.2728e-04],
         [3.7617e-05],
         [5.3068e-04],
         [3.1835e-05],
         [3.5822e-04],
         [5.7593e-05],
         [4.6710e-04],
         [1.1347e-03],
         [2.2519e-05],
         [1.1532e-04],
         [1.0751e-03],
         [5.0770e-05],
         [1.2095e-05],
         [1.6508e-04],
         [1.2092e-03]],

        [[9.7330e-03],
         [2.6759e-04],
         [3.2493e-03],
         [6.4144e-03],
         [1.8687e-03],
         [2.5486e-03],
         [3.4156e-02],
         [4.4108e-02],
         [2.9769e-04],
         [8.1524e-03],
         [2.3747e-02],
         [2.4249e-03],
         [1.1189e-03],
         [8.5738e-03],
         [8.9420e-03]],

        [[2.2507e-03],
         [1.1476e-04],
         [9.8935e-04],
         [2.1150e-03],
         [3.2441e-04],
         [1.5783e-03],
         [1.0904e-02],
         [1.1792e-02],
         [1.1615e-04],
         [1.6213e-03],
         [6.8210e-03],
         [7.6014e-04],
         [2.8550e-04],
         [1.6296e-03],
         [3.1486e-03]],

        [[3.6626e-04],
         [1.0700e-05],
         [1.3659e-04],
         [1.0385e-04],
         [5.9305e-05],
         [7.4388e-05],
         [6.6665e-04],
         [1.1296e-03],
         [3.6091e-05],
         [3.3557e-04],
         [6.6875e-04],
         [1.4181e-04],
         [2.4445e-05],
         [2.1463e-04],
         [4.4306e-04]],

        [[5.2717e-04],
         [6.5122e-05],
         [5.2588e-04],
         [6.8649e-05],
         [2.1979e-04],
         [5.7533e-05],
         [5.8663e-04],
         [7.8648e-04],
         [5.1358e-05],
         [1.0493e-04],
         [7.8905e-04],
         [1.6614e-05],
         [1.4715e-05],
         [6.6622e-05],
         [8.3344e-04]],

        [[5.5017e-05],
         [7.0331e-06],
         [7.2939e-05],
         [1.0832e-05],
         [1.3940e-05],
         [1.4256e-05],
         [6.0139e-05],
         [1.0020e-04],
         [6.4128e-06],
         [1.5899e-05],
         [1.0656e-04],
         [7.6192e-06],
         [4.0172e-06],
         [1.3143e-05],
         [1.2264e-04]],

        [[3.8993e-02],
         [5.3282e-04],
         [9.0617e-03],
         [1.4868e-02],
         [7.7622e-03],
         [6.4081e-03],
         [9.1328e-02],
         [1.4829e-01],
         [1.5313e-03],
         [3.1356e-02],
         [8.0992e-02],
         [1.0006e-02],
         [4.3023e-03],
         [3.6906e-02],
         [3.3893e-02]],

        [[1.4990e-03],
         [8.5574e-05],
         [6.5974e-04],
         [2.3542e-03],
         [3.0803e-04],
         [1.1734e-03],
         [1.0355e-02],
         [1.0656e-02],
         [1.1399e-04],
         [1.5083e-03],
         [5.2697e-03],
         [5.9686e-04],
         [3.3448e-04],
         [1.9180e-03],
         [1.7946e-03]],

        [[8.9432e-03],
         [2.5548e-04],
         [2.5001e-03],
         [3.7048e-03],
         [1.7480e-03],
         [3.3041e-03],
         [1.8986e-02],
         [2.7651e-02],
         [4.3358e-04],
         [5.2678e-03],
         [1.6139e-02],
         [2.5839e-03],
         [3.8650e-04],
         [4.6742e-03],
         [9.9471e-03]]], device='cuda:0')}, 9: {'step': tensor(30200.), 'exp_avg': tensor([-0.0798,  0.0038,  0.0214, -0.0049, -0.0162,  0.0285, -0.0018,  0.0510,
        -0.0073, -0.0040, -0.0079, -0.0014,  0.0492, -0.0082,  0.0205],
       device='cuda:0'), 'exp_avg_sq': tensor([0.1164, 0.0019, 0.0525, 0.0044, 0.0102, 0.0255, 0.0021, 0.0188, 0.0075,
        0.0006, 0.0034, 0.0004, 0.0423, 0.0050, 0.0153], device='cuda:0')}, 10: {'step': tensor(30200.), 'exp_avg': tensor([[ 7.8066e-04,  1.7950e-03,  1.7401e-03,  ..., -3.7819e-04,
          2.5452e-03,  1.9675e-04],
        [ 9.3940e-04, -3.8325e-04,  7.0843e-06,  ..., -1.7290e-03,
          1.1865e-03, -7.2826e-04],
        [ 1.2307e-03,  2.1365e-04,  2.0079e-04,  ...,  7.9295e-04,
         -1.4780e-03, -7.6621e-04],
        ...,
        [ 5.1984e-04, -2.4897e-03, -7.0312e-04,  ..., -3.0757e-04,
         -3.1262e-03, -1.4724e-04],
        [-2.2100e-03,  1.3546e-04, -1.6567e-03,  ...,  4.1308e-04,
         -1.2044e-03, -7.4663e-04],
        [ 2.9202e-04,  1.7506e-03,  4.4135e-04,  ..., -1.2297e-03,
         -1.9225e-05, -1.0242e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[2.3056e-05, 2.0294e-05, 2.0502e-05,  ..., 1.3450e-05, 1.7880e-05,
         1.5397e-05],
        [2.8830e-05, 2.5132e-05, 2.6781e-05,  ..., 2.1985e-05, 2.5766e-05,
         2.6798e-05],
        [3.6438e-05, 3.3993e-05, 3.0740e-05,  ..., 2.3171e-05, 2.4234e-05,
         2.4749e-05],
        ...,
        [3.7711e-05, 3.2520e-05, 2.8881e-05,  ..., 1.9355e-05, 2.0976e-05,
         2.0215e-05],
        [2.7629e-05, 2.5639e-05, 2.4802e-05,  ..., 2.0250e-05, 2.5929e-05,
         2.2790e-05],
        [3.3416e-05, 2.7288e-05, 2.8206e-05,  ..., 1.5690e-05, 1.7376e-05,
         1.9548e-05]], device='cuda:0')}, 11: {'step': tensor(30200.), 'exp_avg': tensor([-2.2040e-04, -2.0463e-04,  1.2238e-03, -5.0140e-04,  4.9896e-04,
        -6.6331e-04, -9.0900e-04, -5.1365e-04, -7.7566e-04, -1.0694e-03,
        -9.1250e-05,  4.6930e-05,  1.0411e-03,  8.8323e-04,  4.8046e-04,
         2.0379e-04, -1.1836e-03, -1.9578e-04,  5.1566e-04, -2.6140e-05,
        -1.9596e-04, -8.2670e-04,  2.4468e-05,  2.7496e-04, -4.4775e-04,
        -6.1616e-04, -5.2933e-04,  1.3249e-03, -1.8158e-04,  4.4437e-04,
        -1.0694e-03, -2.3569e-04,  1.6705e-04, -1.4326e-05,  4.3782e-04,
         2.2327e-04, -3.8210e-04, -7.4911e-04,  6.2617e-05, -7.3615e-04,
        -2.3551e-04, -6.2664e-05, -6.6646e-05,  8.8139e-04, -8.8555e-04,
        -3.1762e-04,  3.5487e-04,  1.4775e-04, -3.0106e-04,  6.7138e-04,
         1.2887e-05, -1.3048e-04, -4.8322e-04,  7.4834e-05,  2.5615e-04,
         2.6800e-04, -4.2891e-04, -1.3605e-04, -4.0702e-04, -1.0285e-03,
        -5.3785e-04, -2.9211e-04, -5.5173e-04,  5.8908e-04,  2.8385e-04,
        -2.3198e-05,  3.3317e-04, -7.6226e-05,  9.2514e-05, -8.7896e-04,
        -1.5763e-04,  1.8802e-04, -1.0423e-04,  1.6695e-04, -1.7693e-04,
         1.1176e-04,  5.7807e-05, -2.4062e-05, -5.8300e-04,  5.2994e-06,
        -2.4622e-04,  4.3700e-05, -4.5240e-04,  5.5504e-05, -1.9948e-05,
        -7.4990e-04, -2.8946e-04,  2.8647e-04,  2.1592e-05, -5.0728e-04,
         5.1116e-04,  1.1165e-04, -4.0508e-04,  1.2681e-04, -8.5610e-04,
        -4.9961e-05,  2.7190e-05, -7.2564e-04, -2.4428e-04,  4.2039e-04,
        -6.1147e-04, -4.8696e-05,  5.6379e-04, -8.9252e-04, -2.7673e-04,
        -2.5057e-04,  4.6125e-04, -3.2937e-04,  9.7559e-04, -1.5814e-04,
        -3.1992e-04, -4.8970e-04, -3.1476e-04,  4.4125e-04, -6.7007e-04,
         4.0141e-04,  2.2915e-04,  3.8080e-04, -1.9968e-04,  4.0645e-04,
         2.8035e-04,  1.4995e-04,  7.4157e-04,  3.7631e-04,  1.3676e-04,
        -4.4779e-04,  8.4885e-05, -3.8823e-04], device='cuda:0'), 'exp_avg_sq': tensor([5.2045e-06, 8.1784e-06, 5.5358e-06, 9.5980e-06, 5.2861e-06, 8.5113e-06,
        5.2022e-06, 1.9067e-06, 1.8145e-05, 5.9600e-06, 3.2673e-06, 1.2561e-06,
        7.6549e-06, 6.1316e-06, 1.0982e-05, 4.7397e-06, 8.4587e-06, 1.1618e-05,
        3.4199e-06, 2.2457e-06, 2.5719e-06, 5.7004e-06, 5.6178e-06, 8.1749e-06,
        7.6280e-06, 4.7553e-06, 5.5464e-06, 9.4362e-06, 2.9726e-06, 1.2325e-05,
        8.1858e-06, 5.5871e-06, 6.4327e-06, 7.1000e-06, 4.6559e-06, 3.4500e-06,
        2.1246e-06, 1.1924e-05, 2.6917e-06, 3.0079e-06, 4.0889e-06, 2.6089e-06,
        8.1232e-06, 4.9925e-06, 8.1994e-06, 1.1760e-05, 6.3740e-06, 3.9837e-06,
        4.1969e-06, 1.9670e-06, 3.8673e-06, 3.8591e-06, 5.3017e-06, 1.5116e-05,
        6.0068e-06, 3.9294e-06, 7.5463e-06, 5.8562e-06, 5.9105e-06, 5.5583e-06,
        1.1981e-05, 9.8703e-06, 3.5549e-06, 3.2751e-06, 4.5969e-06, 6.6722e-06,
        1.2091e-05, 4.0786e-06, 1.0060e-05, 7.1648e-06, 3.1048e-06, 5.1527e-06,
        3.2841e-06, 2.9903e-06, 3.6781e-06, 3.4614e-06, 7.8951e-06, 3.7054e-06,
        4.3741e-06, 4.8644e-06, 4.8586e-06, 2.8162e-06, 8.1244e-06, 5.7920e-06,
        6.0570e-06, 3.4854e-06, 1.2599e-05, 4.0459e-06, 6.2475e-06, 4.7027e-06,
        4.7103e-06, 8.1082e-06, 4.9134e-06, 5.0610e-06, 3.1050e-06, 6.0396e-06,
        4.0936e-06, 5.3312e-06, 3.4575e-06, 4.5964e-06, 1.2321e-05, 3.8532e-06,
        2.2301e-06, 4.6183e-06, 5.8450e-06, 3.9141e-06, 5.1151e-06, 3.0272e-06,
        1.6734e-05, 4.4206e-06, 7.2603e-06, 5.9507e-06, 3.6171e-06, 3.6175e-06,
        3.9269e-06, 5.8322e-06, 7.6531e-06, 7.9748e-06, 7.8031e-06, 5.1434e-06,
        4.0786e-06, 3.0156e-06, 1.0120e-05, 5.1532e-06, 4.5496e-06, 5.7092e-06,
        4.4749e-06, 3.7423e-06], device='cuda:0')}, 12: {'step': tensor(30200.), 'exp_avg': tensor([-1.0853e-03, -3.9692e-04,  2.1510e-03,  2.7882e-04, -1.5327e-03,
        -7.0725e-04, -3.7885e-04,  6.2646e-05,  1.3653e-03, -1.8481e-03,
        -1.4865e-04,  8.6594e-05, -7.5731e-04,  2.0383e-04,  2.3804e-03,
         1.0933e-03, -2.0417e-03, -1.4437e-03, -5.6652e-04,  3.5402e-04,
         2.2477e-04, -5.7931e-04,  9.8450e-04,  3.5690e-06, -3.7018e-04,
         9.5625e-05,  8.3555e-04,  8.8373e-04, -1.8998e-04, -3.1836e-04,
        -1.7634e-04, -6.8702e-04, -1.3986e-05,  7.3246e-04, -3.6460e-05,
        -9.4369e-07,  2.7141e-04,  3.6670e-04, -6.1328e-04, -4.5146e-05,
        -1.5371e-04, -5.7967e-04,  3.9332e-05, -1.5881e-03,  1.4243e-03,
        -5.4921e-05, -1.1678e-03,  9.4898e-04, -2.0010e-04,  1.3780e-03,
         1.0373e-03,  3.0600e-04, -4.8272e-04, -1.5369e-03,  3.3899e-04,
        -8.0359e-04,  6.7915e-04,  7.9655e-04, -1.2134e-05,  5.8416e-04,
        -2.2642e-03, -6.4938e-04,  7.4904e-04, -3.1340e-04, -9.4859e-04,
        -1.1101e-03, -1.7316e-04,  1.4119e-04, -1.8419e-03, -3.6272e-04,
         1.2364e-03,  2.8861e-04,  6.2102e-05,  6.1755e-04,  1.2551e-03,
        -4.9313e-04,  3.0617e-04,  4.6709e-04, -1.0147e-03, -3.5706e-04,
        -6.3935e-04,  6.7237e-04, -8.5940e-04,  4.4204e-04, -4.1142e-05,
        -5.7726e-04, -1.5109e-03,  2.3572e-04,  6.9839e-04, -9.6981e-05,
         1.3250e-03, -1.0366e-04,  7.4967e-04, -4.8140e-04,  9.5139e-04,
        -1.2192e-03,  4.7811e-05, -3.8631e-04, -6.9035e-04,  1.9583e-04,
         4.6859e-04,  1.0497e-03,  2.8496e-04,  9.3512e-06,  1.3465e-03,
        -2.0191e-05,  2.3008e-04, -3.1375e-04,  3.3070e-03, -1.0275e-03,
        -1.5176e-03,  5.5165e-05,  1.6508e-04,  8.3597e-05,  3.3485e-04,
         9.1829e-04, -2.7995e-04, -1.6407e-04, -4.7394e-04, -3.4716e-04,
        -1.3460e-03, -5.1898e-04, -1.7589e-03, -1.2872e-03,  1.3297e-03,
         3.3485e-04,  2.5918e-04,  1.3876e-03], device='cuda:0'), 'exp_avg_sq': tensor([6.0594e-05, 5.7037e-05, 9.1782e-05, 3.4981e-05, 5.2866e-05, 1.7816e-05,
        6.3324e-05, 1.9422e-05, 3.2217e-04, 5.8827e-05, 2.0608e-05, 1.5967e-05,
        2.2747e-05, 7.7081e-06, 1.1344e-04, 2.5750e-05, 1.1895e-04, 6.2867e-05,
        4.4438e-05, 4.7210e-06, 2.1894e-05, 1.9990e-05, 6.3475e-05, 3.1174e-05,
        1.8382e-05, 6.5411e-05, 4.1614e-05, 1.8501e-05, 1.7893e-05, 6.3406e-05,
        1.0145e-04, 2.9375e-05, 1.6753e-05, 1.8368e-05, 4.0782e-05, 1.1645e-05,
        5.2687e-06, 2.0327e-04, 8.5779e-06, 2.4325e-05, 6.5976e-06, 1.3956e-05,
        5.7360e-05, 8.1411e-05, 5.1589e-05, 2.3748e-05, 3.7110e-05, 2.1057e-05,
        2.3753e-05, 5.8032e-05, 3.1658e-05, 1.1618e-05, 2.9227e-05, 8.9734e-05,
        3.0443e-05, 9.0764e-06, 1.0100e-04, 2.1344e-05, 2.0963e-05, 1.3678e-05,
        1.2462e-04, 2.5369e-05, 3.9980e-05, 3.1952e-05, 1.7489e-05, 2.4524e-05,
        3.1371e-05, 3.9819e-05, 9.7967e-05, 3.8953e-05, 1.2782e-05, 1.5160e-05,
        1.5562e-05, 2.6484e-05, 2.1009e-05, 3.9304e-05, 3.5240e-05, 3.0314e-05,
        1.5949e-05, 2.5899e-05, 3.7318e-05, 2.5737e-05, 4.9067e-05, 1.0795e-05,
        3.1558e-05, 2.6361e-05, 9.8150e-05, 1.6539e-05, 6.9029e-05, 9.1621e-05,
        7.7365e-05, 2.3702e-05, 1.1405e-05, 4.6051e-05, 3.7308e-05, 4.1819e-05,
        1.9432e-05, 3.2966e-05, 2.7321e-05, 5.4022e-05, 3.8307e-05, 3.3317e-05,
        1.1910e-05, 3.3610e-05, 4.9240e-05, 1.2314e-05, 1.2754e-05, 3.0181e-05,
        2.8115e-04, 1.5281e-05, 4.9594e-05, 1.5043e-05, 2.4702e-05, 2.1977e-05,
        3.2893e-05, 1.0460e-04, 2.0977e-05, 1.0670e-05, 3.6391e-05, 5.7835e-05,
        2.3803e-05, 1.9884e-05, 4.7476e-05, 2.2493e-05, 1.3944e-05, 5.3476e-06,
        7.6830e-06, 5.8412e-05], device='cuda:0')}, 13: {'step': tensor(30200.), 'exp_avg': tensor([[ 6.6802e-05, -3.5716e-05,  1.8579e-05,  ...,  1.0394e-04,
          4.3482e-05,  9.0509e-06],
        [-1.5828e-04,  6.9395e-05,  6.2755e-05,  ..., -6.6457e-05,
          5.1977e-05, -1.1228e-04],
        [-6.4071e-05, -3.1414e-05,  2.4293e-05,  ..., -1.2039e-04,
          5.6238e-05, -3.7946e-05],
        ...,
        [-1.0809e-04,  3.2046e-05,  6.2461e-04,  ..., -9.8354e-06,
          4.5760e-05,  2.7314e-04],
        [ 8.8723e-05, -2.0450e-04, -4.7424e-04,  ...,  1.1412e-04,
         -1.1600e-04, -3.9624e-04],
        [-1.5247e-05, -6.9966e-05, -4.3097e-05,  ...,  4.0298e-04,
         -1.4769e-04, -1.6282e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[1.2676e-07, 6.1053e-08, 1.5780e-07,  ..., 1.8917e-07, 9.6339e-08,
         9.6095e-08],
        [6.3500e-07, 2.7724e-07, 8.1829e-07,  ..., 1.1675e-06, 4.6449e-07,
         5.0726e-07],
        [2.2791e-07, 7.6963e-08, 2.7460e-07,  ..., 3.6283e-07, 1.6969e-07,
         1.4760e-07],
        ...,
        [1.4131e-06, 2.0116e-06, 2.2502e-06,  ..., 2.8105e-06, 1.2085e-06,
         7.0539e-07],
        [3.4563e-06, 3.4702e-06, 5.0290e-06,  ..., 4.2762e-06, 2.7836e-06,
         1.5900e-06],
        [1.0820e-06, 1.0819e-06, 2.1537e-06,  ..., 1.5498e-06, 7.5222e-07,
         4.6953e-07]], device='cuda:0')}, 14: {'step': tensor(30200.), 'exp_avg': tensor([[-5.5715e-04, -4.3442e-04, -8.5145e-04,  ...,  1.6187e-04,
          4.0395e-04,  3.3910e-04],
        [-4.5213e-04, -7.5148e-04, -1.0830e-03,  ...,  3.0768e-04,
          2.6910e-04,  4.7440e-04],
        [-3.2617e-04, -4.8600e-05, -7.7275e-04,  ..., -6.1890e-05,
         -2.8905e-06,  4.8970e-04],
        ...,
        [ 7.8508e-05,  4.2492e-04,  4.5868e-04,  ..., -2.5203e-05,
          1.9509e-04, -1.5942e-04],
        [ 6.6409e-05,  3.3110e-04,  2.9325e-04,  ..., -4.7815e-04,
         -9.4150e-04, -5.8030e-04],
        [-3.8346e-04, -8.4074e-05, -6.7698e-04,  ...,  1.1374e-05,
         -2.0706e-04, -8.2327e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[3.6756e-06, 2.2417e-06, 5.6096e-06,  ..., 1.8695e-06, 3.6502e-06,
         1.8669e-06],
        [3.4820e-06, 3.3878e-06, 6.9284e-06,  ..., 2.8449e-06, 3.6460e-06,
         2.5832e-06],
        [2.7276e-06, 2.3272e-06, 3.6424e-06,  ..., 1.7719e-06, 2.1545e-06,
         2.0510e-06],
        ...,
        [1.9326e-06, 2.1451e-06, 3.2823e-06,  ..., 1.4434e-06, 2.4006e-06,
         1.5824e-06],
        [3.5526e-06, 4.1581e-06, 5.2051e-06,  ..., 2.4438e-06, 4.2443e-06,
         2.5256e-06],
        [4.4136e-06, 4.2297e-06, 7.5889e-06,  ..., 2.7408e-06, 3.5245e-06,
         3.0996e-06]], device='cuda:0')}, 15: {'step': tensor(30200.), 'exp_avg': tensor([ 3.4042e-04, -9.2415e-04,  1.8234e-03,  1.5760e-03, -8.7181e-04,
        -3.3918e-04, -9.4049e-04,  1.6409e-03,  9.3283e-05, -2.9647e-04,
        -3.9070e-04,  4.7453e-04,  2.5214e-03,  6.0358e-05,  2.5997e-03,
         1.6714e-03,  3.6919e-04, -1.9540e-03, -3.0015e-04,  9.9883e-04,
        -1.6175e-04, -8.6874e-04,  2.4343e-03,  1.5245e-03, -1.7132e-03,
         6.9052e-04, -3.3744e-04, -9.9650e-04,  6.9810e-04, -1.0844e-03,
        -4.5985e-04,  3.8055e-04, -1.3395e-03,  1.5940e-03, -9.0823e-04,
        -7.5262e-04, -7.5279e-04,  1.3224e-03,  1.4792e-04,  1.8778e-04,
         2.4376e-03,  1.1236e-03,  9.3544e-04,  9.6293e-04,  7.3965e-04,
         3.4222e-05,  8.1239e-05, -7.9958e-04, -7.4709e-04,  1.2063e-03,
         3.9406e-05,  7.2425e-04,  2.7407e-05, -3.4754e-05, -8.3898e-04,
         1.0129e-03,  9.5949e-04, -5.9756e-04,  3.9601e-05, -1.1398e-03,
        -1.8569e-03, -1.6382e-04,  1.5951e-03, -1.4410e-03, -1.9199e-03,
        -1.4905e-03, -7.3786e-05,  4.1549e-04, -1.4027e-03, -4.5308e-04,
         7.3936e-04, -1.7806e-03, -1.5232e-03, -1.1662e-03,  8.2225e-04,
        -7.7937e-04, -1.6841e-04,  6.4554e-04,  1.4351e-03,  1.2452e-03,
        -5.1044e-04, -1.5246e-06, -1.5955e-03,  1.5835e-03,  1.1024e-03,
        -8.7680e-04, -9.4052e-04, -1.8328e-04, -1.5315e-04,  9.1881e-04,
         1.1159e-03, -1.4779e-04, -4.1473e-04, -6.7977e-05,  3.2340e-03,
         5.7845e-04,  5.8414e-04, -5.0153e-04, -1.8182e-03, -8.3771e-04,
         9.4400e-04, -4.9835e-04,  1.0296e-03,  1.1946e-04,  5.8844e-04,
         5.2968e-04,  8.7238e-04,  1.4370e-03,  5.7487e-04, -2.5481e-03,
        -9.9653e-04, -2.8689e-05, -3.8089e-04, -5.8521e-04,  9.5460e-04,
         1.3209e-04,  5.7006e-05, -1.3167e-03, -2.5780e-03,  2.0269e-03,
        -2.0581e-03, -8.9647e-05, -1.4105e-03,  3.2764e-04,  4.5164e-05,
        -6.2530e-04, -2.0261e-03, -1.1689e-03], device='cuda:0'), 'exp_avg_sq': tensor([6.1846e-05, 1.1738e-04, 8.6892e-05, 1.2305e-04, 5.5228e-05, 3.7632e-05,
        1.3736e-04, 7.7424e-05, 1.9832e-04, 4.2353e-05, 7.7304e-05, 6.2000e-05,
        1.5060e-04, 8.2816e-05, 1.4278e-04, 1.2056e-04, 2.2970e-04, 1.1222e-04,
        5.0208e-05, 2.9630e-05, 9.1926e-05, 7.0723e-05, 1.2089e-04, 3.9803e-05,
        8.4569e-05, 1.0431e-04, 5.2736e-05, 4.5740e-05, 3.1935e-05, 1.5377e-04,
        1.0106e-04, 5.5008e-05, 1.1879e-04, 7.2883e-05, 2.8399e-04, 4.7016e-05,
        3.2487e-05, 3.9939e-04, 5.9925e-05, 9.8174e-05, 6.8779e-05, 1.2390e-04,
        4.4076e-05, 7.4637e-05, 6.2001e-05, 3.4143e-05, 7.5554e-05, 3.2044e-05,
        3.3862e-05, 3.6378e-05, 1.0968e-04, 9.9612e-05, 3.4537e-04, 2.1809e-04,
        1.2491e-04, 4.6107e-05, 1.3545e-04, 7.1778e-05, 4.9247e-05, 3.1834e-05,
        1.1249e-04, 4.9038e-05, 4.7175e-05, 4.1123e-05, 7.3843e-05, 9.4966e-05,
        5.6313e-05, 5.1139e-05, 2.7671e-05, 6.1781e-05, 1.3281e-04, 4.6298e-05,
        1.1464e-04, 8.3957e-05, 6.4383e-05, 4.2573e-05, 3.9139e-05, 8.7597e-05,
        4.2985e-05, 3.2450e-05, 9.6595e-05, 7.4444e-05, 7.8300e-05, 6.9374e-05,
        1.1237e-04, 1.1681e-04, 9.0077e-05, 5.2289e-05, 1.2573e-04, 2.0011e-04,
        7.6508e-05, 4.2757e-05, 5.6854e-05, 2.7474e-05, 7.4564e-05, 6.3688e-05,
        3.1782e-05, 1.2397e-04, 9.6153e-05, 6.4780e-05, 3.4665e-05, 1.0702e-04,
        1.0578e-04, 9.4268e-05, 2.0205e-04, 3.7908e-05, 5.5817e-05, 3.7496e-05,
        1.2342e-04, 8.5799e-05, 5.1131e-05, 7.8001e-05, 1.0625e-04, 1.0462e-04,
        5.3291e-05, 5.9568e-05, 5.1593e-05, 2.5087e-05, 1.6188e-04, 6.9557e-05,
        1.7584e-04, 6.1808e-05, 1.5559e-04, 4.5418e-05, 5.2581e-05, 7.6745e-05,
        1.5147e-04, 1.2321e-04], device='cuda:0')}, 16: {'step': tensor(30200.), 'exp_avg': tensor([-1.9142e-04, -6.7479e-04,  2.9191e-04,  4.8570e-04,  2.0619e-04,
        -3.2317e-04, -1.5909e-03,  1.2852e-04,  3.9892e-05, -3.0476e-04,
        -1.8158e-04, -1.2586e-04, -3.0191e-04, -1.1039e-03,  9.3958e-05,
        -3.4068e-04, -6.4431e-04,  5.6801e-04, -1.4484e-04, -2.0852e-04,
        -2.1750e-04, -2.6944e-04,  2.2419e-04,  6.9702e-04,  1.9531e-04,
         4.7034e-05, -2.9179e-04,  6.3939e-04,  4.1946e-04, -9.2333e-05,
         2.4976e-04, -1.8200e-05, -4.3771e-04,  1.7424e-04,  5.2394e-04,
        -9.6485e-05,  2.7302e-04, -1.0453e-03, -1.7063e-04, -2.1262e-04,
        -1.1901e-04,  1.3162e-04,  6.6688e-04,  2.0385e-04,  4.8704e-04,
        -3.7317e-04, -1.8507e-04, -8.9565e-05, -4.1338e-05, -5.4031e-04,
        -3.5503e-04,  3.6403e-05, -1.6979e-04, -3.5418e-04,  4.6200e-05,
        -3.1949e-04,  1.4347e-04,  5.1626e-04,  1.4948e-04, -9.4370e-05,
        -2.1149e-04,  3.0485e-04,  2.3897e-04, -3.0636e-04,  1.2434e-04,
        -1.9662e-04, -7.2649e-04, -6.1096e-04,  5.7222e-04, -2.8325e-04,
         3.0271e-04, -2.1480e-04, -3.3442e-04, -3.0717e-04,  8.7039e-05,
        -1.1938e-05, -4.8821e-04,  9.0773e-04, -2.2143e-04,  9.2971e-05,
         1.2464e-05,  3.1816e-04, -1.0440e-04,  2.4348e-04,  1.1549e-04,
         3.2150e-04, -3.6706e-04, -4.0969e-04,  2.9577e-04,  1.5287e-04,
         5.3888e-04,  1.9383e-04,  5.4506e-05,  4.5787e-04, -7.9327e-04,
        -7.8146e-05,  5.5979e-04, -7.2182e-04, -5.7573e-04, -7.3017e-05,
        -4.2958e-04, -1.9687e-04,  1.5717e-04,  2.3716e-04, -9.1198e-04,
         2.8347e-04,  1.7105e-04,  2.3550e-04, -4.3741e-06, -5.6080e-04,
        -4.5529e-04, -3.0177e-04,  2.9889e-04,  1.9107e-04, -3.6276e-04,
        -2.2208e-04, -1.6351e-04, -4.3302e-04, -1.3525e-04,  4.9267e-04,
         1.6667e-05, -5.1110e-04,  4.0956e-04,  1.8999e-04, -3.9920e-04,
         3.9557e-04,  2.7622e-04, -1.8030e-04], device='cuda:0'), 'exp_avg_sq': tensor([3.0098e-06, 1.9114e-06, 3.2331e-06, 3.1130e-06, 1.6129e-06, 1.7702e-06,
        8.8299e-06, 3.0583e-06, 7.9917e-06, 3.7068e-06, 2.7679e-06, 1.4076e-06,
        2.5107e-06, 8.1251e-06, 3.3365e-06, 4.8700e-06, 8.3337e-06, 3.1354e-06,
        1.4103e-06, 1.5663e-06, 2.1712e-06, 3.7906e-06, 4.5802e-06, 1.5677e-05,
        3.7076e-06, 2.4603e-06, 4.0114e-06, 3.8902e-06, 2.7081e-06, 4.0661e-06,
        6.0264e-06, 4.2213e-06, 3.8348e-06, 2.3403e-06, 9.6835e-06, 2.4092e-06,
        2.6268e-06, 9.5941e-06, 7.7315e-06, 2.6160e-06, 2.8184e-06, 3.5048e-06,
        3.7864e-06, 1.8339e-06, 3.2437e-06, 2.5866e-06, 3.1262e-06, 3.1442e-06,
        2.8852e-06, 1.3508e-06, 2.8632e-06, 2.1807e-06, 4.8437e-06, 7.3308e-06,
        2.1100e-06, 4.6094e-06, 4.7828e-06, 2.2774e-06, 3.8738e-06, 5.0907e-06,
        5.2372e-06, 3.8409e-06, 3.7975e-06, 6.7468e-06, 2.5326e-06, 2.4575e-06,
        5.4477e-06, 2.7483e-06, 2.4311e-06, 1.8366e-06, 2.7880e-06, 2.9997e-06,
        2.9776e-06, 2.5292e-06, 1.8592e-06, 1.1366e-06, 2.3372e-06, 3.6526e-06,
        1.7402e-06, 2.1429e-06, 2.4845e-06, 3.6076e-06, 5.7090e-06, 7.4277e-06,
        3.8363e-06, 3.4150e-06, 1.3367e-06, 2.9194e-06, 7.4791e-06, 6.2441e-06,
        1.2209e-06, 1.8431e-06, 3.4406e-06, 4.6684e-06, 3.0971e-06, 2.1189e-06,
        6.7753e-06, 5.8914e-06, 3.5674e-06, 3.3217e-06, 1.6394e-06, 2.9683e-06,
        3.0271e-06, 1.5037e-06, 4.0109e-06, 3.9411e-06, 3.4299e-06, 2.5389e-06,
        2.1103e-06, 6.1769e-06, 3.4743e-06, 2.3930e-06, 3.3561e-06, 2.4992e-06,
        3.1949e-06, 1.5848e-06, 3.1875e-06, 4.6172e-06, 1.5255e-06, 6.3245e-06,
        2.3370e-06, 3.6990e-06, 5.6336e-06, 3.0388e-06, 4.7434e-06, 3.7245e-06,
        2.5654e-06, 2.6954e-06], device='cuda:0')}, 17: {'step': tensor(30200.), 'exp_avg': tensor([-3.8718e-06, -2.2232e-04,  3.5317e-04,  8.8240e-05, -2.7704e-05,
         3.8284e-04, -4.0516e-04,  2.2931e-04,  3.6662e-04, -6.7832e-06,
         7.4536e-05, -3.6120e-04,  5.7630e-04, -5.1887e-04,  5.3905e-04,
         2.7665e-04, -1.4132e-04, -1.5983e-04, -1.7940e-04,  1.1159e-04,
         1.7041e-06, -7.9024e-06,  5.2761e-04,  1.0689e-03,  1.9779e-04,
        -4.3375e-04,  3.5396e-04,  3.2240e-04,  4.0026e-04, -2.9821e-04,
         2.0273e-04,  3.2952e-04, -4.8514e-04, -3.5285e-04, -7.0075e-05,
        -6.9504e-05, -7.1107e-05, -3.3733e-04,  4.8366e-04,  4.6599e-04,
         3.4996e-04,  2.6942e-04,  4.5039e-04, -5.9726e-04,  2.6100e-04,
         1.9511e-05, -4.2234e-04, -1.3702e-04, -1.0157e-04, -1.7790e-04,
         3.9240e-04, -9.9811e-05, -7.8653e-05,  1.1693e-04,  9.1975e-05,
         6.8466e-05, -4.1216e-04, -8.6314e-05, -2.0157e-04,  4.1533e-04,
        -6.1360e-04, -3.2621e-04, -1.2840e-04, -2.1317e-05, -2.7983e-04,
        -1.5680e-04,  2.3962e-04, -2.4140e-04,  3.1882e-04, -5.5138e-04,
         3.2400e-04, -3.3836e-04,  3.7896e-06, -1.3372e-04,  1.4250e-04,
        -2.8499e-05, -4.2573e-04,  4.0134e-04,  1.4162e-04, -1.0885e-04,
        -3.0515e-04, -3.3535e-04, -5.3171e-04,  2.6054e-04,  1.7855e-04,
        -3.0194e-06, -2.1242e-04,  3.1048e-04, -4.8005e-04,  1.5072e-04,
         2.8441e-04,  3.0135e-04,  1.4134e-04,  8.5741e-05,  8.3819e-04,
        -5.3891e-05, -2.2967e-04,  7.8598e-04, -2.2999e-04,  2.0381e-04,
         1.8067e-04, -1.1796e-04, -1.0785e-05, -1.3211e-04, -1.0948e-04,
         3.1148e-04, -1.8098e-04,  7.3230e-05,  5.1218e-04, -3.9544e-04,
         8.2008e-05,  3.6470e-04,  2.6438e-04,  3.2694e-04, -2.5434e-04,
        -1.5225e-04,  3.7150e-04, -4.9938e-04, -2.2058e-05,  1.6738e-04,
        -6.9297e-04,  5.0407e-04, -5.1260e-05,  2.3718e-04, -4.2328e-05,
         9.0610e-05,  3.6306e-05, -2.1336e-04], device='cuda:0'), 'exp_avg_sq': tensor([4.9704e-06, 1.7223e-05, 4.7862e-06, 6.9070e-06, 6.2230e-06, 2.4669e-06,
        3.6528e-05, 9.8457e-06, 3.2947e-05, 3.5999e-06, 2.9972e-06, 5.9490e-06,
        1.0456e-05, 8.0275e-06, 2.1014e-05, 1.3423e-05, 3.7570e-05, 2.1023e-06,
        2.7583e-06, 1.5794e-06, 5.9866e-06, 4.6452e-06, 5.3383e-06, 1.4857e-05,
        4.8980e-06, 5.9780e-06, 7.7255e-06, 4.5172e-06, 5.8458e-06, 4.0174e-06,
        2.8959e-05, 4.3095e-06, 1.1160e-05, 3.6009e-06, 3.5420e-05, 4.3605e-06,
        2.6284e-06, 6.1766e-05, 1.8016e-05, 4.9026e-06, 6.9306e-06, 9.1155e-06,
        4.2489e-06, 5.4165e-06, 8.6630e-06, 1.5408e-06, 8.7807e-06, 2.0573e-06,
        1.8100e-06, 4.4255e-06, 8.0370e-06, 2.4521e-06, 1.7707e-05, 2.1716e-05,
        5.1623e-06, 6.0037e-06, 1.3968e-05, 3.4913e-06, 2.8639e-06, 1.0384e-05,
        8.4021e-06, 2.6203e-06, 4.7394e-06, 8.9181e-06, 1.0277e-05, 6.4761e-06,
        1.0147e-05, 5.3393e-06, 3.3176e-06, 7.3444e-06, 1.6867e-05, 2.2425e-06,
        6.5200e-06, 4.8007e-06, 2.0712e-06, 3.9960e-06, 3.5423e-06, 6.4753e-06,
        3.2747e-06, 2.4686e-06, 4.3090e-06, 2.9914e-06, 1.5591e-05, 3.5268e-06,
        1.2554e-05, 3.6686e-06, 4.2191e-06, 6.8785e-06, 2.0248e-05, 2.1746e-05,
        7.4954e-06, 1.8905e-06, 4.0152e-06, 9.8016e-06, 1.5344e-05, 5.7801e-06,
        6.4334e-06, 1.4708e-05, 6.7268e-06, 5.6471e-06, 3.8257e-06, 8.3945e-06,
        6.7353e-06, 6.0804e-06, 1.0301e-05, 2.6451e-06, 3.3224e-06, 3.9322e-06,
        6.6354e-06, 1.1105e-05, 2.5429e-06, 6.9824e-06, 7.6444e-06, 1.5029e-05,
        4.4336e-06, 7.6886e-06, 3.6928e-06, 7.5317e-06, 5.1176e-06, 1.3561e-05,
        2.2873e-05, 1.0204e-05, 9.5260e-06, 2.6250e-06, 1.0696e-05, 2.2060e-06,
        5.8144e-06, 7.7266e-06], device='cuda:0')}, 18: {'step': tensor(30200.), 'exp_avg': tensor([[ 2.5761e-04, -2.1511e-04, -3.4672e-04,  ...,  2.2093e-04,
          1.6501e-05, -2.5104e-04],
        [ 1.6445e-04,  3.7737e-05, -6.5316e-05,  ..., -9.0999e-05,
          4.7010e-06,  1.5995e-04],
        [-1.8307e-04, -5.5099e-06, -3.4650e-04,  ..., -6.4749e-04,
         -1.2881e-04,  2.5247e-04],
        ...,
        [ 3.7765e-04, -5.1968e-05,  4.4409e-04,  ...,  6.5138e-04,
          3.5337e-05, -4.3277e-04],
        [ 1.7805e-04, -1.8476e-04, -1.0404e-05,  ...,  3.4077e-04,
         -2.9594e-04, -3.5256e-04],
        [ 2.1411e-04,  7.6985e-05,  8.3226e-04,  ...,  3.0062e-05,
          6.7963e-05,  2.1286e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[1.8876e-06, 1.2276e-06, 2.5824e-06,  ..., 2.6431e-06, 1.5408e-06,
         1.3706e-06],
        [5.5050e-06, 4.3878e-06, 5.9716e-06,  ..., 8.9078e-06, 5.2607e-06,
         4.2379e-06],
        [1.7567e-06, 1.0131e-06, 1.3385e-06,  ..., 1.7287e-06, 1.9479e-06,
         8.8022e-07],
        ...,
        [1.6098e-06, 7.0467e-07, 3.8650e-06,  ..., 3.6777e-06, 2.3141e-06,
         1.6334e-06],
        [2.0750e-06, 9.5000e-07, 2.3337e-06,  ..., 2.4346e-06, 1.5626e-06,
         1.1564e-06],
        [3.1439e-06, 4.2931e-07, 3.3976e-06,  ..., 5.0229e-06, 2.3704e-06,
         1.2678e-06]], device='cuda:0')}, 19: {'step': tensor(30200.), 'exp_avg': tensor([ 2.6902e-04,  1.6049e-04, -2.3015e-04,  5.8890e-04, -9.2082e-05,
        -1.2412e-04, -1.5371e-04,  1.7306e-04,  4.8218e-04,  2.9320e-05,
        -1.0497e-04,  3.7972e-05,  3.4398e-04,  5.8628e-04,  2.5468e-04,
         2.7323e-05, -3.0962e-05,  3.3823e-04,  4.6513e-05, -3.6067e-04,
        -3.0649e-04, -1.6239e-04,  2.6338e-04, -3.2743e-04, -1.8192e-04,
        -1.8003e-04,  2.6476e-04,  3.0999e-04,  6.5250e-04,  3.1856e-04,
         4.2426e-04,  3.9329e-04, -3.9153e-04,  2.7429e-04, -4.3122e-05,
         3.1189e-04,  1.5034e-04,  6.8082e-04,  5.1212e-04,  3.7696e-04,
         5.5696e-05, -6.8222e-04,  1.1905e-04, -4.3662e-05, -2.7064e-04,
         4.9652e-04,  3.8728e-04, -1.3718e-04,  1.6751e-05,  7.4617e-04,
         1.5736e-04,  3.5148e-04, -1.0210e-04,  6.0750e-05, -9.7859e-06,
        -3.1509e-05,  2.8959e-04, -3.9775e-04,  4.5085e-04, -1.9812e-04,
        -2.7452e-04, -2.0080e-04,  1.7226e-04, -2.6337e-04, -1.0524e-04,
        -1.8731e-04, -2.7765e-04,  7.8438e-05,  1.0715e-03,  4.1951e-04,
         2.3072e-04, -4.1658e-04, -3.3863e-04, -2.3203e-05, -2.5282e-04,
        -2.5428e-04,  2.0285e-04, -2.3476e-04,  2.1893e-04, -3.9584e-04,
         4.0011e-05,  1.6974e-04, -2.7253e-04, -2.6314e-04,  6.3548e-05,
        -2.5819e-04, -3.9290e-05,  1.3226e-04,  8.8592e-05,  5.9829e-04,
        -4.0121e-04,  4.4327e-05,  2.6488e-04,  5.8827e-04,  3.4383e-04,
         1.1062e-04,  4.0976e-04,  5.8970e-04, -6.0762e-04, -2.3615e-04,
        -2.6083e-04, -4.8235e-04, -7.9884e-05, -1.8183e-04,  7.6909e-06,
        -2.9322e-04,  3.1357e-04,  4.9466e-04,  2.1571e-04, -6.4404e-05,
         5.7292e-04, -4.7693e-04,  1.2287e-05,  2.6488e-04,  3.6020e-04,
         2.8566e-04, -5.4569e-05,  9.3618e-04, -2.2522e-04, -1.6392e-04,
        -6.7041e-04,  6.7171e-05,  3.1952e-06,  2.0379e-04, -3.5983e-04,
        -2.1570e-05, -1.3042e-05, -3.1879e-04,  4.0816e-05, -2.9655e-04,
         1.7605e-04, -5.9642e-04,  1.7926e-05,  1.1680e-05, -1.4514e-04,
        -1.2079e-04, -1.0061e-03,  4.1273e-05,  8.5164e-04, -4.1265e-04,
         1.2064e-04,  1.2509e-04,  3.8527e-04,  1.5187e-04, -3.9836e-04,
         4.5392e-05,  1.2280e-04, -8.2824e-05,  9.0975e-05, -2.3517e-04,
         8.5720e-04, -7.3026e-05, -1.3924e-05, -1.8445e-04, -2.9301e-04,
         6.7143e-05,  8.4205e-06, -4.5898e-04,  4.3257e-04, -6.0909e-04,
         2.4430e-04, -3.9028e-04, -1.3204e-04, -1.3721e-04, -3.0433e-04,
        -1.2542e-04, -1.3560e-04,  3.4028e-04,  2.9535e-04, -7.5684e-04,
         1.1674e-04, -2.8831e-04, -2.5927e-04,  4.5500e-05, -1.6010e-05,
         2.2600e-04,  5.2898e-04, -3.4463e-04,  1.7339e-04, -1.5507e-04,
        -1.1098e-04,  7.9142e-05,  5.3468e-04,  4.5045e-04, -5.7290e-06,
         2.5097e-04,  2.3193e-04, -1.0766e-04,  2.5214e-04, -1.0993e-04,
         4.0685e-04,  2.2773e-04,  8.8308e-04,  2.4496e-04,  4.0525e-04,
         8.1597e-05,  1.3375e-04, -3.4847e-04, -3.2238e-04,  2.6425e-04,
        -1.7505e-04,  4.1624e-04,  3.5337e-05, -3.3329e-04, -2.0989e-04,
         2.2758e-05,  4.5085e-04, -7.4295e-05,  4.3901e-05, -2.8908e-05,
         9.8551e-05, -3.5360e-04, -3.2293e-06, -4.2487e-04, -1.3219e-04,
        -3.8477e-04,  4.2272e-04, -1.0969e-04, -7.1716e-04,  1.3639e-04,
         1.7463e-04, -3.1746e-05, -7.3520e-05, -2.3209e-04, -7.2338e-05,
         3.1189e-04, -4.0376e-04,  1.2969e-04, -3.3352e-04, -1.5755e-04,
        -1.4867e-05,  3.9413e-04, -1.7234e-04, -1.0279e-04, -4.4482e-05,
        -8.0746e-05,  2.0898e-04,  5.1554e-04,  4.9156e-05,  7.0705e-05,
         3.0181e-04,  6.7842e-04,  2.8389e-04, -6.7959e-04, -4.4222e-04,
        -1.0960e-04, -2.5553e-04,  1.5698e-04,  6.1748e-04, -2.4620e-04,
         4.1085e-04,  1.3385e-04,  5.5273e-05,  1.2889e-05, -2.8058e-04,
        -2.4922e-06], device='cuda:0'), 'exp_avg_sq': tensor([2.4350e-06, 8.9773e-06, 1.9728e-06, 9.3943e-06, 1.7804e-06, 1.6915e-06,
        4.0854e-06, 4.4951e-06, 2.5741e-06, 2.4838e-06, 2.1876e-06, 1.7987e-06,
        4.0868e-06, 7.5105e-06, 1.8836e-06, 1.6311e-06, 3.9448e-06, 6.9251e-06,
        1.8397e-06, 2.1726e-06, 3.1613e-06, 5.0233e-06, 3.6747e-06, 4.0698e-06,
        7.3701e-06, 8.1590e-06, 3.5024e-06, 3.5503e-06, 7.6198e-06, 5.4627e-06,
        5.4716e-06, 2.3094e-06, 3.3644e-06, 3.4114e-06, 2.7807e-06, 2.2040e-06,
        2.8238e-06, 6.9326e-06, 6.9880e-06, 5.1436e-06, 3.2489e-06, 6.2547e-06,
        1.4581e-06, 2.4773e-06, 3.7669e-06, 5.5844e-06, 1.6214e-06, 2.7540e-06,
        3.5523e-06, 1.8426e-06, 1.0169e-05, 3.1353e-06, 2.2905e-06, 2.4186e-06,
        2.7870e-06, 3.0989e-06, 2.8999e-06, 3.8199e-06, 5.1957e-06, 6.7195e-06,
        4.3301e-06, 4.0977e-06, 5.2094e-06, 3.5080e-06, 1.5725e-06, 3.4886e-06,
        1.0281e-05, 5.2760e-06, 5.2165e-06, 3.7544e-06, 2.6836e-06, 4.1462e-06,
        8.0943e-06, 5.5898e-06, 4.6243e-06, 4.1000e-06, 2.8681e-06, 3.7395e-06,
        4.0362e-06, 7.2922e-06, 2.4235e-06, 1.5635e-05, 5.3895e-06, 1.4882e-06,
        2.5042e-06, 1.8842e-06, 2.5327e-06, 3.1680e-06, 7.0537e-06, 4.6521e-06,
        1.2645e-06, 2.3565e-06, 8.4363e-06, 3.1733e-06, 4.0357e-06, 3.5449e-06,
        4.9441e-06, 6.4084e-06, 5.2945e-06, 1.8242e-05, 2.3796e-06, 2.7817e-06,
        3.0115e-06, 3.4838e-06, 1.2580e-06, 2.6419e-05, 2.6920e-06, 6.1341e-06,
        3.6858e-06, 2.9327e-06, 6.4755e-06, 1.6484e-05, 2.3276e-06, 3.2145e-06,
        6.1588e-06, 2.0768e-06, 5.0682e-06, 1.8280e-05, 1.3858e-05, 2.1639e-06,
        9.9909e-06, 1.5370e-06, 6.0553e-06, 2.6694e-06, 7.5407e-06, 2.4420e-06,
        1.6081e-06, 2.8484e-06, 7.4915e-06, 3.9034e-06, 7.5130e-06, 3.1899e-06,
        8.4632e-06, 3.0326e-06, 3.4489e-06, 3.6023e-06, 6.4397e-06, 3.5358e-06,
        1.2683e-05, 3.7146e-06, 6.6906e-06, 3.5234e-06, 3.7511e-06, 2.5334e-06,
        6.3123e-06, 1.8847e-06, 8.8315e-07, 4.5451e-06, 3.2034e-06, 4.2369e-06,
        1.2815e-05, 8.8504e-06, 2.8933e-06, 5.2277e-06, 4.6346e-06, 1.7870e-06,
        2.5458e-06, 4.9205e-06, 4.2920e-06, 2.7405e-06, 1.6848e-06, 6.5663e-06,
        5.7510e-06, 4.1904e-06, 1.2191e-05, 2.8847e-06, 2.8047e-06, 5.1014e-06,
        3.2261e-06, 5.9276e-06, 2.5590e-06, 2.7360e-06, 3.5656e-06, 2.5982e-06,
        3.0641e-06, 5.0749e-06, 8.2190e-06, 1.3754e-05, 3.0392e-06, 3.3853e-06,
        6.7696e-06, 4.0927e-06, 3.2201e-06, 2.3824e-06, 1.9835e-06, 8.7597e-06,
        4.4257e-06, 3.7024e-06, 2.1857e-06, 3.6244e-06, 4.6827e-06, 3.4325e-06,
        6.2191e-06, 4.3713e-06, 1.9105e-06, 3.4257e-06, 8.5490e-06, 5.0329e-06,
        2.2172e-06, 3.2579e-06, 3.2149e-06, 5.1803e-06, 4.3901e-06, 8.1475e-06,
        2.1726e-05, 2.5164e-06, 2.3733e-05, 3.1663e-06, 1.1894e-06, 1.0931e-05,
        9.2653e-06, 3.7767e-06, 3.9430e-06, 3.4451e-06, 1.9065e-06, 2.4140e-06,
        2.5415e-06, 6.8218e-06, 3.7225e-06, 7.0540e-06, 2.0689e-06, 5.3654e-06,
        1.8641e-06, 4.3448e-06, 1.4353e-06, 2.7896e-06, 9.0150e-06, 6.3733e-06,
        3.7982e-06, 9.7510e-06, 9.2950e-07, 5.2819e-06, 2.4590e-06, 3.4311e-06,
        2.5823e-06, 3.1227e-06, 5.1436e-06, 6.0792e-06, 5.1427e-06, 3.7698e-06,
        1.9579e-05, 4.4013e-06, 7.1301e-06, 4.4819e-06, 4.3665e-06, 2.0683e-06,
        3.5210e-06, 1.6150e-06, 7.7327e-06, 1.5195e-06, 1.7384e-06, 4.7395e-06,
        7.0292e-06, 2.3877e-06, 2.2065e-06, 3.6831e-06], device='cuda:0')}, 20: {'step': tensor(30200.), 'exp_avg': tensor([[ 3.7866e-05,  8.1141e-04,  4.9383e-04,  ..., -2.1455e-04,
          3.4267e-04, -2.4332e-05],
        [ 2.4480e-04, -1.2757e-04,  1.3098e-04,  ..., -1.3634e-04,
          1.7217e-04,  2.7128e-04],
        [-1.9932e-05,  7.3939e-04,  5.8140e-04,  ...,  2.2880e-04,
         -7.8980e-05,  4.2815e-04],
        ...,
        [-1.2281e-04, -5.3834e-04, -1.1380e-04,  ...,  1.0277e-04,
         -2.5238e-05,  1.6685e-04],
        [-5.9066e-04,  1.0190e-04,  3.1814e-04,  ...,  1.5831e-04,
          9.6156e-05,  1.9297e-04],
        [ 2.6144e-05,  5.1635e-04,  5.3334e-04,  ..., -1.5075e-04,
          3.4439e-04, -1.6883e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[2.9199e-06, 4.3413e-06, 3.7300e-06,  ..., 1.4701e-06, 2.1154e-06,
         2.1876e-06],
        [2.2411e-06, 3.5001e-06, 3.3956e-06,  ..., 1.2205e-06, 2.3567e-06,
         2.3627e-06],
        [2.0072e-06, 4.9682e-06, 5.8531e-06,  ..., 1.4131e-06, 2.7522e-06,
         2.9801e-06],
        ...,
        [2.0516e-06, 4.6788e-06, 6.1656e-06,  ..., 1.3220e-06, 2.3909e-06,
         2.0520e-06],
        [2.8810e-06, 4.8094e-06, 4.8840e-06,  ..., 1.3146e-06, 2.8912e-06,
         2.8443e-06],
        [3.5177e-06, 5.8973e-06, 4.6284e-06,  ..., 2.0592e-06, 2.7263e-06,
         4.7620e-06]], device='cuda:0')}, 21: {'step': tensor(30200.), 'exp_avg': tensor([ 7.7474e-04, -3.2503e-04,  3.1624e-03,  1.7340e-03, -3.9070e-04,
         1.9859e-04, -7.4366e-04,  1.5108e-03, -5.0113e-04, -1.7088e-04,
        -4.4511e-04,  1.1263e-04,  2.3329e-03,  3.8494e-05,  1.7142e-03,
         2.5157e-03,  1.0637e-03, -1.4027e-03, -1.1288e-04,  7.4374e-04,
        -1.6160e-03, -1.8058e-04,  1.3911e-03,  9.4578e-04, -1.2037e-03,
        -4.5556e-05, -1.3684e-03, -7.6071e-04,  3.9274e-04, -1.1306e-03,
         7.3280e-04, -8.4725e-04, -9.7136e-04,  1.7095e-03, -1.5509e-03,
        -3.7259e-04, -6.0107e-04,  6.9054e-04,  1.8427e-04, -1.5099e-05,
         2.4490e-03,  2.1989e-04, -5.7887e-05,  7.7729e-04,  1.2056e-03,
         9.0875e-05,  3.6709e-04, -2.8233e-04, -1.3114e-03,  8.5623e-04,
        -4.2892e-04,  3.8438e-04, -4.6641e-05, -5.8749e-04, -1.1428e-03,
        -2.4425e-05,  5.8542e-04, -1.8506e-04,  2.2624e-04, -1.5653e-03,
        -1.6400e-03, -1.0352e-04,  1.5727e-03, -1.4715e-03, -1.9826e-03,
        -1.0702e-03, -7.3817e-05, -5.2618e-04, -1.1452e-03,  7.4252e-04,
         8.4246e-04, -8.7569e-04, -1.8744e-03, -1.1954e-03,  8.5752e-04,
        -9.3710e-04,  1.0183e-04,  1.0313e-03,  6.6467e-04,  8.2975e-04,
        -6.5097e-04, -6.0702e-04, -2.1025e-04,  1.5259e-03,  4.1194e-04,
        -7.4428e-04, -4.7158e-04, -1.2783e-03,  5.2396e-04,  4.2996e-04,
        -4.5375e-04, -1.3160e-04, -4.9046e-05,  3.3977e-05,  1.8008e-03,
         7.6071e-04,  1.2175e-03, -8.2414e-04, -1.8175e-03, -1.5784e-03,
         1.2921e-03, -8.0304e-04,  7.1559e-04,  4.8256e-04,  8.2315e-05,
         9.7392e-04,  8.4239e-04,  4.9145e-04, -6.9421e-04, -2.0414e-03,
        -2.6489e-04,  8.6081e-05, -3.9895e-04, -5.5892e-04,  1.3518e-03,
         4.2976e-04, -6.0959e-04, -7.5844e-04, -1.7503e-03,  2.1006e-03,
        -1.4344e-03, -9.7489e-04, -1.1755e-03,  1.0766e-04, -1.3901e-04,
         1.0128e-04, -1.5669e-03, -3.5659e-04], device='cuda:0'), 'exp_avg_sq': tensor([4.3786e-05, 6.6810e-05, 7.6401e-05, 1.0413e-04, 3.5503e-05, 3.5916e-05,
        4.8287e-05, 4.8011e-05, 8.6273e-05, 3.8312e-05, 5.9951e-05, 4.0337e-05,
        9.7325e-05, 5.8137e-05, 7.0348e-05, 7.8332e-05, 1.0207e-04, 9.8020e-05,
        4.2918e-05, 3.0934e-05, 7.9402e-05, 6.6086e-05, 1.0104e-04, 3.1456e-05,
        6.8912e-05, 7.0980e-05, 3.5457e-05, 3.3582e-05, 2.7689e-05, 1.5253e-04,
        5.3112e-05, 5.5654e-05, 6.9449e-05, 6.9391e-05, 1.4763e-04, 5.0807e-05,
        3.0094e-05, 1.5183e-04, 2.8365e-05, 7.1570e-05, 5.1213e-05, 8.4800e-05,
        4.8255e-05, 4.9896e-05, 4.5139e-05, 3.2842e-05, 5.6728e-05, 2.8239e-05,
        2.8769e-05, 3.0963e-05, 8.1412e-05, 1.0052e-04, 2.3376e-04, 1.1433e-04,
        8.9008e-05, 4.4964e-05, 7.3018e-05, 5.5509e-05, 4.1918e-05, 2.3563e-05,
        7.8538e-05, 4.8013e-05, 4.5797e-05, 2.5883e-05, 4.4467e-05, 7.2827e-05,
        3.2272e-05, 4.8882e-05, 2.0518e-05, 4.4284e-05, 7.4484e-05, 4.2635e-05,
        8.2565e-05, 6.1988e-05, 6.0570e-05, 4.5420e-05, 3.4007e-05, 6.8563e-05,
        3.4359e-05, 3.1473e-05, 8.0310e-05, 8.3528e-05, 4.3179e-05, 7.1802e-05,
        8.6620e-05, 9.5602e-05, 7.1307e-05, 4.0481e-05, 8.7343e-05, 1.0853e-04,
        5.4466e-05, 3.6565e-05, 5.0010e-05, 1.7603e-05, 4.0293e-05, 4.2803e-05,
        2.2801e-05, 6.7602e-05, 7.0881e-05, 4.7761e-05, 2.7520e-05, 6.5562e-05,
        7.0837e-05, 6.6905e-05, 1.4538e-04, 3.1484e-05, 5.2689e-05, 3.2768e-05,
        9.1322e-05, 7.7284e-05, 4.4426e-05, 5.0042e-05, 8.8647e-05, 5.3764e-05,
        4.8889e-05, 4.0631e-05, 4.1558e-05, 1.8826e-05, 1.2891e-04, 3.6663e-05,
        8.3411e-05, 3.6150e-05, 1.0170e-04, 4.3023e-05, 2.7144e-05, 7.1886e-05,
        1.1552e-04, 8.1987e-05], device='cuda:0')}, 22: {'step': tensor(30200.), 'exp_avg': tensor([-2.2653e-04, -3.7878e-04,  2.1325e-04,  5.1509e-05, -8.3595e-04,
         1.0374e-03, -5.3778e-04,  1.8726e-04, -1.8537e-04,  4.1297e-04,
        -1.4408e-03,  8.4963e-05, -9.4225e-04, -5.8111e-04, -4.8757e-04,
         7.5669e-05, -5.7275e-04, -3.3892e-04, -3.1074e-05, -2.2275e-04,
        -6.1500e-05, -9.7570e-06, -5.2721e-04, -2.0972e-04, -8.5796e-06,
        -7.7340e-04,  1.9098e-04,  1.0769e-03, -1.8142e-04,  1.7248e-03,
        -7.0224e-04,  3.1963e-04, -2.3298e-04, -9.9197e-05,  1.2037e-04,
         4.7633e-04, -2.1562e-04, -4.2122e-04, -5.8965e-04,  6.1734e-04,
        -5.8968e-04, -1.1486e-03,  7.0645e-04, -6.4115e-04, -6.9320e-04,
         2.2811e-05, -5.0237e-05, -3.6308e-04,  1.1882e-04, -1.6637e-04,
        -9.0476e-05,  3.1480e-04, -1.3072e-03, -9.9746e-04, -9.9612e-04,
        -2.9099e-05,  1.6455e-04,  4.5571e-04,  6.6065e-04, -2.3935e-04,
        -2.4291e-04, -9.0172e-04, -6.3797e-04, -6.3135e-04,  1.6054e-04,
         8.2736e-05,  3.9362e-04, -3.7155e-04, -4.2698e-05, -2.2923e-04,
         6.7647e-05, -1.8863e-04,  6.8531e-06, -1.5144e-04, -3.8391e-04,
         2.7617e-04, -7.2800e-04, -9.4765e-05, -2.7532e-05, -4.7057e-04,
        -1.4744e-04, -4.2254e-04, -4.2721e-04, -1.0943e-04,  6.9644e-04,
        -7.6572e-04,  2.4865e-04, -6.6652e-05,  5.6032e-04, -1.2765e-03,
        -8.4895e-05, -3.2824e-05,  9.7814e-05,  6.2958e-04, -1.0672e-03,
        -1.3407e-04, -3.2400e-04, -8.5115e-04, -7.4175e-04, -3.2709e-04,
        -7.6886e-05, -4.0377e-05, -2.6289e-05, -5.7789e-04,  5.7118e-04,
        -1.2379e-04,  6.2447e-04,  1.8172e-04, -3.6529e-05, -1.0369e-03,
         2.4456e-04,  8.1324e-04, -4.6866e-04,  1.5250e-04, -1.4919e-04,
         2.3798e-04,  7.6575e-04, -3.6261e-04,  5.5322e-05, -6.6770e-04,
        -1.2269e-05, -2.5302e-04, -1.9133e-04,  7.6690e-04, -9.4352e-04,
        -1.8223e-04, -6.3738e-05, -9.8605e-04], device='cuda:0'), 'exp_avg_sq': tensor([3.6940e-06, 4.0597e-06, 5.9593e-06, 6.2727e-06, 3.1753e-06, 5.7461e-06,
        7.8698e-06, 4.1158e-06, 8.7861e-06, 4.5053e-06, 4.5839e-06, 1.8973e-06,
        3.3673e-06, 1.0726e-05, 3.0202e-06, 4.2560e-06, 5.8099e-06, 7.0914e-06,
        4.5461e-06, 5.3760e-06, 4.2742e-06, 3.1837e-06, 5.7844e-06, 5.1662e-06,
        2.8433e-06, 4.2983e-06, 3.9472e-06, 9.3015e-06, 1.8215e-06, 7.7427e-06,
        5.9878e-06, 5.1840e-06, 7.1265e-06, 2.7882e-06, 7.7106e-06, 4.7496e-06,
        3.3005e-06, 8.1645e-06, 5.4771e-06, 2.8875e-06, 6.1471e-06, 8.4810e-06,
        5.5335e-06, 4.3511e-06, 4.1078e-06, 4.9387e-06, 4.0231e-06, 3.5981e-06,
        4.6052e-06, 2.5777e-06, 5.7531e-06, 5.6261e-06, 1.4248e-05, 7.4424e-06,
        6.4033e-06, 5.7276e-06, 4.6219e-06, 5.1448e-06, 1.2442e-05, 4.5375e-06,
        3.6247e-06, 4.8385e-06, 3.6628e-06, 4.1008e-06, 2.4177e-06, 4.3169e-06,
        5.0833e-06, 4.9372e-06, 2.6624e-06, 3.8052e-06, 2.1356e-06, 3.4073e-06,
        4.7195e-06, 3.4211e-06, 3.6828e-06, 2.0164e-06, 5.5814e-06, 3.7588e-06,
        4.3566e-06, 2.5932e-06, 5.4451e-06, 4.0074e-06, 3.6553e-06, 5.2978e-06,
        3.8609e-06, 4.2970e-06, 3.2275e-06, 2.0236e-06, 7.6168e-06, 5.2802e-06,
        1.8749e-06, 2.9720e-06, 5.4061e-06, 5.7241e-06, 5.5309e-06, 3.2831e-06,
        2.0962e-06, 6.7573e-06, 6.8093e-06, 2.9990e-06, 2.2396e-06, 4.9182e-06,
        3.8209e-06, 5.2645e-06, 6.2674e-06, 5.6528e-06, 7.7717e-06, 3.5692e-06,
        3.5489e-06, 6.7233e-06, 2.8180e-06, 4.8821e-06, 5.2923e-06, 3.0858e-06,
        3.6641e-06, 1.6022e-06, 5.0736e-06, 4.9071e-06, 5.9959e-06, 4.5161e-06,
        2.5794e-06, 5.1222e-06, 5.4487e-06, 4.4074e-06, 3.4230e-06, 4.7665e-06,
        5.3239e-06, 4.2481e-06], device='cuda:0')}, 23: {'step': tensor(30200.), 'exp_avg': tensor([ 2.0749e-04, -5.6338e-04,  1.2474e-03,  1.0352e-03, -1.2036e-04,
        -3.1775e-04, -9.3698e-04,  2.7615e-04,  1.6517e-04, -1.3407e-04,
        -7.2557e-04, -3.7917e-04,  8.2874e-04,  5.9891e-05,  4.5754e-04,
         3.7811e-04,  9.7175e-04, -9.3873e-04, -4.7194e-04,  3.3483e-04,
        -4.4025e-04, -3.0314e-05,  2.3753e-04, -5.5982e-04, -2.1957e-04,
        -4.4088e-04, -2.6878e-04,  6.7148e-04, -3.4963e-04, -9.7318e-05,
         4.6495e-04, -2.4086e-04, -2.8613e-04,  5.7856e-04, -2.4223e-04,
        -3.5877e-04, -2.3264e-04, -4.2189e-04,  2.1175e-04,  8.3423e-06,
         4.7527e-04,  6.5597e-04,  1.0628e-03, -2.4352e-04,  3.0199e-04,
        -5.6201e-06, -5.7024e-05, -3.7318e-04, -4.5797e-04, -1.6133e-04,
         9.9893e-05,  2.8234e-04,  6.5045e-04, -2.7134e-04, -9.1512e-04,
        -3.6132e-04, -1.9386e-04,  5.7805e-07, -7.9911e-04, -4.9910e-05,
        -1.7232e-04,  1.5868e-04,  2.2115e-04, -2.0464e-05, -5.2678e-04,
        -4.4055e-04,  4.0046e-05, -4.8147e-04, -9.4455e-05, -4.7279e-04,
         6.8170e-04, -1.3264e-04, -5.3651e-04, -2.9086e-04,  7.9648e-04,
         1.5130e-04, -2.6135e-04, -9.7741e-05, -2.6079e-05, -2.2672e-04,
        -1.1854e-05,  7.9285e-04, -1.9110e-04,  2.5694e-04, -2.7558e-04,
        -2.9091e-04, -7.8193e-04, -1.8657e-04,  4.0085e-04,  4.3858e-04,
         2.8384e-04, -2.7493e-05, -6.6939e-04, -2.8369e-04,  6.5702e-04,
         1.9206e-04,  1.0386e-04, -3.5187e-04, -3.6900e-04,  4.3731e-05,
         1.5985e-04,  6.4626e-05,  2.8034e-04,  1.9456e-04,  5.6252e-04,
         3.0340e-05,  5.9653e-04, -1.3055e-04,  4.8900e-04,  3.1087e-05,
        -2.9661e-05, -3.0473e-04,  3.3556e-04,  3.6488e-05, -2.7162e-04,
        -5.3688e-05, -4.1728e-04, -5.9057e-04, -2.9606e-04,  2.9988e-04,
        -5.8333e-04,  2.1916e-04, -5.3863e-04, -4.9408e-04,  5.5362e-04,
         5.0260e-04,  4.5128e-04, -6.5204e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.1007e-05, 1.5928e-05, 1.5096e-05, 3.0541e-05, 9.9831e-06, 1.2147e-05,
        1.1668e-05, 6.2628e-06, 5.8772e-05, 1.2827e-05, 9.3096e-06, 1.1801e-05,
        6.7086e-06, 1.3081e-05, 1.2311e-05, 1.2886e-05, 2.1041e-05, 2.5116e-05,
        9.2559e-06, 2.5808e-05, 1.0791e-05, 8.5609e-06, 2.3656e-05, 7.5594e-06,
        6.9859e-06, 1.2029e-05, 8.9998e-06, 8.6843e-06, 2.3665e-06, 5.1010e-05,
        1.5070e-05, 8.2892e-06, 3.1488e-05, 8.7600e-06, 4.1500e-05, 5.7244e-06,
        6.0733e-06, 4.2409e-05, 1.6717e-05, 1.1258e-05, 1.3570e-05, 1.8414e-05,
        2.3043e-05, 6.5027e-06, 8.1587e-06, 8.8126e-06, 7.9774e-06, 1.8916e-05,
        9.6374e-06, 2.5183e-05, 2.3281e-05, 1.6153e-05, 4.7467e-05, 4.1101e-05,
        1.8016e-05, 9.3159e-06, 2.3632e-05, 1.0979e-05, 1.0628e-05, 4.8217e-06,
        1.1420e-05, 9.2371e-06, 1.1805e-05, 7.7337e-06, 7.7095e-06, 2.2937e-05,
        1.4573e-05, 1.2339e-05, 7.8410e-06, 9.2906e-06, 2.1430e-05, 8.3581e-06,
        7.3881e-06, 1.2907e-05, 1.5260e-05, 1.1864e-05, 8.9863e-06, 1.2855e-05,
        1.8681e-05, 1.1008e-05, 2.3070e-05, 1.2835e-05, 7.8345e-06, 3.5370e-06,
        3.7933e-05, 1.0167e-05, 2.3024e-05, 8.2955e-06, 1.4426e-05, 2.4425e-05,
        1.3840e-05, 7.8730e-06, 7.0943e-06, 3.9598e-06, 9.6557e-06, 1.2127e-05,
        7.3044e-06, 7.1942e-06, 1.5755e-05, 1.7884e-05, 6.0941e-06, 1.5126e-05,
        1.2225e-05, 2.9246e-05, 1.9534e-05, 7.3575e-06, 2.5568e-05, 8.0475e-06,
        3.5030e-05, 1.3960e-05, 5.6048e-06, 1.7138e-05, 2.6818e-05, 4.8551e-06,
        8.4234e-06, 8.7251e-06, 9.6158e-06, 9.6350e-06, 2.9180e-05, 7.9901e-06,
        9.9117e-06, 1.0894e-05, 9.8661e-06, 1.2195e-05, 7.1265e-06, 1.2875e-05,
        1.2475e-05, 3.2526e-05], device='cuda:0')}, 24: {'step': tensor(30200.), 'exp_avg': tensor([[ 2.9569e-04,  8.3597e-05,  3.5008e-04,  ...,  4.0513e-04,
         -9.1094e-05, -1.3282e-04],
        [-1.8548e-05,  1.1264e-05,  1.6645e-04,  ..., -1.4032e-04,
         -5.4016e-05,  1.0833e-04],
        [ 7.1496e-05,  6.8225e-05,  5.5094e-05,  ...,  1.1397e-04,
         -2.3887e-05, -9.1073e-05],
        ...,
        [ 6.5841e-06,  4.0532e-05, -2.0708e-05,  ..., -1.5973e-04,
          3.3562e-04,  3.0125e-04],
        [ 2.8542e-04,  3.3478e-04, -5.5632e-05,  ..., -5.4501e-04,
          2.7242e-04,  1.6270e-04],
        [ 2.3569e-04,  2.4083e-05,  2.9942e-04,  ..., -4.0093e-04,
          3.3608e-04, -2.7524e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[6.6551e-07, 3.2290e-07, 8.7543e-07,  ..., 9.2735e-07, 9.1004e-07,
         4.2794e-07],
        [2.9532e-07, 2.2042e-07, 7.1225e-07,  ..., 6.9383e-07, 5.2732e-07,
         3.2841e-07],
        [2.3185e-07, 1.1808e-07, 3.8618e-07,  ..., 4.2428e-07, 2.7455e-07,
         1.8880e-07],
        ...,
        [1.8347e-06, 1.2090e-06, 3.0386e-06,  ..., 3.3735e-06, 4.1368e-06,
         1.2228e-06],
        [1.3499e-06, 9.1849e-07, 2.0146e-06,  ..., 2.2438e-06, 2.8199e-06,
         8.5244e-07],
        [9.4878e-07, 6.5713e-07, 1.1367e-06,  ..., 2.0417e-06, 1.9889e-06,
         6.6929e-07]], device='cuda:0')}, 25: {'step': tensor(30200.), 'exp_avg': tensor([[ 7.3417e-05, -1.0121e-04,  5.3146e-04,  ..., -4.5091e-04,
         -3.5931e-04,  2.4865e-04],
        [-3.1894e-04, -1.5448e-04,  2.5105e-04,  ...,  2.8942e-04,
          9.0049e-05, -1.5018e-05],
        [ 8.1046e-04,  1.2283e-04,  4.2244e-05,  ...,  4.0906e-04,
         -5.1672e-04,  6.5823e-04],
        ...,
        [-1.8668e-04, -1.6984e-04, -8.4063e-04,  ...,  2.4987e-04,
          4.5542e-04, -1.3241e-04],
        [-7.8069e-05, -1.0168e-04, -4.6708e-04,  ...,  4.1526e-04,
          1.1045e-04,  5.2003e-04],
        [-1.4210e-04,  2.1758e-04,  7.5734e-04,  ...,  5.2137e-04,
          1.3136e-04,  1.1142e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[1.6757e-06, 1.0834e-06, 1.8832e-06,  ..., 2.4719e-06, 2.9049e-06,
         1.2479e-06],
        [1.7677e-06, 9.3963e-07, 1.9740e-06,  ..., 1.8844e-06, 2.3419e-06,
         1.1590e-06],
        [1.6988e-06, 1.1776e-06, 2.1783e-06,  ..., 3.4159e-06, 3.4879e-06,
         1.3544e-06],
        ...,
        [1.6888e-06, 1.3253e-06, 2.2163e-06,  ..., 2.5684e-06, 3.1505e-06,
         1.2899e-06],
        [2.3914e-06, 1.4832e-06, 2.6380e-06,  ..., 2.9618e-06, 3.3876e-06,
         1.5966e-06],
        [1.8661e-06, 1.0783e-06, 2.3448e-06,  ..., 3.4456e-06, 3.6527e-06,
         1.5267e-06]], device='cuda:0')}, 26: {'step': tensor(30200.), 'exp_avg': tensor([ 3.9918e-04,  4.8753e-04, -5.2723e-05,  3.5767e-04, -5.7645e-05,
         1.2913e-04,  2.1422e-04,  1.6587e-03, -3.3154e-04, -7.6976e-04,
         2.6276e-04,  6.8136e-04,  5.0687e-04,  2.5641e-04,  9.7701e-04,
         1.3266e-03,  1.3297e-03, -5.1447e-04,  7.7828e-05, -1.3441e-05,
         5.3111e-05, -2.1527e-04,  9.0248e-04,  1.6516e-03, -4.0755e-04,
         6.2746e-04, -6.2351e-04, -1.3450e-03,  4.8195e-04, -3.8951e-04,
        -3.9617e-04, -2.2460e-04, -8.6822e-04,  9.9706e-04,  1.0279e-04,
         2.7685e-04, -3.5423e-04,  1.3453e-03,  1.7181e-04,  2.6823e-04,
         1.3536e-03,  5.6281e-04, -6.7102e-04,  1.3239e-03,  5.4059e-04,
         4.4390e-04,  5.1045e-04,  2.3147e-04, -6.8224e-04,  1.2649e-03,
         1.6299e-04,  3.8037e-04, -6.3807e-04, -2.7760e-04,  2.7008e-05,
         1.5384e-03,  1.6154e-03, -9.1816e-04,  9.6929e-05, -1.1161e-03,
        -1.3246e-03, -4.8101e-05,  1.0091e-03, -1.0248e-03, -1.2144e-03,
        -2.2067e-04, -2.0372e-04,  7.9963e-04, -7.0324e-04,  1.7775e-03,
         6.5407e-04, -1.0996e-03, -1.9546e-04, -3.1174e-04, -1.3445e-05,
        -1.3487e-03,  4.8181e-04,  9.4471e-04,  9.5641e-04,  9.3056e-04,
        -4.2508e-04, -3.6967e-04, -2.7808e-04,  7.7915e-04,  6.7276e-04,
        -4.2320e-04,  7.1534e-04, -8.2448e-05,  9.8892e-05, -5.0315e-04,
         6.3377e-04, -1.1022e-03,  1.7939e-04, -3.7043e-04,  8.7172e-04,
         7.1486e-04,  7.7712e-04, -6.4722e-04, -1.6034e-03, -1.1730e-03,
         4.1132e-04, -1.0201e-03,  3.0776e-04,  9.0566e-04, -1.6292e-04,
         4.3796e-04,  4.1047e-04,  6.2117e-04, -2.6287e-04, -2.0980e-03,
         2.6492e-05,  1.0861e-04, -1.3832e-04, -7.4557e-04,  1.6651e-03,
         2.1740e-04, -6.2342e-04, -6.6012e-04, -2.1262e-03,  1.5955e-03,
        -6.7842e-04, -1.4406e-03, -2.2783e-04,  4.7892e-04, -5.2052e-04,
        -8.9083e-04, -2.2597e-03, -4.5878e-04], device='cuda:0'), 'exp_avg_sq': tensor([2.9024e-05, 3.2110e-05, 4.1421e-05, 4.2022e-05, 2.6603e-05, 3.0488e-05,
        3.2193e-05, 5.9544e-05, 4.2979e-05, 2.6138e-05, 3.6770e-05, 2.3047e-05,
        8.1307e-05, 4.4963e-05, 4.3192e-05, 4.9289e-05, 4.8229e-05, 5.0875e-05,
        2.8458e-05, 2.5974e-05, 5.3911e-05, 4.8873e-05, 4.8233e-05, 2.6249e-05,
        5.0394e-05, 3.8805e-05, 2.9372e-05, 3.4859e-05, 2.3722e-05, 6.2792e-05,
        2.9641e-05, 4.1858e-05, 2.3530e-05, 4.4054e-05, 6.2358e-05, 4.5619e-05,
        2.0272e-05, 5.8126e-05, 1.9850e-05, 5.9960e-05, 5.3390e-05, 3.6402e-05,
        1.7306e-05, 3.8031e-05, 4.5930e-05, 3.2658e-05, 4.7072e-05, 1.9398e-05,
        2.4829e-05, 3.1097e-05, 4.0254e-05, 6.4243e-05, 1.0562e-04, 5.7552e-05,
        5.6021e-05, 3.6815e-05, 5.5099e-05, 3.3833e-05, 3.7149e-05, 2.2099e-05,
        4.8565e-05, 3.5428e-05, 2.5963e-05, 2.8765e-05, 3.4530e-05, 2.8835e-05,
        3.0536e-05, 3.4007e-05, 1.6986e-05, 4.5558e-05, 4.0938e-05, 2.8620e-05,
        7.3705e-05, 3.7515e-05, 3.3985e-05, 2.8914e-05, 2.1621e-05, 4.2847e-05,
        1.4243e-05, 2.5294e-05, 4.1271e-05, 6.3385e-05, 3.6244e-05, 6.9703e-05,
        3.5501e-05, 6.7685e-05, 2.9647e-05, 3.7623e-05, 5.2717e-05, 4.9259e-05,
        3.2855e-05, 2.3952e-05, 5.3109e-05, 1.4090e-05, 3.3305e-05, 2.2366e-05,
        1.5352e-05, 5.5935e-05, 3.2368e-05, 2.7992e-05, 2.0620e-05, 3.9769e-05,
        4.1777e-05, 2.5146e-05, 8.0006e-05, 2.2673e-05, 2.1832e-05, 1.9098e-05,
        3.5044e-05, 4.8751e-05, 4.4002e-05, 3.5808e-05, 3.8484e-05, 4.2072e-05,
        4.3557e-05, 2.8554e-05, 3.0038e-05, 1.7257e-05, 7.0461e-05, 2.6070e-05,
        5.6167e-05, 2.1131e-05, 7.0764e-05, 2.8994e-05, 2.4611e-05, 4.7165e-05,
        7.6457e-05, 2.5913e-05], device='cuda:0')}, 27: {'step': tensor(30200.), 'exp_avg': tensor([ 4.7264e-05,  3.1006e-05,  3.2244e-04,  5.9755e-04,  5.2006e-05,
         1.4449e-04, -2.4023e-05, -4.5737e-05, -5.3495e-05, -1.0823e-04,
        -7.1012e-04,  1.5320e-04, -1.7016e-04, -1.2973e-04,  7.8723e-05,
        -7.3775e-05,  1.2772e-04,  2.2951e-05,  6.3209e-05, -6.1886e-05,
        -6.5481e-05,  2.6797e-04, -1.9283e-05,  5.7247e-04,  2.3822e-04,
        -9.5961e-05, -3.7519e-04, -1.5073e-06, -2.9550e-05,  3.2207e-04,
        -2.8705e-04,  2.9676e-04,  6.8941e-05,  2.6624e-04,  1.3833e-04,
        -1.9143e-04, -6.8868e-05,  3.2660e-04,  1.6759e-04,  1.7727e-04,
         1.5108e-04,  6.1846e-04,  3.0745e-05,  3.0786e-05, -3.1219e-04,
         4.6719e-05,  2.4713e-04, -2.7591e-05,  2.4638e-04, -1.4761e-04,
        -1.4098e-04,  5.2702e-04,  1.0209e-04, -4.6303e-04, -1.3886e-04,
         1.1261e-04,  2.4172e-05,  2.6690e-05,  3.3073e-04, -8.6967e-05,
         9.7730e-05,  4.9719e-04,  9.1007e-05, -4.7554e-04,  7.4774e-06,
        -4.0487e-04, -4.7183e-05,  3.1365e-04,  2.5409e-04, -6.0253e-04,
         2.3692e-04,  2.1385e-04,  7.1203e-05, -1.2452e-04, -4.6301e-04,
        -1.1522e-04,  5.9337e-04,  9.0319e-05, -1.4053e-04, -1.4820e-04,
        -7.8305e-05, -4.9688e-05, -2.6186e-04,  1.0672e-04,  2.0082e-04,
        -9.3067e-05, -1.5608e-04,  9.3437e-05, -1.1899e-04, -1.7001e-04,
         5.7561e-05,  2.7312e-04,  1.8100e-04,  2.5097e-04, -5.3754e-05,
        -6.8833e-05,  1.2065e-04,  3.2105e-06,  7.7022e-05,  9.9104e-05,
        -2.9204e-04, -3.6842e-04,  5.2572e-04,  4.7302e-05, -8.8566e-05,
        -3.6339e-04,  5.8088e-05, -5.1212e-05, -4.3617e-04, -1.0187e-04,
         7.1271e-04, -3.7973e-04, -2.5728e-04, -1.4735e-04, -9.8399e-05,
         4.4697e-05, -2.0136e-04,  1.2192e-04, -1.6489e-04, -3.0833e-04,
         5.1172e-05, -7.2842e-05, -5.3799e-04, -3.6119e-04, -8.7967e-05,
        -4.3418e-04,  1.6874e-04, -3.2242e-04], device='cuda:0'), 'exp_avg_sq': tensor([2.7349e-06, 4.4891e-07, 1.9606e-06, 2.4609e-06, 1.4972e-06, 1.8966e-06,
        1.7780e-06, 2.0247e-06, 3.2109e-06, 1.5902e-06, 2.3623e-06, 1.0770e-06,
        2.2077e-06, 1.3939e-06, 1.2756e-06, 3.2470e-06, 2.0999e-06, 1.4182e-06,
        1.1396e-06, 1.0918e-06, 8.5637e-07, 2.0908e-06, 2.7920e-06, 2.2926e-06,
        1.3360e-06, 1.3433e-06, 1.6026e-06, 2.5564e-06, 1.5995e-06, 2.4305e-06,
        1.6139e-06, 1.3563e-06, 1.2975e-06, 2.7970e-06, 2.1526e-06, 1.3266e-06,
        9.2354e-07, 2.1177e-06, 1.8012e-06, 9.6760e-07, 3.2384e-06, 3.2426e-06,
        1.4677e-06, 2.0880e-06, 2.2189e-06, 2.8418e-06, 4.4438e-06, 1.8042e-06,
        1.5358e-06, 7.6917e-07, 1.5995e-06, 3.1943e-06, 2.9760e-06, 1.7371e-06,
        1.9716e-06, 1.7040e-06, 2.1155e-06, 1.5358e-06, 2.0474e-06, 5.1815e-06,
        3.8002e-06, 2.1523e-06, 9.2996e-07, 2.2900e-06, 1.1808e-06, 3.6714e-06,
        1.2144e-06, 8.4489e-07, 1.2526e-06, 2.1710e-06, 1.0598e-06, 2.3024e-06,
        2.5299e-06, 2.3303e-06, 1.6344e-06, 6.7857e-07, 2.4066e-06, 1.9244e-06,
        8.6371e-07, 1.1841e-06, 1.3008e-06, 1.1750e-06, 1.4014e-06, 3.0459e-06,
        1.7920e-06, 2.9853e-06, 1.6273e-06, 9.6719e-07, 2.5091e-06, 2.9491e-06,
        7.7208e-07, 8.8979e-07, 1.9528e-06, 1.9586e-06, 2.0424e-06, 1.4598e-06,
        2.1008e-06, 2.5261e-06, 1.2026e-06, 1.4923e-06, 1.3911e-06, 3.6800e-06,
        1.9566e-06, 1.1014e-06, 1.9148e-06, 2.4265e-06, 1.2388e-06, 1.4079e-06,
        2.0799e-06, 2.0882e-06, 2.2155e-06, 1.1463e-06, 1.2449e-06, 1.1336e-06,
        2.0048e-06, 5.3487e-07, 1.3758e-06, 2.1331e-06, 1.0491e-06, 1.6002e-06,
        1.4967e-06, 1.7207e-06, 2.4165e-06, 1.6440e-06, 1.2044e-06, 2.8099e-06,
        2.0832e-06, 1.5924e-06], device='cuda:0')}, 28: {'step': tensor(30200.), 'exp_avg': tensor([ 6.6955e-05, -2.9799e-04,  6.5338e-06,  8.3267e-05,  2.4478e-06,
        -6.7822e-05,  1.1661e-05,  1.3857e-04, -2.1426e-04, -2.3880e-04,
        -3.5340e-04, -2.7327e-04,  4.4331e-04,  6.9561e-05,  1.8094e-04,
        -2.1067e-04,  9.3575e-05, -1.4988e-04,  6.4079e-06, -2.4749e-04,
        -7.2238e-05, -3.2576e-04,  1.5022e-04,  1.9777e-04,  4.5065e-05,
         8.9030e-05,  2.4841e-04, -3.1494e-04, -5.1164e-04, -9.0503e-05,
        -2.1554e-04,  1.7165e-04, -1.8736e-04,  3.1539e-04, -8.3949e-05,
         9.2243e-05, -1.0480e-04, -3.6466e-04, -1.9269e-04,  1.1609e-04,
         1.4193e-04,  2.3315e-05,  9.5783e-05, -2.5741e-04, -2.9677e-05,
         6.9726e-05, -3.9681e-04, -2.6484e-04, -2.8430e-04,  8.0665e-05,
        -1.9453e-05,  2.2289e-04, -2.9638e-04, -1.0191e-04,  3.4583e-05,
         5.2994e-04,  2.6282e-05, -6.2839e-04, -1.6607e-04,  7.0362e-05,
        -5.3007e-04, -2.3146e-04,  2.4232e-04,  1.3920e-04, -4.3599e-04,
         1.9032e-04,  1.4332e-04,  4.4854e-05,  3.6518e-04, -1.5223e-04,
         5.2463e-05,  6.4260e-04,  1.6758e-05, -1.4473e-04,  7.3819e-04,
         2.7934e-04,  1.5139e-04, -1.9271e-04,  9.2766e-05, -1.1180e-04,
        -2.5026e-04, -1.9095e-04, -2.5363e-04,  7.0007e-05, -5.9578e-05,
         3.0396e-04,  2.4663e-04,  9.0274e-05, -1.0659e-04,  1.8972e-04,
         1.3701e-04,  7.1076e-05,  2.8971e-04,  1.9114e-05, -8.5433e-07,
         4.2779e-05,  2.2527e-04, -1.6647e-05, -4.4606e-04, -1.8010e-04,
         3.4947e-04, -2.5637e-04, -1.8828e-04,  1.5059e-04, -1.0112e-04,
        -4.7100e-04,  1.2298e-04,  5.7309e-05, -1.7751e-04, -5.1103e-04,
        -1.5119e-04,  4.8886e-05, -3.5778e-04,  1.7398e-04,  2.7234e-04,
         3.6764e-05,  1.2267e-04, -3.2757e-04, -8.1685e-05,  2.6521e-04,
        -2.3342e-04,  2.7103e-05,  1.6033e-05,  2.9358e-05, -2.0589e-04,
         8.7911e-05, -2.2983e-04, -1.4453e-04], device='cuda:0'), 'exp_avg_sq': tensor([6.3953e-06, 1.1587e-06, 2.0962e-06, 2.3603e-06, 3.5768e-06, 2.5179e-06,
        2.8592e-06, 7.1831e-06, 4.3680e-06, 2.0801e-06, 2.3698e-06, 1.8482e-06,
        2.9411e-06, 1.4237e-06, 4.4797e-06, 3.7471e-06, 3.6457e-06, 2.8969e-06,
        1.7499e-06, 1.2374e-06, 3.2666e-06, 2.1725e-06, 3.6291e-06, 1.7660e-06,
        2.4314e-06, 1.6066e-06, 3.0612e-06, 2.6384e-06, 2.2365e-06, 4.0110e-06,
        3.3593e-06, 1.1277e-06, 2.4170e-06, 4.5239e-06, 2.7289e-06, 1.3171e-06,
        1.7045e-06, 4.7415e-06, 1.9883e-06, 1.7526e-06, 5.1625e-06, 6.5805e-06,
        1.8348e-06, 4.4081e-06, 1.9591e-06, 2.4575e-06, 9.1647e-06, 2.7752e-06,
        1.4477e-06, 2.0407e-06, 2.0186e-06, 4.6171e-06, 4.9479e-06, 3.3494e-06,
        3.4540e-06, 2.0883e-06, 3.3032e-06, 1.7696e-06, 1.7242e-06, 2.9229e-06,
        7.1675e-06, 2.5789e-06, 9.5614e-07, 2.3816e-06, 2.5826e-06, 1.6369e-06,
        1.1153e-06, 1.3547e-06, 1.7268e-06, 4.2908e-06, 2.2946e-06, 2.4857e-06,
        5.8537e-06, 2.8204e-06, 3.7141e-06, 1.6576e-06, 2.5468e-06, 1.8858e-06,
        1.5216e-06, 1.6284e-06, 2.6272e-06, 2.0266e-06, 2.7708e-06, 3.4860e-06,
        2.4289e-06, 3.0233e-06, 2.8062e-06, 1.4321e-06, 4.0636e-06, 7.9729e-06,
        2.1747e-06, 2.0205e-06, 3.7449e-06, 1.5418e-06, 2.2721e-06, 2.5202e-06,
        2.6579e-06, 1.3921e-06, 2.1608e-06, 3.9175e-06, 1.9841e-06, 4.8625e-06,
        2.4878e-06, 1.3488e-06, 4.3588e-06, 2.5928e-06, 1.7115e-06, 1.9370e-06,
        3.7223e-06, 5.4106e-06, 5.3762e-06, 1.8505e-06, 1.3375e-06, 2.3747e-06,
        1.3815e-06, 1.0531e-06, 1.8986e-06, 1.7298e-06, 2.3564e-06, 1.8831e-06,
        4.0927e-06, 1.6341e-06, 2.7263e-06, 3.0556e-06, 2.1831e-06, 2.3480e-06,
        2.6179e-06, 3.7009e-06], device='cuda:0')}, 29: {'step': tensor(30200.), 'exp_avg': tensor([[ 3.0727e-04, -1.5001e-04,  5.7195e-04,  ...,  7.4580e-04,
          1.0325e-04, -3.4694e-04],
        [-1.8221e-04, -1.7776e-04, -4.0546e-04,  ...,  2.3083e-04,
         -1.4411e-04,  1.4230e-04],
        [ 5.4785e-04,  1.8468e-04,  5.7909e-04,  ...,  2.4329e-04,
         -7.8880e-05, -6.3040e-05],
        ...,
        [-2.5278e-04,  1.5329e-04, -6.5343e-04,  ..., -5.6620e-04,
         -1.7944e-04, -8.2663e-06],
        [ 1.1274e-04,  1.0694e-04,  1.8436e-04,  ..., -2.2709e-04,
         -3.3773e-04,  1.4796e-04],
        [-4.1628e-04, -4.8346e-05, -2.8180e-04,  ..., -4.3680e-04,
          1.2512e-04,  3.5928e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[1.4283e-06, 8.8147e-07, 2.3347e-06,  ..., 1.9257e-06, 1.4509e-06,
         1.1830e-06],
        [3.5135e-06, 1.1549e-06, 4.0089e-06,  ..., 5.7231e-06, 2.5677e-06,
         3.3308e-06],
        [2.0820e-06, 7.6358e-07, 4.5913e-06,  ..., 6.8794e-06, 3.2747e-06,
         2.1384e-06],
        ...,
        [1.9094e-06, 7.7022e-07, 2.2004e-06,  ..., 2.0052e-06, 1.2876e-06,
         1.3785e-06],
        [2.0647e-06, 9.7646e-07, 3.7380e-06,  ..., 4.7566e-06, 5.1419e-06,
         2.5801e-06],
        [1.1908e-06, 6.6982e-07, 2.7831e-06,  ..., 2.8476e-06, 1.2242e-06,
         1.0759e-06]], device='cuda:0')}, 30: {'step': tensor(30200.), 'exp_avg': tensor([-4.0282e-04, -3.2891e-06, -7.3371e-04, -8.0042e-05, -1.2861e-04,
         4.3947e-05, -8.4447e-05, -2.8465e-04, -1.1383e-04,  1.0109e-04,
         2.3862e-04, -2.7476e-04,  1.5767e-04, -3.1181e-04,  1.2825e-04,
        -7.7890e-05,  3.3315e-04,  2.9370e-04,  1.6473e-04, -1.6463e-05,
         2.4506e-04,  3.1492e-05,  4.5008e-04, -2.8783e-04,  1.0086e-04,
         3.4687e-04,  1.0957e-04, -8.1133e-05, -1.3207e-05, -2.8065e-04,
         2.6094e-04,  2.2194e-05,  2.9783e-04,  9.2857e-05,  2.7985e-05,
        -3.4647e-05, -1.5503e-04,  4.1807e-04, -1.6599e-04,  2.4203e-05,
        -2.4800e-04,  1.1675e-04,  2.8870e-05, -4.4588e-04, -9.2328e-05,
        -1.6702e-04, -4.1828e-04,  1.4122e-04,  1.3155e-04,  8.3335e-05,
        -3.1532e-04,  1.7393e-04,  1.5543e-04, -1.3737e-04, -3.2763e-04,
         7.6875e-05, -1.2498e-04,  1.9815e-04,  2.7435e-04, -1.3172e-04,
        -4.6500e-04,  8.9942e-05,  1.3474e-04,  7.2969e-06,  1.5428e-04,
        -2.7236e-05,  6.5807e-04, -3.0465e-04, -2.5560e-04,  3.4301e-05,
         5.9870e-05,  1.1823e-04,  2.1785e-04, -3.9307e-04,  1.6594e-04,
         5.7255e-04, -1.7842e-04, -4.6046e-05, -4.6558e-04,  6.2998e-04,
         9.3662e-06, -1.5466e-04, -1.2063e-04,  4.6708e-04,  7.8176e-04,
         1.4314e-04, -3.9598e-04,  7.0434e-05, -2.7955e-04,  2.3556e-04,
        -8.7666e-05, -1.9057e-04, -1.5217e-04,  2.7851e-05,  1.6383e-04,
        -1.1255e-04, -3.8128e-04,  1.5970e-04,  2.5329e-04,  3.4150e-04,
        -6.5675e-05, -2.9532e-04,  9.8512e-05,  4.2117e-05, -2.6127e-04,
        -2.2806e-04,  1.9191e-04, -2.6861e-04, -3.5309e-04,  6.9728e-05,
        -1.3670e-04,  6.8195e-04, -3.2849e-04,  1.6827e-04,  1.5408e-04,
         1.2727e-04,  1.6616e-04, -5.4232e-04, -2.7867e-05, -6.0337e-05,
        -2.7887e-04,  6.4067e-05, -2.7978e-04,  5.2507e-05,  5.2198e-05,
         2.7442e-04, -9.9926e-05,  3.0968e-04,  3.1036e-04,  1.7404e-04,
        -5.8428e-04,  8.6856e-04,  3.0908e-05, -2.9829e-04,  9.8216e-05,
         3.8896e-04, -1.3682e-04,  5.8391e-05,  2.6135e-04, -1.0624e-04,
         5.1687e-04,  2.2375e-04,  1.5151e-04,  8.9962e-05,  1.4617e-04,
        -5.5506e-06, -1.8340e-04,  3.6199e-04, -1.8535e-04,  4.6543e-04,
        -1.2972e-04,  9.9020e-05,  3.1088e-05, -1.3774e-04,  5.3882e-05,
        -2.7462e-04, -5.6019e-04,  3.7745e-05, -2.7339e-04, -2.7269e-04,
         4.7772e-05, -3.8557e-04, -3.4999e-04,  6.4677e-05,  5.2506e-04,
        -7.9439e-05, -2.5666e-05, -2.7833e-05,  8.4852e-05, -2.2275e-05,
        -9.4140e-05, -1.1975e-04, -1.0883e-04,  4.7920e-05, -2.7084e-04,
        -9.7523e-05,  3.8879e-04, -9.4665e-05,  1.7979e-04,  3.2097e-04,
        -5.9530e-05,  1.4866e-04,  1.1362e-04, -6.6768e-05, -1.5908e-05,
        -6.0053e-05, -5.5239e-05,  3.0947e-05, -1.0311e-04, -1.4926e-04,
         4.2110e-04,  2.4346e-04,  5.3800e-05, -1.0704e-04, -1.6166e-04,
        -2.0626e-05,  2.5059e-04,  1.1384e-04, -4.9173e-04, -4.6786e-05,
         2.5415e-04,  1.0353e-04,  4.2158e-04,  1.5459e-04, -5.4307e-05,
        -5.1334e-05, -4.9869e-05,  4.5342e-04,  4.4421e-04,  1.1953e-04,
        -1.9692e-04,  2.4045e-04,  1.7331e-04, -7.5148e-06, -8.4255e-05,
         3.6457e-05,  3.8094e-04, -7.8635e-05, -2.4998e-04,  4.9440e-04,
         2.4349e-04, -1.0101e-04, -7.1889e-05, -8.8282e-05, -3.7247e-05,
         3.0962e-04, -1.2812e-04, -5.8028e-04, -8.6831e-05, -2.0545e-04,
         4.3631e-05,  1.2863e-04, -1.7651e-04,  8.2174e-04,  4.2489e-05,
         4.9449e-04,  2.2064e-04, -8.8863e-05, -2.4556e-04, -1.1651e-05,
         1.0816e-04,  1.8469e-04,  3.0188e-04,  9.4172e-04,  6.0849e-04,
        -2.1580e-04, -1.7983e-05,  1.3479e-04,  1.5521e-04, -8.1563e-05,
         1.5974e-04,  1.2725e-04, -1.2581e-04, -1.4749e-04, -5.3128e-04,
        -2.9749e-05], device='cuda:0'), 'exp_avg_sq': tensor([2.5154e-06, 3.3197e-06, 3.1634e-06, 5.8035e-07, 4.6227e-06, 1.7603e-06,
        1.7230e-06, 3.4108e-06, 1.8189e-06, 1.8584e-06, 2.7839e-06, 2.0149e-06,
        2.0325e-06, 1.4159e-06, 2.3362e-06, 2.4326e-06, 2.4916e-06, 3.3107e-06,
        1.8941e-06, 2.7776e-06, 1.9835e-06, 2.6215e-06, 2.9978e-06, 2.3217e-06,
        1.9253e-06, 1.0045e-06, 2.6737e-06, 1.0114e-06, 2.9757e-06, 1.6627e-06,
        2.8850e-06, 2.5856e-06, 3.7815e-06, 3.0341e-06, 1.5981e-06, 2.6213e-06,
        3.6864e-06, 6.5212e-06, 1.5684e-06, 2.2519e-06, 2.6725e-06, 1.6348e-06,
        3.1333e-06, 2.9658e-06, 1.6835e-06, 4.1822e-06, 2.6521e-06, 3.3029e-06,
        1.6281e-06, 3.0425e-06, 1.1411e-06, 2.4123e-06, 2.8290e-06, 1.5773e-06,
        2.4826e-06, 2.7347e-06, 1.9821e-06, 2.8859e-06, 5.0205e-06, 1.7082e-06,
        2.8285e-06, 1.3992e-06, 1.6318e-06, 2.0934e-06, 1.8159e-06, 1.3757e-06,
        3.9366e-06, 1.2795e-06, 1.9333e-06, 1.6976e-06, 3.0181e-06, 1.8174e-06,
        1.9463e-06, 2.6236e-06, 1.7848e-06, 6.4809e-06, 2.1379e-06, 1.8814e-06,
        7.4191e-06, 5.7828e-06, 3.0632e-06, 1.9196e-06, 1.0264e-06, 3.6077e-06,
        5.1859e-06, 1.0856e-06, 1.5254e-06, 1.0462e-06, 2.5129e-06, 2.5119e-06,
        2.8713e-06, 2.2210e-06, 4.2671e-06, 2.5712e-06, 1.7108e-06, 1.6413e-06,
        8.4095e-07, 2.0658e-06, 2.0889e-06, 1.1543e-06, 1.1060e-06, 2.8656e-06,
        1.7268e-06, 3.9315e-06, 1.5889e-06, 2.2687e-06, 1.8424e-06, 2.3454e-06,
        1.7750e-06, 1.2617e-06, 1.6800e-06, 1.7703e-06, 3.9882e-06, 3.1709e-06,
        1.0550e-06, 2.8655e-06, 3.1923e-06, 2.6985e-06, 2.0410e-06, 1.2295e-06,
        4.2220e-06, 1.8057e-06, 2.1706e-06, 1.7543e-06, 2.0388e-06, 2.9095e-06,
        3.4869e-06, 2.2462e-06, 1.2116e-06, 1.8914e-06, 2.2904e-06, 2.1664e-06,
        2.2025e-06, 8.0791e-06, 1.9921e-06, 2.3104e-06, 1.5572e-06, 1.4642e-06,
        1.8839e-06, 2.1665e-06, 3.0483e-06, 2.3600e-06, 1.4528e-06, 1.1448e-06,
        9.1780e-07, 8.6852e-07, 3.1243e-06, 4.4584e-06, 1.2972e-06, 4.3864e-06,
        4.6428e-06, 2.1060e-06, 2.5135e-06, 1.4873e-06, 1.5689e-06, 2.5276e-06,
        2.4067e-06, 4.2974e-06, 1.4233e-06, 3.2033e-06, 9.4305e-07, 1.6682e-06,
        3.0395e-06, 2.3827e-06, 6.1017e-06, 2.4176e-06, 8.2545e-07, 1.7654e-06,
        3.8078e-06, 9.5219e-07, 2.3143e-06, 1.4132e-06, 2.3210e-06, 2.5781e-06,
        2.4484e-06, 2.0478e-06, 1.2009e-06, 2.0954e-06, 2.6236e-06, 1.0095e-06,
        1.9132e-06, 3.4963e-06, 1.8698e-06, 1.4500e-06, 1.6888e-06, 2.2051e-06,
        1.8667e-06, 1.5318e-06, 1.7959e-06, 1.0845e-06, 7.1748e-06, 7.4770e-07,
        2.1954e-06, 1.4500e-06, 1.7503e-06, 2.2208e-06, 3.8402e-06, 2.4734e-06,
        1.6254e-06, 1.3270e-06, 2.8968e-06, 1.7781e-06, 2.9507e-06, 5.0677e-06,
        1.9748e-06, 1.9216e-06, 2.0483e-06, 1.7415e-06, 7.4503e-07, 2.9811e-06,
        1.8930e-06, 1.3797e-06, 2.2426e-06, 3.2208e-06, 3.0154e-06, 2.2868e-06,
        3.7451e-06, 1.2730e-06, 1.7058e-06, 4.8261e-06, 1.8860e-06, 2.1741e-06,
        3.8418e-06, 1.3129e-06, 2.9379e-06, 4.5757e-06, 1.4298e-06, 4.0801e-06,
        1.9142e-06, 3.4197e-06, 1.8355e-06, 5.5854e-06, 2.9977e-06, 3.6957e-06,
        1.5975e-06, 2.8067e-06, 3.7521e-06, 1.4326e-06, 2.2140e-06, 3.0419e-06,
        1.8605e-06, 1.2807e-06, 2.1137e-06, 2.9038e-06, 1.8199e-06, 2.7054e-06,
        9.4332e-07, 1.2625e-06, 1.4994e-06, 1.2104e-06, 7.0311e-07, 8.2693e-06,
        3.7443e-06, 2.7154e-06, 3.6108e-06, 1.9061e-06], device='cuda:0')}, 31: {'step': tensor(30200.), 'exp_avg': tensor([[-9.5016e-05, -2.8333e-04,  1.6898e-04,  ...,  2.2427e-04,
          1.5414e-04,  3.0001e-04],
        [-1.9089e-04, -1.5102e-04,  5.3943e-04,  ..., -3.8177e-04,
         -4.9412e-05,  1.8343e-04],
        [ 7.0425e-05, -2.3289e-04,  1.3893e-03,  ..., -1.5775e-04,
          6.4055e-04,  7.3592e-04],
        ...,
        [ 2.7375e-04, -3.4339e-04, -6.5531e-04,  ...,  1.4034e-04,
          3.6987e-05, -3.3648e-07],
        [-1.4282e-04, -2.3138e-04, -7.9491e-04,  ...,  3.4306e-04,
          2.6001e-04, -1.0253e-04],
        [-2.6710e-04,  1.7794e-04,  5.4727e-04,  ..., -5.6174e-04,
         -1.3850e-04,  2.2808e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[1.5691e-06, 6.0344e-06, 4.8665e-06,  ..., 2.1145e-06, 2.8399e-06,
         1.1338e-06],
        [1.2428e-06, 3.9963e-06, 5.3752e-06,  ..., 2.5321e-06, 3.4553e-06,
         1.2959e-06],
        [1.9286e-06, 4.6947e-06, 6.5205e-06,  ..., 3.0614e-06, 4.7715e-06,
         1.2071e-06],
        ...,
        [1.8966e-06, 3.4025e-06, 5.2232e-06,  ..., 2.9534e-06, 3.8853e-06,
         1.2637e-06],
        [2.0336e-06, 6.3457e-06, 8.2005e-06,  ..., 3.2883e-06, 4.0727e-06,
         1.4146e-06],
        [1.7881e-06, 4.2124e-06, 7.6332e-06,  ..., 3.4745e-06, 4.6570e-06,
         1.0969e-06]], device='cuda:0')}, 32: {'step': tensor(30200.), 'exp_avg': tensor([ 6.3471e-05,  3.0682e-04,  1.1049e-03,  1.1765e-03, -1.1855e-04,
         2.4664e-04,  9.8924e-06,  8.6872e-04, -6.3493e-04, -4.8417e-04,
         3.2033e-04,  1.1285e-04,  2.5014e-04,  1.0237e-03,  8.4872e-04,
         1.7197e-03, -1.3894e-04, -6.7382e-04,  4.1509e-04,  8.1251e-04,
         3.9654e-04, -6.6158e-04,  7.2817e-04,  9.6471e-04, -5.4168e-04,
         8.7067e-04, -1.4794e-03, -7.6156e-04,  1.2014e-03, -1.0757e-03,
        -4.3042e-04,  2.5379e-04, -1.1861e-03,  1.0688e-03, -8.3136e-06,
         1.7227e-04, -7.0715e-04,  1.6561e-03, -6.9397e-05,  3.1346e-04,
         9.6886e-04, -8.0102e-05, -4.5167e-04,  1.2648e-03,  5.6473e-04,
        -3.5026e-04,  7.9723e-04,  3.6207e-04, -8.4057e-04,  7.8174e-04,
         4.0860e-06,  5.9400e-04, -1.0752e-03,  5.5719e-04, -1.1353e-04,
         4.1389e-04,  1.3466e-03,  1.4697e-04,  3.8800e-05, -1.4307e-03,
        -1.0498e-03, -3.4033e-04,  1.0186e-03, -1.1060e-03, -7.3773e-04,
        -1.2373e-03, -1.1801e-03,  5.6041e-04, -1.3537e-03,  1.2319e-03,
         1.7355e-04, -1.4340e-03, -1.2128e-03, -5.4353e-04, -1.4480e-03,
        -1.6961e-03,  1.0686e-04,  1.0111e-03,  9.2797e-04,  1.5607e-03,
        -4.3259e-04, -1.0078e-03, -3.8163e-04,  6.1924e-04,  7.8440e-04,
        -7.0158e-04,  7.9020e-05, -9.4277e-04,  5.4597e-04, -1.2620e-03,
         6.4395e-04, -1.0062e-03, -4.1661e-04,  1.5428e-04,  2.6442e-04,
         3.2172e-04,  2.1181e-04,  2.3340e-04, -1.2691e-03, -7.6991e-04,
         4.4279e-04, -9.5799e-04,  4.8205e-04,  5.0389e-04, -9.6817e-06,
         1.1229e-03,  8.9328e-05,  4.2848e-04, -2.8581e-04, -1.5383e-03,
         2.8986e-04,  1.7343e-04,  1.1881e-04,  5.7595e-05,  1.5112e-03,
         3.2847e-04, -3.3023e-04, -4.6643e-04, -2.1850e-03,  1.2240e-03,
        -8.4481e-04, -5.7463e-04, -1.3166e-03,  1.1885e-04, -7.8477e-04,
        -8.8285e-04, -1.7632e-03, -3.0306e-05], device='cuda:0'), 'exp_avg_sq': tensor([2.1638e-05, 2.9292e-05, 3.3943e-05, 4.2119e-05, 2.0460e-05, 2.1762e-05,
        2.4892e-05, 3.3273e-05, 3.3895e-05, 2.5658e-05, 3.4821e-05, 2.0079e-05,
        6.6710e-05, 3.9279e-05, 2.7236e-05, 3.8063e-05, 3.8743e-05, 4.7790e-05,
        2.6039e-05, 2.5421e-05, 4.1371e-05, 4.0206e-05, 3.5550e-05, 2.9077e-05,
        4.0534e-05, 3.3501e-05, 2.0899e-05, 2.7423e-05, 2.2102e-05, 4.9274e-05,
        2.2300e-05, 3.9975e-05, 1.8698e-05, 3.0951e-05, 5.2328e-05, 4.3522e-05,
        1.9806e-05, 4.6691e-05, 1.7820e-05, 5.6317e-05, 4.0767e-05, 2.4032e-05,
        1.6447e-05, 2.5665e-05, 4.6601e-05, 3.8551e-05, 3.5037e-05, 2.5297e-05,
        2.1563e-05, 2.7074e-05, 3.9376e-05, 5.2279e-05, 7.9166e-05, 4.3860e-05,
        5.0201e-05, 4.0633e-05, 4.6506e-05, 2.8764e-05, 3.8154e-05, 2.4552e-05,
        3.7349e-05, 2.7231e-05, 2.5700e-05, 2.4257e-05, 2.5638e-05, 3.0219e-05,
        2.7419e-05, 3.2943e-05, 1.7384e-05, 3.3144e-05, 3.7942e-05, 3.0714e-05,
        5.0124e-05, 3.3866e-05, 2.9009e-05, 2.7918e-05, 1.8076e-05, 4.0284e-05,
        1.4811e-05, 2.5740e-05, 3.5073e-05, 6.0051e-05, 2.8137e-05, 5.2508e-05,
        2.8683e-05, 6.9962e-05, 2.8563e-05, 3.2750e-05, 4.2298e-05, 2.9507e-05,
        2.9078e-05, 2.3034e-05, 4.2808e-05, 1.3696e-05, 3.5529e-05, 1.7936e-05,
        1.4801e-05, 5.2844e-05, 2.6147e-05, 2.3853e-05, 1.6334e-05, 3.4287e-05,
        4.1150e-05, 2.4818e-05, 6.6025e-05, 1.9592e-05, 1.9264e-05, 1.8821e-05,
        2.6436e-05, 3.6939e-05, 3.2989e-05, 2.7929e-05, 3.5437e-05, 3.3676e-05,
        4.1751e-05, 2.9913e-05, 2.7531e-05, 1.7659e-05, 5.8539e-05, 2.5681e-05,
        3.7968e-05, 1.7966e-05, 5.7144e-05, 2.6078e-05, 2.0199e-05, 4.8548e-05,
        6.1221e-05, 1.9733e-05], device='cuda:0')}, 33: {'step': tensor(30200.), 'exp_avg': tensor([-3.5772e-04, -1.9697e-04, -2.5572e-04, -6.3883e-04,  2.8637e-05,
        -2.1223e-04, -2.7070e-04,  3.4562e-04,  1.2988e-04,  6.1976e-04,
        -6.8625e-05,  1.9939e-04,  2.9287e-04, -5.5001e-04, -9.6681e-05,
         4.1659e-04, -3.0306e-04, -7.2996e-04,  1.5465e-04, -8.8650e-05,
        -2.7336e-04, -1.4379e-04, -1.0065e-03,  4.9634e-05,  5.1990e-05,
        -8.2267e-04,  3.4125e-04,  4.6352e-04, -2.5844e-04,  7.4998e-05,
        -1.1727e-03,  1.8640e-04,  9.2484e-05, -2.6723e-04,  9.7031e-04,
         2.8284e-04,  3.5160e-04,  9.4995e-05,  1.3466e-04,  1.5652e-04,
        -4.1408e-04, -6.7373e-04, -4.6031e-04, -2.1672e-04,  2.6159e-04,
        -1.0492e-03,  4.0774e-05, -5.3295e-04,  1.1114e-04, -9.5393e-05,
         5.2653e-04, -1.8450e-04,  4.6714e-04, -1.0750e-03,  4.3529e-04,
        -3.9118e-04, -1.0299e-03, -3.3519e-05, -4.0890e-04, -1.5118e-03,
        -3.5327e-04,  3.7697e-04, -1.3378e-04,  2.2320e-04, -1.5831e-04,
        -9.3680e-04,  2.3748e-04,  1.5949e-04,  2.7976e-04, -7.3509e-05,
        -3.3785e-04,  7.1787e-06,  5.2550e-04,  1.2973e-04, -3.7975e-04,
         7.9502e-04,  3.6513e-04, -2.1922e-04, -4.6652e-04,  2.7671e-04,
         4.0218e-05, -6.5762e-04, -4.9036e-04,  4.4117e-05, -4.3952e-05,
        -2.5014e-04, -6.5369e-04, -1.0467e-03, -1.8994e-04, -7.4822e-05,
         8.7159e-05, -2.8312e-04, -5.8850e-04, -1.2863e-04, -6.6788e-04,
        -1.6515e-04, -1.7634e-04, -5.8598e-04, -3.0828e-04,  2.5036e-04,
         6.1300e-04, -5.9427e-04,  9.2833e-05, -4.8948e-04, -9.9376e-04,
        -5.9273e-04, -1.1055e-04,  2.3030e-04, -4.9660e-05, -1.0900e-03,
         5.5934e-04, -3.5341e-04, -7.2189e-05,  9.3581e-05, -4.0742e-04,
        -1.4511e-04,  2.1571e-04,  4.1879e-05, -1.2962e-03,  1.2489e-04,
         6.2975e-06, -1.0196e-04, -7.4776e-04,  3.5279e-04, -6.3755e-04,
        -4.0943e-04, -4.2476e-04, -3.5499e-04], device='cuda:0'), 'exp_avg_sq': tensor([5.8377e-06, 2.8200e-06, 6.4582e-06, 7.3468e-06, 2.2500e-06, 4.0199e-06,
        5.1356e-06, 5.3134e-06, 1.5027e-05, 3.7194e-06, 4.7294e-06, 3.9160e-06,
        6.1352e-06, 1.0078e-05, 4.0314e-06, 8.9680e-06, 2.1592e-05, 6.4740e-06,
        4.7750e-06, 5.8308e-06, 3.2566e-06, 7.6044e-06, 9.4659e-06, 1.0474e-05,
        6.0663e-06, 7.4078e-06, 2.9089e-06, 1.0917e-05, 5.6824e-06, 4.7961e-06,
        4.0098e-06, 5.6840e-06, 3.4847e-06, 5.6688e-06, 1.7537e-05, 4.7768e-06,
        3.8209e-06, 1.0140e-05, 3.5958e-06, 5.2175e-06, 4.6931e-06, 7.0081e-06,
        2.8307e-06, 5.1603e-06, 1.1661e-05, 7.4688e-06, 4.9705e-06, 3.9436e-06,
        5.5912e-06, 3.2802e-06, 1.2698e-05, 5.4468e-06, 1.0639e-05, 1.1148e-05,
        9.3462e-06, 6.4095e-06, 5.1404e-06, 7.8644e-06, 1.0193e-05, 1.1628e-05,
        6.4072e-06, 6.0264e-06, 4.8767e-06, 3.4388e-06, 2.9663e-06, 9.5942e-06,
        5.0547e-06, 9.1521e-06, 2.9766e-06, 4.1663e-06, 3.8061e-06, 5.0120e-06,
        5.4799e-06, 3.2325e-06, 3.5574e-06, 3.0941e-06, 4.1409e-06, 5.1111e-06,
        3.4256e-06, 3.3042e-06, 9.8219e-06, 5.1600e-06, 5.6179e-06, 1.0048e-05,
        3.4561e-06, 9.2865e-06, 3.8189e-06, 4.8036e-06, 1.3639e-05, 8.9241e-06,
        3.7646e-06, 1.1094e-05, 9.9811e-06, 1.1954e-05, 4.6117e-06, 6.9484e-06,
        4.4139e-06, 2.5939e-05, 7.7997e-06, 3.2012e-06, 3.1295e-06, 3.6602e-06,
        6.4268e-06, 5.7683e-06, 2.2294e-05, 3.6099e-06, 5.7608e-06, 3.2234e-06,
        3.5722e-06, 8.9049e-06, 4.4990e-06, 4.1366e-06, 5.5907e-06, 3.6796e-06,
        4.1205e-06, 2.5952e-06, 4.3714e-06, 5.9801e-06, 6.8951e-06, 7.5470e-06,
        7.1384e-06, 1.2395e-05, 2.1680e-05, 5.9986e-06, 4.1939e-06, 6.8234e-06,
        1.1814e-05, 7.0914e-06], device='cuda:0')}, 34: {'step': tensor(30200.), 'exp_avg': tensor([ 3.7108e-04, -4.2968e-04,  6.4322e-04,  1.5980e-04,  2.0790e-04,
         1.5421e-04, -6.8210e-04,  3.3375e-04, -3.8115e-04, -6.4131e-04,
        -9.7689e-05, -3.8004e-04,  2.5121e-04,  7.3242e-05,  5.6405e-04,
        -1.0028e-05,  1.4761e-04, -5.4377e-04,  1.7265e-04,  7.8754e-04,
         1.1119e-04, -5.7360e-04,  3.5915e-04,  3.9179e-04, -2.5033e-04,
         2.2875e-04, -2.6996e-04, -4.9739e-04, -5.6710e-04, -4.5581e-04,
        -1.0409e-03,  6.2261e-04, -5.6883e-04,  5.6107e-04,  4.0094e-05,
        -6.6352e-05,  1.5278e-04,  6.1357e-04,  1.3498e-04, -4.0119e-04,
         6.3982e-04,  3.3244e-05, -7.2182e-04,  1.9626e-05,  9.8462e-05,
         7.3365e-04, -1.2185e-04,  8.9301e-06, -7.2776e-04, -3.5171e-04,
         5.9095e-04,  5.1829e-04,  2.6395e-05,  8.7005e-04, -2.0301e-04,
        -2.3109e-04,  4.1578e-04,  3.8038e-04,  1.6154e-04, -5.9652e-04,
         7.0921e-04,  2.5824e-04,  4.6542e-04, -5.8864e-04, -3.6545e-04,
         1.2639e-05,  4.9722e-04,  5.9709e-05, -2.7009e-04,  4.3219e-04,
        -5.1091e-05, -5.9122e-04, -5.3550e-04, -2.9709e-04, -5.7353e-04,
        -6.0845e-04,  6.8820e-05,  6.2376e-04, -1.6126e-04,  2.9483e-04,
        -5.5098e-04, -4.9000e-04, -9.9475e-05,  2.2621e-04, -5.2321e-06,
        -1.2093e-04,  1.1364e-04, -8.7195e-04, -7.8405e-05,  5.6013e-05,
        -1.3333e-04, -2.0504e-06, -2.4174e-04, -2.3394e-06, -5.5491e-04,
        -2.2760e-04,  3.7017e-04, -4.2423e-04, -9.3367e-04, -8.4228e-04,
        -7.7668e-06, -1.0588e-04,  4.0587e-04, -1.4682e-05, -3.0812e-04,
         5.6160e-06,  4.8717e-04,  2.2324e-04,  7.2904e-05, -4.9198e-04,
        -7.1489e-04,  3.8404e-04, -4.9795e-04,  7.3491e-05,  1.7237e-04,
         3.4513e-05,  3.1029e-05, -1.5701e-04, -6.6470e-04,  3.8341e-04,
        -6.2792e-04, -3.4527e-04, -1.0218e-04, -6.9149e-05,  1.2803e-04,
        -2.1750e-04,  7.1519e-05,  5.0301e-04], device='cuda:0'), 'exp_avg_sq': tensor([7.3152e-06, 7.5525e-06, 7.0516e-06, 9.4027e-06, 1.0491e-05, 6.7059e-06,
        1.4357e-05, 6.0077e-06, 1.9125e-05, 1.1381e-05, 6.6348e-06, 1.1907e-05,
        6.9998e-06, 7.4582e-06, 1.3228e-05, 1.0042e-05, 2.5012e-05, 1.3990e-05,
        4.6903e-06, 1.0601e-05, 3.3733e-06, 6.3130e-06, 9.8151e-06, 6.9808e-06,
        6.8363e-06, 1.6754e-05, 5.4325e-06, 1.1518e-05, 4.0641e-06, 1.2434e-05,
        1.0147e-05, 8.7083e-06, 1.3876e-05, 4.1500e-06, 2.9847e-05, 1.1149e-05,
        6.3613e-06, 2.8987e-05, 5.5633e-06, 1.1486e-05, 9.5166e-06, 7.0481e-06,
        5.3524e-06, 1.1686e-05, 8.6432e-06, 6.5001e-06, 4.1082e-06, 1.0251e-05,
        5.7153e-06, 3.5738e-06, 1.1665e-05, 1.5358e-05, 3.1501e-05, 1.4113e-05,
        1.9461e-05, 3.7700e-06, 1.0059e-05, 9.2366e-06, 2.0065e-05, 4.8763e-06,
        1.3315e-05, 3.6247e-06, 8.5423e-06, 5.8422e-06, 5.9859e-06, 7.5429e-06,
        5.8820e-06, 5.6802e-06, 5.7628e-06, 7.8151e-06, 1.0835e-05, 8.9105e-06,
        1.2258e-05, 5.8804e-06, 1.0304e-05, 1.1441e-05, 1.0880e-05, 7.0000e-06,
        6.0834e-06, 9.7374e-06, 1.4772e-05, 1.2219e-05, 9.0151e-06, 1.1637e-05,
        6.1563e-06, 2.0509e-05, 9.1092e-06, 6.2773e-06, 1.4879e-05, 6.7469e-06,
        1.3419e-05, 2.5026e-05, 1.4308e-05, 5.0322e-06, 7.9250e-06, 9.6905e-06,
        8.7101e-06, 8.3268e-06, 1.7037e-05, 6.0388e-06, 8.4419e-06, 8.4103e-06,
        1.2136e-05, 1.2930e-05, 1.5789e-05, 5.7919e-06, 8.0855e-06, 7.3303e-06,
        5.9064e-06, 6.5796e-06, 5.3975e-06, 8.7941e-06, 1.2077e-05, 1.5028e-05,
        3.0692e-06, 1.0065e-05, 8.6823e-06, 6.2388e-06, 7.0716e-06, 5.2341e-06,
        7.7669e-06, 1.0986e-05, 1.6361e-05, 8.8066e-06, 1.0787e-05, 8.0726e-06,
        1.9160e-05, 5.5770e-06], device='cuda:0')}, 35: {'step': tensor(30200.), 'exp_avg': tensor([[ 1.2992e-04,  3.2275e-05,  2.4028e-04,  ...,  9.6205e-05,
          7.8656e-05, -1.2678e-04],
        [ 1.7169e-04,  1.3379e-04,  2.7831e-04,  ...,  7.0275e-05,
         -5.7932e-05, -1.8023e-04],
        [-2.4222e-06, -7.8654e-06, -3.4607e-05,  ..., -9.2695e-05,
          1.1836e-04,  1.3644e-04],
        ...,
        [ 3.6793e-04,  1.4346e-04,  2.8974e-05,  ...,  2.0646e-04,
          6.2306e-05,  1.6410e-04],
        [-1.7036e-05, -5.3141e-04, -5.7142e-04,  ..., -1.6768e-05,
         -2.9378e-04, -4.1972e-04],
        [ 4.4159e-06, -3.1552e-04, -1.5703e-05,  ..., -1.6266e-05,
          3.7020e-04, -1.8313e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[3.4992e-07, 1.3953e-07, 3.9908e-07,  ..., 4.3491e-07, 3.9105e-07,
         3.1905e-07],
        [8.9892e-07, 3.5706e-07, 1.2284e-06,  ..., 1.6981e-06, 7.5651e-07,
         6.1170e-07],
        [4.1095e-07, 1.5146e-07, 3.4815e-07,  ..., 3.5351e-07, 3.6425e-07,
         3.2536e-07],
        ...,
        [2.6970e-06, 1.1991e-06, 3.9779e-06,  ..., 2.3984e-06, 3.0838e-06,
         1.8790e-06],
        [1.8942e-06, 7.4322e-07, 2.2729e-06,  ..., 1.4488e-06, 2.0001e-06,
         1.1075e-06],
        [3.6426e-06, 1.9035e-06, 5.0194e-06,  ..., 3.3015e-06, 4.5291e-06,
         2.7385e-06]], device='cuda:0')}, 36: {'step': tensor(30200.), 'exp_avg': tensor([[-3.9516e-04, -1.0002e-04,  6.8339e-04,  ...,  1.8921e-05,
         -4.0544e-04, -4.9321e-04],
        [ 1.0324e-03,  5.4832e-05, -3.7140e-04,  ..., -3.1622e-04,
         -4.4767e-04, -2.1830e-04],
        [ 7.5839e-04,  1.1580e-04, -2.5256e-04,  ...,  5.5729e-04,
         -3.3972e-04,  2.7431e-04],
        ...,
        [-5.5250e-04, -7.3949e-04,  7.0841e-04,  ..., -5.1842e-04,
         -1.4524e-04,  9.7164e-04],
        [-5.7907e-04,  1.0979e-04,  3.1461e-04,  ...,  5.5816e-05,
         -4.7002e-04,  1.0240e-03],
        [ 9.9863e-04, -2.8676e-04, -1.0349e-03,  ...,  4.7255e-04,
         -4.7590e-05,  6.2567e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[5.4889e-06, 3.4394e-06, 4.2455e-06,  ..., 5.6096e-06, 4.1254e-06,
         3.7952e-06],
        [5.6892e-06, 3.3951e-06, 5.1479e-06,  ..., 3.9101e-06, 3.1975e-06,
         3.4361e-06],
        [6.1653e-06, 3.9711e-06, 5.5911e-06,  ..., 6.3107e-06, 3.6318e-06,
         4.4975e-06],
        ...,
        [8.1875e-06, 5.4681e-06, 6.6650e-06,  ..., 7.3464e-06, 5.4032e-06,
         5.0025e-06],
        [5.2560e-06, 3.9106e-06, 4.7082e-06,  ..., 5.5435e-06, 4.5808e-06,
         3.9588e-06],
        [5.1741e-06, 2.7663e-06, 3.7175e-06,  ..., 4.4829e-06, 3.0391e-06,
         3.0538e-06]], device='cuda:0')}, 37: {'step': tensor(30200.), 'exp_avg': tensor([-2.3041e-05,  8.1407e-04, -2.1910e-04,  3.7763e-04, -8.6075e-04,
         5.2848e-05,  1.0289e-03,  5.7735e-04,  4.2162e-04,  3.0198e-04,
         1.7954e-04,  9.4472e-04,  4.4441e-06,  2.0314e-04, -5.5308e-05,
         1.3256e-03, -1.7787e-05,  6.5359e-05, -5.4769e-05,  5.7274e-04,
         5.3583e-05,  3.5924e-04,  4.5641e-04,  8.5829e-04, -9.1418e-04,
         3.3256e-04, -9.4060e-04, -5.4844e-04,  1.4758e-03,  1.3532e-04,
         3.5141e-04, -5.7044e-04, -5.7139e-05,  1.5131e-04, -5.2133e-04,
        -3.0555e-04, -7.2714e-04,  6.5950e-04, -1.1294e-04,  7.2568e-04,
         8.4517e-04,  3.6978e-04, -4.9492e-04,  1.1995e-03,  7.6453e-04,
        -1.1589e-03,  9.8128e-04,  3.2179e-04,  6.1063e-05,  1.1061e-03,
        -9.4644e-05, -3.5104e-04,  6.8277e-04, -5.1175e-04, -2.1985e-04,
         5.5891e-04,  8.7368e-04, -7.6077e-04,  7.0928e-05, -9.4595e-04,
        -1.0587e-03, -2.8524e-04,  2.1185e-04, -3.2124e-04, -7.6637e-04,
        -1.9444e-04, -6.9012e-04,  6.6983e-04, -1.6752e-03,  1.8065e-04,
         6.9359e-05, -5.3939e-04, -7.4038e-04,  4.3457e-05, -1.2241e-03,
        -9.6164e-04,  1.8257e-05, -3.9060e-05,  3.5221e-04,  1.0113e-03,
         1.6802e-04, -3.5058e-04, -1.8806e-04,  1.3150e-04,  8.0585e-04,
        -7.8347e-04,  3.4202e-06,  6.3812e-04,  1.6970e-04, -8.6401e-04,
        -3.7616e-04,  7.4933e-05,  4.5198e-04,  5.5249e-06,  8.8876e-04,
        -1.5111e-04,  1.9933e-04,  2.0542e-04, -1.3725e-04, -7.7274e-04,
         2.5790e-04, -1.0370e-03,  3.9275e-04,  4.7217e-04, -2.4047e-04,
         6.0868e-04, -2.7213e-04,  5.1205e-05, -4.7300e-05, -7.4024e-04,
         1.0035e-03,  2.7949e-04,  2.3543e-04, -4.7733e-04,  8.8320e-04,
         4.4062e-04, -1.3072e-04, -3.0914e-05, -1.1007e-03,  1.2445e-03,
         7.7432e-04, -7.8954e-04, -9.5820e-04,  2.3193e-05, -2.0758e-05,
        -1.0617e-03, -2.4397e-03, -3.4197e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.7987e-05, 2.0404e-05, 2.1819e-05, 2.7999e-05, 1.9586e-05, 1.9965e-05,
        1.1256e-05, 2.5142e-05, 4.2792e-05, 1.5466e-05, 2.3176e-05, 1.2171e-05,
        5.2534e-05, 3.5269e-05, 1.8246e-05, 2.5613e-05, 1.9324e-05, 4.3810e-05,
        2.0236e-05, 1.8059e-05, 3.6753e-05, 3.1528e-05, 1.7877e-05, 2.3670e-05,
        3.4708e-05, 1.7286e-05, 1.5219e-05, 1.7164e-05, 1.7538e-05, 2.5518e-05,
        1.7257e-05, 3.8126e-05, 1.3395e-05, 2.3175e-05, 1.9997e-05, 2.7263e-05,
        1.4364e-05, 1.7464e-05, 1.3751e-05, 4.3585e-05, 2.6105e-05, 1.4524e-05,
        1.1211e-05, 1.1609e-05, 3.0077e-05, 3.1168e-05, 2.8252e-05, 1.4946e-05,
        1.6321e-05, 2.7561e-05, 5.1536e-05, 3.1709e-05, 3.5366e-05, 2.9908e-05,
        2.2081e-05, 3.8167e-05, 3.3932e-05, 2.2888e-05, 3.4562e-05, 1.8010e-05,
        2.4356e-05, 2.1378e-05, 2.0386e-05, 2.4432e-05, 1.7834e-05, 1.7781e-05,
        2.5391e-05, 2.9446e-05, 1.1983e-05, 2.9896e-05, 2.3175e-05, 1.6394e-05,
        3.7568e-05, 2.3942e-05, 1.7604e-05, 1.9180e-05, 1.5854e-05, 3.3651e-05,
        1.2580e-05, 1.7681e-05, 1.8513e-05, 4.5811e-05, 1.7695e-05, 3.5934e-05,
        1.6731e-05, 3.2324e-05, 1.8905e-05, 2.4178e-05, 2.7579e-05, 2.3166e-05,
        2.3590e-05, 1.5031e-05, 2.3365e-05, 1.2205e-05, 3.0496e-05, 1.7673e-05,
        9.9642e-06, 3.0613e-05, 1.5602e-05, 1.9340e-05, 8.8582e-06, 2.9201e-05,
        2.1012e-05, 1.2544e-05, 3.1963e-05, 1.7796e-05, 1.1880e-05, 1.1482e-05,
        3.4750e-05, 3.0549e-05, 3.2849e-05, 2.2592e-05, 1.9023e-05, 2.0611e-05,
        3.7958e-05, 1.2869e-05, 2.0935e-05, 1.8932e-05, 4.7660e-05, 1.9702e-05,
        2.7910e-05, 1.4092e-05, 2.3220e-05, 2.1309e-05, 1.3433e-05, 4.2886e-05,
        2.8779e-05, 1.1573e-05], device='cuda:0')}, 38: {'step': tensor(30200.), 'exp_avg': tensor([-3.4769e-04, -4.8044e-05,  3.7007e-04,  3.3282e-04, -3.6493e-04,
         1.0675e-04, -1.5673e-04, -3.4044e-04, -1.5991e-04, -4.9752e-04,
         4.1617e-04,  3.7841e-04,  1.9340e-04, -4.1599e-04, -1.4262e-04,
         4.8184e-05, -4.0258e-04,  9.1639e-05,  3.2209e-06,  7.4989e-05,
        -3.3636e-04,  2.4321e-05, -1.5285e-04,  3.5750e-05, -6.3888e-05,
        -3.0427e-04, -2.6356e-04, -7.1534e-04, -4.2703e-05, -1.3930e-04,
        -3.0357e-05, -1.2193e-04,  4.1259e-04, -4.4719e-04,  5.4707e-05,
         2.8428e-04,  6.9229e-05, -1.4894e-04,  2.5593e-04,  5.5825e-05,
        -5.1369e-05,  1.9164e-04, -3.0039e-04, -1.2477e-04,  6.7006e-05,
         4.3724e-04,  7.0306e-04, -3.5554e-05, -3.7813e-04, -2.7344e-05,
        -4.8479e-04, -1.7933e-05, -6.5811e-06, -3.7128e-06, -6.1419e-05,
        -3.2130e-04,  3.9279e-04, -6.1099e-04,  7.2130e-05,  4.9466e-05,
         2.5215e-04, -2.6135e-04,  2.5510e-04, -1.8234e-04, -1.3345e-04,
         1.0429e-04, -4.3763e-05, -9.1337e-05, -3.1631e-04, -4.7672e-04,
        -3.2620e-04, -2.5198e-05,  2.6706e-05,  1.8202e-05,  3.4977e-05,
        -2.2647e-05, -4.6544e-04, -1.2171e-04, -1.0004e-04, -1.4369e-04,
        -4.7400e-05,  4.2872e-04,  1.0772e-05,  2.1572e-04,  4.9974e-04,
         8.6814e-05,  2.3011e-04,  2.3491e-04, -2.5763e-04, -2.1118e-04,
        -1.5977e-04, -6.2935e-05, -1.2031e-04,  1.4908e-04, -3.1761e-04,
        -3.4348e-04, -1.7635e-04,  2.7152e-04,  2.2474e-05, -1.0882e-04,
        -2.6577e-05, -1.4798e-04,  1.4781e-04, -1.6892e-04, -3.0058e-04,
        -2.6968e-05, -2.1237e-04, -2.3829e-05, -6.8390e-05, -1.2492e-05,
        -9.3211e-05, -4.8546e-04, -3.9855e-04, -1.9380e-04, -1.4037e-04,
         6.1440e-05, -9.5262e-05, -1.4903e-04,  9.4613e-05, -2.7217e-04,
        -1.0380e-04,  2.4865e-04, -1.4118e-05,  1.5351e-04, -3.3021e-04,
         1.7806e-04,  1.4850e-04, -3.8149e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.4612e-06, 7.4763e-07, 1.6113e-06, 2.0478e-06, 1.6455e-06, 7.4824e-07,
        1.0625e-06, 1.2337e-06, 1.5657e-06, 7.9789e-07, 1.6086e-06, 6.6961e-07,
        1.2024e-06, 1.6520e-06, 1.0827e-06, 1.8899e-06, 9.3310e-07, 1.4271e-06,
        8.3389e-07, 1.1793e-06, 1.0944e-06, 1.4775e-06, 2.4739e-06, 1.6191e-06,
        1.9370e-06, 2.2391e-06, 1.3463e-06, 1.5284e-06, 1.1051e-06, 1.0942e-06,
        1.5894e-06, 1.8317e-06, 1.8587e-06, 1.3742e-06, 2.0094e-06, 1.3482e-06,
        9.1877e-07, 1.0536e-06, 9.9435e-07, 6.2199e-07, 1.6893e-06, 1.4915e-06,
        1.1167e-06, 1.7127e-06, 1.1909e-06, 2.9486e-06, 3.3509e-06, 1.8139e-06,
        1.2883e-06, 1.1726e-06, 1.4573e-06, 9.4843e-07, 2.2542e-06, 1.5745e-06,
        1.3381e-06, 1.7579e-06, 8.9372e-07, 3.2771e-06, 9.9162e-07, 2.7174e-06,
        7.8890e-07, 2.1986e-06, 6.7201e-07, 1.4320e-06, 1.1084e-06, 2.1867e-06,
        1.0953e-06, 1.1344e-06, 9.4687e-07, 1.9436e-06, 1.0516e-06, 1.8928e-06,
        1.4981e-06, 1.4342e-06, 4.8142e-07, 1.0863e-06, 1.2412e-06, 1.8172e-06,
        6.8751e-07, 6.9656e-07, 6.1690e-07, 1.0030e-06, 1.7845e-06, 2.5456e-06,
        2.4207e-06, 2.1794e-06, 1.2096e-06, 7.5733e-07, 2.8663e-06, 1.2990e-06,
        1.0015e-06, 6.3803e-07, 1.7853e-06, 1.0676e-06, 1.1334e-06, 1.6963e-06,
        2.4964e-06, 3.1866e-06, 1.0508e-06, 7.7492e-07, 5.8125e-07, 1.0170e-06,
        6.5807e-07, 1.7216e-06, 1.4897e-06, 9.4191e-07, 1.0032e-06, 1.2413e-06,
        1.4136e-06, 1.2397e-06, 1.2346e-06, 6.2486e-07, 1.5569e-06, 1.2213e-06,
        1.1352e-06, 6.5704e-07, 1.0934e-06, 2.1112e-06, 1.3071e-06, 1.0299e-06,
        6.0419e-07, 1.4597e-06, 2.8064e-06, 1.0910e-06, 1.3907e-06, 1.9592e-06,
        1.5240e-06, 1.4530e-06], device='cuda:0')}, 39: {'step': tensor(30200.), 'exp_avg': tensor([-1.5013e-05,  7.8723e-05, -3.1149e-04, -8.4113e-05, -1.9839e-04,
        -5.7195e-05,  2.8932e-04,  2.6585e-04,  3.4842e-06,  3.1105e-04,
         5.8496e-05, -1.1846e-04, -1.1557e-04, -3.2520e-04,  6.5688e-05,
         2.4861e-04,  1.9326e-04, -1.7616e-04, -1.1483e-04,  1.2014e-04,
         3.0956e-04,  1.3058e-05,  3.3046e-04,  1.7037e-04, -9.8286e-05,
        -4.6441e-05,  2.5914e-05, -2.1521e-04, -2.3816e-04,  2.0743e-04,
         1.1136e-04,  4.8239e-04, -4.4751e-04,  2.2286e-04,  3.7512e-04,
        -1.3429e-04, -1.4064e-04,  1.7806e-04, -9.8570e-05,  1.9389e-05,
         3.5023e-04,  7.2910e-05, -3.2223e-04, -7.4140e-05, -8.1443e-05,
         2.2104e-04,  8.2217e-05, -2.2906e-04, -1.7328e-04, -3.2708e-04,
         2.8695e-05,  2.0935e-04,  4.8039e-04, -4.2900e-04, -1.8717e-04,
         2.6856e-04,  1.2308e-04, -3.2983e-04, -6.0902e-05,  5.1560e-05,
        -7.4121e-05,  2.3982e-04,  2.0163e-04,  7.9583e-05, -6.1863e-07,
         2.2383e-04, -8.7433e-05,  9.4138e-06, -4.0851e-04,  1.0972e-04,
         2.8164e-06, -1.4096e-04, -2.3108e-04,  1.4902e-04,  3.0808e-05,
        -5.3653e-04,  1.3934e-04, -4.3535e-05,  1.2605e-04, -7.7590e-05,
         6.8638e-05, -2.7866e-04, -1.1919e-05,  1.7429e-04,  4.8805e-05,
         6.6852e-05,  2.4080e-04,  8.4486e-05,  6.1647e-05, -5.5336e-04,
        -6.1605e-05, -3.2659e-05,  1.5840e-04,  1.0881e-04,  2.0238e-05,
        -1.4675e-04,  1.4904e-04, -6.6717e-05,  8.0202e-05, -1.9778e-05,
         1.8280e-04, -2.3416e-05, -7.1197e-05,  4.2487e-04, -4.3568e-04,
        -1.3599e-04, -3.0559e-04, -3.4000e-04, -1.5536e-04,  2.4847e-05,
        -3.8196e-04, -9.5759e-05, -1.5162e-04, -1.6121e-04, -4.2569e-04,
        -1.8099e-04, -1.5847e-04,  2.1721e-04,  8.6572e-05, -3.0545e-05,
        -2.2242e-04, -2.5626e-04,  6.4226e-05, -1.1030e-04, -1.5300e-04,
        -1.2513e-04,  3.6272e-05,  9.3390e-05], device='cuda:0'), 'exp_avg_sq': tensor([2.0497e-06, 1.4753e-06, 1.4395e-06, 1.4027e-06, 3.2931e-06, 1.1838e-06,
        1.3882e-06, 2.1066e-06, 2.0756e-06, 1.2529e-06, 2.5106e-06, 1.1489e-06,
        1.9990e-06, 1.5325e-06, 1.2852e-06, 2.1756e-06, 1.0739e-06, 1.1469e-06,
        1.4514e-06, 2.3352e-06, 1.7380e-06, 1.6718e-06, 2.1737e-06, 1.9949e-06,
        2.0581e-06, 2.9327e-06, 2.2912e-06, 1.0355e-06, 1.2716e-06, 9.4783e-07,
        1.8144e-06, 1.0848e-06, 2.3167e-06, 1.0903e-06, 1.6543e-06, 1.7589e-06,
        1.1820e-06, 1.1008e-06, 2.6308e-06, 1.0635e-06, 2.1779e-06, 1.4769e-06,
        2.3742e-06, 2.4815e-06, 2.2341e-06, 2.5766e-06, 2.6686e-06, 3.8265e-06,
        1.1774e-06, 2.1423e-06, 2.1983e-06, 7.0929e-07, 3.1560e-06, 2.1353e-06,
        1.5666e-06, 1.2651e-06, 8.5569e-07, 3.8955e-06, 1.0332e-06, 1.7064e-06,
        9.3932e-07, 1.8933e-06, 1.2417e-06, 1.6206e-06, 1.8459e-06, 1.8533e-06,
        1.4024e-06, 1.4009e-06, 1.9616e-06, 1.7425e-06, 1.3796e-06, 2.5589e-06,
        2.2074e-06, 1.5899e-06, 9.4515e-07, 1.2147e-06, 1.5136e-06, 1.9775e-06,
        1.1378e-06, 1.3952e-06, 1.4237e-06, 1.5944e-06, 2.3604e-06, 1.6681e-06,
        2.0246e-06, 2.3467e-06, 1.9616e-06, 1.3369e-06, 3.5645e-06, 1.4629e-06,
        1.9439e-06, 1.7881e-06, 2.2383e-06, 1.2282e-06, 1.1116e-06, 2.1668e-06,
        2.3956e-06, 1.5303e-06, 1.1218e-06, 1.2778e-06, 8.1795e-07, 1.6779e-06,
        1.0637e-06, 1.0973e-06, 2.0765e-06, 1.3514e-06, 8.9326e-07, 1.2396e-06,
        1.2861e-06, 1.5336e-06, 1.0624e-06, 1.0635e-06, 2.1486e-06, 1.3325e-06,
        9.5195e-07, 1.0742e-06, 1.6294e-06, 2.2059e-06, 1.6040e-06, 9.6772e-07,
        1.0131e-06, 1.9846e-06, 1.8359e-06, 1.9489e-06, 2.7081e-06, 1.2939e-06,
        1.6581e-06, 1.7156e-06], device='cuda:0')}, 40: {'step': tensor(30200.), 'exp_avg': tensor([[-7.6369e-04, -3.4291e-04, -4.4803e-04,  ..., -1.4462e-04,
         -9.2914e-05, -4.7038e-04],
        [-2.5547e-04, -5.5503e-05,  4.6127e-05,  ..., -1.7996e-04,
         -1.3961e-04,  1.2347e-04],
        [-9.0825e-06,  4.2937e-05, -4.0080e-04,  ...,  9.6210e-05,
          2.5294e-05,  1.7636e-04],
        ...,
        [ 1.4558e-04,  4.5855e-04,  2.6957e-04,  ...,  1.7307e-04,
         -9.2613e-05,  2.4283e-05],
        [ 9.4365e-05,  1.9983e-04, -1.1087e-04,  ..., -2.2901e-04,
         -8.8991e-05, -4.4786e-05],
        [ 3.5754e-04,  9.4328e-05,  3.5229e-04,  ...,  3.1877e-04,
          3.7678e-05,  2.2922e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[2.7100e-06, 1.7667e-06, 3.3095e-06,  ..., 3.5644e-06, 2.9105e-06,
         1.5392e-06],
        [8.0098e-07, 5.4399e-07, 1.1493e-06,  ..., 1.4625e-06, 1.1619e-06,
         9.9114e-07],
        [1.1693e-06, 6.2031e-07, 1.3398e-06,  ..., 1.2609e-06, 9.8261e-07,
         1.2569e-06],
        ...,
        [2.2539e-06, 1.2959e-06, 3.3417e-06,  ..., 3.3107e-06, 3.4897e-06,
         2.8985e-06],
        [1.1219e-06, 6.7944e-07, 1.5077e-06,  ..., 1.9840e-06, 1.7309e-06,
         1.3575e-06],
        [1.2194e-06, 5.1045e-07, 1.4243e-06,  ..., 1.3754e-06, 1.2466e-06,
         9.9116e-07]], device='cuda:0')}, 41: {'step': tensor(30200.), 'exp_avg': tensor([-3.5618e-04,  1.2627e-07,  1.4261e-04,  1.6295e-04, -8.3527e-06,
        -1.7345e-04, -1.3168e-04, -2.5700e-05, -4.0124e-04, -3.0039e-04,
         1.4905e-04,  1.9305e-04,  9.6024e-05,  1.2140e-05, -1.0002e-04,
        -7.5851e-06, -5.1897e-04, -4.1991e-05, -5.5133e-04, -4.0575e-05,
         2.4423e-04, -2.5513e-04,  2.6869e-04,  3.8651e-05,  7.3018e-05,
        -2.6627e-04, -1.7182e-04,  2.6045e-04, -2.3003e-05, -1.8805e-04,
        -2.2046e-04, -2.6443e-05,  8.2326e-06, -4.6373e-04, -3.2569e-04,
        -1.6833e-04, -5.8506e-05,  2.6865e-04,  1.3838e-04,  1.6292e-04,
         3.6673e-04,  4.7608e-04,  8.1867e-06,  2.4125e-04, -1.5346e-05,
         7.6295e-05, -1.8600e-06,  5.8938e-05,  3.5242e-05, -1.5967e-04,
         4.6348e-05, -3.4854e-05,  1.9385e-04, -1.7141e-04, -3.0506e-04,
         8.2560e-05, -6.5598e-06, -2.9858e-04, -5.0960e-04,  2.8826e-04,
        -8.1123e-05,  3.5733e-04,  1.9402e-04, -1.6558e-04, -1.0275e-04,
        -2.8792e-04, -2.7552e-04, -2.7175e-04, -3.2599e-04,  1.5779e-04,
        -1.2609e-04,  3.3706e-04,  3.9084e-04, -4.3515e-04, -2.0573e-04,
        -5.3186e-05, -1.6339e-04, -1.6710e-04,  1.3507e-04,  1.3313e-04,
        -2.1294e-05,  2.3297e-04, -1.1818e-04, -2.5998e-04, -1.4675e-04,
         5.8305e-05, -3.6441e-04, -1.2785e-04, -4.4197e-05,  5.5706e-04,
        -1.0423e-04, -1.0358e-05, -3.4256e-04,  3.7327e-05,  5.8837e-05,
        -1.0301e-04, -1.9051e-04,  1.7745e-04, -1.9885e-04, -4.4463e-04,
        -6.5700e-04,  3.0340e-04,  2.1242e-05, -2.6811e-05,  1.7344e-04,
         3.0151e-04, -1.1637e-04, -5.4486e-05,  9.3956e-05,  9.5970e-05,
         2.8306e-04, -2.5701e-04, -6.2929e-05,  3.1096e-04,  3.2661e-04,
         6.2244e-06,  8.4825e-05, -1.3448e-04, -2.6248e-04,  6.9838e-05,
        -3.5257e-06,  4.1230e-04,  3.7091e-04,  7.4647e-05,  4.2456e-04,
        -3.1817e-04,  1.3125e-04, -1.7188e-04, -1.7079e-04, -1.3944e-04,
         3.5438e-04, -3.1094e-05,  2.6310e-04,  1.0514e-04, -8.7023e-05,
        -4.5840e-04, -1.4747e-04,  8.5464e-05, -1.3264e-04,  6.6773e-05,
        -2.8121e-04,  3.8706e-05,  6.5206e-05,  3.0722e-05,  8.9197e-05,
        -2.0952e-05, -2.3915e-04, -9.0578e-06,  1.2854e-04,  1.4058e-04,
        -2.7074e-04,  1.7284e-04,  2.3391e-04,  3.7143e-05, -1.4722e-04,
         9.9913e-05, -2.2255e-04, -1.9278e-04, -1.0722e-04,  2.8390e-05,
        -1.7891e-04, -1.1797e-04,  1.8280e-04,  1.5406e-04,  1.0116e-05,
        -1.4256e-04, -4.0375e-04,  1.5332e-04, -4.2547e-05,  1.0745e-04,
         2.6634e-04,  8.2571e-05, -2.1385e-04, -3.4860e-04,  4.0149e-06,
        -2.6108e-05, -3.0952e-04,  1.8185e-04, -1.8172e-04,  5.7732e-04,
        -2.1523e-04, -2.4624e-05,  2.5303e-04,  4.8442e-04,  3.9400e-05,
        -1.3744e-04, -8.1046e-04,  1.5697e-04,  1.7372e-04,  1.8671e-04,
        -1.2853e-06,  1.5792e-04, -1.1272e-04, -7.7741e-05,  1.0991e-04,
        -2.5449e-04,  1.7244e-04,  6.3436e-04, -1.3085e-05, -2.5098e-05,
         5.2616e-05,  2.9498e-04, -5.8872e-05,  3.6522e-04, -1.6170e-04,
        -1.4997e-04,  1.3665e-04, -1.3845e-04, -1.5243e-04,  2.3370e-04,
        -2.6419e-05, -1.6850e-04, -4.4161e-05, -8.0801e-05, -4.0650e-04,
         1.9144e-04,  3.5136e-04,  2.1591e-04,  3.2442e-04, -1.4801e-06,
        -3.7735e-05, -4.1756e-04,  3.4790e-05, -1.1642e-04, -1.3807e-04,
        -6.7620e-05, -2.8925e-04, -2.0665e-04, -1.1909e-04,  2.7602e-04,
        -8.8442e-05,  4.7351e-04,  4.4823e-04, -2.1636e-05,  5.8151e-05,
         1.1613e-04,  2.1459e-04, -1.1357e-04,  1.0584e-04, -6.0188e-04,
        -1.1371e-04,  4.2460e-05,  2.8223e-04,  4.6790e-05, -1.5323e-04,
         4.8275e-04,  2.3065e-05,  5.9322e-04, -1.3945e-04, -2.1604e-04,
         8.2300e-05, -8.5676e-05,  2.9829e-05, -8.8286e-05,  3.7063e-04,
        -2.3135e-04], device='cuda:0'), 'exp_avg_sq': tensor([3.1239e-06, 1.1342e-06, 1.0893e-06, 1.4028e-06, 1.5831e-06, 1.5490e-06,
        1.0223e-06, 1.3677e-06, 1.5716e-06, 2.2883e-06, 3.4518e-06, 1.6180e-06,
        8.5907e-07, 1.4421e-06, 3.2113e-06, 7.7194e-07, 1.1341e-06, 1.6842e-06,
        2.1830e-06, 1.2620e-06, 8.7069e-07, 1.6425e-06, 1.3309e-06, 2.1428e-06,
        1.5445e-06, 1.2297e-06, 8.8635e-07, 1.4476e-06, 1.6404e-06, 2.4509e-06,
        4.2983e-06, 1.1096e-06, 1.7546e-06, 1.2109e-06, 1.2157e-06, 2.0900e-06,
        1.0398e-06, 1.7998e-06, 1.2527e-06, 2.6777e-06, 1.5949e-06, 1.5530e-06,
        1.2942e-06, 1.0516e-06, 2.0306e-06, 2.4805e-06, 1.1157e-06, 8.6228e-07,
        3.2961e-06, 8.0151e-07, 1.0150e-06, 9.4710e-07, 2.0389e-06, 3.1920e-06,
        2.1429e-06, 1.0580e-06, 2.6384e-06, 1.6683e-06, 2.1479e-06, 1.9015e-06,
        1.6651e-06, 1.9538e-06, 1.0887e-06, 1.3104e-06, 4.4208e-06, 2.6972e-06,
        2.5053e-06, 2.2123e-06, 2.0722e-06, 2.8826e-06, 4.5584e-06, 1.2455e-06,
        1.0008e-06, 1.9024e-06, 1.2905e-06, 6.2237e-07, 2.8815e-06, 2.7866e-06,
        1.6816e-06, 1.2329e-06, 2.1516e-06, 1.4743e-06, 2.4511e-06, 1.1505e-06,
        1.3440e-06, 8.6918e-07, 1.3032e-06, 1.2564e-06, 1.6613e-06, 2.1970e-06,
        1.1837e-06, 1.4713e-06, 1.5930e-06, 1.2180e-06, 1.7500e-06, 1.0614e-06,
        1.3441e-06, 1.6157e-06, 1.4367e-06, 1.0626e-06, 1.6542e-06, 9.7779e-07,
        1.6375e-06, 1.9103e-06, 1.1777e-06, 1.2382e-06, 1.5171e-06, 1.8863e-06,
        8.1839e-07, 9.4661e-07, 9.4421e-07, 4.0168e-06, 1.1078e-06, 1.8218e-06,
        3.3068e-06, 8.7487e-07, 1.7727e-06, 1.4264e-06, 1.5698e-06, 2.0385e-06,
        2.2184e-06, 5.0092e-06, 1.3879e-06, 1.5270e-06, 4.5095e-06, 9.8765e-07,
        1.6415e-06, 5.3881e-07, 2.4574e-06, 1.0214e-06, 2.0264e-06, 1.7025e-06,
        6.2640e-07, 1.1674e-06, 2.1429e-06, 1.0374e-06, 2.0807e-06, 8.5580e-07,
        3.2792e-06, 1.9500e-06, 1.4216e-06, 1.8149e-06, 7.6998e-07, 8.7808e-07,
        2.8460e-06, 1.1459e-06, 1.3261e-06, 1.8698e-06, 9.3165e-07, 2.4159e-06,
        1.6253e-06, 2.1857e-06, 1.3760e-06, 1.3678e-06, 1.5143e-06, 8.3681e-07,
        1.5633e-06, 3.0132e-06, 8.9251e-07, 1.1424e-06, 1.3311e-06, 1.6814e-06,
        7.8581e-07, 1.0631e-06, 2.6057e-06, 2.0412e-06, 1.2978e-06, 1.9521e-06,
        1.2974e-06, 1.7479e-06, 1.4495e-06, 2.5547e-06, 1.3247e-06, 9.4968e-07,
        1.1829e-06, 1.6331e-06, 1.6456e-06, 1.7537e-06, 2.9045e-06, 1.6308e-06,
        1.0831e-06, 1.7358e-06, 2.9715e-06, 1.0587e-06, 1.3763e-06, 1.8924e-06,
        2.3751e-06, 2.3225e-06, 1.7139e-06, 2.3138e-06, 1.9474e-06, 9.5320e-07,
        1.3123e-06, 5.5356e-06, 9.3912e-07, 1.0458e-06, 8.4509e-07, 1.5841e-06,
        1.0415e-06, 1.4333e-06, 2.3504e-06, 1.5372e-06, 1.2041e-06, 1.2235e-06,
        1.2604e-06, 1.5699e-06, 1.3508e-06, 2.1920e-06, 9.2619e-07, 1.5510e-06,
        1.7548e-06, 1.2378e-06, 5.9563e-06, 9.6173e-07, 1.9685e-06, 1.2296e-06,
        1.5749e-06, 2.2385e-06, 1.8338e-06, 1.4586e-06, 1.4189e-06, 1.9712e-06,
        6.4929e-07, 1.0829e-06, 1.3329e-06, 1.9970e-06, 1.7329e-06, 1.2861e-06,
        1.9109e-06, 2.2253e-06, 1.9856e-06, 3.1171e-06, 2.6789e-06, 1.6520e-06,
        1.0862e-06, 8.8232e-07, 2.4872e-06, 1.6558e-06, 2.4500e-06, 1.7147e-06,
        1.9146e-06, 1.2828e-06, 1.1681e-06, 7.9083e-07, 2.3411e-06, 1.7732e-06,
        9.0963e-07, 1.8705e-06, 1.1584e-06, 1.8549e-06, 1.7563e-06, 2.3064e-06,
        1.2278e-06, 3.1263e-06, 1.1594e-06, 1.5757e-06], device='cuda:0')}, 42: {'step': tensor(30200.), 'exp_avg': tensor([[-1.6297e-04,  2.1726e-05,  7.5172e-05,  ...,  9.7942e-05,
          7.2015e-05, -4.1711e-04],
        [ 7.3142e-04,  3.4262e-04, -1.9015e-04,  ...,  2.0500e-04,
          1.9893e-04, -2.8142e-04],
        [-4.2689e-04,  5.0364e-04, -2.1434e-04,  ..., -7.2429e-05,
          2.3676e-04, -2.5252e-04],
        ...,
        [-6.0832e-04, -2.7289e-04,  2.6458e-04,  ...,  3.1624e-05,
         -1.7197e-04,  7.3277e-05],
        [-1.9137e-04, -7.3861e-04, -4.5028e-05,  ..., -3.2816e-04,
         -3.4041e-05, -2.5170e-04],
        [ 2.4376e-04, -2.2865e-05, -4.3957e-05,  ..., -3.0004e-04,
          2.9753e-04, -4.4748e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[1.8783e-06, 2.2251e-06, 1.6568e-06,  ..., 2.4459e-06, 2.0946e-06,
         1.0433e-06],
        [2.4787e-06, 2.3803e-06, 2.3391e-06,  ..., 3.2145e-06, 1.6064e-06,
         1.2794e-06],
        [2.5732e-06, 3.2714e-06, 2.5673e-06,  ..., 3.6038e-06, 1.5565e-06,
         1.1753e-06],
        ...,
        [4.3726e-06, 2.4591e-06, 1.8400e-06,  ..., 4.4140e-06, 1.7426e-06,
         2.3298e-06],
        [2.5461e-06, 2.8314e-06, 1.5507e-06,  ..., 3.6887e-06, 1.8413e-06,
         1.3008e-06],
        [1.8301e-06, 2.7308e-06, 2.4825e-06,  ..., 3.2839e-06, 1.8975e-06,
         1.0506e-06]], device='cuda:0')}, 43: {'step': tensor(30200.), 'exp_avg': tensor([-8.1918e-04,  8.3553e-04,  4.4662e-04,  6.5957e-04, -4.5858e-04,
         4.9827e-04,  4.1662e-04,  5.6963e-04,  8.7766e-04,  5.1791e-04,
         5.9943e-04,  7.2000e-04,  2.7191e-04,  9.3052e-04,  5.8033e-05,
         1.3389e-03, -4.5377e-04,  1.9463e-04, -2.9999e-04, -7.5709e-05,
        -3.8836e-04, -5.3662e-04,  2.0962e-04,  7.8001e-04, -8.3208e-04,
         2.5456e-04, -1.1512e-03, -8.2421e-04,  8.7156e-04, -1.9708e-05,
         7.8673e-04, -5.9384e-04,  7.9626e-04, -4.7228e-04, -6.0426e-04,
         1.5694e-04, -1.1472e-04,  7.4383e-04,  4.3151e-05,  6.7827e-04,
         1.4361e-04, -1.2011e-04,  2.4414e-04,  8.1204e-04,  1.0975e-04,
        -1.0730e-03,  1.1214e-03,  1.4549e-04, -4.1530e-05,  1.3862e-03,
        -5.6616e-04, -3.1103e-04, -2.8143e-04, -4.3842e-04,  4.5941e-06,
         8.4063e-04,  4.0683e-04, -7.7985e-04,  1.2344e-04, -3.2630e-04,
        -2.0248e-03, -6.5253e-04,  2.2854e-04, -4.6995e-04, -4.5268e-04,
        -1.0427e-03, -6.8087e-04,  1.1192e-04, -9.4922e-04,  2.3240e-04,
         1.0896e-04, -6.7256e-04, -7.0858e-04, -3.7221e-04, -8.1552e-04,
        -7.7892e-04,  6.6682e-05,  4.3802e-04,  3.5773e-04,  8.2161e-04,
         1.1040e-05,  4.1916e-05, -2.1602e-04,  1.0891e-03,  7.5038e-04,
        -9.6999e-04, -3.0173e-04, -1.7921e-05,  2.1803e-04, -9.1895e-04,
         6.8600e-05, -6.9034e-04,  1.9524e-04, -2.8277e-04,  1.3327e-03,
         5.0183e-04,  1.0537e-04,  4.1153e-04, -3.1978e-04, -1.0747e-03,
        -1.7652e-04, -1.1341e-03,  4.1889e-04, -1.1644e-04,  3.0814e-04,
         1.0654e-03,  1.4439e-04,  5.0422e-04,  1.8858e-04, -3.9185e-04,
         6.9713e-04, -1.6239e-04,  5.6967e-04, -5.5252e-04,  6.5829e-04,
         5.9285e-04,  7.1071e-05,  2.5806e-05, -1.2835e-03,  4.5284e-04,
         3.3846e-04, -6.0186e-04, -1.8498e-04,  6.2929e-04, -5.2694e-04,
        -1.3978e-03, -2.2971e-03, -1.9209e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.3923e-05, 1.8679e-05, 2.1036e-05, 2.4146e-05, 1.7873e-05, 1.7488e-05,
        1.0187e-05, 1.9128e-05, 3.7654e-05, 1.6183e-05, 2.1359e-05, 1.0834e-05,
        4.1605e-05, 3.7026e-05, 1.5327e-05, 2.4666e-05, 1.9549e-05, 4.3210e-05,
        1.9422e-05, 1.6037e-05, 3.3866e-05, 2.6909e-05, 1.5564e-05, 2.0701e-05,
        3.5883e-05, 1.4434e-05, 1.1615e-05, 1.8944e-05, 1.4787e-05, 2.1866e-05,
        1.4833e-05, 3.7937e-05, 1.4908e-05, 2.3830e-05, 1.8517e-05, 2.5002e-05,
        1.2982e-05, 1.5119e-05, 1.4468e-05, 4.0005e-05, 2.0924e-05, 1.4290e-05,
        1.3427e-05, 1.4519e-05, 2.5894e-05, 3.0781e-05, 2.4366e-05, 1.9076e-05,
        1.5654e-05, 2.2248e-05, 3.8544e-05, 2.9441e-05, 2.7363e-05, 2.8756e-05,
        2.3110e-05, 3.5076e-05, 3.3852e-05, 1.5438e-05, 3.1768e-05, 1.9717e-05,
        2.3195e-05, 2.5169e-05, 1.9310e-05, 2.6509e-05, 1.8476e-05, 1.8237e-05,
        2.2234e-05, 2.7594e-05, 1.4292e-05, 2.7136e-05, 2.0411e-05, 1.5793e-05,
        3.2298e-05, 2.1170e-05, 1.7365e-05, 1.7986e-05, 1.8340e-05, 2.8753e-05,
        1.2410e-05, 1.6486e-05, 1.7004e-05, 4.8984e-05, 1.6469e-05, 3.4141e-05,
        1.6929e-05, 2.8918e-05, 1.5064e-05, 2.2310e-05, 2.0821e-05, 1.8141e-05,
        1.9028e-05, 1.3505e-05, 2.0246e-05, 1.3219e-05, 3.3050e-05, 1.6919e-05,
        1.0672e-05, 2.4580e-05, 1.2549e-05, 2.0139e-05, 9.0409e-06, 2.3016e-05,
        1.7730e-05, 1.2217e-05, 2.8204e-05, 1.8455e-05, 1.1268e-05, 1.1670e-05,
        3.1329e-05, 2.5953e-05, 3.3118e-05, 2.0258e-05, 1.6845e-05, 1.8472e-05,
        3.6225e-05, 1.0535e-05, 1.8199e-05, 1.3847e-05, 4.5175e-05, 1.8406e-05,
        2.3948e-05, 1.6158e-05, 1.9353e-05, 2.0430e-05, 1.3370e-05, 4.7441e-05,
        2.5436e-05, 1.1364e-05], device='cuda:0')}, 44: {'step': tensor(30200.), 'exp_avg': tensor([ 3.8673e-04,  5.8023e-04, -8.8838e-05,  4.6212e-04,  1.2044e-04,
         4.3389e-05,  1.2832e-04,  8.2370e-04, -4.4350e-04,  1.3243e-05,
         1.0167e-03,  4.6701e-04,  6.0175e-04,  3.2485e-04,  1.9365e-04,
         2.4047e-04, -6.7245e-04, -3.6145e-04, -8.9481e-05,  4.2846e-04,
        -7.3781e-04,  1.1779e-04,  9.9799e-05, -1.1994e-03,  3.1625e-04,
         5.6699e-04, -5.2163e-04,  1.0385e-03, -4.0729e-04,  1.0666e-03,
        -4.3331e-05, -3.3191e-04, -1.2708e-04, -3.9075e-04,  7.8145e-04,
         4.4762e-04, -1.3751e-04,  1.1527e-03,  1.4862e-05, -1.7556e-04,
         8.0233e-05, -4.2844e-04, -5.8061e-04,  9.9869e-04, -6.3398e-04,
         5.6709e-04,  6.9599e-04,  5.7478e-05, -3.1276e-04,  8.3891e-04,
        -1.9718e-05,  9.0670e-04, -1.9490e-04,  3.2931e-04,  6.3455e-04,
        -2.2355e-04,  2.8433e-04, -5.3285e-04, -1.7800e-04,  9.3017e-04,
         1.3716e-04, -3.2072e-04,  7.1073e-04, -3.2330e-04,  4.7018e-04,
         5.2157e-05, -1.2527e-04, -9.6091e-04,  3.4166e-04, -2.3402e-04,
        -6.3894e-04, -5.3356e-04,  2.6670e-04, -6.2732e-04, -2.1339e-04,
         6.5062e-04, -1.1854e-04, -5.8633e-04,  2.9892e-04,  2.6086e-04,
        -3.5920e-05, -8.4412e-04, -2.8569e-04, -1.6405e-04, -8.6914e-04,
         9.6177e-04,  2.6192e-04, -3.7308e-04,  1.8404e-04,  6.0077e-05,
         2.4007e-04,  4.8345e-04,  1.4282e-04,  1.3582e-04, -6.0060e-04,
         2.3791e-04,  1.2611e-03,  9.5022e-04,  2.7768e-05,  4.0624e-04,
        -1.1959e-04,  8.3731e-04, -9.4178e-05,  3.8748e-04, -1.0468e-03,
         1.8415e-04,  2.0525e-05, -3.5443e-04, -7.3037e-04, -2.6191e-04,
         5.7088e-04,  2.6782e-04,  5.2751e-04,  2.0384e-04,  8.5615e-04,
        -3.3765e-04,  7.9628e-05, -5.0526e-04, -6.0183e-04, -7.1947e-04,
         1.7847e-04,  4.3975e-04, -2.9960e-05, -3.2540e-04, -1.1336e-04,
        -2.0848e-04,  2.1298e-04, -4.4471e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.2569e-05, 3.0669e-06, 5.6649e-06, 9.7692e-06, 2.9100e-06, 5.0933e-06,
        5.6823e-06, 4.3440e-06, 7.5515e-06, 3.8832e-06, 7.3486e-06, 2.5876e-06,
        4.8031e-06, 5.8861e-06, 4.4998e-06, 5.7481e-06, 4.0969e-06, 4.7426e-06,
        3.9940e-06, 3.7997e-06, 2.9945e-06, 1.0909e-05, 6.9983e-06, 6.6830e-06,
        7.1059e-06, 5.9481e-06, 3.0309e-06, 1.0045e-05, 5.9548e-06, 8.5977e-06,
        4.9498e-06, 7.6598e-06, 5.6270e-06, 7.2777e-06, 6.9163e-06, 4.6950e-06,
        5.6008e-06, 9.7793e-06, 2.9592e-06, 3.8688e-06, 4.4960e-06, 7.0366e-06,
        2.8706e-06, 5.9103e-06, 6.6059e-06, 7.5694e-06, 8.2748e-06, 3.3424e-06,
        9.4174e-06, 3.1442e-06, 1.0447e-05, 5.1715e-06, 6.7295e-06, 8.2822e-06,
        5.2746e-06, 4.1882e-06, 3.6622e-06, 4.2029e-06, 7.0650e-06, 1.0705e-05,
        5.2816e-06, 5.3384e-06, 2.8373e-06, 5.8557e-06, 4.5044e-06, 4.7937e-06,
        3.4794e-06, 8.5416e-06, 4.8082e-06, 1.0154e-05, 5.3817e-06, 5.7811e-06,
        3.5601e-06, 3.6893e-06, 4.7209e-06, 4.0018e-06, 4.3015e-06, 5.5675e-06,
        3.6455e-06, 2.9466e-06, 3.0547e-06, 5.4832e-06, 5.1171e-06, 8.7404e-06,
        3.7355e-06, 8.7601e-06, 3.5551e-06, 5.5088e-06, 8.0105e-06, 5.7405e-06,
        4.9186e-06, 4.1685e-06, 5.0565e-06, 4.8283e-06, 8.7108e-06, 6.7392e-06,
        8.0748e-06, 1.0758e-05, 3.6356e-06, 5.9316e-06, 2.8958e-06, 6.7494e-06,
        3.6971e-06, 4.0716e-06, 1.2879e-05, 4.2633e-06, 5.4508e-06, 3.7823e-06,
        4.0575e-06, 4.3548e-06, 3.0574e-06, 4.5789e-06, 5.4508e-06, 5.3417e-06,
        4.8360e-06, 3.9259e-06, 4.5116e-06, 4.2970e-06, 5.3564e-06, 6.3144e-06,
        2.8959e-06, 6.4864e-06, 9.4574e-06, 5.3796e-06, 6.0164e-06, 5.3810e-06,
        5.6007e-06, 6.0600e-06], device='cuda:0')}, 45: {'step': tensor(30200.), 'exp_avg': tensor([-5.6178e-04, -2.5991e-04,  5.4532e-04,  1.4122e-04, -4.8313e-04,
         9.1355e-05, -4.7345e-04,  1.8069e-04,  2.1727e-04,  4.1842e-04,
        -2.2111e-04,  3.5596e-04,  4.7815e-04, -3.4459e-04,  1.4916e-04,
         6.1594e-04,  1.9578e-04, -2.6145e-04, -1.7493e-04,  3.4304e-04,
         6.6326e-04, -2.3321e-04,  1.5413e-04,  4.5133e-04, -2.1494e-04,
         6.3829e-05, -4.6668e-05,  5.9236e-05,  2.1391e-04, -4.4378e-04,
         7.0784e-05, -3.2141e-05, -3.8802e-04,  5.0029e-04,  2.3828e-04,
        -6.4106e-05, -2.3747e-04, -4.1915e-04,  2.9349e-04,  4.6624e-04,
         6.7511e-04,  9.7682e-04, -2.5117e-04,  3.3588e-04,  3.5643e-05,
        -1.3739e-04,  4.6528e-04,  1.5631e-04, -4.3743e-04,  4.0031e-04,
         7.5383e-04, -1.9328e-04, -4.0095e-06,  3.4746e-04, -1.0990e-03,
        -3.9766e-06,  3.5663e-04,  9.6453e-05,  4.8058e-04, -6.7054e-04,
         3.1443e-04,  1.1706e-03, -5.1951e-05, -6.0848e-04, -3.3211e-04,
        -1.1434e-04,  2.3414e-04, -6.1896e-04, -3.1602e-05,  1.1282e-03,
         1.0493e-04,  8.2940e-05, -1.2136e-05, -3.1513e-04, -3.3530e-04,
        -2.1547e-04,  2.3502e-04,  1.9662e-05,  5.5238e-05,  1.9736e-05,
        -3.1690e-05, -2.2786e-04,  3.9185e-04,  6.2856e-04,  6.2468e-04,
        -2.1879e-05, -5.1397e-05,  2.0635e-04,  5.7787e-04, -1.4037e-04,
        -8.1577e-04, -3.3058e-04, -1.6810e-04,  5.1794e-04,  3.1224e-04,
        -7.4171e-04,  5.7267e-04,  2.3012e-04, -7.3878e-04, -4.2043e-04,
        -7.2088e-04,  4.1973e-04,  5.8003e-04,  1.1891e-04, -3.9034e-04,
        -5.3806e-05, -1.7507e-04,  7.0129e-05, -4.2035e-04, -4.0177e-04,
        -3.8226e-04, -9.0934e-05,  3.5664e-04,  3.3080e-04, -2.5056e-04,
         3.2554e-04,  1.3501e-04,  2.1869e-04, -8.7140e-04,  3.3295e-04,
        -1.8249e-04,  1.1384e-04, -5.3475e-04, -3.0344e-04,  3.6422e-04,
        -3.5984e-04, -8.6028e-04, -9.7966e-05], device='cuda:0'), 'exp_avg_sq': tensor([3.1333e-06, 9.2579e-06, 6.8882e-06, 1.5071e-05, 6.2830e-06, 6.6269e-06,
        5.4168e-06, 4.2452e-06, 6.6444e-06, 1.1419e-05, 1.1249e-05, 1.0798e-05,
        6.6367e-06, 8.8462e-06, 1.0687e-05, 7.1778e-06, 6.0929e-06, 3.0395e-06,
        1.0087e-05, 5.3926e-06, 4.9544e-06, 1.1119e-05, 3.7645e-06, 4.0996e-06,
        1.1375e-05, 4.4256e-06, 5.1475e-06, 9.4296e-06, 4.8548e-06, 1.0761e-05,
        1.0270e-05, 1.0959e-05, 8.0339e-06, 6.2265e-06, 4.0092e-06, 7.7968e-06,
        7.2572e-06, 1.2147e-05, 3.8513e-06, 1.1037e-05, 7.8673e-06, 1.1139e-05,
        1.3591e-05, 6.6146e-06, 8.7461e-06, 8.5283e-06, 1.0100e-05, 3.4249e-06,
        9.5665e-06, 4.3195e-06, 5.1458e-06, 1.3235e-05, 5.8804e-06, 1.1837e-05,
        8.7826e-06, 9.1041e-06, 6.8848e-06, 5.4899e-06, 8.8924e-06, 8.5171e-06,
        7.5906e-06, 1.0567e-05, 5.5988e-06, 1.0816e-05, 4.6614e-06, 6.1443e-06,
        7.8642e-06, 6.1944e-06, 8.4941e-06, 1.1531e-05, 8.1789e-06, 4.6632e-06,
        1.0078e-05, 6.2150e-06, 1.4548e-05, 6.8710e-06, 9.3770e-06, 8.1475e-06,
        6.0055e-06, 8.8717e-06, 4.5529e-06, 9.7332e-06, 6.3710e-06, 8.1535e-06,
        1.0532e-05, 1.2226e-05, 6.9970e-06, 7.0142e-06, 6.5857e-06, 5.7895e-06,
        1.0546e-05, 3.9467e-06, 9.7514e-06, 7.5127e-06, 1.3036e-05, 1.6737e-05,
        5.5382e-06, 5.1145e-06, 3.4413e-06, 1.0265e-05, 5.4046e-06, 8.2547e-06,
        4.5734e-06, 4.4611e-06, 1.5946e-05, 6.7791e-06, 7.5851e-06, 5.0487e-06,
        9.3683e-06, 8.3325e-06, 9.4957e-06, 6.1842e-06, 5.0773e-06, 1.0762e-05,
        2.8061e-06, 7.1215e-06, 4.3150e-06, 5.8712e-06, 8.0678e-06, 6.3144e-06,
        7.2362e-06, 3.7781e-06, 6.9656e-06, 5.6903e-06, 5.5742e-06, 1.2871e-05,
        8.6744e-06, 7.0610e-06], device='cuda:0')}, 46: {'step': tensor(30200.), 'exp_avg': tensor([[ 9.2158e-05,  8.8503e-05, -2.6082e-05,  ...,  1.9393e-04,
          6.7063e-05, -9.9557e-05],
        [ 1.6697e-04,  1.1995e-04,  1.0272e-04,  ...,  3.8028e-05,
         -1.3418e-04,  3.6010e-05],
        [-4.7525e-05, -3.2344e-05, -1.9585e-04,  ...,  2.7560e-04,
          9.8147e-05,  8.8802e-06],
        ...,
        [-1.2491e-04,  1.5803e-04, -2.1696e-04,  ..., -4.6063e-04,
         -3.8402e-04, -7.5365e-05],
        [ 3.5474e-04,  6.0206e-05, -5.5173e-05,  ...,  1.7941e-04,
         -2.6371e-04,  4.3468e-05],
        [ 6.8675e-04, -5.9053e-04,  3.7292e-04,  ...,  4.2867e-05,
          1.0025e-04,  3.1451e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[2.9085e-07, 1.7281e-07, 3.8464e-07,  ..., 6.3630e-07, 2.8301e-07,
         3.1396e-07],
        [5.7942e-07, 2.5306e-07, 7.0849e-07,  ..., 9.9129e-07, 4.7652e-07,
         6.0985e-07],
        [9.8297e-07, 5.9322e-07, 1.2753e-06,  ..., 2.4779e-06, 1.2250e-06,
         1.0635e-06],
        ...,
        [2.0173e-06, 1.0507e-06, 1.9701e-06,  ..., 1.9578e-06, 1.5289e-06,
         8.4337e-07],
        [2.0612e-06, 9.8140e-07, 2.1209e-06,  ..., 1.7479e-06, 1.6369e-06,
         8.6030e-07],
        [3.9744e-06, 1.4926e-06, 1.9766e-06,  ..., 1.9831e-06, 1.8378e-06,
         1.1843e-06]], device='cuda:0')}, 47: {'step': tensor(30200.), 'exp_avg': tensor([[ 4.0977e-04, -1.1648e-05,  1.0100e-04,  ..., -4.0750e-05,
          1.0351e-03, -4.3479e-04],
        [-3.0766e-04, -8.1422e-05, -5.5799e-04,  ..., -8.6859e-04,
         -7.6413e-04, -2.3840e-04],
        [-4.2268e-04, -2.7337e-04, -2.6658e-04,  ..., -2.7649e-04,
         -8.0892e-04,  3.2804e-04],
        ...,
        [-9.7107e-05,  6.9580e-05, -8.3228e-05,  ...,  5.9213e-04,
         -7.3707e-05,  1.0205e-03],
        [ 3.3221e-04,  1.4841e-04,  5.8151e-07,  ..., -8.2898e-05,
         -6.0003e-04,  4.1777e-04],
        [-1.3692e-04,  3.9762e-04, -1.9032e-04,  ..., -4.5208e-04,
         -1.8884e-04, -4.7028e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[1.8271e-06, 1.4950e-06, 1.1186e-06,  ..., 1.0742e-06, 2.2926e-06,
         2.9149e-06],
        [3.7900e-06, 3.4229e-06, 1.9104e-06,  ..., 2.2416e-06, 4.0477e-06,
         5.1560e-06],
        [2.9543e-06, 3.5871e-06, 1.6961e-06,  ..., 1.6418e-06, 3.3943e-06,
         4.4538e-06],
        ...,
        [3.8075e-06, 3.5086e-06, 2.8321e-06,  ..., 2.1477e-06, 4.9256e-06,
         5.7357e-06],
        [2.2671e-06, 2.5615e-06, 1.6428e-06,  ..., 1.5970e-06, 3.8986e-06,
         4.3199e-06],
        [2.1048e-06, 2.3314e-06, 1.3700e-06,  ..., 1.1334e-06, 2.1107e-06,
         3.4385e-06]], device='cuda:0')}, 48: {'step': tensor(30200.), 'exp_avg': tensor([ 1.7150e-04,  7.9028e-04,  3.5129e-04,  4.2661e-04, -4.4295e-04,
         1.3418e-04,  1.1250e-03,  5.6078e-04,  2.2131e-04, -4.8942e-04,
         6.7066e-04,  8.7555e-04, -4.5979e-05,  1.3934e-03,  8.5246e-06,
         5.6745e-04, -4.3257e-04, -2.3972e-06,  4.9199e-04,  2.6855e-04,
        -1.4650e-03, -2.7213e-04,  4.6020e-04,  3.9085e-04, -8.8881e-04,
         2.3670e-04, -1.3305e-03, -7.9461e-04,  8.5203e-04,  1.1123e-04,
         4.3392e-04, -6.7030e-04,  4.6611e-04, -8.9430e-05, -7.9703e-04,
         1.0297e-04, -3.0214e-04,  9.4428e-04, -4.6992e-05,  6.8713e-04,
        -1.5231e-04, -3.0150e-06,  5.6728e-04,  7.7457e-04,  2.7946e-04,
        -1.0722e-03,  5.7281e-04,  3.3383e-04,  7.2697e-04,  7.1228e-04,
        -1.0626e-03, -7.6026e-05, -1.8694e-04, -1.1785e-04,  6.4674e-04,
         5.7051e-04,  3.9090e-04,  1.3433e-04, -1.5031e-04, -2.4518e-04,
        -7.4447e-04, -1.1150e-03,  1.3262e-05, -1.7912e-05, -5.5342e-04,
        -1.0931e-03, -1.3567e-03,  3.6160e-04, -5.8210e-04, -1.5226e-04,
         1.2078e-04, -6.0495e-04, -6.9530e-04, -6.0081e-05, -5.4403e-04,
        -4.6727e-04, -2.3119e-05,  7.4305e-04,  2.1586e-04,  1.3057e-03,
         3.0973e-04,  2.4324e-04, -2.0873e-04,  4.1141e-04,  2.6189e-04,
        -9.2364e-04,  3.0278e-04, -2.4422e-04, -2.4283e-04, -3.8106e-04,
         9.8200e-04, -1.4679e-04,  1.4692e-04,  2.6125e-05,  6.0033e-04,
         1.3333e-03,  7.6265e-05,  6.5507e-04,  3.8388e-04, -5.7230e-04,
         6.8934e-04, -1.3450e-03, -5.0797e-04,  1.7081e-04,  6.0810e-04,
         9.0674e-04,  6.8452e-05,  7.5981e-04, -1.5338e-04, -7.5706e-04,
         1.0088e-03,  2.3899e-05,  2.5286e-04, -4.6399e-04,  1.0942e-03,
        -1.4346e-04, -5.4310e-04, -8.7422e-05, -7.0142e-04,  5.3653e-04,
         3.5544e-05, -6.7808e-04, -1.7695e-04,  3.5716e-04, -3.6297e-04,
        -6.3295e-04, -1.5442e-03, -1.7106e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.1313e-05, 1.9604e-05, 1.4454e-05, 1.1689e-05, 1.2844e-05, 2.1363e-05,
        6.2348e-06, 2.0130e-05, 3.8749e-05, 7.6842e-06, 1.4568e-05, 9.6298e-06,
        2.8458e-05, 2.3562e-05, 2.0964e-05, 1.4266e-05, 1.2696e-05, 4.1866e-05,
        9.6627e-06, 1.9952e-05, 3.3273e-05, 2.4177e-05, 1.2190e-05, 1.6473e-05,
        1.6374e-05, 1.2153e-05, 9.3030e-06, 1.6605e-05, 1.2503e-05, 1.6884e-05,
        1.7533e-05, 2.9036e-05, 1.2265e-05, 1.5068e-05, 1.6024e-05, 2.0509e-05,
        8.2551e-06, 9.9201e-06, 1.2593e-05, 2.9133e-05, 1.8006e-05, 1.1504e-05,
        9.5766e-06, 8.8456e-06, 1.6564e-05, 2.9056e-05, 1.6639e-05, 1.8038e-05,
        2.1245e-05, 2.4033e-05, 3.2943e-05, 1.6241e-05, 2.1223e-05, 2.3709e-05,
        1.5174e-05, 2.1990e-05, 2.3159e-05, 1.2885e-05, 2.0731e-05, 1.3643e-05,
        2.6761e-05, 1.8625e-05, 1.3740e-05, 1.3499e-05, 1.8733e-05, 1.0744e-05,
        1.3546e-05, 2.2682e-05, 6.8613e-06, 2.8510e-05, 1.2467e-05, 1.0389e-05,
        1.4710e-05, 1.4264e-05, 8.7005e-06, 1.7852e-05, 9.8920e-06, 1.8905e-05,
        1.0641e-05, 1.4346e-05, 1.2103e-05, 3.5834e-05, 1.4451e-05, 2.6492e-05,
        1.3690e-05, 1.3257e-05, 1.3931e-05, 2.4145e-05, 1.5912e-05, 1.6014e-05,
        1.2948e-05, 1.4489e-05, 1.4777e-05, 1.1817e-05, 2.4098e-05, 1.3860e-05,
        1.3651e-05, 1.4553e-05, 1.2290e-05, 1.3413e-05, 8.4334e-06, 1.5071e-05,
        1.3781e-05, 9.8152e-06, 2.2335e-05, 1.8534e-05, 1.3776e-05, 6.1121e-06,
        2.3820e-05, 1.4042e-05, 3.6658e-05, 1.7967e-05, 1.1189e-05, 2.2342e-05,
        3.3205e-05, 5.5590e-06, 1.4725e-05, 1.1585e-05, 3.4318e-05, 1.2191e-05,
        1.3527e-05, 1.1393e-05, 1.3655e-05, 1.3184e-05, 1.5427e-05, 2.5244e-05,
        1.5561e-05, 7.1802e-06], device='cuda:0')}, 49: {'step': tensor(30200.), 'exp_avg': tensor([-2.9735e-04, -3.8264e-05, -3.6587e-05,  2.5042e-05,  1.7500e-04,
         2.7934e-04,  2.8629e-04,  2.0437e-04, -1.2674e-04, -9.8497e-05,
         1.2914e-04,  2.0213e-04,  2.0884e-04,  9.5750e-05, -3.1956e-04,
        -9.8826e-05,  3.1432e-04, -1.2469e-04, -2.5047e-04, -3.8748e-04,
         1.0527e-04, -1.4470e-04, -2.3814e-04, -3.2584e-05, -4.2685e-04,
        -2.4431e-05,  1.8366e-04, -1.3624e-04,  1.5524e-04,  2.4557e-04,
        -1.2621e-04,  1.2942e-04,  2.3800e-06, -1.5540e-04,  6.9148e-05,
         2.9028e-04, -1.6644e-04,  2.2210e-05,  1.1073e-04, -5.1407e-05,
        -5.2884e-04,  1.7713e-04, -1.0316e-04,  3.1342e-05,  2.4441e-05,
        -2.3919e-04,  1.2597e-04, -9.8768e-05, -1.7026e-04,  1.4629e-05,
        -5.7956e-05, -4.4280e-05,  2.4697e-04, -2.6703e-06,  1.0616e-04,
        -1.4631e-04,  3.6861e-04, -5.9010e-04, -2.5754e-05,  3.6209e-04,
        -1.1997e-04,  1.6969e-04, -2.7654e-05, -1.9997e-04, -1.3146e-04,
         2.7988e-04,  1.7129e-04, -4.8642e-04,  4.7003e-04, -2.2061e-04,
        -5.1957e-04,  8.6567e-05,  2.2894e-04, -7.0851e-05, -4.6997e-04,
        -1.3793e-04,  2.9364e-05,  3.3936e-04,  4.6832e-05, -3.8240e-04,
        -3.2043e-04, -6.2235e-06,  1.2673e-04,  2.2573e-04, -1.0189e-04,
        -4.9392e-05, -3.0053e-04, -3.0240e-04,  5.5663e-05, -4.3713e-04,
         1.0599e-04, -2.1201e-04, -1.8841e-04, -1.1007e-04,  5.5585e-05,
        -2.7619e-04, -3.6063e-04, -2.5170e-04,  7.5378e-05,  5.9351e-05,
        -4.8524e-04,  2.0067e-04,  2.1712e-04, -8.3423e-05, -1.2366e-04,
         3.3667e-04, -5.6992e-05, -3.8675e-06, -3.8698e-04,  8.6298e-05,
        -3.6337e-04, -2.4421e-04, -7.7902e-05,  6.1659e-05,  8.9590e-05,
        -9.4831e-05,  1.1654e-04, -2.5817e-04, -1.0696e-04,  1.6204e-04,
        -1.9367e-04, -2.1294e-04,  6.0439e-05,  7.4063e-05, -2.7998e-04,
         2.6840e-04, -2.8885e-05,  1.3865e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.0200e-06, 8.3123e-07, 9.8966e-07, 1.1480e-06, 7.3255e-07, 7.7939e-07,
        6.9696e-07, 1.0856e-06, 1.1876e-06, 4.3125e-07, 1.0349e-06, 5.6158e-07,
        9.9687e-07, 7.1435e-07, 1.2124e-06, 1.0068e-06, 8.5503e-07, 1.0121e-06,
        9.9647e-07, 1.4319e-06, 8.5353e-07, 7.6173e-07, 1.1322e-06, 1.3329e-06,
        1.4395e-06, 7.2762e-07, 9.7333e-07, 1.3515e-06, 9.8992e-07, 9.8691e-07,
        8.5780e-07, 6.7397e-07, 7.2645e-07, 8.7981e-07, 7.0810e-07, 1.3463e-06,
        7.9898e-07, 9.3280e-07, 8.1651e-07, 9.4542e-07, 1.0513e-06, 1.4522e-06,
        6.8458e-07, 1.0481e-06, 5.8518e-07, 1.0715e-06, 1.2236e-06, 5.8785e-07,
        5.6725e-07, 8.5951e-07, 1.0669e-06, 6.7854e-07, 8.2892e-07, 9.9454e-07,
        1.0266e-06, 9.5738e-07, 1.2315e-06, 1.8228e-06, 1.0032e-06, 2.2820e-06,
        9.3307e-07, 1.5630e-06, 8.5760e-07, 1.0248e-06, 7.4871e-07, 7.4925e-07,
        1.1203e-06, 1.3169e-06, 1.2569e-06, 1.3009e-06, 1.0865e-06, 1.2032e-06,
        9.5616e-07, 9.1381e-07, 9.0988e-07, 1.0124e-06, 5.9638e-07, 6.6004e-07,
        1.0505e-06, 1.0168e-06, 8.4032e-07, 7.0852e-07, 9.2549e-07, 1.6782e-06,
        6.0430e-07, 1.1827e-06, 1.2194e-06, 4.9025e-07, 1.8856e-06, 1.3245e-06,
        7.0321e-07, 1.2955e-06, 1.1517e-06, 6.6777e-07, 1.3363e-06, 8.7743e-07,
        1.9291e-06, 2.2441e-06, 7.9707e-07, 1.6122e-06, 8.8899e-07, 9.5310e-07,
        1.2557e-06, 9.9515e-07, 1.3288e-06, 7.8361e-07, 1.2787e-06, 1.1347e-06,
        7.0910e-07, 6.7077e-07, 9.8615e-07, 1.0504e-06, 9.3275e-07, 3.6430e-07,
        9.4816e-07, 6.1543e-07, 6.0595e-07, 1.1055e-06, 1.0134e-06, 1.9516e-06,
        5.1315e-07, 1.2802e-06, 1.6242e-06, 4.6088e-07, 7.3398e-07, 1.3023e-06,
        8.1308e-07, 9.0172e-07], device='cuda:0')}, 50: {'step': tensor(30200.), 'exp_avg': tensor([ 1.2676e-04,  5.7571e-05,  6.9397e-05, -9.1114e-05,  2.8679e-05,
        -2.1833e-04,  1.0099e-04,  6.4856e-05,  2.8639e-04,  1.1537e-04,
        -1.7311e-04, -8.5508e-05,  2.1813e-04,  2.3057e-04, -1.2315e-04,
         1.7545e-04, -5.3520e-05, -1.9710e-04,  2.4095e-04,  1.2873e-04,
         4.9447e-05,  1.5383e-05,  6.0580e-05,  3.6273e-04, -2.9224e-04,
        -2.9071e-06, -2.8441e-05,  2.8036e-05,  2.3123e-04, -4.9220e-05,
        -2.3833e-04, -3.5299e-04,  1.7445e-04, -1.2703e-04, -2.3799e-04,
         3.5658e-04, -7.6333e-05,  2.3445e-04, -7.7462e-05,  8.4133e-05,
         1.0094e-04, -1.3745e-04,  4.1197e-04,  2.0157e-04,  3.2509e-04,
        -3.0467e-04,  2.0671e-04,  1.7301e-04, -3.7353e-05, -1.0999e-04,
        -1.4823e-04, -1.4986e-04,  3.1028e-04, -6.1991e-06, -1.6703e-04,
         1.6026e-04,  1.7683e-05,  8.0208e-05,  4.0042e-04,  4.8771e-06,
        -1.1602e-04, -2.3420e-04, -2.1217e-05,  3.6797e-05, -2.4178e-04,
         1.3820e-04,  2.4423e-04, -2.1972e-04,  1.5265e-04,  1.6458e-04,
         2.6432e-04, -1.4531e-04, -1.6029e-04, -2.6931e-04, -1.0663e-04,
        -3.1010e-04, -1.9147e-04,  1.1602e-04,  2.5182e-05,  2.4924e-04,
        -2.0717e-04, -8.1736e-05,  2.3249e-05,  7.5074e-05,  2.4311e-04,
        -2.2052e-04,  4.7448e-04,  3.8382e-06, -2.3907e-04, -9.1791e-05,
        -6.6680e-05, -6.0351e-05, -1.5150e-04,  2.7209e-04,  2.7166e-05,
         1.8156e-04, -3.0249e-05,  1.7082e-04, -7.0982e-05, -9.8146e-06,
         5.1943e-04, -3.8545e-04,  2.4092e-04, -2.1368e-04, -8.0113e-05,
         7.7982e-05,  1.1742e-05, -1.5757e-04,  3.4980e-05, -1.0633e-04,
         5.1042e-05,  6.2555e-05, -2.3210e-04,  8.4127e-06, -2.7309e-04,
         4.8176e-05,  1.2755e-04,  2.5961e-04, -6.6095e-05, -1.8018e-04,
        -2.4400e-05, -3.1353e-05, -1.2824e-04,  1.3471e-05, -4.8110e-05,
         3.7543e-05, -2.9188e-04, -1.2971e-04], device='cuda:0'), 'exp_avg_sq': tensor([9.6854e-07, 1.4040e-06, 1.0697e-06, 1.0727e-06, 1.0372e-06, 1.2956e-06,
        8.8949e-07, 1.8607e-06, 1.3234e-06, 8.6252e-07, 1.0660e-06, 7.9000e-07,
        1.3087e-06, 7.7191e-07, 1.2188e-06, 1.1828e-06, 8.0022e-07, 1.2793e-06,
        1.5344e-06, 1.5178e-06, 7.6785e-07, 7.9130e-07, 8.8691e-07, 1.5760e-06,
        1.2938e-06, 9.5530e-07, 1.2832e-06, 1.2341e-06, 1.0503e-06, 9.3034e-07,
        9.7953e-07, 8.1302e-07, 1.0184e-06, 9.3808e-07, 1.1111e-06, 1.5242e-06,
        1.6451e-06, 6.4325e-07, 8.2979e-07, 1.5594e-06, 1.4672e-06, 1.2508e-06,
        1.4652e-06, 6.6233e-07, 8.0105e-07, 1.1378e-06, 1.2367e-06, 7.5659e-07,
        5.8018e-07, 1.7144e-06, 9.4036e-07, 6.6626e-07, 1.0912e-06, 2.1592e-06,
        1.7677e-06, 6.8111e-07, 1.4878e-06, 3.2857e-06, 9.9636e-07, 1.5368e-06,
        7.0392e-07, 9.5597e-07, 1.2959e-06, 9.8081e-07, 7.5702e-07, 6.1044e-07,
        1.1803e-06, 1.1512e-06, 1.1585e-06, 8.8927e-07, 1.1435e-06, 1.5023e-06,
        1.2692e-06, 1.3936e-06, 9.8829e-07, 1.3419e-06, 9.8808e-07, 8.2218e-07,
        1.3057e-06, 2.1289e-06, 1.2487e-06, 7.0740e-07, 1.3581e-06, 1.8196e-06,
        1.0441e-06, 1.1141e-06, 2.3445e-06, 7.7972e-07, 1.8479e-06, 1.7908e-06,
        8.0061e-07, 7.3319e-07, 1.6998e-06, 1.1665e-06, 1.0278e-06, 9.2835e-07,
        1.5061e-06, 1.7252e-06, 1.2691e-06, 1.5261e-06, 1.1256e-06, 1.4449e-06,
        1.6126e-06, 1.0550e-06, 7.1563e-07, 1.4881e-06, 1.1280e-06, 1.0085e-06,
        9.4556e-07, 9.9092e-07, 7.2863e-07, 1.4803e-06, 9.5199e-07, 5.2949e-07,
        7.3369e-07, 1.0108e-06, 6.8996e-07, 1.2067e-06, 1.4626e-06, 1.6501e-06,
        6.4977e-07, 8.2888e-07, 1.1794e-06, 4.2124e-07, 1.3082e-06, 9.1443e-07,
        1.1249e-06, 9.4457e-07], device='cuda:0')}, 51: {'step': tensor(30200.), 'exp_avg': tensor([[-1.8141e-04,  4.6467e-05,  3.8353e-06,  ..., -1.5336e-04,
          6.9411e-05,  1.4137e-04],
        [-2.6427e-04, -3.0625e-04,  5.9394e-06,  ...,  2.8008e-04,
         -2.3485e-04, -8.4603e-05],
        [ 2.1613e-04,  2.2713e-04,  2.5489e-04,  ...,  2.7271e-05,
         -4.4787e-04, -6.7878e-05],
        ...,
        [-9.9813e-05, -2.9486e-04,  9.4772e-05,  ...,  2.9349e-04,
         -3.0539e-04, -9.3951e-05],
        [-1.7416e-04, -1.1711e-04, -4.8755e-05,  ..., -1.7120e-04,
         -1.7476e-04, -1.2890e-04],
        [ 1.3153e-04, -1.7762e-04, -2.1454e-05,  ..., -5.0954e-05,
         -2.8185e-04, -1.1812e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[8.9918e-07, 7.2770e-07, 1.5005e-06,  ..., 2.9671e-06, 1.2620e-06,
         1.3391e-06],
        [6.2483e-07, 3.6192e-07, 9.0410e-07,  ..., 1.0709e-06, 6.2652e-07,
         7.0463e-07],
        [1.4400e-06, 1.1038e-06, 1.7654e-06,  ..., 2.3350e-06, 1.7289e-06,
         1.5472e-06],
        ...,
        [1.9701e-06, 1.5320e-06, 2.3156e-06,  ..., 2.2431e-06, 1.7893e-06,
         1.6935e-06],
        [1.5295e-06, 8.6844e-07, 1.1856e-06,  ..., 8.8828e-07, 1.0256e-06,
         9.3252e-07],
        [4.6291e-07, 2.5338e-07, 4.7968e-07,  ..., 5.9707e-07, 4.5950e-07,
         7.1089e-07]], device='cuda:0')}, 52: {'step': tensor(30200.), 'exp_avg': tensor([ 1.0076e-04, -4.0362e-04,  6.6678e-05,  5.6032e-05, -1.4512e-04,
        -3.4572e-04,  4.1486e-04, -3.6210e-04, -3.2478e-04,  1.4787e-04,
        -1.1814e-05, -1.4554e-04,  2.8067e-04, -1.7741e-04, -9.7726e-05,
        -1.2269e-04, -2.3594e-04, -3.0178e-04,  1.7023e-04, -9.2914e-05,
         1.3249e-04, -5.1274e-04,  1.4322e-04,  3.5613e-04,  1.3249e-04,
        -1.5196e-04, -2.8662e-05, -2.9720e-05, -2.1397e-04,  1.6259e-04,
         1.8681e-04,  3.6784e-05, -2.2300e-04, -3.9020e-04,  3.2163e-04,
        -2.0644e-04,  1.1268e-04, -2.4087e-04,  8.1974e-05, -9.1920e-05,
         1.9722e-04,  5.5231e-05, -7.7918e-05, -1.4601e-04,  5.9204e-05,
         3.0393e-05,  6.0182e-05,  1.7572e-04,  1.2113e-04, -3.1473e-05,
         2.3569e-04,  5.3447e-04,  1.2356e-04,  6.5421e-06, -2.6959e-04,
         8.4575e-05, -5.3817e-05, -3.7130e-04, -1.2811e-04,  4.2919e-04,
         4.9189e-05,  2.4192e-05, -1.9663e-04,  6.5478e-05, -2.4662e-04,
         2.1175e-05, -1.7207e-04, -1.8057e-04,  1.5476e-04,  1.7431e-04,
        -1.9284e-04, -2.7133e-04,  1.1597e-04,  1.6609e-04,  2.3191e-04,
         1.9767e-04, -2.6335e-04, -1.4130e-04,  3.0026e-04,  2.2736e-04,
         8.7099e-06,  1.7953e-04,  2.2123e-04, -1.2590e-05, -2.3110e-04,
         9.3178e-05, -2.8126e-04, -4.2680e-06, -9.1889e-05, -8.1766e-05,
        -3.1125e-04, -1.0212e-04, -2.6105e-04,  6.3764e-04, -2.5446e-05,
        -3.2457e-04,  8.3929e-05, -1.0124e-04,  2.4343e-04, -1.5078e-05,
         2.0534e-04, -2.4225e-04, -4.2949e-05,  9.4747e-05, -1.2522e-04,
         1.4185e-04, -3.1246e-04, -7.9715e-05, -6.7617e-05,  7.2692e-06,
        -1.1603e-04, -8.4649e-06,  4.3582e-04, -1.7869e-04, -4.6485e-04,
         6.6564e-05,  1.6091e-04, -2.8669e-05, -9.2557e-05,  3.5837e-04,
         1.7160e-04, -5.4062e-05,  3.1202e-04, -1.4913e-04, -5.2536e-04,
        -3.1300e-05, -7.0592e-05,  1.1239e-04, -3.5563e-05,  5.8910e-05,
        -1.0336e-04,  3.4222e-04, -5.0298e-05,  5.1234e-05,  1.5473e-04,
         2.0798e-04, -3.8301e-04, -2.9770e-04, -1.2786e-04,  2.5270e-04,
         1.0766e-04, -2.5263e-04, -3.5139e-05, -1.2648e-04,  3.4478e-05,
         2.0585e-04,  1.1968e-06, -2.7735e-04, -4.6540e-05, -1.6324e-04,
         1.0404e-04, -8.6213e-05,  1.3858e-04,  4.9327e-05, -1.6773e-04,
        -1.3268e-04, -1.6035e-04,  2.9412e-04,  1.3170e-05, -1.3410e-04,
         2.0576e-04,  2.6491e-04, -1.2429e-04, -2.5134e-05, -9.1040e-05,
         4.4240e-04, -3.3640e-04, -3.8706e-04,  9.2503e-05, -1.7499e-04,
        -1.4586e-04,  2.2280e-04,  3.9337e-05, -9.9689e-05,  2.2385e-04,
        -7.5036e-05, -4.5004e-04, -6.6203e-05, -1.0870e-04, -8.7287e-05,
         3.7495e-05,  5.7403e-05,  1.4193e-04, -1.2135e-04,  3.1080e-04,
        -9.4693e-05,  4.6647e-04,  1.1534e-04,  2.9753e-05,  2.2531e-04,
         1.5912e-05, -1.3421e-04,  8.5025e-06,  2.9458e-04,  5.2561e-05,
        -2.8605e-05,  5.4781e-05, -1.3108e-04,  2.0184e-04,  8.2024e-05,
        -6.5331e-05,  7.9612e-05, -1.6327e-04,  4.3822e-05, -6.0219e-04,
        -7.5601e-05, -1.1380e-04, -2.3513e-04, -1.3915e-04,  2.4696e-05,
         1.9730e-04, -8.1023e-05, -1.0995e-04,  2.0947e-04,  2.1490e-04,
         2.9723e-04, -1.5798e-04, -3.1722e-05,  2.4291e-05, -3.7320e-05,
        -3.3079e-04, -1.3854e-04,  7.2223e-05,  1.3973e-04, -1.5305e-04,
        -1.9852e-04, -1.8555e-04, -6.5644e-05, -3.5563e-04, -3.1051e-04,
         2.2415e-04,  7.9411e-05,  6.2916e-04, -3.4257e-04,  1.6195e-04,
        -4.9769e-05, -3.7624e-05, -4.3968e-04, -4.8799e-05,  3.6686e-05,
         6.1666e-05,  1.8818e-04, -1.8097e-04,  7.2129e-05, -3.7040e-04,
        -1.2389e-04,  1.8862e-04, -1.6780e-04, -1.3843e-04,  3.7239e-04,
        -2.0464e-04, -5.8853e-05, -1.5824e-05,  3.2611e-04, -7.6383e-05,
        -2.7449e-05], device='cuda:0'), 'exp_avg_sq': tensor([1.0703e-06, 7.8193e-07, 1.0915e-06, 1.2418e-06, 1.2387e-06, 1.6518e-06,
        1.5394e-06, 1.3479e-06, 8.6917e-07, 1.4936e-06, 6.3834e-07, 2.8173e-06,
        1.0768e-06, 1.2214e-06, 6.8596e-07, 1.3084e-06, 1.1238e-06, 1.4585e-06,
        6.3673e-07, 1.2647e-06, 1.0544e-06, 2.7815e-06, 1.0591e-06, 9.2106e-07,
        2.2819e-06, 8.5231e-07, 1.2485e-06, 1.3567e-06, 1.7759e-06, 2.4570e-06,
        1.9892e-06, 5.7855e-07, 9.9089e-07, 2.2680e-06, 9.6483e-07, 1.4548e-06,
        6.8545e-07, 8.5187e-07, 1.2963e-06, 1.1207e-06, 9.5258e-07, 1.2205e-06,
        1.0017e-06, 1.3127e-06, 1.5381e-06, 1.0897e-06, 1.6697e-06, 6.2137e-07,
        1.4133e-06, 1.5684e-06, 9.5459e-07, 1.8473e-06, 1.4925e-06, 1.8684e-06,
        7.9884e-07, 8.5029e-07, 7.8191e-07, 1.2329e-06, 6.7158e-07, 1.6571e-06,
        5.8271e-07, 1.5880e-06, 1.6262e-06, 1.0135e-06, 8.0025e-07, 1.1432e-06,
        1.8561e-06, 1.4121e-06, 5.5200e-07, 1.0582e-06, 8.8650e-07, 1.3544e-06,
        8.3791e-07, 8.6831e-07, 6.5447e-07, 1.0948e-06, 6.6653e-07, 2.1916e-06,
        1.8960e-06, 1.5032e-06, 4.3113e-07, 2.2119e-06, 9.1230e-07, 3.8682e-07,
        1.5713e-06, 1.2311e-06, 5.5865e-07, 1.7821e-06, 1.5155e-06, 2.2958e-06,
        1.5913e-06, 1.3315e-06, 5.6713e-07, 1.5227e-06, 1.6279e-06, 9.6729e-07,
        2.7468e-06, 1.0309e-06, 9.9781e-07, 1.3553e-06, 9.2736e-07, 5.6966e-07,
        1.4226e-06, 1.5665e-06, 1.1389e-06, 7.1306e-07, 9.6308e-07, 1.5223e-06,
        2.2713e-06, 1.4699e-06, 1.4381e-06, 8.7396e-07, 1.2490e-06, 2.2542e-06,
        1.8262e-06, 5.8398e-07, 2.7858e-06, 7.5287e-07, 5.5023e-07, 1.9693e-06,
        9.6746e-07, 1.3260e-06, 1.9462e-06, 1.4198e-06, 7.5763e-07, 7.0582e-07,
        7.4394e-07, 5.7088e-07, 1.1035e-06, 1.2212e-06, 8.9038e-07, 6.9337e-07,
        8.7254e-07, 1.1652e-06, 1.6201e-06, 2.1886e-06, 1.0811e-06, 1.5185e-06,
        1.6220e-06, 8.5444e-07, 6.5877e-07, 2.1391e-06, 2.2830e-06, 4.7460e-07,
        1.1124e-06, 1.8193e-06, 1.5522e-06, 9.9171e-07, 1.5568e-06, 2.4824e-06,
        1.4495e-06, 2.7802e-06, 1.8063e-06, 1.1671e-06, 1.4515e-06, 3.2990e-06,
        8.3692e-07, 1.0399e-06, 1.1846e-06, 8.1739e-07, 9.5863e-07, 9.9549e-07,
        3.0900e-06, 6.2475e-07, 4.9803e-07, 1.3735e-06, 1.7293e-06, 1.0684e-06,
        6.4112e-07, 1.0055e-06, 2.3450e-06, 2.2139e-06, 8.8870e-07, 2.0435e-06,
        1.7155e-06, 8.9561e-07, 1.6318e-06, 7.7115e-07, 2.8077e-06, 7.9875e-07,
        9.4384e-07, 9.8157e-07, 1.2627e-06, 1.7190e-06, 5.7100e-07, 1.3020e-06,
        1.2354e-06, 1.0438e-06, 9.0104e-07, 1.4296e-06, 1.5117e-06, 2.7257e-06,
        1.5614e-06, 1.8172e-06, 1.0316e-06, 1.6803e-06, 8.3003e-07, 1.4994e-06,
        9.7654e-07, 9.2443e-07, 9.0331e-07, 7.7872e-07, 1.5217e-06, 1.2647e-06,
        2.9452e-06, 8.8316e-07, 1.2490e-06, 6.8657e-07, 1.8770e-06, 2.0952e-06,
        1.4162e-06, 5.4638e-07, 9.4050e-07, 1.8151e-06, 1.3399e-06, 1.1997e-06,
        7.4301e-07, 2.6149e-06, 8.0762e-07, 8.4818e-07, 8.4986e-07, 1.4712e-06,
        1.1585e-06, 1.2191e-06, 5.2814e-07, 1.1170e-06, 2.4240e-06, 2.2357e-06,
        2.3007e-06, 1.6503e-06, 9.5586e-07, 1.4748e-06, 1.5251e-06, 8.5272e-07,
        1.0685e-06, 9.0186e-07, 1.4509e-06, 9.3981e-07, 1.1551e-06, 1.0378e-06,
        9.9719e-07, 2.0982e-06, 1.1766e-06, 9.2421e-07, 1.1868e-06, 9.1823e-07,
        9.9764e-07, 1.0213e-06, 9.0669e-07, 1.0773e-06, 1.3670e-06, 7.2854e-07,
        7.6745e-07, 1.7508e-06, 1.0286e-06, 4.7482e-07], device='cuda:0')}, 53: {'step': tensor(30200.), 'exp_avg': tensor([[ 3.6747e-04, -3.7401e-04,  8.1364e-05,  ..., -1.8217e-04,
         -2.3823e-04, -1.4516e-05],
        [-3.3692e-04, -1.3726e-04, -2.6076e-04,  ...,  1.1246e-04,
          1.1833e-04,  1.8870e-04],
        [ 1.6211e-04, -2.0736e-04, -6.8971e-04,  ...,  2.2886e-04,
         -5.4914e-04,  3.9921e-05],
        ...,
        [ 5.2209e-04, -1.2757e-04, -3.1754e-04,  ...,  6.9239e-05,
         -1.0357e-04,  1.5804e-04],
        [-1.2242e-04,  3.6343e-05, -4.0862e-04,  ..., -4.7267e-05,
         -1.7453e-04, -1.2212e-05],
        [-1.8840e-04, -7.0751e-04, -6.4377e-04,  ..., -3.7315e-04,
         -1.8571e-04,  7.7311e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[1.7314e-06, 1.1557e-06, 3.0488e-06,  ..., 1.7683e-06, 7.8518e-07,
         7.0422e-07],
        [2.5344e-06, 1.4368e-06, 5.3916e-06,  ..., 2.7622e-06, 1.5291e-06,
         8.1547e-07],
        [2.4938e-06, 1.3899e-06, 5.2739e-06,  ..., 3.0365e-06, 1.6945e-06,
         8.9829e-07],
        ...,
        [2.1403e-06, 1.5412e-06, 6.7508e-06,  ..., 3.7564e-06, 1.6099e-06,
         1.0034e-06],
        [2.1660e-06, 1.6107e-06, 4.5896e-06,  ..., 2.5252e-06, 9.0092e-07,
         8.2773e-07],
        [1.8711e-06, 1.2864e-06, 4.6211e-06,  ..., 1.5371e-06, 9.7874e-07,
         8.4953e-07]], device='cuda:0')}, 54: {'step': tensor(30200.), 'exp_avg': tensor([ 4.5371e-04,  6.0538e-04,  2.8617e-05,  1.4683e-04, -8.1369e-04,
         6.6146e-04,  1.2263e-03,  2.6803e-04, -2.4161e-05, -4.9683e-04,
         5.7179e-04,  8.5941e-04, -3.7239e-04,  9.4284e-04, -3.7332e-04,
         6.5087e-04, -4.0662e-04,  2.3689e-04, -1.9615e-04, -4.2641e-04,
        -8.4106e-04, -1.7640e-04,  1.2592e-04,  1.4015e-04, -7.9590e-04,
         2.1702e-04, -1.3155e-03, -2.9678e-04,  1.0895e-03,  2.7109e-05,
         6.0380e-04, -8.0291e-04,  2.7704e-04, -1.8901e-04, -6.8094e-04,
        -2.4460e-05, -2.8627e-04,  7.6355e-04, -1.9655e-05,  6.5294e-04,
        -7.2206e-05, -5.1605e-04, -6.8640e-05,  4.9239e-04,  2.0292e-04,
        -5.2394e-04,  1.0165e-04, -5.7298e-06,  5.7987e-04,  1.4292e-03,
        -9.2885e-04,  1.6671e-04, -2.8776e-04, -5.7053e-05,  6.7642e-04,
         4.3761e-04,  5.3104e-04, -9.3084e-04, -5.1740e-04, -1.6925e-04,
        -1.5380e-03, -1.1328e-03,  1.6312e-04,  3.3305e-04,  2.9224e-04,
        -1.0126e-03, -1.5851e-03,  8.6547e-04, -4.4539e-04, -6.4281e-04,
         1.7288e-04, -6.9823e-04, -4.2866e-04,  4.5888e-05, -5.6918e-04,
        -3.2108e-04,  2.0169e-04,  8.1720e-04,  2.4046e-04,  5.4188e-04,
         1.1034e-04,  4.1204e-04, -3.7337e-04,  1.3500e-04,  3.2849e-04,
        -7.2805e-04,  5.6880e-05, -6.9414e-05, -5.2340e-04, -3.4065e-04,
         7.6495e-04, -3.1747e-04,  5.8934e-04, -7.5474e-05,  8.4913e-04,
         9.2970e-04,  1.3144e-04,  2.4566e-04,  4.6944e-04, -5.6389e-04,
         2.2022e-04, -7.5420e-04, -6.2691e-04,  1.9093e-04,  2.7870e-04,
         1.0156e-03,  3.3992e-04,  5.3649e-04, -9.1131e-05, -6.8776e-04,
         1.5104e-03,  3.5571e-04,  1.0905e-04, -3.8260e-04,  1.8322e-03,
         3.0873e-04, -1.0543e-04, -2.7654e-04, -4.5538e-04,  1.0365e-03,
         1.3619e-04, -5.5209e-04, -5.6965e-05,  2.2184e-04, -1.2155e-04,
        -8.1161e-04, -1.2062e-03, -5.0372e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.0713e-05, 2.0311e-05, 1.2486e-05, 1.1357e-05, 1.0641e-05, 1.9743e-05,
        5.7715e-06, 1.5179e-05, 3.2317e-05, 8.0899e-06, 1.4800e-05, 1.0086e-05,
        2.5315e-05, 2.3020e-05, 2.1077e-05, 1.3776e-05, 1.4108e-05, 4.2272e-05,
        8.1063e-06, 2.2209e-05, 3.2094e-05, 2.2877e-05, 9.9479e-06, 1.4011e-05,
        1.5544e-05, 1.1433e-05, 8.2407e-06, 1.6273e-05, 1.1029e-05, 1.6876e-05,
        1.5915e-05, 2.5583e-05, 1.1290e-05, 1.3044e-05, 1.6996e-05, 1.7126e-05,
        8.0596e-06, 9.5266e-06, 1.3752e-05, 2.2475e-05, 1.5427e-05, 1.3129e-05,
        9.3569e-06, 9.1601e-06, 1.8172e-05, 2.5514e-05, 1.5021e-05, 1.8553e-05,
        2.1893e-05, 2.0909e-05, 3.6612e-05, 1.6188e-05, 2.0155e-05, 2.6026e-05,
        1.7093e-05, 2.2927e-05, 2.0491e-05, 9.3407e-06, 1.8982e-05, 1.4370e-05,
        2.4231e-05, 1.7760e-05, 1.4069e-05, 1.2464e-05, 1.8186e-05, 9.7108e-06,
        1.4979e-05, 2.1095e-05, 7.3667e-06, 2.7205e-05, 1.3767e-05, 7.8162e-06,
        1.3787e-05, 1.4919e-05, 7.8218e-06, 1.7496e-05, 8.9727e-06, 1.8618e-05,
        1.1364e-05, 1.6772e-05, 9.3527e-06, 3.5951e-05, 1.6151e-05, 1.9704e-05,
        1.5676e-05, 1.2877e-05, 1.0853e-05, 2.1997e-05, 1.3302e-05, 1.1463e-05,
        1.2000e-05, 1.4060e-05, 1.6648e-05, 1.3348e-05, 2.2425e-05, 1.1078e-05,
        1.5033e-05, 1.1318e-05, 1.1480e-05, 1.2876e-05, 7.8919e-06, 1.1137e-05,
        1.5641e-05, 9.4500e-06, 2.0301e-05, 1.6365e-05, 1.2948e-05, 5.6855e-06,
        2.1661e-05, 1.2823e-05, 3.7491e-05, 1.8924e-05, 1.1348e-05, 2.0727e-05,
        3.4043e-05, 6.2830e-06, 1.4181e-05, 1.2509e-05, 2.7469e-05, 1.2720e-05,
        1.2392e-05, 1.0918e-05, 1.1504e-05, 1.3566e-05, 1.3983e-05, 2.6155e-05,
        1.3990e-05, 6.0834e-06], device='cuda:0')}, 55: {'step': tensor(30200.), 'exp_avg': tensor([ 7.6911e-04, -6.3118e-04, -2.6101e-04,  6.5820e-04, -3.7338e-04,
        -3.9112e-04, -9.8433e-04, -1.2281e-03, -1.3388e-03,  1.2343e-04,
        -5.8467e-04, -7.6477e-04, -1.2722e-04, -8.6659e-04, -1.6628e-04,
         1.4272e-04, -8.8495e-05,  2.7969e-04,  4.4843e-04,  1.3016e-04,
         3.2432e-04,  1.3888e-03,  6.0758e-04, -7.5034e-04, -1.2233e-03,
        -1.7884e-03, -1.1672e-04,  1.6777e-04, -5.1946e-05,  2.6048e-04,
         2.4111e-04, -3.2530e-04, -1.0327e-03, -1.0366e-03,  9.1788e-04,
        -3.3686e-04,  3.4995e-05,  2.6215e-05, -6.4703e-04,  5.7914e-04,
        -1.1798e-03,  1.9848e-04, -8.3480e-04, -4.5586e-04, -1.3929e-04,
        -8.4313e-04,  2.7266e-04, -3.5172e-04, -1.5873e-05, -2.7189e-04,
        -2.4564e-04, -2.4790e-04, -3.6860e-04, -1.0084e-05,  1.7811e-04,
        -4.4475e-04,  7.1531e-04, -4.8205e-06,  4.5936e-04, -1.2759e-03,
        -9.5349e-04, -5.7558e-04, -1.8096e-05, -5.5461e-04, -1.9048e-04,
        -4.3841e-04,  1.1768e-03, -4.0413e-04, -1.5216e-04, -1.5917e-04,
         1.2746e-04, -3.2372e-04, -1.1019e-04, -7.4792e-04,  1.2279e-03,
         1.8043e-04,  8.2569e-04, -1.9083e-04, -6.9207e-04,  1.6885e-05,
         4.4633e-04, -1.3193e-03, -1.1079e-04,  3.5165e-04, -4.5489e-04,
        -5.1715e-05, -2.5353e-04,  4.0730e-04, -1.9124e-03, -1.0745e-03,
        -4.7002e-04,  1.0214e-03, -5.4728e-04,  3.3586e-04, -1.0627e-03,
         3.5305e-05, -8.3578e-04,  1.9112e-05, -1.2912e-04, -8.0648e-05,
        -5.1639e-04,  1.1900e-04,  3.4417e-04,  7.9977e-05, -6.9631e-04,
        -4.7039e-04,  1.8172e-03, -8.8711e-04, -1.2841e-04,  3.1919e-04,
         4.0761e-04, -6.5179e-04,  2.1297e-04,  5.8111e-04, -8.6554e-04,
        -2.8357e-04, -2.6371e-04,  2.3252e-04, -5.8374e-04, -2.5423e-04,
        -4.6060e-04, -3.1915e-04,  1.3286e-03, -6.0795e-04, -4.3852e-04,
         9.6831e-05,  2.2447e-04,  2.5958e-04], device='cuda:0'), 'exp_avg_sq': tensor([6.8850e-06, 8.5653e-06, 6.5726e-06, 9.1298e-06, 3.1945e-06, 7.7014e-06,
        3.9792e-06, 1.2444e-05, 1.2997e-05, 4.3020e-06, 5.7289e-06, 3.8749e-06,
        3.8930e-06, 8.8060e-06, 5.7148e-06, 1.2013e-05, 1.0041e-05, 4.6284e-06,
        5.3062e-06, 5.8841e-06, 3.6795e-06, 7.6036e-06, 6.4941e-06, 1.1703e-05,
        8.7001e-06, 8.4272e-06, 4.0998e-06, 1.2069e-05, 1.1131e-05, 9.8899e-06,
        6.3104e-06, 7.3984e-06, 5.3094e-06, 7.9008e-06, 8.7787e-06, 6.5315e-06,
        4.7640e-06, 8.2522e-06, 5.8493e-06, 1.0252e-05, 7.3608e-06, 8.2706e-06,
        5.6162e-06, 4.2090e-06, 4.1919e-06, 9.3838e-06, 5.7579e-06, 4.3724e-06,
        8.0439e-06, 6.6290e-06, 8.5720e-06, 7.4949e-06, 1.2527e-05, 1.1583e-05,
        5.0913e-06, 5.0130e-06, 5.5399e-06, 6.2860e-06, 6.2951e-06, 7.9684e-06,
        8.6310e-06, 6.7532e-06, 4.6939e-06, 6.3145e-06, 4.2115e-06, 7.7063e-06,
        5.0608e-06, 6.5325e-06, 5.7547e-06, 1.2790e-05, 7.8957e-06, 4.2503e-06,
        4.5932e-06, 2.4373e-06, 5.0734e-06, 1.0303e-05, 3.1123e-06, 7.6993e-06,
        4.3396e-06, 3.2516e-06, 3.1357e-06, 4.7185e-06, 6.8658e-06, 5.7884e-06,
        7.4312e-06, 1.4288e-05, 5.9825e-06, 8.1418e-06, 1.3817e-05, 7.2827e-06,
        6.3871e-06, 1.0124e-05, 6.7630e-06, 3.6720e-06, 9.1325e-06, 1.0276e-05,
        8.5534e-06, 2.1273e-05, 7.9653e-06, 8.6849e-06, 3.3147e-06, 5.0621e-06,
        4.6431e-06, 6.9086e-06, 1.0301e-05, 4.6541e-06, 1.0213e-05, 7.7007e-06,
        3.3797e-06, 7.0011e-06, 5.1672e-06, 5.7523e-06, 5.9085e-06, 4.1157e-06,
        1.3006e-05, 5.5337e-06, 7.1483e-06, 3.7186e-06, 1.0969e-05, 5.9569e-06,
        5.7593e-06, 9.6804e-06, 1.3467e-05, 9.5521e-06, 6.5986e-06, 8.6624e-06,
        7.4346e-06, 7.9298e-06], device='cuda:0')}, 56: {'step': tensor(30200.), 'exp_avg': tensor([ 9.0393e-04, -1.2875e-05,  1.1845e-04,  9.1860e-04, -6.2771e-05,
         8.6546e-04,  7.1671e-04, -1.0072e-03, -1.2163e-04, -2.8158e-04,
         3.6704e-04,  3.4953e-04,  1.0996e-03,  5.2008e-05,  6.7062e-04,
         6.4869e-04, -8.4940e-04, -7.4194e-05,  9.3422e-05, -5.2368e-04,
        -1.0110e-03,  7.5190e-04,  1.8824e-04,  5.3690e-04, -5.3942e-04,
         5.4885e-04, -7.8353e-04, -1.3523e-03,  1.5496e-03, -1.1394e-03,
         5.9442e-04, -3.4690e-04, -2.0808e-05,  1.0809e-04, -1.3132e-03,
        -4.2300e-05, -1.1925e-04,  1.4234e-03, -2.4786e-04,  1.4165e-03,
        -1.6977e-04,  6.9743e-04, -3.7311e-04,  4.3639e-04, -7.8027e-05,
        -2.5681e-04,  5.0712e-04,  3.8221e-04,  5.2088e-04,  1.1121e-03,
        -4.4697e-04, -2.5735e-04,  3.5160e-04, -1.7434e-04, -1.7179e-04,
        -2.5453e-05, -3.9114e-04,  5.4651e-04, -4.3299e-04, -1.2593e-03,
        -2.6151e-04, -5.7426e-04,  3.6368e-04,  1.4327e-04, -2.6913e-04,
        -1.9185e-03, -1.1329e-03,  6.6344e-04, -1.0552e-04, -6.6766e-05,
        -3.3933e-04, -8.4715e-04,  6.3766e-04,  5.5929e-04, -1.2528e-03,
         3.4787e-05,  5.3968e-04,  8.3749e-04,  1.8596e-04,  7.7094e-04,
        -1.1869e-04,  4.9067e-04, -5.8642e-04,  4.4840e-04,  2.9519e-04,
        -1.0587e-03,  1.0475e-04, -7.8396e-04, -3.0146e-04, -1.3669e-05,
         3.7382e-04, -7.3863e-04, -3.1270e-04, -2.7147e-04,  5.0200e-04,
         1.6195e-03, -8.6813e-05, -1.5762e-03,  8.3904e-04, -9.3651e-04,
         9.8458e-04, -1.5828e-03, -1.3175e-03, -6.0086e-04,  1.1764e-03,
         5.0281e-04, -1.9275e-04,  2.6896e-04, -3.5811e-04, -8.3967e-04,
         4.4510e-04,  6.8499e-04,  4.7368e-04, -2.9014e-04,  1.7149e-03,
         1.3396e-03, -1.4003e-04,  7.5790e-04, -6.5933e-04,  5.8433e-04,
        -8.1278e-04, -1.1237e-03,  5.1188e-04,  5.6289e-04, -1.3246e-04,
        -3.1925e-04, -1.3789e-03, -1.2529e-04], device='cuda:0'), 'exp_avg_sq': tensor([5.8913e-06, 1.3651e-05, 4.5599e-06, 1.2986e-05, 4.5239e-06, 9.4465e-06,
        6.4478e-06, 9.8547e-06, 9.7008e-06, 7.5663e-06, 1.1298e-05, 5.0928e-06,
        1.0111e-05, 1.5465e-05, 8.6418e-06, 1.7529e-05, 1.2119e-05, 1.7071e-05,
        7.3680e-06, 7.4103e-06, 4.4240e-06, 1.6462e-05, 3.9191e-06, 2.4478e-05,
        1.8956e-05, 6.9000e-06, 4.9678e-06, 1.0704e-05, 1.8815e-05, 1.4775e-05,
        1.0854e-05, 8.2975e-06, 1.2090e-05, 5.4606e-06, 1.7567e-05, 5.2325e-06,
        8.4977e-06, 8.9512e-06, 7.5441e-06, 2.4104e-05, 8.4083e-06, 5.3134e-06,
        1.0064e-05, 3.7354e-06, 4.4640e-06, 1.3912e-05, 8.3443e-06, 5.6876e-06,
        1.1123e-05, 1.5344e-05, 1.4781e-05, 1.6050e-05, 1.0659e-05, 8.0757e-06,
        4.9640e-06, 1.3858e-05, 7.8278e-06, 6.8543e-06, 6.6699e-06, 7.2596e-06,
        1.8408e-05, 7.8004e-06, 7.8122e-06, 8.7104e-06, 5.0235e-06, 1.2877e-05,
        1.5640e-05, 3.5928e-06, 9.9343e-06, 7.5863e-06, 1.3183e-05, 5.8193e-06,
        7.8477e-06, 7.5343e-06, 1.0143e-05, 5.4753e-06, 5.0457e-06, 8.2009e-06,
        6.6905e-06, 4.7377e-06, 2.9777e-06, 8.8751e-06, 6.9115e-06, 7.8243e-06,
        4.3062e-06, 8.5053e-06, 1.0547e-05, 1.0595e-05, 1.4385e-05, 6.4253e-06,
        6.1335e-06, 9.6340e-06, 8.7317e-06, 4.2654e-06, 7.0305e-06, 1.9184e-05,
        4.8066e-06, 1.7644e-05, 8.3908e-06, 9.8715e-06, 8.4201e-06, 1.5169e-05,
        1.4298e-05, 7.2844e-06, 1.2551e-05, 1.1118e-05, 1.9670e-05, 4.4273e-06,
        4.7032e-06, 6.3856e-06, 7.2701e-06, 8.7877e-06, 6.8579e-06, 1.1976e-05,
        2.3779e-05, 8.8869e-06, 6.5786e-06, 5.6437e-06, 1.0945e-05, 4.8284e-06,
        1.0853e-05, 1.3621e-05, 9.8246e-06, 1.0406e-05, 7.8460e-06, 1.1845e-05,
        1.5737e-05, 9.4889e-06], device='cuda:0')}, 57: {'step': tensor(30200.), 'exp_avg': tensor([[-1.8542e-04,  3.6982e-05, -1.8302e-05,  ..., -7.7555e-05,
          2.0355e-04,  1.3769e-04],
        [-2.2583e-04, -4.2285e-04, -2.4502e-04,  ..., -4.8148e-04,
          3.2689e-04,  3.9046e-04],
        [-9.9250e-05, -3.8017e-04, -1.6219e-04,  ..., -3.7506e-05,
          3.0119e-04,  1.7706e-04],
        ...,
        [-4.7446e-05, -3.7392e-04, -1.3973e-04,  ..., -2.8650e-04,
         -3.4634e-04, -2.6612e-04],
        [-1.0451e-04,  6.8687e-05,  2.9598e-04,  ...,  3.9896e-04,
         -1.0655e-04, -1.3153e-04],
        [ 2.1298e-05, -5.5930e-04, -1.4400e-04,  ..., -2.7314e-05,
          1.1814e-04, -2.0419e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[7.2680e-07, 8.3760e-07, 1.7499e-06,  ..., 1.7223e-06, 7.1257e-07,
         9.2917e-07],
        [8.0882e-07, 7.2866e-07, 1.0936e-06,  ..., 2.2004e-06, 7.0749e-07,
         1.0260e-06],
        [1.0386e-06, 1.0925e-06, 2.5947e-06,  ..., 2.8809e-06, 1.0214e-06,
         1.2474e-06],
        ...,
        [1.1233e-06, 1.3804e-06, 2.7470e-06,  ..., 1.2732e-06, 1.6130e-06,
         1.8376e-06],
        [8.6057e-07, 8.8724e-07, 1.4258e-06,  ..., 7.5356e-07, 8.4997e-07,
         1.0009e-06],
        [7.9279e-07, 8.6657e-07, 1.3183e-06,  ..., 8.6312e-07, 1.0391e-06,
         1.0830e-06]], device='cuda:0')}, 58: {'step': tensor(30200.), 'exp_avg': tensor([[ 9.4001e-05, -1.3289e-04, -4.2755e-04,  ...,  1.4710e-04,
         -2.4002e-04,  4.8902e-04],
        [-1.0224e-04, -2.0588e-04,  4.2636e-04,  ..., -1.3453e-04,
         -7.0077e-05, -2.1642e-04],
        [-3.8763e-04,  2.7644e-04,  3.6711e-04,  ...,  1.1530e-04,
          7.1824e-05, -2.9082e-05],
        ...,
        [-5.6855e-05,  2.5063e-04, -3.4767e-04,  ..., -4.2317e-04,
         -6.6357e-05,  2.1392e-05],
        [ 1.1221e-04, -1.0502e-04, -1.3771e-04,  ..., -1.1917e-04,
          1.0099e-04, -6.4841e-04],
        [-8.5405e-07,  1.5904e-04,  2.7699e-04,  ..., -4.9650e-05,
         -8.6438e-06, -2.9448e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[1.5887e-06, 2.0980e-06, 3.3479e-06,  ..., 2.1078e-06, 4.6580e-07,
         3.0894e-06],
        [1.6071e-06, 3.2558e-06, 4.1288e-06,  ..., 2.4901e-06, 6.3945e-07,
         3.8306e-06],
        [1.7644e-06, 2.4870e-06, 4.7455e-06,  ..., 2.4973e-06, 5.4819e-07,
         3.1331e-06],
        ...,
        [2.1091e-06, 3.3322e-06, 6.4831e-06,  ..., 3.3067e-06, 6.9601e-07,
         3.5535e-06],
        [2.4450e-06, 3.8303e-06, 6.4297e-06,  ..., 4.3923e-06, 8.1908e-07,
         5.0875e-06],
        [1.4888e-06, 1.9606e-06, 4.0089e-06,  ..., 1.8867e-06, 4.3013e-07,
         2.2651e-06]], device='cuda:0')}, 59: {'step': tensor(30200.), 'exp_avg': tensor([-2.4779e-04,  6.5874e-04,  1.8049e-04, -1.5086e-04,  1.3979e-04,
        -6.3988e-04,  3.1903e-04,  1.0854e-03, -1.1015e-04,  1.0398e-04,
         4.6672e-04,  2.5402e-04, -9.8634e-04,  6.1056e-04, -4.0978e-04,
         1.6786e-04,  2.5139e-04,  6.5570e-04,  2.4984e-05, -1.8607e-04,
        -4.6356e-04, -3.4816e-04, -3.0821e-04,  8.5931e-05, -2.4061e-04,
        -3.9108e-05, -6.0274e-04,  3.2212e-04, -5.4201e-04,  7.7174e-04,
         1.7528e-04, -4.8288e-04,  1.4350e-04, -6.8906e-05,  4.4232e-04,
        -3.6587e-04, -3.2341e-04,  2.1389e-04,  2.1946e-04, -6.6721e-04,
         1.0614e-04, -8.9971e-04,  8.1913e-05,  4.6509e-04,  4.4212e-04,
        -6.0611e-04, -6.7959e-05, -1.4772e-04,  1.9950e-04,  2.9835e-04,
        -7.1016e-04,  2.9671e-04, -2.0525e-04, -1.3688e-04,  8.3824e-04,
         6.4930e-04,  4.5324e-04, -1.0579e-03, -1.8025e-04,  6.0859e-04,
        -1.3048e-03, -7.8580e-04, -2.5167e-05, -2.0976e-04,  5.0232e-04,
         4.1714e-04, -3.1569e-04,  6.7033e-04, -7.5347e-04, -3.2224e-04,
         4.7745e-04,  1.7434e-05, -9.3624e-04, -7.7353e-04,  1.0090e-03,
        -5.6473e-04, -7.0338e-05,  1.4117e-04, -1.8161e-04,  2.8094e-04,
         4.2413e-04, -3.2069e-04, -2.9294e-05,  2.7588e-04,  1.7705e-04,
        -2.7728e-04, -5.5647e-04,  1.7802e-05, -2.1685e-04, -2.0563e-05,
         3.6612e-04,  1.9355e-04,  4.9473e-04, -3.0793e-04,  1.5280e-05,
        -8.8098e-05,  3.5808e-04,  1.2147e-03, -1.6315e-06,  1.3010e-04,
        -3.4750e-04,  3.1888e-04,  2.8216e-04,  1.5482e-04, -2.9295e-04,
         5.0542e-04,  8.8367e-05,  1.8278e-04,  4.2848e-04, -1.1397e-05,
         8.8691e-04, -2.4831e-04, -3.2715e-06, -1.7354e-04,  4.3831e-04,
        -7.3583e-04, -2.6950e-04, -6.7791e-04, -1.4431e-04,  3.1508e-04,
         1.3311e-03, -5.8654e-05, -4.0678e-04,  1.3632e-04, -1.5086e-04,
        -6.3649e-04, -3.4529e-04,  2.6032e-04], device='cuda:0'), 'exp_avg_sq': tensor([6.3492e-06, 8.6200e-06, 7.9688e-06, 1.1058e-05, 7.7118e-06, 1.4929e-05,
        5.7484e-06, 1.8483e-05, 2.3314e-05, 1.1062e-05, 1.9650e-05, 5.9859e-06,
        2.8059e-05, 1.0663e-05, 1.5590e-05, 4.9768e-06, 8.4668e-06, 1.6049e-05,
        5.0462e-06, 1.4000e-05, 2.7558e-05, 1.2551e-05, 5.6339e-06, 1.6356e-05,
        7.3755e-06, 1.2222e-05, 6.5984e-06, 1.2025e-05, 1.7217e-05, 2.1654e-05,
        8.8139e-06, 1.5358e-05, 1.2307e-05, 9.6061e-06, 5.8324e-06, 1.1108e-05,
        1.1223e-05, 6.6429e-06, 1.7276e-05, 6.4271e-06, 1.1480e-05, 1.0347e-05,
        1.3924e-05, 4.7835e-06, 1.7921e-05, 1.0939e-05, 1.2280e-05, 2.0242e-05,
        2.1158e-05, 1.5195e-05, 1.7098e-05, 1.2645e-05, 1.7738e-05, 2.0278e-05,
        1.2178e-05, 2.1134e-05, 1.0587e-05, 7.0808e-06, 1.7710e-05, 1.2625e-05,
        8.3653e-06, 1.0223e-05, 9.7045e-06, 1.1651e-05, 1.2852e-05, 1.4917e-05,
        8.6556e-06, 1.7216e-05, 7.1921e-06, 1.6870e-05, 6.0649e-06, 7.0103e-06,
        6.6773e-06, 1.8283e-05, 6.4885e-06, 1.4283e-05, 5.8604e-06, 1.9039e-05,
        8.4535e-06, 1.6740e-05, 9.5288e-06, 2.1512e-05, 1.4656e-05, 1.6549e-05,
        1.2213e-05, 6.9274e-06, 1.0337e-05, 1.0447e-05, 4.7613e-06, 5.7189e-06,
        8.1375e-06, 1.2670e-05, 9.0229e-06, 1.0032e-05, 1.9883e-05, 1.2157e-05,
        1.0567e-05, 1.8894e-05, 5.2783e-06, 6.6262e-06, 3.8434e-06, 1.1546e-05,
        5.0506e-06, 5.1794e-06, 1.4540e-05, 6.5443e-06, 7.1818e-06, 4.4270e-06,
        2.2533e-05, 9.4491e-06, 2.6171e-05, 2.2019e-05, 7.0471e-06, 8.5798e-06,
        1.2097e-05, 8.5137e-06, 1.4029e-05, 1.1804e-05, 1.7693e-05, 9.7746e-06,
        1.0511e-05, 9.3988e-06, 8.5817e-06, 9.8474e-06, 7.9888e-06, 1.3599e-05,
        1.5731e-05, 5.0747e-06], device='cuda:0')}, 60: {'step': tensor(30200.), 'exp_avg': tensor([ 6.0348e-05, -6.0394e-05, -3.6447e-04, -1.2993e-04, -3.7962e-05,
        -1.0985e-04,  1.7636e-04,  4.3702e-04, -1.9120e-04,  9.7666e-05,
         2.3074e-04,  5.4721e-04, -3.1423e-04, -3.9439e-05, -1.5143e-04,
        -8.2635e-04, -1.6817e-04, -2.2365e-04,  2.3437e-05,  3.2128e-05,
        -1.5386e-04, -3.9697e-05,  8.1204e-05,  2.6002e-05, -4.8831e-05,
         3.8628e-04, -1.2735e-04, -2.6299e-04, -6.7174e-05, -2.6164e-04,
        -4.0551e-04, -3.1697e-04, -2.5598e-04,  2.9387e-04,  7.2806e-05,
        -3.0780e-06, -2.2612e-04, -5.3886e-05, -1.3035e-04,  2.7700e-04,
        -1.0587e-04,  1.2287e-04, -8.1723e-05,  1.0295e-04,  8.9047e-05,
        -1.7580e-04,  1.1388e-04,  4.8250e-05, -1.7846e-06,  8.4443e-05,
        -2.5361e-04, -3.3012e-05,  2.2722e-05,  4.4317e-05, -1.2813e-04,
         5.0544e-05,  2.6686e-04,  1.2942e-04, -4.0576e-06, -3.0419e-04,
        -2.2051e-04, -2.0166e-04, -3.2657e-05,  7.3119e-05, -3.1186e-04,
        -1.7389e-05, -3.2073e-04, -5.1451e-04,  3.4383e-04, -1.0211e-04,
        -1.5926e-04,  3.5383e-05,  2.0889e-04,  3.8006e-04, -1.9016e-04,
         3.3991e-04,  7.2894e-05,  2.0676e-05, -2.6308e-04, -2.9360e-05,
         1.2389e-04,  1.1357e-04, -5.2945e-04, -3.6535e-04,  2.1089e-06,
         1.3342e-05, -2.2490e-04, -1.2439e-04, -1.6865e-04, -2.1271e-04,
        -1.5655e-04, -4.2668e-04,  1.3190e-04,  1.8084e-04, -4.6097e-05,
        -1.0849e-04, -1.8838e-04, -7.9692e-05, -2.1196e-04,  3.5371e-04,
        -5.1431e-04, -4.4245e-04, -6.3522e-05,  1.5563e-04, -2.7112e-04,
        -4.6742e-05,  1.2172e-04,  2.6421e-04, -1.1186e-04,  3.2521e-04,
         4.2302e-04, -3.7668e-04, -3.6449e-04,  2.3979e-04, -4.2360e-04,
         2.3609e-04,  2.6815e-04, -1.2809e-04, -4.1256e-05, -1.4109e-04,
         9.2893e-05, -5.5874e-05, -7.2030e-04,  1.6174e-04, -2.4484e-05,
         2.1670e-04, -2.1762e-04, -4.3018e-05], device='cuda:0'), 'exp_avg_sq': tensor([6.2584e-07, 3.5768e-07, 1.4869e-06, 1.4404e-06, 5.5249e-07, 7.6562e-07,
        8.7659e-07, 1.2214e-06, 1.0290e-06, 7.7651e-07, 8.4933e-07, 5.0613e-07,
        4.8407e-07, 4.0809e-07, 7.8579e-07, 2.3709e-06, 5.3253e-07, 1.5463e-06,
        4.7977e-07, 5.1197e-07, 5.8944e-07, 4.2333e-07, 1.1795e-06, 8.0256e-07,
        7.3914e-07, 8.3598e-07, 7.1678e-07, 1.0696e-06, 1.3267e-06, 4.2561e-07,
        8.6214e-07, 1.1296e-06, 7.2037e-07, 6.0404e-07, 7.2313e-07, 9.0641e-07,
        4.7693e-07, 6.8509e-07, 3.7229e-07, 9.3164e-07, 1.1636e-06, 6.2136e-07,
        5.9603e-07, 8.3030e-07, 4.0694e-07, 8.9281e-07, 8.7173e-07, 2.6486e-07,
        7.4242e-07, 6.1912e-07, 7.4282e-07, 4.6301e-07, 8.8945e-07, 4.1574e-07,
        3.7862e-07, 5.2292e-07, 5.7415e-07, 7.8415e-07, 9.3755e-07, 1.7776e-06,
        6.4225e-07, 5.0990e-07, 7.7552e-07, 7.1957e-07, 7.3481e-07, 6.3800e-07,
        9.8565e-07, 1.5226e-06, 1.0079e-06, 7.5115e-07, 8.9596e-07, 7.7539e-07,
        9.0429e-07, 9.6970e-07, 7.2018e-07, 5.0382e-07, 5.6358e-07, 8.8678e-07,
        5.0969e-07, 4.3415e-07, 7.1915e-07, 5.8175e-07, 1.2244e-06, 6.7847e-07,
        8.7207e-07, 5.7591e-07, 7.9345e-07, 7.1953e-07, 7.4346e-07, 7.4617e-07,
        6.2957e-07, 2.0067e-06, 6.2551e-07, 5.0991e-07, 1.7110e-06, 5.2575e-07,
        1.0859e-06, 1.6943e-06, 6.3563e-07, 7.1772e-07, 8.1419e-07, 1.6882e-06,
        4.9814e-07, 6.2048e-07, 7.5505e-07, 8.3643e-07, 8.2784e-07, 9.5838e-07,
        6.0452e-07, 9.2668e-07, 6.1898e-07, 5.4860e-07, 5.8079e-07, 8.0077e-07,
        1.5663e-06, 6.0616e-07, 5.5309e-07, 6.1969e-07, 1.7732e-06, 6.1807e-07,
        4.0364e-07, 6.9696e-07, 2.4120e-06, 4.2632e-07, 5.1616e-07, 5.9360e-07,
        4.9444e-07, 6.4093e-07], device='cuda:0')}, 61: {'step': tensor(30200.), 'exp_avg': tensor([-1.2993e-04,  1.1891e-04, -2.1557e-04,  5.9894e-05,  1.6091e-04,
        -6.9357e-05, -3.0799e-06,  9.3908e-05,  1.7922e-04,  2.2570e-04,
        -1.3033e-04,  2.0702e-04, -5.3041e-04,  1.0621e-04,  2.4274e-04,
        -1.1880e-04,  1.6060e-04, -2.7494e-04, -1.1261e-05,  2.1592e-04,
        -2.0095e-05,  5.1562e-05, -1.0023e-04, -5.3981e-05, -2.3893e-04,
        -1.9821e-04,  5.1782e-06,  2.1896e-04, -5.0149e-05, -3.9035e-05,
        -5.8984e-05, -3.6868e-04,  1.6696e-04,  1.0974e-05,  3.0559e-04,
         1.0211e-04, -1.3111e-04,  1.5081e-04,  3.4154e-05, -1.6693e-04,
         1.9144e-04, -2.5114e-05, -1.2074e-04,  1.2252e-04, -1.8258e-04,
         8.0206e-05,  2.0142e-04,  4.9859e-05,  9.4905e-05, -1.0097e-04,
         1.9960e-05, -7.6336e-05, -3.4089e-04, -7.0554e-05, -1.5029e-05,
        -4.7804e-05, -5.1883e-05, -3.9301e-04, -1.4366e-04,  6.3829e-05,
         6.2820e-05,  1.8889e-04, -2.2106e-04,  4.9769e-05, -6.6681e-05,
        -1.1280e-04,  9.1221e-05, -2.6948e-04,  2.3296e-04, -2.4498e-04,
         1.4334e-05, -3.8738e-05, -1.6687e-04, -1.7899e-04, -2.7002e-06,
        -5.1143e-05,  6.1335e-05, -2.9084e-04, -1.5004e-04,  3.9687e-05,
         3.0691e-04, -3.6996e-04, -3.7842e-04, -1.3183e-04,  3.5634e-05,
        -9.1111e-05,  1.6033e-04,  3.9264e-04,  2.7848e-04, -2.7393e-04,
         5.2304e-05, -2.8363e-04, -3.3913e-04,  1.3518e-04, -1.7474e-05,
         2.2420e-04,  2.2129e-04,  4.5308e-04, -1.3373e-04, -3.3015e-04,
         1.8446e-04, -1.7560e-04, -1.4144e-04,  4.5498e-05, -1.8236e-04,
         9.9652e-05,  2.0114e-04,  2.4187e-04, -9.5994e-05,  2.8875e-04,
         6.3201e-05,  1.8585e-04, -3.5860e-04, -4.4945e-05,  1.9692e-04,
         2.7718e-04, -1.0959e-04, -1.6092e-05, -1.7100e-04, -3.4288e-05,
        -2.5477e-05,  2.9973e-05,  2.6809e-04,  1.8625e-05,  2.4931e-04,
        -5.6429e-05, -1.3697e-04, -3.3187e-05], device='cuda:0'), 'exp_avg_sq': tensor([6.4189e-07, 4.9950e-07, 1.0223e-06, 7.9147e-07, 8.0181e-07, 1.0619e-06,
        9.9454e-07, 2.2955e-06, 1.3308e-06, 7.9796e-07, 2.0733e-06, 6.8932e-07,
        1.0407e-06, 4.9459e-07, 1.1941e-06, 1.8772e-06, 1.1587e-06, 1.3938e-06,
        7.3724e-07, 5.8460e-07, 6.4147e-07, 6.0803e-07, 1.8364e-06, 1.0089e-06,
        1.1753e-06, 8.8664e-07, 1.2414e-06, 8.0317e-07, 1.7094e-06, 5.3152e-07,
        1.1391e-06, 1.9416e-06, 8.5984e-07, 7.0624e-07, 6.1350e-07, 1.0059e-06,
        7.4723e-07, 1.5654e-06, 7.9237e-07, 1.1563e-06, 1.4422e-06, 9.7095e-07,
        9.0413e-07, 1.6530e-06, 9.2051e-07, 1.0309e-06, 1.7088e-06, 3.8565e-07,
        8.2419e-07, 9.5733e-07, 5.9952e-07, 5.6306e-07, 2.1306e-06, 4.2781e-07,
        6.1261e-07, 5.0945e-07, 9.4769e-07, 5.5618e-07, 8.7994e-07, 1.2925e-06,
        6.3463e-07, 9.5357e-07, 1.2355e-06, 5.2153e-07, 1.0132e-06, 1.2773e-06,
        9.5752e-07, 2.1263e-06, 1.3722e-06, 9.9152e-07, 9.5695e-07, 1.4110e-06,
        1.7983e-06, 1.7333e-06, 9.4182e-07, 7.0764e-07, 1.0767e-06, 1.3266e-06,
        6.1540e-07, 4.2435e-07, 1.0366e-06, 6.0836e-07, 1.5017e-06, 7.5189e-07,
        1.3928e-06, 5.3028e-07, 1.1745e-06, 1.5180e-06, 8.1608e-07, 9.9929e-07,
        9.5234e-07, 1.6696e-06, 1.5846e-06, 9.5035e-07, 2.3384e-06, 5.3121e-07,
        7.3833e-07, 1.3030e-06, 8.3241e-07, 9.9527e-07, 8.8530e-07, 2.2414e-06,
        8.1217e-07, 9.9309e-07, 7.5843e-07, 1.2119e-06, 6.3220e-07, 1.0647e-06,
        1.6069e-06, 8.8806e-07, 7.3418e-07, 5.9335e-07, 1.0193e-06, 1.3749e-06,
        6.5421e-07, 1.2297e-06, 9.5074e-07, 1.3106e-06, 1.4841e-06, 7.8791e-07,
        6.2187e-07, 9.2106e-07, 1.8032e-06, 3.5143e-07, 6.1732e-07, 5.8085e-07,
        8.2933e-07, 5.0284e-07], device='cuda:0')}, 62: {'step': tensor(30200.), 'exp_avg': tensor([[ 2.2254e-04, -2.3147e-04,  1.3333e-04,  ..., -2.4234e-04,
         -1.9895e-04,  1.8330e-04],
        [ 2.6530e-06, -9.1915e-05, -3.5357e-05,  ...,  5.2974e-05,
          1.3418e-04,  4.0679e-05],
        [-1.1494e-04, -1.1183e-04, -2.0973e-04,  ...,  3.5192e-05,
         -1.7246e-05,  6.7924e-05],
        ...,
        [ 6.2403e-05, -9.9952e-05, -2.9773e-04,  ...,  1.3500e-04,
         -1.7716e-04, -8.6497e-05],
        [-2.2907e-04,  1.4596e-04,  3.9410e-04,  ..., -2.6482e-04,
          1.2414e-04,  1.5654e-04],
        [-2.4021e-04, -2.7930e-04, -3.7086e-05,  ..., -1.6177e-05,
         -7.3372e-05,  1.4162e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[9.3377e-07, 3.8049e-07, 6.8510e-07,  ..., 5.3694e-07, 5.3800e-07,
         5.4809e-07],
        [6.7586e-07, 5.6986e-07, 1.1633e-06,  ..., 6.9959e-07, 7.6271e-07,
         5.8558e-07],
        [7.7485e-07, 6.2693e-07, 7.6252e-07,  ..., 6.1024e-07, 5.7110e-07,
         8.4457e-07],
        ...,
        [8.4782e-07, 5.5156e-07, 1.1835e-06,  ..., 1.4968e-06, 8.4654e-07,
         6.5163e-07],
        [8.7064e-07, 4.9187e-07, 8.1630e-07,  ..., 1.0114e-06, 6.8687e-07,
         9.0494e-07],
        [7.7652e-07, 5.8054e-07, 6.9191e-07,  ..., 4.6991e-07, 7.5580e-07,
         1.0719e-06]], device='cuda:0')}, 63: {'step': tensor(30200.), 'exp_avg': tensor([ 5.6875e-05,  2.7721e-04, -1.2808e-04, -1.3525e-04,  1.9559e-04,
        -6.3753e-05,  5.7391e-05,  1.5992e-04, -1.3782e-04,  1.9641e-04,
        -2.1279e-04, -6.9413e-05, -1.4499e-04,  5.9277e-06,  3.0827e-04,
        -2.9045e-04,  7.0553e-05,  4.6041e-05,  2.4864e-04, -2.5002e-04,
         5.7661e-05,  2.8813e-04, -1.6193e-04, -1.4823e-04,  2.2449e-04,
         2.7707e-04, -1.6190e-04, -1.9029e-04,  1.2940e-05, -2.1874e-04,
         6.7960e-05, -1.2024e-04,  2.5884e-04, -3.3112e-04,  1.3843e-04,
        -1.0534e-04,  1.0971e-04,  2.3708e-04,  1.9826e-05,  1.6559e-04,
         2.1565e-04,  1.0451e-04, -1.3204e-05,  1.5751e-05,  1.0182e-05,
        -2.9784e-04,  1.9565e-05, -5.0786e-05, -1.9603e-05, -2.0392e-04,
        -2.3027e-04, -3.5077e-04,  2.3508e-04,  4.0653e-05, -1.7609e-04,
        -4.5054e-04,  3.1126e-04,  1.5933e-04,  2.7483e-04, -1.0242e-04,
         2.2983e-05, -2.3295e-04, -4.7273e-05,  2.2270e-04,  1.1599e-04,
         2.7813e-05, -1.9679e-04,  2.2596e-05,  4.0065e-04, -1.1810e-04,
         1.4464e-04, -9.8421e-05, -1.0687e-04,  1.8344e-04,  1.2393e-04,
         2.2558e-04,  1.8513e-04,  6.7247e-05,  5.9115e-05,  1.9905e-05,
        -3.6408e-04, -1.3598e-04,  1.0359e-04,  1.6370e-04,  3.1257e-05,
         1.2435e-05,  7.6502e-05, -9.1877e-05, -1.9663e-06,  6.0509e-05,
        -6.5993e-05,  2.1981e-04, -2.1233e-05, -1.3483e-04, -1.4667e-04,
         2.4445e-04,  1.9047e-04,  1.0516e-05,  9.2487e-05, -4.9061e-07,
        -9.7168e-05, -2.1386e-04, -1.0035e-04, -5.8219e-04,  1.4838e-04,
        -1.0573e-04,  1.7811e-04,  3.1753e-05, -8.5277e-05, -3.7384e-04,
        -3.0934e-04,  6.4547e-05,  3.5705e-04, -3.2233e-05, -8.1462e-05,
         1.4812e-04,  2.6680e-04, -8.6589e-05,  4.1885e-05, -9.5286e-05,
        -3.5354e-04,  7.2473e-05,  4.3001e-05,  1.4111e-04,  1.8506e-04,
        -1.5671e-04, -2.9098e-04, -1.6949e-04, -2.8905e-04,  2.1863e-04,
         5.6282e-05,  2.0537e-04, -4.1601e-04, -1.0818e-04, -8.2650e-06,
        -1.3460e-04,  3.4057e-04, -2.7313e-04, -1.4517e-04, -4.0784e-05,
        -7.2635e-05,  1.3648e-04,  1.0693e-04,  3.0803e-04, -1.7371e-04,
        -3.3732e-05,  5.1483e-04,  7.1863e-05, -8.7933e-05, -1.5429e-04,
         6.9265e-05,  4.3959e-05, -9.5293e-05, -2.9662e-04, -1.0543e-04,
         4.0483e-05, -6.8259e-05,  5.9976e-05, -8.1816e-05, -4.9429e-04,
        -2.8848e-05, -7.7354e-05,  2.6228e-05,  2.2075e-04, -5.1134e-05,
         7.7127e-05, -3.0350e-05,  8.7781e-06, -1.2051e-04,  2.5245e-04,
         2.6576e-04, -5.1812e-04, -1.3405e-04,  1.6334e-04, -1.3150e-04,
        -9.4401e-05,  2.1017e-04, -7.0538e-05, -1.0968e-04, -1.5312e-04,
        -2.6361e-04, -1.3057e-04,  2.0402e-04,  1.6353e-04, -2.4649e-04,
         9.1849e-05, -6.8329e-06, -2.7352e-04,  8.5820e-05,  1.3258e-04,
         9.7038e-05, -7.5478e-05, -5.0095e-04,  1.6923e-04,  2.4543e-04,
         1.9405e-05,  1.8876e-05,  1.7864e-04,  1.2937e-04, -1.6131e-05,
        -1.9692e-04,  1.3347e-04, -2.4100e-04,  1.6515e-04, -2.6072e-04,
         1.1185e-06, -2.4309e-04, -1.8765e-05,  1.4574e-05,  7.5941e-05,
         6.2981e-05, -4.0101e-05,  2.3022e-05, -1.0660e-04,  1.7238e-04,
        -2.9948e-04, -2.1167e-04, -6.9851e-04, -1.8662e-04, -3.5272e-06,
        -9.0024e-05,  6.5830e-06,  2.5198e-04, -4.9242e-05, -2.3701e-04,
        -1.8419e-04,  2.5063e-05,  7.6614e-05, -4.2468e-05,  1.0365e-05,
        -8.6806e-05,  6.3916e-05, -1.4051e-04, -2.2566e-04,  1.1236e-04,
        -1.0162e-04, -2.2290e-05, -2.3064e-04,  1.3813e-04,  1.1337e-04,
        -1.4258e-04,  8.2181e-05, -1.9821e-04, -1.0346e-04,  1.6721e-04,
        -1.0338e-04,  3.5052e-04, -1.1658e-04,  3.0447e-05, -2.8644e-04,
        -2.6100e-06, -2.2236e-04,  1.0845e-04, -3.9432e-05, -4.6742e-05,
         2.0551e-04], device='cuda:0'), 'exp_avg_sq': tensor([7.8571e-07, 1.4488e-06, 6.8298e-07, 8.1895e-07, 2.4978e-06, 7.6873e-07,
        7.2530e-07, 6.2736e-07, 7.2960e-07, 1.8060e-06, 1.0962e-06, 8.6136e-07,
        9.2935e-07, 8.6745e-07, 9.9965e-07, 9.8872e-07, 6.2619e-07, 9.3509e-07,
        6.5285e-07, 7.3403e-07, 4.8497e-07, 1.2966e-06, 9.3225e-07, 7.8643e-07,
        1.3733e-06, 2.5824e-06, 6.0349e-07, 8.5623e-07, 6.2942e-07, 9.9588e-07,
        4.2028e-07, 6.5552e-07, 8.6665e-07, 2.3428e-06, 5.5586e-07, 6.0828e-07,
        4.7737e-07, 1.1363e-06, 8.2587e-07, 9.2015e-07, 6.0621e-07, 7.4122e-07,
        6.8286e-07, 7.1454e-07, 5.1240e-07, 9.0770e-07, 6.2102e-07, 8.3867e-07,
        1.0424e-06, 5.3999e-07, 8.1026e-07, 1.1270e-06, 1.1537e-06, 5.0521e-07,
        1.1020e-06, 1.4877e-06, 9.2064e-07, 6.4696e-07, 5.1253e-07, 4.9247e-07,
        3.5312e-07, 1.5054e-06, 5.0413e-07, 1.1570e-06, 1.3368e-06, 6.3586e-07,
        1.3204e-06, 6.4961e-07, 1.4476e-06, 8.8379e-07, 1.0281e-06, 4.6813e-07,
        1.6682e-06, 1.0610e-06, 5.4114e-07, 5.4850e-07, 1.0485e-06, 1.1245e-06,
        9.5398e-07, 7.3541e-07, 7.0387e-07, 1.3937e-06, 5.1649e-07, 6.6827e-07,
        4.1537e-07, 1.0946e-06, 1.0710e-06, 8.6165e-07, 3.7708e-07, 1.5278e-06,
        1.0493e-06, 1.6349e-06, 9.6568e-07, 1.3847e-06, 6.0859e-07, 3.6397e-07,
        8.3624e-07, 1.7774e-06, 1.2400e-06, 7.3710e-07, 3.2030e-07, 3.1366e-07,
        9.4191e-07, 1.6000e-06, 1.2069e-06, 1.5283e-06, 7.2324e-07, 2.4957e-07,
        4.1264e-07, 1.0277e-06, 4.1101e-07, 7.7559e-07, 1.0465e-06, 6.3214e-07,
        5.0005e-07, 1.1367e-06, 1.1604e-06, 9.2193e-07, 4.9815e-07, 5.9025e-07,
        6.4251e-07, 6.7702e-07, 6.5997e-07, 1.2668e-06, 8.1087e-07, 4.6399e-07,
        2.1908e-06, 8.1629e-07, 9.5831e-07, 6.9179e-07, 1.8015e-06, 6.7058e-07,
        1.9472e-06, 1.9616e-06, 1.0915e-06, 6.0415e-07, 2.1269e-06, 7.0446e-07,
        6.1672e-07, 6.3625e-07, 2.4366e-06, 8.2511e-07, 7.7900e-07, 5.9388e-07,
        7.2094e-07, 6.3157e-07, 3.1609e-06, 7.1214e-07, 3.2665e-07, 8.1571e-07,
        4.4641e-07, 8.8677e-07, 8.1666e-07, 1.2394e-06, 8.0607e-07, 5.1728e-07,
        9.5989e-07, 1.1077e-06, 4.6927e-07, 1.0264e-06, 7.6033e-07, 8.8473e-07,
        6.6566e-07, 5.3338e-07, 1.6032e-06, 4.0146e-07, 6.9498e-07, 6.5447e-07,
        5.1281e-07, 9.9327e-07, 1.3355e-06, 2.1897e-06, 6.9966e-07, 5.6196e-07,
        9.2605e-07, 1.5650e-06, 2.0200e-06, 1.8139e-06, 9.4744e-07, 8.6905e-07,
        1.3327e-06, 6.9891e-07, 4.7731e-07, 8.5089e-07, 5.9845e-07, 1.1599e-06,
        2.0864e-06, 1.2054e-06, 6.4138e-07, 7.9203e-07, 6.4014e-07, 7.5112e-07,
        1.3225e-06, 8.1385e-07, 7.9787e-07, 8.2371e-07, 7.4964e-07, 4.5329e-07,
        1.6367e-06, 4.8322e-07, 1.7871e-06, 8.0203e-07, 1.1026e-06, 3.7199e-07,
        1.1468e-06, 2.1264e-06, 7.7003e-07, 8.9235e-07, 1.5023e-06, 9.1287e-07,
        3.6082e-07, 1.0877e-06, 7.1985e-07, 5.1180e-07, 6.9101e-07, 1.4185e-06,
        7.0288e-07, 2.9344e-06, 1.0332e-06, 4.6938e-07, 1.4939e-06, 2.9767e-06,
        6.5189e-07, 8.8612e-07, 2.4575e-06, 1.1352e-06, 1.0801e-06, 8.3604e-07,
        6.9139e-07, 6.9075e-07, 9.6089e-07, 3.5233e-07, 1.7526e-06, 1.2715e-06,
        9.2762e-07, 8.8815e-07, 7.8821e-07, 8.1669e-07, 1.1131e-06, 4.4185e-07,
        1.1844e-06, 8.0622e-07, 1.2750e-06, 1.2226e-06, 1.1446e-06, 5.9164e-07,
        2.6188e-06, 8.1708e-07, 8.3758e-07, 1.0843e-06, 1.2234e-06, 5.1339e-07,
        9.1164e-07, 8.2156e-07, 6.9212e-07, 8.5103e-07], device='cuda:0')}, 64: {'step': tensor(30200.), 'exp_avg': tensor([[ 9.8946e-06, -9.2993e-05,  2.2459e-05,  ...,  3.4201e-04,
         -5.2858e-05, -3.1665e-04],
        [ 8.6398e-05,  3.1460e-04,  3.7208e-04,  ...,  3.7246e-04,
          3.7962e-04,  2.2800e-04],
        [-5.1364e-04,  3.0141e-04, -2.1865e-04,  ...,  3.2137e-04,
          2.4955e-04,  3.4245e-04],
        ...,
        [ 4.4602e-05, -1.8864e-04, -4.7459e-04,  ..., -1.2504e-04,
          1.9270e-04, -1.0469e-04],
        [-2.8895e-05,  4.1761e-05,  2.7906e-04,  ..., -1.7760e-04,
         -3.0576e-04, -1.0884e-04],
        [ 3.7334e-04,  6.5052e-05,  3.5879e-04,  ...,  5.5700e-04,
         -8.0599e-05, -2.9214e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[6.4312e-07, 5.1171e-07, 9.5460e-07,  ..., 9.9174e-07, 1.0707e-06,
         1.0792e-06],
        [1.0283e-06, 8.0366e-07, 9.5495e-07,  ..., 1.3882e-06, 1.8046e-06,
         1.2843e-06],
        [1.2867e-06, 7.6435e-07, 1.5555e-06,  ..., 1.1599e-06, 1.2581e-06,
         1.9528e-06],
        ...,
        [1.1845e-06, 9.5609e-07, 1.9743e-06,  ..., 9.3862e-07, 1.7223e-06,
         2.7909e-06],
        [1.2279e-06, 1.0301e-06, 1.3438e-06,  ..., 1.5681e-06, 2.6699e-06,
         1.9699e-06],
        [1.0576e-06, 5.4029e-07, 8.4557e-07,  ..., 1.4719e-06, 1.0826e-06,
         8.2903e-07]], device='cuda:0')}, 65: {'step': tensor(30200.), 'exp_avg': tensor([-2.3233e-04,  8.1031e-04, -1.1438e-05, -2.1476e-04,  2.0810e-04,
        -3.5223e-04,  3.6863e-04,  1.0726e-03,  7.5852e-06, -5.9286e-04,
         5.8142e-04,  4.6630e-04, -3.4642e-04,  4.5941e-04, -6.7486e-04,
        -4.9117e-04,  2.6899e-04,  1.1781e-03,  3.6888e-04, -1.4512e-04,
        -3.2647e-04, -1.9250e-04, -1.8481e-04, -1.7858e-04, -1.1073e-04,
         3.6447e-04, -7.2251e-04,  2.8686e-04,  5.4439e-05,  8.4451e-04,
         2.7499e-04, -2.2674e-04,  3.0165e-05, -1.8949e-04, -5.6424e-05,
        -2.8860e-04, -7.2868e-05, -8.5644e-05,  1.0111e-04, -5.4027e-04,
        -1.4065e-04, -9.0420e-04,  4.6888e-04,  3.1922e-04,  2.0791e-04,
        -5.2877e-04, -2.6128e-05,  7.4620e-05,  8.9804e-05,  3.9788e-04,
        -9.6782e-04,  2.6180e-04, -4.4593e-04, -8.7589e-05,  5.4726e-04,
         5.8908e-04,  9.3699e-04, -1.2360e-03,  2.8486e-05,  8.3874e-04,
        -1.2588e-03, -1.0437e-03,  1.7195e-04, -5.9692e-04,  7.0573e-04,
         7.6612e-04, -4.0378e-04,  6.2756e-04, -9.3437e-04, -2.1619e-04,
         2.7611e-04, -1.3647e-04, -1.0048e-03, -3.5356e-04,  1.8701e-04,
        -5.5672e-04, -2.7528e-04,  4.4615e-04,  9.0325e-05, -9.6021e-05,
         2.1601e-04, -1.0745e-04,  6.5546e-04, -4.2692e-04,  4.3539e-04,
        -3.0974e-04, -4.9861e-04,  5.0880e-04, -4.6091e-04,  2.7893e-05,
         1.9722e-04,  4.8446e-04,  5.9740e-04, -2.3484e-05,  2.4595e-05,
        -1.0269e-04,  2.3891e-04,  8.8662e-04,  8.1348e-05,  8.6963e-05,
        -6.4391e-04,  1.2797e-04,  4.0260e-04,  3.1723e-04, -4.3273e-05,
         3.0499e-04, -1.1713e-04,  2.6746e-04,  3.6464e-04, -1.6935e-04,
         1.1324e-03, -4.8693e-04,  4.0477e-04,  7.8263e-05,  1.9178e-04,
        -1.0763e-03, -9.2884e-05, -5.0582e-04,  3.6532e-04,  2.6082e-04,
         1.2241e-03,  2.7796e-04, -6.5976e-04, -3.3713e-05, -2.1231e-04,
        -7.9808e-04, -4.9458e-04,  3.0189e-04], device='cuda:0'), 'exp_avg_sq': tensor([5.4165e-06, 8.2912e-06, 7.3598e-06, 1.0385e-05, 6.8658e-06, 1.2659e-05,
        4.9949e-06, 1.1865e-05, 1.8360e-05, 1.1817e-05, 2.6200e-05, 5.2728e-06,
        2.7135e-05, 1.0242e-05, 1.4813e-05, 5.3602e-06, 7.0724e-06, 1.8721e-05,
        5.0716e-06, 1.4528e-05, 2.5999e-05, 1.0044e-05, 4.2519e-06, 1.4863e-05,
        6.9965e-06, 1.1551e-05, 5.6370e-06, 1.1661e-05, 2.1597e-05, 1.9389e-05,
        7.3448e-06, 1.2212e-05, 9.5632e-06, 9.6663e-06, 5.8284e-06, 8.7039e-06,
        1.0192e-05, 6.5084e-06, 1.4970e-05, 5.4021e-06, 1.2817e-05, 1.0798e-05,
        1.6130e-05, 5.4333e-06, 1.5217e-05, 1.0260e-05, 1.1559e-05, 1.9045e-05,
        1.8438e-05, 1.4622e-05, 1.4956e-05, 1.3677e-05, 1.2099e-05, 2.0061e-05,
        1.2165e-05, 2.1071e-05, 8.9962e-06, 6.2333e-06, 1.6450e-05, 1.2077e-05,
        7.3008e-06, 1.0545e-05, 8.5168e-06, 1.0586e-05, 1.3160e-05, 1.2121e-05,
        7.2198e-06, 2.1862e-05, 9.4680e-06, 1.4376e-05, 5.3477e-06, 6.6130e-06,
        6.1324e-06, 1.7786e-05, 6.8402e-06, 1.6211e-05, 6.1765e-06, 1.9006e-05,
        7.6894e-06, 1.6294e-05, 8.2764e-06, 2.1733e-05, 1.1987e-05, 1.5818e-05,
        1.4330e-05, 6.4277e-06, 1.1131e-05, 7.6189e-06, 4.6681e-06, 5.4640e-06,
        7.1830e-06, 1.6049e-05, 1.0131e-05, 1.0500e-05, 1.5523e-05, 1.1880e-05,
        1.1741e-05, 1.3976e-05, 4.4997e-06, 7.9686e-06, 3.9327e-06, 1.5600e-05,
        5.3687e-06, 5.0509e-06, 1.3958e-05, 5.7026e-06, 6.2167e-06, 4.0219e-06,
        2.1389e-05, 8.7258e-06, 2.5042e-05, 2.3220e-05, 6.2248e-06, 7.6006e-06,
        1.2436e-05, 1.0297e-05, 1.4100e-05, 1.0306e-05, 1.6929e-05, 8.6424e-06,
        1.0502e-05, 7.8093e-06, 6.8542e-06, 9.7163e-06, 7.5112e-06, 1.3921e-05,
        1.3856e-05, 5.5815e-06], device='cuda:0')}, 66: {'step': tensor(30200.), 'exp_avg': tensor([ 2.5070e-04,  3.8048e-04, -2.7758e-04, -1.4531e-03, -3.6385e-04,
        -1.6217e-03,  9.6609e-04,  8.5555e-04, -1.7264e-03,  2.6156e-04,
         8.3028e-04, -1.5435e-04, -1.9643e-04, -1.3156e-04,  5.8319e-04,
         1.0954e-03, -1.0265e-03, -6.2780e-04,  6.2222e-04,  4.6702e-04,
        -4.5271e-04, -1.5261e-05, -5.4740e-04, -1.5852e-05, -6.3117e-05,
        -3.9933e-04, -7.8978e-04,  1.3469e-03,  3.1705e-04, -2.8651e-04,
        -1.3981e-04, -7.4570e-04, -5.8864e-04,  4.7774e-04, -4.9739e-04,
        -4.0042e-04, -1.1022e-04,  2.9800e-04,  4.6896e-05,  7.3339e-05,
        -1.8317e-04, -6.1426e-04, -4.4353e-04,  1.4636e-03,  2.9250e-04,
        -3.8842e-04,  1.7541e-04, -7.2484e-05,  1.4414e-03,  6.1111e-04,
        -5.9056e-05,  4.4128e-04,  7.9288e-04, -7.1024e-04,  2.1805e-04,
         1.9161e-04, -4.2285e-04, -3.2488e-05, -1.7278e-04, -2.3077e-04,
         2.4246e-04,  5.9898e-04, -8.2712e-04,  1.7882e-04,  1.4649e-03,
        -2.1129e-04,  5.5459e-04, -2.1686e-03, -3.0130e-04,  4.9571e-04,
         4.9249e-04,  2.1064e-04,  9.6369e-04, -5.2716e-04, -4.9426e-05,
         9.3875e-04,  1.1539e-03, -6.6462e-04,  6.7520e-05, -4.9992e-04,
        -9.2852e-04, -5.7183e-04,  7.5089e-04,  8.7355e-04, -7.0458e-04,
         2.4655e-04,  9.4254e-04,  1.1743e-03,  1.5681e-03, -4.3845e-04,
        -2.3297e-04,  1.5781e-03,  4.0590e-04, -4.7953e-04, -1.5643e-04,
        -8.1902e-04,  7.7494e-04, -7.2114e-04, -2.4342e-04,  1.3531e-03,
         1.3317e-04,  7.2217e-04, -1.2413e-03,  1.1252e-03,  1.2831e-03,
        -1.6474e-04,  7.9812e-04,  1.0685e-03, -6.0521e-04, -6.2953e-04,
         2.3707e-04,  1.0474e-03,  9.0063e-04,  1.5358e-03, -9.0124e-05,
        -7.6167e-04, -1.6433e-04, -3.4366e-04,  2.8940e-04, -1.1396e-03,
         3.6300e-04,  1.7479e-03,  4.9172e-04,  1.9323e-04, -3.6258e-04,
         7.1653e-04, -1.8322e-03, -1.6325e-04], device='cuda:0'), 'exp_avg_sq': tensor([9.2292e-06, 5.6160e-06, 1.6215e-05, 1.1159e-05, 4.4646e-06, 5.7635e-06,
        4.5974e-06, 4.6978e-06, 8.8931e-06, 7.3229e-06, 1.0069e-05, 2.4738e-06,
        2.9491e-06, 5.6939e-06, 5.1914e-06, 5.2564e-06, 1.0136e-05, 7.7909e-06,
        4.9877e-06, 4.7252e-06, 6.7663e-06, 9.8064e-06, 1.6622e-05, 7.9182e-06,
        5.8049e-06, 7.2888e-06, 4.8689e-06, 8.2760e-06, 6.5208e-06, 1.2349e-05,
        3.8935e-06, 1.0826e-05, 6.3807e-06, 1.1626e-05, 8.2748e-06, 3.8374e-06,
        3.5656e-06, 7.1317e-06, 4.3720e-06, 6.6576e-06, 3.1645e-06, 9.1447e-06,
        8.8484e-06, 6.6745e-06, 4.5596e-06, 3.8732e-06, 5.8269e-06, 5.1838e-06,
        8.8410e-06, 5.5662e-06, 9.9537e-06, 4.1798e-06, 6.8168e-06, 5.6950e-06,
        3.6755e-06, 4.9019e-06, 7.0950e-06, 9.6006e-06, 1.1990e-05, 4.9936e-06,
        5.5500e-06, 1.1906e-05, 9.1056e-06, 7.3830e-06, 7.8295e-06, 1.1894e-05,
        4.9218e-06, 2.0513e-05, 3.6955e-06, 6.0507e-06, 5.3452e-06, 4.6533e-06,
        8.6176e-06, 3.4769e-06, 6.0536e-06, 4.3653e-06, 3.0109e-06, 3.5424e-06,
        6.6910e-06, 7.7291e-06, 7.3948e-06, 6.2362e-06, 7.7885e-06, 1.2060e-05,
        3.4908e-06, 9.1417e-06, 9.5653e-06, 7.3879e-06, 6.7431e-06, 3.3959e-06,
        6.1806e-06, 1.6301e-05, 3.8128e-06, 2.8156e-06, 6.6422e-06, 5.5622e-06,
        8.3967e-06, 5.9247e-06, 4.4439e-06, 6.5683e-06, 8.6696e-06, 5.4612e-06,
        4.5561e-06, 3.9745e-06, 1.2088e-05, 1.1894e-05, 7.7226e-06, 3.9287e-06,
        8.1284e-06, 5.2643e-06, 5.2381e-06, 4.9854e-06, 5.1471e-06, 7.0177e-06,
        4.9447e-06, 4.2056e-06, 3.8620e-06, 3.5408e-06, 4.8678e-06, 5.3539e-06,
        8.1205e-06, 7.3142e-06, 6.8556e-06, 7.1702e-06, 6.4262e-06, 1.3792e-05,
        6.9030e-06, 1.1375e-05], device='cuda:0')}, 67: {'step': tensor(30200.), 'exp_avg': tensor([-1.3991e-04,  6.8868e-04,  4.8270e-04,  9.3193e-05,  3.5057e-04,
        -1.7297e-04, -1.1248e-04,  2.6742e-04, -4.6323e-04,  1.8491e-04,
         1.3250e-04,  3.1639e-04, -5.8928e-04,  3.5694e-04,  5.1430e-05,
        -5.8601e-06,  6.2730e-04,  3.9369e-04,  1.1836e-03,  2.2209e-05,
        -7.2119e-04,  4.8854e-04, -5.6634e-04,  7.4127e-05, -6.1883e-05,
         4.2742e-04, -6.7391e-04, -4.7208e-04, -2.9084e-04,  2.7237e-04,
        -2.6084e-04,  2.9469e-04,  1.2551e-04, -3.5632e-04,  3.0799e-04,
         1.1696e-04, -5.3698e-04,  3.8476e-04, -2.3658e-04, -6.7972e-04,
        -3.1754e-04, -5.6100e-04,  2.2245e-04,  1.4791e-04,  3.8153e-04,
        -6.9360e-04,  3.0980e-04,  6.9149e-05,  5.0300e-04,  8.4139e-04,
        -8.0548e-04,  2.4503e-04, -3.4131e-04, -2.9194e-04,  2.5539e-04,
         1.1590e-04,  4.9550e-04, -3.0096e-04,  3.4244e-04, -3.8667e-04,
         8.0544e-05, -5.9707e-04, -6.4223e-05, -7.6743e-04, -5.9167e-05,
         4.7334e-04, -8.1594e-04,  1.2866e-03,  2.5893e-04, -2.4133e-04,
        -1.0789e-04,  2.7568e-05, -4.2751e-04,  8.3018e-04,  6.0061e-05,
        -1.7552e-04, -4.7373e-04, -7.6861e-05, -9.3272e-05,  8.0940e-04,
        -2.2173e-04, -7.0810e-04, -5.1947e-04, -3.1921e-04,  2.1698e-04,
        -3.7413e-04,  2.7307e-04, -4.1813e-04, -9.1886e-04, -5.3913e-04,
        -6.1979e-05,  5.3704e-04, -4.9895e-05, -2.6608e-04,  3.3740e-04,
        -1.8784e-05, -4.4589e-04,  2.2717e-04,  1.7036e-04, -9.9194e-05,
         3.5660e-05,  3.1864e-04, -3.4792e-04, -1.8688e-04,  8.9817e-04,
         9.6788e-05, -6.8848e-05,  8.6999e-05,  7.6844e-04,  6.0942e-04,
         8.8174e-04, -3.5226e-04, -2.1118e-04, -2.4121e-06, -1.1297e-04,
        -1.7541e-04,  5.8620e-04, -2.0660e-04,  4.5294e-04,  1.0249e-03,
         1.3527e-03, -7.4110e-04, -4.7872e-04,  2.6305e-04, -1.8391e-04,
        -5.0068e-04,  2.2805e-04,  7.5011e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.1437e-05, 2.0467e-05, 4.3360e-06, 1.6373e-05, 1.0447e-05, 1.0695e-05,
        6.0712e-06, 4.9113e-06, 2.5930e-05, 9.4493e-06, 1.3746e-05, 4.4369e-06,
        4.2480e-06, 5.4700e-06, 1.2243e-05, 3.6176e-06, 1.4727e-05, 1.4527e-05,
        1.5338e-05, 4.3940e-06, 1.6229e-05, 8.3556e-06, 1.7716e-05, 7.4125e-06,
        3.5397e-06, 4.0019e-06, 8.3439e-06, 1.3971e-05, 1.1461e-05, 1.1367e-05,
        5.6853e-06, 9.7767e-06, 7.1043e-06, 1.9697e-05, 1.0066e-05, 8.1733e-06,
        8.3378e-06, 8.7578e-06, 5.5555e-06, 9.8436e-06, 6.4254e-06, 9.3841e-06,
        1.6987e-05, 9.8747e-06, 7.1266e-06, 8.4552e-06, 1.7187e-05, 1.0931e-05,
        1.3186e-05, 1.9442e-05, 7.6132e-06, 4.0780e-06, 1.7459e-05, 6.6920e-06,
        8.6617e-06, 6.6472e-06, 1.5436e-05, 9.6461e-06, 1.9264e-05, 2.2037e-06,
        4.7187e-06, 1.9046e-05, 2.7587e-05, 1.2355e-05, 7.4930e-06, 2.1367e-05,
        9.5791e-06, 5.7499e-05, 4.2333e-06, 2.0887e-05, 1.1727e-05, 4.8524e-06,
        1.6319e-05, 8.7207e-06, 7.7198e-06, 9.2596e-06, 5.6749e-06, 5.9586e-06,
        8.8970e-06, 1.5329e-05, 1.0832e-05, 6.9649e-06, 1.7709e-05, 3.1173e-05,
        9.0123e-06, 8.2234e-06, 1.6197e-05, 1.8338e-05, 1.3958e-05, 7.2900e-06,
        1.1423e-05, 2.1139e-05, 5.8814e-06, 6.3150e-06, 1.4399e-05, 1.6359e-05,
        2.5435e-05, 5.3358e-06, 5.2122e-06, 4.4719e-06, 2.1649e-05, 6.2591e-06,
        1.1989e-05, 4.3268e-06, 1.3974e-05, 2.8901e-05, 7.2452e-06, 5.2687e-06,
        1.1417e-05, 4.2435e-06, 1.6749e-05, 5.4252e-06, 4.8111e-06, 1.2149e-05,
        6.1002e-06, 6.6540e-06, 1.0117e-05, 6.0554e-06, 5.5556e-06, 1.0886e-05,
        2.4104e-05, 7.6479e-06, 5.8737e-06, 9.3470e-06, 4.8614e-06, 2.9738e-05,
        1.7299e-05, 8.0639e-06], device='cuda:0')}, 68: {'step': tensor(30200.), 'exp_avg': tensor([[ 1.4558e-04, -6.6916e-07,  4.6837e-05,  ...,  1.0073e-04,
          6.0403e-05,  8.2665e-05],
        [ 2.2213e-04, -1.5621e-04,  6.0066e-05,  ...,  3.9304e-05,
         -1.2114e-04, -2.3535e-04],
        [-3.1131e-04,  1.0503e-04,  1.4532e-04,  ...,  9.9702e-06,
          1.1909e-04, -1.3467e-04],
        ...,
        [-3.1224e-04, -1.3757e-04, -2.9253e-05,  ...,  1.9034e-04,
          2.3625e-04, -1.9573e-04],
        [-2.2539e-04,  2.3508e-04, -3.5550e-04,  ...,  2.0603e-04,
         -3.8250e-04, -5.0926e-04],
        [ 1.2998e-04, -8.1668e-05,  2.9252e-05,  ...,  6.6205e-06,
          3.3174e-04,  1.4412e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[5.5742e-07, 5.2977e-07, 9.0955e-07,  ..., 7.9671e-07, 4.4972e-07,
         1.0781e-06],
        [2.1617e-07, 2.3922e-07, 4.1727e-07,  ..., 2.7379e-07, 1.5620e-07,
         3.6319e-07],
        [2.6308e-07, 2.6564e-07, 4.9095e-07,  ..., 3.8982e-07, 2.0733e-07,
         5.7890e-07],
        ...,
        [9.2687e-07, 7.7221e-07, 1.6850e-06,  ..., 1.0579e-06, 9.5353e-07,
         1.4661e-06],
        [1.8710e-06, 2.2900e-06, 4.8286e-06,  ..., 2.6195e-06, 1.6584e-06,
         2.0341e-06],
        [8.8921e-07, 5.2307e-07, 1.3584e-06,  ..., 9.9457e-07, 8.4422e-07,
         1.3326e-06]], device='cuda:0')}, 69: {'step': tensor(30200.), 'exp_avg': tensor([[ 2.6741e-04, -3.5130e-04,  3.4281e-04,  ..., -1.6128e-04,
         -9.1568e-05, -3.7476e-04],
        [ 1.1141e-04, -2.1080e-05,  4.9601e-05,  ..., -7.0241e-05,
          1.6875e-04, -1.9315e-04],
        [-1.5208e-04,  1.8857e-04, -3.0637e-05,  ..., -3.0585e-04,
         -4.9004e-05,  1.1510e-04],
        ...,
        [-3.3819e-04, -6.2568e-04, -1.3881e-05,  ...,  9.7808e-06,
         -4.8600e-04,  3.8012e-04],
        [ 1.7560e-04, -2.0527e-05, -2.6017e-04,  ..., -1.5894e-04,
         -3.7164e-04, -3.9769e-05],
        [ 2.1160e-05, -4.7420e-04,  6.8200e-05,  ...,  1.0802e-04,
         -1.5639e-04, -9.0667e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[7.5639e-07, 1.0087e-06, 7.4039e-07,  ..., 8.1924e-07, 1.6740e-06,
         1.0677e-06],
        [7.6083e-07, 1.2177e-06, 7.5255e-07,  ..., 1.3719e-06, 2.0234e-06,
         1.1504e-06],
        [6.5987e-07, 1.0974e-06, 7.8564e-07,  ..., 8.4337e-07, 1.6128e-06,
         7.8850e-07],
        ...,
        [2.0678e-06, 2.3688e-06, 2.0961e-06,  ..., 1.9325e-06, 4.5503e-06,
         1.7588e-06],
        [8.3424e-07, 1.3001e-06, 1.0912e-06,  ..., 1.2357e-06, 2.5985e-06,
         1.5932e-06],
        [6.9875e-07, 8.4082e-07, 5.7407e-07,  ..., 7.5952e-07, 1.3179e-06,
         6.9649e-07]], device='cuda:0')}, 70: {'step': tensor(30200.), 'exp_avg': tensor([ 1.3814e-04, -5.8423e-05, -9.1493e-05, -1.5861e-04, -3.5777e-04,
        -1.8099e-05,  4.6576e-04,  7.7073e-04,  2.6712e-04, -6.7769e-04,
         4.7244e-04,  1.2242e-04, -5.1048e-04,  4.1522e-04, -3.5557e-04,
         2.8245e-04, -3.0851e-04,  4.6618e-04, -5.8613e-04, -4.7053e-05,
        -2.8214e-06, -6.5077e-04, -9.6931e-06, -1.0873e-04,  1.5385e-04,
        -1.8691e-04,  1.2192e-04, -2.7995e-05, -5.5816e-05,  6.4042e-04,
         5.1282e-04, -4.7912e-04,  2.3192e-04, -1.8301e-04, -2.3741e-04,
        -5.1825e-04,  3.4643e-04, -3.2252e-04,  1.6159e-04, -1.9545e-04,
        -1.1532e-04, -5.3109e-04,  3.0560e-04,  1.8784e-04,  1.3358e-04,
         2.8502e-04, -2.1539e-04, -1.8067e-04,  2.3273e-04,  1.6224e-04,
        -6.2557e-04, -4.1214e-04, -3.7610e-04, -2.4393e-04,  5.1054e-04,
         3.3660e-04,  3.9115e-04, -5.6969e-04,  1.9238e-04,  6.4273e-04,
        -9.2635e-04, -7.4077e-04, -9.3135e-05,  1.2219e-05,  6.5753e-04,
         1.6681e-05,  1.1288e-04, -2.9431e-04, -8.7884e-04, -6.9940e-05,
         2.5799e-04, -2.1321e-04, -7.1169e-04, -1.0485e-03,  4.0404e-04,
        -4.7304e-04,  4.5927e-05,  9.5009e-05, -4.9226e-05, -2.9920e-04,
         1.1820e-04,  3.2939e-04,  4.1719e-04,  3.3131e-04,  1.5002e-04,
        -5.7135e-05, -4.7200e-04,  4.2477e-04,  1.3127e-04,  4.9240e-04,
         3.4973e-04,  4.2063e-04,  7.5324e-04, -1.6459e-04, -8.1669e-05,
        -1.4525e-04,  2.5110e-04,  8.1116e-04,  1.9004e-04,  2.9513e-04,
        -5.8227e-04,  2.1855e-04,  5.9003e-04,  1.7740e-04, -7.3186e-04,
         3.0477e-04,  1.8415e-04,  4.4950e-04,  1.7143e-04, -2.9542e-04,
         2.2691e-04, -2.5676e-04,  4.0443e-04, -3.0548e-04,  9.1079e-06,
        -6.3666e-04, -2.3170e-04, -5.7915e-04,  2.8626e-04, -5.1473e-04,
         4.7976e-05,  5.2119e-04, -3.5269e-04,  2.6680e-04, -1.7524e-04,
        -4.5476e-04, -2.7801e-04, -2.5803e-04], device='cuda:0'), 'exp_avg_sq': tensor([7.7473e-06, 9.6406e-06, 4.2737e-06, 3.7638e-06, 3.9817e-06, 5.3732e-06,
        2.6302e-06, 8.8399e-06, 4.1004e-06, 6.0175e-06, 1.5091e-05, 5.2104e-06,
        2.4723e-05, 6.2294e-06, 5.9391e-06, 3.9982e-06, 1.0426e-05, 7.0622e-06,
        4.6814e-06, 8.6903e-06, 1.0732e-05, 1.4371e-05, 7.6560e-06, 7.6292e-06,
        3.9495e-06, 8.5567e-06, 5.3072e-06, 6.8358e-06, 9.3502e-06, 1.2367e-05,
        4.0427e-06, 6.0528e-06, 1.0128e-05, 3.3339e-06, 1.1271e-05, 6.3627e-06,
        6.9341e-06, 2.4058e-06, 2.0761e-05, 7.3616e-06, 8.7543e-06, 4.2658e-06,
        1.2026e-05, 7.8808e-06, 1.9809e-05, 5.3836e-06, 7.1411e-06, 2.0583e-05,
        1.0057e-05, 7.2401e-06, 1.4299e-05, 1.9120e-05, 3.8678e-06, 1.1606e-05,
        7.9453e-06, 1.1885e-05, 8.0176e-06, 3.7651e-06, 1.3915e-05, 9.4644e-06,
        6.7843e-06, 4.3443e-06, 6.3848e-06, 1.3135e-05, 7.0985e-06, 7.0195e-06,
        3.7711e-06, 2.9929e-06, 1.0074e-05, 7.5601e-06, 9.4360e-06, 2.4451e-06,
        9.8437e-06, 1.8263e-05, 3.8395e-06, 8.6739e-06, 8.9129e-06, 1.4536e-05,
        4.5679e-06, 5.7715e-06, 9.4595e-06, 1.8217e-05, 2.5700e-05, 1.6103e-05,
        8.1041e-06, 4.3484e-06, 5.1069e-06, 7.9909e-06, 3.5546e-06, 4.0457e-06,
        5.7933e-06, 5.8488e-06, 1.0092e-05, 7.7001e-06, 5.7587e-06, 6.4969e-06,
        5.6715e-06, 8.4902e-06, 6.1251e-06, 4.0393e-06, 7.0156e-06, 1.2402e-05,
        5.1096e-06, 3.6964e-06, 1.6085e-05, 1.4150e-05, 2.9385e-06, 3.2566e-06,
        1.5260e-05, 9.1867e-06, 9.3376e-06, 2.0420e-05, 3.2427e-06, 5.2284e-06,
        9.5866e-06, 4.6643e-06, 1.3187e-05, 8.4055e-06, 1.5607e-05, 6.5344e-06,
        9.3742e-06, 5.3842e-06, 6.0471e-06, 6.1902e-06, 5.0821e-06, 2.4556e-05,
        9.3261e-06, 5.0692e-06], device='cuda:0')}, 71: {'step': tensor(30200.), 'exp_avg': tensor([ 1.7423e-04, -1.0243e-04, -2.5530e-04, -3.8974e-05, -1.6030e-04,
         1.5321e-04, -1.6862e-05,  1.7653e-04,  1.1927e-04,  1.1606e-04,
         1.4370e-04,  1.4335e-04,  7.1492e-05,  1.5467e-04, -3.2390e-04,
         1.4074e-04, -5.2106e-04,  1.8059e-04,  1.3412e-04, -2.9429e-04,
        -3.6580e-04, -7.2498e-05,  6.5717e-05,  4.3805e-05, -7.9114e-05,
         4.5546e-05,  7.0259e-05, -2.1949e-05,  1.0156e-04,  1.4279e-04,
         2.1426e-05, -4.6479e-05, -1.0737e-04, -8.1794e-05, -4.9062e-05,
        -1.3030e-04,  1.9786e-04, -1.0814e-04,  6.4641e-05, -2.2558e-04,
        -2.0887e-04,  2.8786e-04, -1.6712e-04,  2.2365e-05, -7.8544e-05,
         3.4925e-05, -2.9390e-04,  3.0712e-04, -1.7282e-04, -2.7056e-04,
         2.4692e-04,  2.2196e-05,  1.5629e-04,  2.3635e-05, -9.9400e-05,
         1.0439e-04,  4.3329e-05,  1.0301e-04, -4.4854e-05,  1.0732e-04,
        -8.6853e-05, -2.0348e-04,  2.1192e-04, -2.0273e-04, -1.7253e-04,
        -3.4799e-05, -2.1372e-04,  1.4914e-04, -2.2920e-04,  1.5229e-05,
         2.9628e-05,  3.6366e-05,  2.0711e-04,  1.7637e-04,  1.1841e-04,
        -2.1412e-04,  2.1230e-04,  1.3052e-05, -4.7002e-04,  2.2445e-05,
        -4.8283e-05,  1.7705e-04, -1.3677e-04, -4.5882e-04,  2.4861e-05,
         1.1669e-04, -2.4899e-04, -1.2144e-04, -8.0976e-05, -2.7020e-04,
        -1.0505e-04,  1.5850e-04,  2.3184e-04,  1.9758e-04,  1.4170e-04,
        -5.9236e-05, -3.9448e-04, -9.4174e-05, -1.5083e-04,  2.5373e-04,
        -1.1751e-04, -2.5437e-04, -1.4220e-05, -6.6081e-05, -3.5516e-04,
        -1.0211e-04,  2.0513e-04,  1.8212e-04,  1.9758e-04,  3.5286e-05,
         1.7365e-04, -1.7859e-04,  8.1626e-05, -2.9683e-04, -1.7523e-04,
         2.1961e-04, -7.6464e-05, -7.6947e-05,  1.1312e-04,  1.8959e-04,
        -1.8922e-04, -3.1233e-04, -1.9377e-04,  1.0945e-04, -5.8215e-05,
         1.3430e-04, -1.0291e-06,  2.8812e-05], device='cuda:0'), 'exp_avg_sq': tensor([6.1037e-07, 7.8655e-07, 7.1505e-07, 1.7640e-06, 1.2274e-06, 8.5991e-07,
        4.9428e-07, 4.8130e-07, 4.8573e-07, 5.6818e-07, 1.2992e-06, 2.0250e-07,
        3.1817e-07, 5.6401e-07, 7.2814e-07, 4.7097e-07, 5.5616e-07, 5.4488e-07,
        4.1043e-07, 6.1513e-07, 8.6202e-07, 3.3724e-07, 4.1237e-07, 6.2447e-07,
        1.6820e-06, 7.6872e-07, 4.6124e-07, 5.0855e-07, 9.0962e-07, 6.5495e-07,
        4.0698e-07, 4.5473e-07, 4.1746e-07, 5.7229e-07, 4.2272e-07, 3.6807e-07,
        6.3296e-07, 4.3688e-07, 9.3620e-07, 4.4658e-07, 1.0478e-06, 5.4867e-07,
        6.7195e-07, 5.4476e-07, 3.5167e-07, 7.0558e-07, 3.9690e-07, 6.4179e-07,
        6.4198e-07, 6.6831e-07, 8.7672e-07, 5.2448e-07, 6.2729e-07, 3.5321e-07,
        3.7338e-07, 2.8418e-07, 4.7638e-07, 7.0833e-07, 8.7406e-07, 6.1812e-07,
        6.7533e-07, 6.9281e-07, 6.0444e-07, 4.5818e-07, 8.9726e-07, 4.0590e-07,
        7.4315e-07, 7.3764e-07, 6.7838e-07, 4.6381e-07, 3.9462e-07, 5.7613e-07,
        4.8635e-07, 3.3941e-07, 1.1397e-06, 3.9768e-07, 4.2423e-07, 4.2393e-07,
        9.9836e-07, 3.4556e-07, 7.5516e-07, 6.3642e-07, 1.2317e-06, 7.5618e-07,
        2.8292e-07, 9.8857e-07, 8.0690e-07, 4.7264e-07, 5.1365e-07, 6.3641e-07,
        4.7260e-07, 1.2476e-06, 4.2184e-07, 7.0188e-07, 4.9249e-07, 6.9569e-07,
        1.3403e-06, 6.0103e-07, 5.3452e-07, 8.2687e-07, 3.0268e-07, 2.2168e-06,
        3.7086e-07, 6.0326e-07, 1.3049e-06, 5.9830e-07, 7.1911e-07, 5.0976e-07,
        8.9677e-07, 5.5626e-07, 9.8561e-07, 4.7098e-07, 7.7572e-07, 4.6482e-07,
        4.2242e-07, 1.0541e-06, 3.2313e-07, 6.7001e-07, 1.0625e-06, 8.3738e-07,
        7.6228e-07, 8.2671e-07, 6.5235e-07, 5.8451e-07, 4.7604e-07, 7.6788e-07,
        6.6375e-07, 3.7568e-07], device='cuda:0')}, 72: {'step': tensor(30200.), 'exp_avg': tensor([-1.1859e-05, -1.8742e-04,  5.6674e-05,  1.2962e-06,  7.7501e-06,
         7.0488e-05,  6.6562e-05,  1.1219e-04,  7.2599e-05,  1.7060e-04,
        -1.7115e-04,  5.5978e-05, -1.6357e-04,  1.8428e-04, -2.5058e-04,
        -4.3010e-05,  1.8578e-04,  8.5539e-05,  1.3949e-04,  1.5954e-04,
         3.2834e-05, -2.7834e-05,  3.4669e-04,  7.3149e-05, -7.1498e-05,
         5.8740e-05,  5.1277e-05,  1.4200e-04, -2.2599e-06,  1.1245e-05,
         9.4640e-05, -2.6742e-04, -1.4312e-04, -9.4413e-05, -5.3580e-06,
         3.2284e-04, -6.1490e-05, -1.9758e-04,  1.0550e-05,  5.6093e-05,
        -1.5741e-04,  9.6426e-05, -1.6208e-04, -3.5264e-05, -2.5972e-05,
        -1.0845e-04, -1.7298e-04,  8.0350e-05, -6.2345e-05, -1.9382e-04,
        -7.5447e-05,  3.4081e-05, -8.1151e-05, -8.8276e-05, -1.2634e-04,
        -6.4373e-05,  9.7045e-05, -1.1183e-04, -4.0343e-05,  1.2869e-04,
        -3.9703e-04, -6.5939e-05,  1.7844e-05, -4.7423e-05, -6.6224e-05,
         1.8928e-04,  2.1261e-04, -7.7375e-05,  5.3671e-05,  1.3543e-05,
         8.8937e-05, -3.6837e-05, -5.3043e-04,  3.8717e-05, -1.4134e-05,
        -1.0399e-04,  2.5032e-05,  6.5599e-05, -5.1442e-04, -1.0377e-04,
         3.2150e-04, -2.7017e-04, -1.8203e-04,  1.7960e-04,  1.0640e-04,
         2.9668e-04,  1.6825e-04,  4.9481e-05, -3.2597e-05,  9.2883e-05,
        -6.7529e-05,  1.6395e-06, -1.2245e-04, -1.3114e-04, -7.9716e-05,
        -6.8144e-05,  2.7363e-04,  2.8810e-05, -6.0929e-05, -4.9673e-05,
        -2.4115e-04, -3.5639e-05,  2.6461e-05, -9.2882e-05, -1.4005e-04,
        -1.7712e-05, -4.9107e-05, -4.0272e-05, -3.2328e-04, -2.2288e-04,
        -7.7283e-05, -1.4272e-04,  9.5016e-05,  4.2431e-05, -8.0096e-05,
         8.0053e-05,  1.5429e-04, -6.5117e-05,  2.3232e-04, -2.2423e-04,
         7.2280e-05, -5.7720e-06, -9.8266e-05, -7.1034e-05, -4.3441e-05,
        -1.0557e-04, -4.9114e-06,  2.1341e-05], device='cuda:0'), 'exp_avg_sq': tensor([1.0567e-06, 9.7768e-07, 9.5235e-07, 1.3562e-06, 1.0839e-06, 2.6776e-06,
        9.7481e-07, 8.1261e-07, 9.2802e-07, 6.2775e-07, 2.0945e-06, 3.7284e-07,
        8.3052e-07, 8.1165e-07, 7.8146e-07, 7.7169e-07, 1.0481e-06, 5.8742e-07,
        5.8829e-07, 9.2604e-07, 1.3166e-06, 5.3837e-07, 5.1182e-07, 8.6662e-07,
        3.4428e-06, 9.7172e-07, 1.0350e-06, 7.0002e-07, 1.5883e-06, 1.2224e-06,
        7.2798e-07, 5.7538e-07, 5.7382e-07, 9.3744e-07, 3.8599e-07, 6.9636e-07,
        9.3640e-07, 4.1378e-07, 1.5464e-06, 6.5139e-07, 1.7672e-06, 1.0191e-06,
        7.4588e-07, 5.4297e-07, 5.4190e-07, 1.9637e-06, 8.1939e-07, 1.0914e-06,
        6.0225e-07, 1.2490e-06, 4.3855e-07, 5.7142e-07, 1.0070e-06, 1.0695e-06,
        1.0511e-06, 2.9256e-07, 8.8022e-07, 7.3674e-07, 1.6822e-06, 1.0031e-06,
        7.6470e-07, 9.7863e-07, 1.9606e-06, 3.6028e-07, 1.3466e-06, 5.9877e-07,
        1.1650e-06, 8.3941e-07, 8.5642e-07, 5.1508e-07, 4.0940e-07, 5.7136e-07,
        6.5934e-07, 6.3666e-07, 1.0276e-06, 5.2455e-07, 8.5052e-07, 4.4727e-07,
        1.5868e-06, 7.9968e-07, 1.2639e-06, 1.0469e-06, 1.5272e-06, 7.0164e-07,
        4.1207e-07, 1.2601e-06, 6.8284e-07, 7.2697e-07, 4.1609e-07, 1.3842e-06,
        5.3373e-07, 1.1211e-06, 5.1649e-07, 9.4615e-07, 1.0486e-06, 7.1040e-07,
        1.0395e-06, 8.2361e-07, 5.3865e-07, 9.4000e-07, 3.8684e-07, 3.0387e-06,
        9.5271e-07, 7.2055e-07, 1.7605e-06, 9.0208e-07, 2.0692e-06, 5.2778e-07,
        1.6189e-06, 9.8274e-07, 1.3283e-06, 6.8831e-07, 1.5613e-06, 8.4326e-07,
        5.9444e-07, 1.6994e-06, 6.3405e-07, 1.3647e-06, 1.3491e-06, 1.1171e-06,
        1.0486e-06, 4.8921e-07, 7.0397e-07, 6.3034e-07, 7.3952e-07, 7.3559e-07,
        9.2240e-07, 3.0630e-07], device='cuda:0')}, 73: {'step': tensor(30200.), 'exp_avg': tensor([[-4.4630e-04,  2.5070e-04,  5.9557e-05,  ...,  5.6362e-05,
          3.2969e-04,  2.8733e-04],
        [ 2.7516e-04, -1.8632e-04, -2.3824e-04,  ...,  2.4236e-04,
         -4.9341e-04, -1.2400e-04],
        [-3.7504e-04,  9.0873e-05,  8.5548e-05,  ..., -1.8308e-04,
          5.1076e-04,  2.3915e-04],
        ...,
        [-1.4869e-05, -9.0646e-05,  1.4845e-05,  ..., -2.5088e-04,
          9.0871e-05,  1.8521e-04],
        [-4.0849e-04,  2.5305e-04,  7.4930e-04,  ..., -4.2362e-04,
          2.9109e-04,  8.3176e-05],
        [-1.8443e-04,  7.3249e-06, -4.6297e-04,  ..., -8.9536e-05,
          1.3183e-05,  2.8842e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[7.4518e-07, 3.9441e-07, 4.7899e-07,  ..., 5.6207e-07, 5.0016e-07,
         5.1095e-07],
        [5.0490e-07, 5.1696e-07, 7.2283e-07,  ..., 8.4970e-07, 6.4375e-07,
         7.4448e-07],
        [4.5916e-07, 3.3314e-07, 4.3503e-07,  ..., 4.2632e-07, 3.6990e-07,
         7.3253e-07],
        ...,
        [4.6859e-07, 4.0123e-07, 5.8547e-07,  ..., 5.7107e-07, 3.7436e-07,
         5.5423e-07],
        [2.6423e-06, 2.0410e-06, 2.3323e-06,  ..., 3.3081e-06, 1.7032e-06,
         3.3370e-06],
        [5.7050e-07, 5.6246e-07, 1.0670e-06,  ..., 9.8929e-07, 6.6714e-07,
         8.8657e-07]], device='cuda:0')}, 74: {'step': tensor(30200.), 'exp_avg': tensor([-2.0079e-04,  1.7918e-05, -2.3958e-05, -1.5104e-05, -1.2288e-04,
         1.5549e-04, -3.2337e-04, -1.4333e-04,  6.6115e-05, -1.5820e-04,
        -4.5566e-05,  7.0031e-05, -1.4484e-04,  5.3225e-05,  3.5279e-04,
         1.3560e-04,  1.3185e-04,  4.7264e-05, -1.9279e-05,  2.1261e-04,
         1.6951e-04, -2.2723e-04,  2.8290e-04, -1.8693e-05,  1.5622e-05,
        -1.1478e-04,  2.7851e-05, -2.2695e-05, -3.0360e-04, -7.8194e-06,
         4.9706e-05, -1.1680e-04,  1.5741e-04, -5.3910e-05,  1.0070e-04,
        -9.0531e-05, -3.2203e-04,  1.0613e-04, -1.7869e-04,  1.7416e-04,
         5.2012e-05, -1.9995e-05,  6.0582e-05,  5.1247e-05,  9.4175e-05,
        -1.8125e-04,  2.7425e-04, -4.5503e-05, -1.5351e-04, -1.5795e-04,
        -3.7974e-05,  9.3401e-05,  6.6130e-06, -4.8974e-05,  4.6437e-05,
         1.0450e-04,  2.1577e-04, -1.4523e-04, -9.1205e-06,  1.6538e-06,
        -2.5282e-04,  7.2690e-05,  4.7600e-05,  1.5981e-05, -1.5634e-04,
        -1.5205e-04, -2.0578e-04, -1.0830e-04, -6.3829e-05, -2.8533e-05,
        -2.3344e-04,  3.3016e-04, -7.8547e-05, -3.0534e-04, -2.5732e-04,
         6.8517e-05,  3.0065e-04, -3.2138e-05, -8.0634e-06,  8.1356e-06,
         1.5765e-04, -5.1046e-05, -3.1675e-05,  2.3784e-05, -2.1237e-04,
        -4.1524e-05, -2.6173e-04, -1.2046e-04, -1.5668e-04, -8.2713e-06,
        -5.6594e-05,  5.6444e-05, -3.1604e-04,  1.9163e-05, -8.3267e-05,
         1.4599e-04,  1.2900e-04, -7.1458e-05,  1.5358e-05,  7.4676e-05,
        -5.2209e-05, -1.7705e-04, -1.6594e-04,  1.3251e-04, -3.6602e-06,
        -5.7164e-05,  3.9386e-05,  5.8312e-05,  2.8980e-05, -9.9599e-05,
        -1.3825e-04,  6.2633e-05, -2.0324e-04, -1.6327e-04,  4.2931e-05,
         1.5576e-04,  1.7096e-04, -1.0078e-04, -1.2073e-05, -7.3097e-05,
         3.5505e-04,  2.7357e-04, -1.2086e-04, -1.7676e-04,  2.6031e-05,
        -6.6832e-05,  1.1187e-04,  9.6671e-05,  1.1168e-04, -1.3927e-04,
         5.3374e-06, -2.3272e-04,  7.0322e-06, -2.3813e-04, -1.0371e-04,
         1.2699e-04,  9.9860e-05,  1.2009e-04,  2.0185e-04,  3.1953e-04,
        -2.8843e-04, -7.6630e-05, -1.4847e-04, -1.2706e-04, -1.6346e-05,
        -1.3304e-04,  3.2461e-04, -2.7373e-06, -2.1869e-05,  6.4778e-05,
        -1.2666e-04,  4.9446e-04, -1.0359e-04,  2.6116e-04,  2.0614e-04,
        -4.2929e-05,  4.3238e-05, -4.9351e-05,  3.8659e-04, -9.0124e-05,
         3.5858e-05,  7.7021e-05,  7.8890e-05, -1.8403e-04,  1.8535e-04,
         1.8777e-05,  5.8722e-05,  1.4752e-04, -1.7490e-04,  9.6276e-05,
        -3.5152e-05, -2.5361e-04, -2.5263e-04, -1.2328e-04, -2.4220e-06,
         1.8261e-04, -3.6195e-05, -3.8958e-05,  7.9799e-05, -5.8361e-05,
        -3.0900e-05, -1.3967e-04,  1.4003e-05, -1.7985e-04, -7.1321e-05,
         4.2003e-05, -1.0022e-06, -5.1844e-05, -1.1556e-04, -2.6042e-05,
        -5.1773e-05,  2.0804e-04,  2.9497e-05,  6.1237e-05, -6.5994e-05,
         3.9901e-05,  2.3676e-05,  2.2666e-05, -5.2010e-05,  1.1168e-04,
         1.0293e-04, -2.4685e-05, -2.2504e-04, -4.1028e-04, -7.3679e-05,
        -1.2844e-04, -9.7311e-05,  3.2427e-04, -6.4328e-05,  4.5379e-05,
         7.6098e-05,  5.6623e-05,  4.7373e-05, -1.4323e-04, -5.6820e-05,
        -1.6441e-04, -1.4685e-04,  1.8179e-04, -3.0629e-05, -2.5939e-04,
         7.2977e-05,  1.8614e-04, -9.3535e-05,  1.7263e-04,  7.2334e-05,
        -7.9912e-05, -4.8944e-05, -3.0817e-04, -3.5718e-06, -2.2690e-05,
        -3.8479e-06,  3.3861e-04, -1.0148e-04, -7.0321e-05,  1.8963e-04,
        -2.2465e-04,  1.6183e-05, -5.9733e-05, -1.8515e-04,  1.9810e-04,
         2.0306e-04, -6.7056e-05,  8.7397e-05, -2.3707e-05, -3.0268e-05,
        -2.1782e-04, -1.9020e-04,  3.4931e-04,  1.9184e-04, -6.9899e-05,
         7.4816e-05, -9.6776e-05,  1.5864e-04,  1.2908e-04,  1.5767e-04,
         1.2396e-05], device='cuda:0'), 'exp_avg_sq': tensor([6.0099e-07, 7.7026e-07, 4.8787e-07, 3.8584e-07, 5.7289e-07, 3.1735e-07,
        1.1933e-06, 7.4345e-07, 2.4112e-06, 1.1820e-06, 7.2617e-07, 3.7790e-07,
        8.0366e-07, 5.1494e-07, 1.8421e-06, 2.2704e-07, 1.1978e-06, 2.6419e-07,
        5.9006e-07, 9.9798e-07, 8.0943e-07, 6.0043e-07, 9.2572e-07, 7.0616e-07,
        8.0792e-07, 1.4234e-06, 2.5233e-07, 7.4390e-07, 2.2968e-06, 6.3455e-07,
        4.5702e-07, 3.2410e-07, 8.5030e-07, 2.9038e-07, 7.0636e-07, 1.9828e-06,
        8.8398e-07, 9.3157e-07, 3.2670e-07, 2.0096e-06, 6.6403e-07, 9.0297e-07,
        1.2198e-06, 4.6978e-07, 5.1024e-07, 1.0580e-06, 1.7983e-06, 4.9988e-07,
        1.2554e-06, 4.4770e-07, 5.3706e-07, 7.9645e-07, 6.1798e-07, 1.0381e-06,
        6.1165e-07, 8.0884e-07, 1.4864e-06, 2.4197e-07, 2.1235e-06, 4.0259e-07,
        8.0610e-07, 8.8399e-07, 4.1214e-07, 4.7924e-07, 3.8859e-07, 3.4739e-07,
        6.9804e-07, 3.7314e-07, 5.7121e-07, 9.3633e-07, 6.1679e-07, 6.9844e-07,
        9.9590e-07, 1.2784e-06, 7.5251e-07, 6.6787e-07, 1.2967e-06, 9.4608e-07,
        2.7099e-07, 3.6284e-07, 9.2951e-07, 4.9944e-07, 2.8550e-07, 1.5027e-07,
        1.6025e-06, 9.8070e-07, 4.9413e-07, 6.8236e-07, 1.0602e-06, 4.2237e-07,
        7.8307e-07, 6.9142e-07, 7.2048e-07, 5.5266e-07, 6.9224e-07, 4.3910e-07,
        7.6642e-07, 3.6179e-07, 7.5593e-07, 6.1509e-07, 4.0762e-07, 8.2517e-07,
        1.0186e-06, 3.1438e-07, 2.6595e-07, 5.2986e-07, 9.0342e-07, 1.0229e-06,
        8.8091e-07, 3.8235e-07, 1.1401e-06, 1.2705e-06, 7.4405e-07, 1.1813e-06,
        8.9865e-07, 9.9676e-07, 5.5285e-07, 1.0550e-06, 6.0230e-07, 1.3233e-06,
        7.9280e-07, 7.2779e-07, 3.3654e-07, 1.2955e-06, 5.2458e-07, 5.4570e-07,
        7.0742e-07, 5.0288e-07, 4.2415e-07, 2.8825e-07, 4.7423e-07, 7.9740e-07,
        1.1784e-06, 5.8053e-07, 4.6291e-07, 5.9817e-07, 1.1569e-06, 5.9583e-07,
        2.2727e-06, 1.1402e-06, 1.7464e-06, 5.8679e-07, 5.4632e-07, 6.7862e-07,
        4.7761e-07, 1.0405e-06, 6.3325e-07, 8.0388e-07, 2.2706e-06, 5.6646e-07,
        3.9646e-07, 1.1964e-06, 2.8479e-07, 1.7739e-06, 5.6147e-07, 1.6962e-06,
        9.9364e-07, 4.0342e-07, 6.9867e-07, 1.1285e-06, 2.9978e-07, 3.8373e-07,
        7.2542e-07, 8.8720e-07, 5.8207e-07, 8.2498e-07, 1.8617e-06, 9.4740e-07,
        6.2824e-07, 6.9493e-07, 4.9360e-07, 9.1918e-07, 3.0389e-07, 5.3280e-07,
        8.2702e-07, 2.4182e-06, 3.4685e-07, 4.0382e-07, 3.4802e-07, 5.3612e-07,
        1.0883e-06, 3.9559e-07, 1.3453e-06, 6.1707e-07, 3.8031e-07, 5.5033e-07,
        3.4242e-07, 7.6402e-07, 1.3474e-06, 1.6502e-06, 4.5856e-07, 9.8070e-07,
        7.5395e-07, 9.5120e-07, 3.4030e-07, 1.8837e-06, 3.8569e-07, 4.1562e-07,
        8.7615e-07, 2.5907e-07, 5.6137e-07, 9.0392e-07, 1.6162e-06, 1.0371e-06,
        1.1227e-06, 7.8905e-07, 1.1498e-06, 1.2437e-06, 5.6723e-07, 1.0258e-06,
        1.7313e-06, 1.0710e-06, 5.5935e-07, 4.6292e-07, 3.5923e-07, 4.1457e-07,
        1.1441e-06, 3.1357e-07, 5.1215e-07, 1.1409e-06, 2.8941e-07, 9.8106e-07,
        8.5496e-07, 3.7088e-07, 2.3404e-07, 1.7043e-07, 1.0829e-06, 8.3212e-07,
        4.2228e-07, 4.8315e-07, 6.0952e-07, 1.0762e-06, 6.3164e-07, 6.8733e-07,
        1.7946e-06, 1.2687e-06, 8.7483e-07, 6.8779e-07, 4.9175e-07, 8.1662e-07,
        6.5022e-07, 4.3291e-07, 9.3403e-07, 6.0673e-07, 3.8843e-07, 7.5794e-07,
        1.8644e-06, 6.5430e-07, 1.0273e-06, 2.8801e-07, 5.9373e-07, 7.3394e-07,
        1.0071e-06, 8.7126e-07, 1.9276e-06, 9.2775e-07], device='cuda:0')}, 75: {'step': tensor(30200.), 'exp_avg': tensor([[ 1.5523e-04,  2.4759e-04,  1.3459e-04,  ..., -2.0578e-04,
         -1.8266e-05,  3.0857e-04],
        [ 3.0126e-04,  3.3986e-05, -9.9206e-05,  ...,  1.3224e-04,
          1.7354e-04, -2.7242e-05],
        [-2.0782e-04, -3.3012e-04, -2.1059e-04,  ...,  1.0072e-04,
          5.1654e-05, -3.4380e-04],
        ...,
        [-3.6905e-04, -3.4997e-04,  1.7224e-04,  ...,  3.4078e-04,
          1.3092e-04,  2.6415e-04],
        [-2.0849e-04,  3.4559e-04,  1.1011e-05,  ...,  1.4328e-04,
          1.0351e-04, -3.7577e-04],
        [-3.2802e-06,  1.9107e-05,  9.2073e-05,  ...,  1.1716e-04,
         -8.0767e-05,  1.9445e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[9.8313e-07, 1.6864e-06, 4.8967e-07,  ..., 6.9470e-07, 2.0757e-06,
         1.3217e-06],
        [8.2314e-07, 1.0884e-06, 3.8768e-07,  ..., 1.0494e-06, 1.3707e-06,
         9.6429e-07],
        [7.3934e-07, 1.3421e-06, 4.2838e-07,  ..., 4.1434e-07, 1.4667e-06,
         6.7998e-07],
        ...,
        [1.9327e-06, 1.7468e-06, 5.9321e-07,  ..., 9.5766e-07, 2.0597e-06,
         1.5395e-06],
        [1.2093e-06, 1.7055e-06, 4.8749e-07,  ..., 8.9470e-07, 1.4123e-06,
         1.7698e-06],
        [6.7167e-07, 1.1406e-06, 3.8513e-07,  ..., 5.6053e-07, 1.5097e-06,
         8.0887e-07]], device='cuda:0')}, 76: {'step': tensor(30200.), 'exp_avg': tensor([ 2.9434e-05,  1.5114e-04, -6.5256e-05,  1.9450e-06, -2.9027e-04,
        -3.1803e-04,  3.9975e-04,  5.7282e-04,  3.8429e-04, -5.7026e-04,
         5.8011e-04, -3.5866e-06, -4.1705e-05,  4.0467e-04,  7.6828e-05,
         1.2232e-04, -6.9160e-04,  7.2057e-04, -7.2302e-04, -2.1475e-05,
        -1.1654e-04, -2.8984e-04,  1.8838e-04, -1.1512e-04,  2.2225e-04,
        -2.6911e-04,  1.4006e-04,  5.0364e-05, -4.8426e-04,  5.7010e-04,
         3.8356e-04, -2.0444e-04,  4.9790e-04, -1.0476e-04, -8.1112e-05,
        -4.0175e-04,  2.1640e-04, -4.7138e-04,  6.0080e-05,  2.2297e-04,
         5.8060e-05, -5.1932e-04,  4.5968e-04,  2.9542e-04,  2.4415e-04,
         6.2054e-05, -3.5214e-04,  3.9567e-05, -2.1275e-05,  2.2079e-04,
        -5.9775e-04, -8.4302e-05,  1.6905e-04, -3.1390e-05,  7.9853e-04,
         2.6203e-04,  1.0363e-04, -6.9032e-04,  9.7144e-05,  7.8914e-04,
        -9.8735e-04, -5.2481e-04,  2.4141e-04,  2.3051e-04,  8.4342e-04,
         4.9901e-05, -9.0395e-05, -3.0715e-04, -7.3037e-04, -3.3429e-04,
         8.8185e-05, -4.9772e-05, -5.2962e-04, -8.8671e-04,  3.1517e-04,
        -4.4384e-04, -1.3717e-04,  3.0149e-04,  3.0238e-04, -4.7440e-04,
        -2.5813e-05,  5.0287e-04,  4.2575e-04, -1.3012e-04, -1.1108e-05,
         3.3162e-05, -8.9112e-04, -1.3661e-04,  1.5905e-04,  1.0398e-04,
         1.7193e-04,  2.2007e-04,  6.8876e-04, -4.0244e-05,  8.6219e-05,
        -2.3788e-04,  3.7300e-05,  7.2590e-04, -2.4561e-04,  5.1820e-04,
        -2.4731e-04,  3.9308e-04,  7.9803e-04,  9.9240e-05, -7.5532e-04,
         3.2537e-04,  1.9720e-04,  3.1246e-04,  7.2828e-05, -3.1625e-04,
         4.4504e-04, -9.0971e-05,  5.7247e-04, -4.8092e-04,  2.1948e-04,
        -5.2478e-04, -2.7253e-04, -4.5586e-04, -1.7890e-05, -1.5853e-05,
         5.1279e-04,  5.4504e-04, -3.4989e-04,  3.3844e-04, -3.3945e-04,
        -4.9735e-07, -8.1613e-05, -3.5874e-04], device='cuda:0'), 'exp_avg_sq': tensor([8.3987e-06, 1.0012e-05, 2.7626e-06, 2.5718e-06, 4.0396e-06, 3.5981e-06,
        2.4888e-06, 6.7617e-06, 4.7376e-06, 5.1590e-06, 1.1423e-05, 5.8837e-06,
        2.3124e-05, 4.6657e-06, 6.3738e-06, 3.8105e-06, 9.3344e-06, 7.4516e-06,
        4.5587e-06, 9.8884e-06, 7.5547e-06, 1.4298e-05, 7.5436e-06, 6.8847e-06,
        7.1042e-06, 8.4214e-06, 6.6026e-06, 6.0465e-06, 8.0845e-06, 1.5753e-05,
        4.5022e-06, 5.5335e-06, 1.1145e-05, 4.2372e-06, 1.1687e-05, 7.4103e-06,
        6.6005e-06, 2.2004e-06, 1.8577e-05, 6.0821e-06, 9.1985e-06, 5.7117e-06,
        1.2630e-05, 6.9139e-06, 1.7250e-05, 5.9051e-06, 8.5345e-06, 1.9273e-05,
        8.1825e-06, 7.3561e-06, 1.4578e-05, 1.7606e-05, 3.2621e-06, 1.1076e-05,
        1.0092e-05, 1.1071e-05, 6.7168e-06, 4.3826e-06, 1.0441e-05, 7.1162e-06,
        7.0193e-06, 4.7157e-06, 3.7946e-06, 1.2268e-05, 7.6265e-06, 5.9637e-06,
        2.9931e-06, 2.2980e-06, 8.6250e-06, 7.9086e-06, 9.3831e-06, 2.1804e-06,
        9.9420e-06, 1.6815e-05, 4.0826e-06, 9.3828e-06, 9.4210e-06, 1.3612e-05,
        4.4646e-06, 5.0656e-06, 7.8320e-06, 1.9371e-05, 2.0009e-05, 1.8424e-05,
        8.1988e-06, 4.7062e-06, 4.4329e-06, 7.4745e-06, 3.9715e-06, 4.8617e-06,
        4.8267e-06, 5.8744e-06, 1.0127e-05, 9.4363e-06, 4.1983e-06, 6.9880e-06,
        6.3211e-06, 7.3271e-06, 6.8356e-06, 5.2018e-06, 6.8210e-06, 1.4564e-05,
        4.0056e-06, 4.3182e-06, 1.2444e-05, 1.2979e-05, 5.3619e-06, 2.7588e-06,
        1.7347e-05, 9.1377e-06, 8.4856e-06, 2.2789e-05, 3.2754e-06, 6.2526e-06,
        8.7597e-06, 6.6497e-06, 1.4321e-05, 1.0030e-05, 1.2386e-05, 4.5528e-06,
        8.7079e-06, 4.8122e-06, 5.7195e-06, 5.0492e-06, 4.9022e-06, 2.3838e-05,
        9.8892e-06, 5.2625e-06], device='cuda:0')}, 77: {'step': tensor(30200.), 'exp_avg': tensor([-2.3965e-05, -2.8981e-05,  2.4530e-04,  3.4942e-04, -3.5541e-04,
        -6.0950e-04,  6.5318e-04, -6.5383e-04,  6.0717e-05,  3.5598e-04,
         8.2735e-05,  2.7659e-04,  2.9370e-04,  8.9322e-04, -3.2145e-04,
         3.1401e-04, -1.9020e-04, -1.0982e-04, -1.4696e-04, -2.3921e-04,
        -1.6555e-04, -1.2195e-03,  3.9384e-05, -2.5241e-04, -3.3317e-04,
        -3.4167e-04,  2.8978e-05, -6.1387e-04,  3.6660e-05, -8.9243e-04,
        -3.1620e-04,  4.7626e-05,  2.3405e-04,  3.4250e-04, -1.1967e-05,
         3.7573e-04, -3.3483e-04, -1.0320e-04,  3.9046e-04,  6.9027e-07,
        -2.4569e-05, -1.2782e-04, -1.7299e-04, -9.2529e-05, -4.3201e-04,
         6.0696e-05, -8.5511e-04, -1.4203e-04, -7.5165e-04,  7.7801e-04,
         3.6190e-04,  4.7141e-04,  2.1373e-04, -3.7778e-04, -1.5341e-04,
         2.0130e-04, -1.4729e-04,  1.3057e-04,  2.3094e-04,  3.4830e-04,
        -1.7661e-04,  5.2439e-05,  3.8600e-04, -5.5992e-04, -1.7360e-04,
         2.9789e-04,  3.8629e-04,  1.9160e-04,  5.5354e-04, -1.6301e-04,
         9.2831e-05, -1.2776e-04,  4.6592e-05,  4.9773e-04,  8.3402e-04,
        -4.3634e-04,  6.3019e-05, -3.8606e-04,  4.0744e-04,  2.5801e-05,
        -1.5912e-04, -1.5601e-03,  2.8406e-04,  2.7595e-04, -6.0253e-04,
         6.5793e-04,  1.6262e-04, -1.5138e-05,  4.6014e-04,  6.1564e-04,
         5.2133e-04, -9.5469e-04, -6.4870e-07,  8.4071e-05, -2.3201e-04,
         6.4109e-04, -5.6221e-04,  2.9114e-04,  7.0319e-04,  7.8063e-04,
         8.0779e-05, -6.1733e-04, -3.9324e-05,  8.5102e-04,  3.4125e-05,
        -1.0451e-03, -6.2943e-04,  2.7259e-04, -8.8270e-04,  1.2080e-04,
         5.4345e-04,  9.2214e-04,  7.3923e-05,  7.1423e-04,  8.6347e-04,
        -8.1600e-04,  2.3431e-04, -5.2703e-04,  3.2801e-04,  9.3466e-04,
         5.6971e-04, -2.1576e-04, -5.7688e-05,  7.2646e-04, -8.3929e-04,
        -4.9176e-05, -2.0656e-04,  1.9629e-04], device='cuda:0'), 'exp_avg_sq': tensor([7.0341e-06, 3.0673e-06, 5.3271e-06, 1.4715e-05, 9.9803e-06, 5.4616e-06,
        3.0827e-06, 5.1463e-06, 7.3513e-06, 6.9558e-06, 2.8856e-06, 3.8937e-06,
        3.5319e-06, 6.2843e-06, 8.6602e-06, 2.7534e-06, 7.1609e-06, 7.7505e-06,
        3.7833e-06, 7.8461e-06, 3.9597e-06, 8.2056e-06, 5.4254e-06, 5.2695e-06,
        4.9142e-06, 4.9109e-06, 4.4503e-06, 5.0231e-06, 5.1662e-06, 5.6538e-06,
        6.6275e-06, 9.7392e-06, 5.3318e-06, 6.6686e-06, 4.9677e-06, 5.8417e-06,
        4.6496e-06, 4.7115e-06, 6.2650e-06, 3.1977e-06, 5.6428e-06, 4.0722e-06,
        6.2625e-06, 5.0421e-06, 7.4646e-06, 9.0210e-06, 7.2024e-06, 2.4887e-06,
        7.2664e-06, 5.4393e-06, 1.7438e-05, 1.0377e-05, 3.6259e-06, 6.9606e-06,
        3.1449e-06, 4.6703e-06, 2.5955e-06, 6.9909e-06, 6.0212e-06, 8.2026e-06,
        3.8971e-06, 5.1166e-06, 4.5794e-06, 5.9729e-06, 3.8304e-06, 4.3806e-06,
        5.8087e-06, 6.5562e-06, 5.2124e-06, 6.3234e-06, 8.4863e-06, 2.5622e-06,
        4.4814e-06, 4.6720e-06, 5.5579e-06, 4.0088e-06, 3.8561e-06, 6.5556e-06,
        6.8629e-06, 3.7406e-06, 6.0913e-06, 8.2703e-06, 1.1710e-05, 7.3174e-06,
        3.5851e-06, 5.8467e-06, 6.5761e-06, 3.8030e-06, 5.2470e-06, 3.1323e-06,
        9.5927e-06, 6.2732e-06, 5.5234e-06, 4.9240e-06, 7.0268e-06, 7.1045e-06,
        5.8663e-06, 5.7268e-06, 1.0508e-05, 4.6869e-06, 3.2363e-06, 4.9553e-06,
        6.6029e-06, 6.1456e-06, 1.0306e-05, 1.1037e-05, 4.4499e-06, 4.5637e-06,
        8.9139e-06, 6.0395e-06, 6.0627e-06, 6.0091e-06, 3.9978e-06, 2.5325e-06,
        3.2640e-06, 3.9016e-06, 5.3824e-06, 2.7874e-06, 1.3341e-05, 9.4011e-06,
        3.7536e-06, 9.0814e-06, 1.2416e-05, 7.8524e-06, 7.1924e-06, 9.1279e-06,
        1.3299e-05, 7.4854e-06], device='cuda:0')}, 78: {'step': tensor(30200.), 'exp_avg': tensor([ 8.4972e-05,  5.6387e-04, -1.9310e-04, -1.7599e-04, -5.4045e-04,
        -6.3321e-04,  2.9938e-04,  3.6782e-04, -9.0483e-05, -2.1637e-05,
         4.0588e-04,  2.0481e-04, -4.6316e-05, -3.1802e-04, -1.8590e-04,
         4.0596e-04, -7.0367e-04,  2.5815e-04, -7.9038e-04, -3.4657e-04,
         3.9454e-04, -5.5885e-04, -1.7365e-04, -7.5100e-05,  4.5675e-05,
        -1.7525e-04, -7.3586e-05,  2.3168e-04, -9.7901e-05,  7.7466e-04,
         3.8397e-05,  1.9062e-04,  1.5062e-04, -4.1024e-04, -1.2306e-04,
        -5.3844e-04,  1.3514e-04, -3.3729e-04, -1.6496e-04, -1.3669e-04,
        -2.9966e-04, -3.6430e-04,  1.3164e-04,  5.0881e-04,  2.0408e-04,
         3.2274e-04, -3.9469e-04,  2.1765e-05,  1.6187e-04,  9.1769e-04,
        -3.8825e-04,  6.4593e-04,  1.6901e-04, -7.0412e-04,  3.3747e-04,
         2.5375e-05, -4.9763e-04, -1.0042e-03, -1.7269e-04,  2.4369e-04,
        -9.9504e-04, -5.8783e-04,  3.9729e-04, -6.8766e-05,  3.5176e-04,
         3.2846e-04, -2.4565e-04,  3.0950e-05, -4.9625e-04,  3.4731e-04,
        -4.0801e-05, -1.3769e-04, -2.2398e-04, -3.7372e-04, -6.6811e-05,
        -2.9203e-04,  5.2837e-06,  2.2327e-04,  5.4472e-04,  2.1208e-04,
         1.1554e-04,  8.8663e-06,  5.1794e-04, -2.2345e-04,  2.6697e-04,
        -3.8971e-04, -3.6160e-04, -3.6000e-05, -3.5387e-05,  6.2050e-05,
         7.3653e-04,  3.5318e-04,  5.5016e-04, -1.7697e-04, -2.4132e-05,
        -1.2266e-04, -4.1128e-04,  3.7809e-04,  1.6039e-04, -2.5046e-05,
        -3.3202e-04,  5.6738e-04,  1.8813e-04,  3.4110e-05, -7.8032e-05,
        -4.4124e-04,  6.2942e-04, -1.6977e-04,  7.0126e-04, -3.8945e-04,
         2.7753e-04, -1.8033e-04,  2.4232e-04, -5.5981e-04,  1.2669e-04,
        -4.8184e-04, -7.0329e-04, -2.9153e-04, -4.9119e-06,  1.6133e-04,
         2.2062e-04,  7.5053e-04, -1.2503e-04,  1.8884e-04, -7.6112e-04,
        -2.0678e-04,  2.6539e-04,  1.6894e-05], device='cuda:0'), 'exp_avg_sq': tensor([1.1617e-05, 8.0679e-06, 3.2520e-06, 1.7332e-05, 7.4523e-06, 9.8356e-06,
        5.6194e-06, 3.3085e-06, 8.9462e-06, 1.1733e-05, 3.8218e-06, 9.1086e-06,
        7.6365e-06, 6.5626e-06, 1.1701e-05, 2.4799e-06, 7.4703e-06, 8.2426e-06,
        3.8155e-06, 9.8772e-06, 2.7874e-06, 2.2022e-05, 3.9147e-06, 4.6849e-06,
        1.1838e-05, 8.2109e-06, 1.0124e-05, 4.9662e-06, 3.7328e-06, 1.6706e-05,
        9.0913e-06, 5.8804e-06, 8.2509e-06, 7.1978e-06, 5.8286e-06, 1.0212e-05,
        6.6021e-06, 4.0040e-06, 6.2003e-06, 5.4985e-06, 7.3031e-06, 5.4072e-06,
        5.2663e-06, 5.0388e-06, 1.6633e-05, 5.4224e-06, 3.7746e-06, 2.9187e-06,
        2.4495e-05, 1.3232e-05, 9.1877e-06, 4.1341e-06, 5.0853e-06, 1.8879e-05,
        1.0813e-05, 6.6999e-06, 3.0116e-06, 3.5745e-06, 1.4167e-05, 1.3271e-05,
        7.7500e-06, 4.3485e-06, 3.5855e-06, 4.1767e-06, 4.9077e-06, 1.2476e-05,
        5.1940e-06, 2.5235e-06, 4.4257e-06, 7.9915e-06, 8.8697e-06, 1.8006e-06,
        9.6991e-06, 1.5082e-05, 5.5074e-06, 5.5098e-06, 6.3131e-06, 1.0434e-05,
        6.0058e-06, 4.4998e-06, 8.2345e-06, 1.8450e-05, 7.2757e-06, 1.7357e-05,
        5.6053e-06, 6.4331e-06, 9.6328e-06, 3.4126e-06, 5.7279e-06, 4.8234e-06,
        1.7773e-05, 9.0304e-06, 9.5825e-06, 1.3448e-05, 1.7250e-05, 4.1843e-06,
        2.8196e-06, 1.1040e-05, 9.2918e-06, 4.0977e-06, 1.0682e-05, 1.6614e-05,
        9.3717e-06, 4.3472e-06, 7.6929e-06, 8.1411e-06, 1.1903e-05, 5.5621e-06,
        3.5753e-05, 1.1036e-05, 6.6122e-06, 2.0644e-05, 5.1983e-06, 5.8569e-06,
        6.3067e-06, 8.7932e-06, 8.6968e-06, 4.5653e-06, 2.9830e-05, 9.1833e-06,
        3.1894e-06, 9.0983e-06, 1.7501e-05, 1.3423e-05, 1.3704e-05, 1.8797e-05,
        9.4314e-06, 7.2119e-06], device='cuda:0')}, 79: {'step': tensor(30200.), 'exp_avg': tensor([[-2.1442e-04,  1.1720e-04, -1.6507e-04,  ...,  9.1035e-05,
          4.7944e-05, -2.3306e-04],
        [-7.0404e-05,  8.4627e-06,  3.9925e-05,  ...,  6.3907e-05,
         -2.4358e-04, -3.0160e-04],
        [-2.8311e-05,  1.0032e-05, -2.9862e-05,  ...,  5.1559e-05,
          9.6294e-05,  1.6025e-04],
        ...,
        [-1.4467e-06,  1.9826e-04, -1.8098e-04,  ..., -1.1985e-04,
         -6.6522e-05, -6.7983e-05],
        [ 1.1893e-05,  1.4032e-04, -5.7978e-05,  ...,  3.6003e-05,
         -1.8761e-04, -6.0132e-05],
        [ 1.2264e-04,  3.7726e-04, -3.4961e-04,  ...,  6.3713e-04,
         -6.6372e-04, -6.9432e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[7.7840e-07, 6.3555e-07, 1.0005e-06,  ..., 9.0332e-07, 8.5218e-07,
         1.2848e-06],
        [7.4383e-07, 5.6544e-07, 1.0601e-06,  ..., 7.8661e-07, 9.6038e-07,
         1.4780e-06],
        [3.6847e-07, 3.7266e-07, 5.2315e-07,  ..., 3.8769e-07, 6.7396e-07,
         7.5879e-07],
        ...,
        [7.3446e-07, 3.0441e-07, 1.2724e-06,  ..., 7.7999e-07, 5.6783e-07,
         5.4254e-07],
        [3.9982e-07, 1.5324e-07, 7.9126e-07,  ..., 4.3132e-07, 3.6089e-07,
         3.9089e-07],
        [3.3799e-06, 1.2436e-06, 7.2193e-06,  ..., 4.1148e-06, 2.2361e-06,
         2.8433e-06]], device='cuda:0')}, 80: {'step': tensor(30200.), 'exp_avg': tensor([[ 2.7103e-04, -1.2664e-05,  5.9321e-05,  ...,  3.8352e-05,
         -1.5365e-04,  1.8876e-04],
        [-6.5088e-05,  8.6499e-05,  5.5883e-04,  ...,  5.1563e-06,
         -1.1727e-04,  8.5113e-05],
        [ 2.2604e-05,  1.2170e-04,  2.8203e-04,  ...,  1.2363e-04,
         -2.2594e-04,  4.0100e-04],
        ...,
        [-2.1721e-04, -7.4403e-04, -5.0273e-04,  ...,  3.1916e-04,
          2.8202e-04,  2.6270e-04],
        [-4.4349e-04,  8.9880e-05, -9.1547e-05,  ...,  1.3217e-04,
          3.9820e-05, -6.8320e-05],
        [-2.9850e-04,  1.0739e-05, -1.0718e-04,  ...,  3.0814e-05,
         -1.1819e-04, -1.3315e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[1.4501e-06, 1.5084e-06, 2.4536e-06,  ..., 1.0716e-06, 9.9265e-07,
         1.8256e-06],
        [1.3061e-06, 1.2417e-06, 2.4561e-06,  ..., 9.4511e-07, 7.6600e-07,
         1.8051e-06],
        [7.1816e-07, 5.9196e-07, 1.0568e-06,  ..., 3.8468e-07, 3.3333e-07,
         8.2478e-07],
        ...,
        [1.3655e-06, 1.5720e-06, 2.0471e-06,  ..., 1.3815e-06, 1.1921e-06,
         1.8962e-06],
        [1.3266e-06, 2.0308e-06, 2.0074e-06,  ..., 9.4848e-07, 8.3553e-07,
         2.3271e-06],
        [8.1004e-07, 9.2459e-07, 1.0864e-06,  ..., 5.0510e-07, 4.4587e-07,
         1.1777e-06]], device='cuda:0')}, 81: {'step': tensor(30200.), 'exp_avg': tensor([-1.8445e-04, -4.3112e-05,  9.9924e-05, -2.8733e-04,  2.9671e-04,
        -4.3316e-05,  5.5749e-04,  5.2393e-04,  9.0473e-05, -4.9545e-04,
         2.2096e-04, -2.0404e-04, -1.4635e-04,  3.2110e-04, -2.6480e-04,
        -4.4299e-05,  6.7588e-05,  3.5559e-04, -3.6194e-04,  1.7844e-04,
        -3.8585e-04, -1.7900e-04,  1.7596e-04, -1.3736e-04,  5.3614e-05,
         3.3345e-05,  3.3949e-05, -1.0576e-04, -2.0853e-04,  4.5033e-04,
         2.6768e-04, -5.3461e-04,  8.5709e-05, -4.8188e-05,  7.2590e-05,
        -3.1491e-04, -3.9725e-05,  8.2095e-05,  1.1161e-04,  2.6189e-04,
         1.8786e-04, -3.5684e-04, -1.0056e-05,  2.0560e-05,  2.6078e-04,
        -1.3410e-04,  2.4056e-04, -4.7229e-05, -8.1063e-05, -1.1924e-04,
        -4.1663e-04, -2.5438e-04, -2.6108e-04,  3.0275e-04,  2.5306e-04,
         3.7493e-04,  5.0556e-04,  1.4019e-04,  1.9356e-04,  4.7888e-04,
        -3.2135e-04, -1.2335e-04, -9.6844e-05,  1.2096e-04,  6.5080e-04,
         8.0245e-06, -1.1588e-04, -2.0452e-04, -8.2572e-04, -2.0595e-04,
         4.5606e-04, -8.7525e-05, -3.3756e-04, -7.4478e-04,  2.9026e-04,
        -5.0549e-04, -3.4578e-05, -5.9256e-05,  2.2515e-04, -2.2697e-04,
         1.5987e-04,  4.5422e-04,  7.7269e-05, -1.2463e-04, -2.3240e-04,
         7.6427e-05, -3.8769e-04,  8.4412e-05,  8.8596e-05,  3.2293e-04,
        -1.6894e-04,  2.1524e-04,  4.2255e-04,  1.3224e-04,  1.3796e-04,
         7.9511e-05,  3.2209e-04,  4.7202e-04, -8.0829e-05,  2.6377e-04,
        -1.7940e-04, -2.0503e-04,  5.1296e-04,  2.4905e-04, -5.7312e-04,
         2.8079e-04, -2.6174e-04,  2.8796e-04, -1.2395e-04, -9.7492e-06,
         2.7292e-04,  5.2664e-05,  2.1959e-04, -7.4025e-05,  3.3148e-04,
        -4.2497e-04,  6.4432e-05, -3.1820e-04,  4.2293e-04, -1.0279e-04,
         3.3435e-04,  1.1217e-04, -3.7815e-04,  1.0911e-04, -1.2500e-04,
        -3.8891e-04, -3.3661e-04, -3.0659e-04], device='cuda:0'), 'exp_avg_sq': tensor([6.2102e-06, 4.7413e-06, 1.4794e-06, 2.9405e-06, 3.6123e-06, 7.0442e-07,
        2.0143e-06, 3.6530e-06, 5.5267e-06, 2.6197e-06, 6.1022e-06, 1.3338e-06,
        1.2154e-05, 1.2733e-06, 1.6343e-06, 2.1911e-06, 2.8186e-06, 2.2873e-06,
        1.8674e-06, 8.1548e-06, 4.0804e-06, 6.7042e-06, 4.4329e-06, 3.7214e-06,
        1.5893e-06, 2.2231e-06, 6.1688e-06, 2.5020e-06, 2.9538e-06, 5.4031e-06,
        3.0692e-06, 5.7673e-06, 7.1505e-06, 2.8529e-06, 6.1679e-06, 6.8625e-06,
        1.7965e-06, 1.7164e-06, 1.2149e-05, 4.8719e-06, 3.0511e-06, 3.0758e-06,
        1.0445e-05, 6.0911e-06, 4.6165e-06, 3.2478e-06, 5.0907e-06, 1.4502e-05,
        1.7166e-06, 7.2420e-06, 7.4476e-06, 1.6441e-05, 2.2498e-06, 5.2953e-06,
        2.2215e-06, 8.2913e-06, 8.0552e-06, 1.9544e-06, 1.7690e-06, 5.5260e-06,
        1.1861e-06, 2.9928e-06, 1.3436e-06, 6.2793e-06, 3.9204e-06, 3.7753e-06,
        1.7462e-06, 1.1932e-06, 3.9149e-06, 3.5344e-06, 2.7357e-06, 2.0317e-06,
        1.9837e-06, 6.3108e-06, 2.5817e-06, 3.1748e-06, 3.6990e-06, 9.2374e-06,
        1.5876e-06, 1.5894e-06, 3.5709e-06, 4.0855e-06, 1.4281e-05, 4.1326e-06,
        3.8394e-06, 1.3185e-06, 4.3314e-06, 6.4164e-06, 5.7619e-06, 7.5516e-06,
        4.2138e-06, 1.7020e-06, 3.8106e-06, 3.8559e-06, 5.0353e-06, 5.4443e-06,
        3.3044e-06, 1.0961e-06, 1.0515e-06, 3.9393e-06, 1.9199e-06, 4.0932e-06,
        9.1387e-06, 1.9489e-06, 4.9235e-06, 7.4565e-06, 3.7591e-06, 2.3040e-06,
        2.4019e-06, 4.7653e-06, 3.7374e-06, 4.2594e-06, 2.2429e-06, 4.9313e-06,
        7.5451e-06, 2.2186e-06, 6.2812e-06, 4.1576e-06, 1.5719e-06, 1.4143e-06,
        5.6326e-06, 1.6660e-06, 2.8240e-06, 2.2559e-06, 3.6348e-06, 6.9000e-06,
        5.9552e-06, 2.6545e-06], device='cuda:0')}, 82: {'step': tensor(30200.), 'exp_avg': tensor([-6.7415e-05, -1.6879e-04, -1.4136e-04,  7.4048e-05, -1.8569e-04,
         3.0696e-05, -3.2539e-05, -1.1803e-04,  1.5409e-04, -2.2709e-05,
        -2.1506e-04,  3.2847e-05, -2.4518e-04, -5.6807e-05, -1.8741e-04,
        -1.8767e-04, -2.0211e-04, -2.0142e-05, -1.3001e-04, -2.7460e-04,
         2.6734e-05, -6.4805e-05,  1.2244e-04, -1.1669e-04,  2.7565e-05,
        -1.0671e-04, -1.9965e-05,  2.0376e-04, -2.0866e-04, -2.2527e-04,
        -3.4149e-05, -1.2646e-04,  2.1854e-05, -2.0772e-04,  2.2972e-05,
         4.7567e-05, -1.3954e-04, -1.2861e-04, -1.1941e-04,  1.0991e-04,
        -8.9043e-05,  1.9925e-05, -6.6009e-05, -2.7286e-05, -2.4589e-04,
         5.8179e-05,  1.1084e-04, -3.4358e-04,  9.8270e-05,  6.8103e-05,
         2.3430e-04,  3.5312e-05,  4.7105e-05, -6.2075e-05, -2.9271e-04,
        -1.0374e-04,  8.1076e-05, -9.9398e-06, -5.8733e-05,  2.8603e-05,
        -1.2327e-04,  2.9542e-05,  1.4906e-04,  1.8121e-04,  1.3670e-04,
        -8.1657e-06, -5.5785e-05,  1.1713e-04, -1.1029e-04, -1.2184e-04,
        -2.3032e-04,  5.1763e-05, -6.1089e-05,  2.9320e-05,  5.5770e-05,
        -1.3424e-04, -1.0472e-04,  1.3243e-04, -2.2333e-04, -6.8882e-05,
        -1.2183e-04, -2.0281e-04, -8.3023e-05,  1.8863e-04, -1.2166e-04,
         3.8424e-05, -1.6862e-04, -1.0461e-04, -4.9259e-05,  3.9816e-05,
        -1.2168e-07, -2.4801e-05,  1.0403e-04,  1.3396e-04,  1.7564e-05,
         4.4069e-06, -4.1341e-06,  1.5222e-04,  5.1840e-05, -3.0295e-04,
         4.6808e-05, -4.1162e-05, -1.9426e-04, -2.6138e-05,  2.5455e-05,
         1.1067e-04,  1.1751e-04,  1.2729e-04,  8.4745e-05, -1.4965e-04,
         1.9526e-04, -9.8294e-05,  1.5417e-04, -6.0860e-06,  2.8559e-04,
        -1.7754e-05,  2.9685e-05, -2.1002e-04,  4.3963e-05, -3.7657e-05,
        -6.3435e-05, -2.6611e-05,  1.1601e-04, -6.8757e-05, -1.9631e-04,
        -1.8784e-04, -5.8905e-05, -3.4942e-05], device='cuda:0'), 'exp_avg_sq': tensor([6.2736e-07, 2.3930e-07, 3.2882e-07, 2.4600e-07, 5.5497e-07, 5.6042e-07,
        1.7342e-07, 2.7652e-07, 4.0195e-07, 4.9249e-07, 4.7868e-07, 1.6653e-07,
        4.0209e-07, 3.9671e-07, 4.7008e-07, 3.2249e-07, 2.5668e-07, 2.1657e-07,
        3.2051e-07, 6.2528e-07, 2.6488e-07, 3.4342e-07, 2.3047e-07, 2.5023e-07,
        2.9364e-07, 2.7074e-07, 2.6277e-07, 3.8788e-07, 3.2571e-07, 3.4585e-07,
        4.7626e-07, 5.0575e-07, 2.2532e-07, 2.3414e-07, 2.3811e-07, 2.6103e-07,
        2.2714e-07, 2.5937e-07, 2.2386e-07, 2.8367e-07, 1.7560e-07, 2.7445e-07,
        3.7290e-07, 2.2175e-07, 3.0448e-07, 2.7130e-07, 2.3289e-07, 4.6915e-07,
        4.0819e-07, 2.1521e-07, 6.7408e-07, 5.9715e-07, 3.0119e-07, 4.3751e-07,
        2.3292e-07, 3.4798e-07, 2.0470e-07, 2.9394e-07, 4.4122e-07, 2.5450e-07,
        2.1525e-07, 2.4574e-07, 1.8848e-07, 4.9247e-07, 3.0828e-07, 2.2318e-07,
        1.7016e-07, 2.4743e-07, 2.8248e-07, 3.6597e-07, 4.3685e-07, 2.9602e-07,
        5.1791e-07, 2.4101e-07, 7.7521e-07, 2.3818e-07, 1.7758e-07, 9.4137e-07,
        4.0988e-07, 4.7226e-07, 4.0802e-07, 4.1137e-07, 6.0753e-07, 4.7178e-07,
        5.4502e-07, 3.2247e-07, 4.0013e-07, 3.7886e-07, 3.9345e-07, 3.0610e-07,
        5.2164e-07, 4.0705e-07, 4.8147e-07, 1.7287e-07, 2.7916e-07, 5.5842e-07,
        2.9666e-07, 4.7171e-07, 3.9909e-07, 5.9274e-07, 1.6908e-07, 2.7330e-07,
        2.8018e-07, 6.1671e-07, 5.8711e-07, 4.6660e-07, 3.4739e-07, 3.4247e-07,
        3.4977e-07, 2.6251e-07, 3.8876e-07, 3.9254e-07, 3.9396e-07, 1.8475e-07,
        4.0449e-07, 2.3379e-07, 2.6061e-07, 2.2949e-07, 2.4583e-07, 1.7912e-07,
        2.9053e-07, 3.4736e-07, 3.7146e-07, 3.4562e-07, 2.6740e-07, 3.0420e-07,
        5.0414e-07, 5.2507e-07], device='cuda:0')}, 83: {'step': tensor(30200.), 'exp_avg': tensor([-9.0429e-05,  1.0449e-04, -1.1539e-04, -9.1439e-05, -9.0290e-05,
         1.6478e-04, -2.7876e-05,  1.6833e-04,  1.3634e-04, -5.4547e-05,
         1.1145e-04, -9.5777e-05, -8.4698e-05, -1.1172e-04, -1.4861e-04,
        -1.2321e-04, -2.7444e-05,  1.2044e-04, -3.6348e-05, -1.1682e-04,
        -1.3744e-04, -4.6440e-05,  2.7130e-04, -1.4262e-05,  1.0565e-05,
        -4.2398e-06,  1.3103e-04,  5.8545e-05,  4.4955e-05, -1.1508e-04,
         2.1248e-04, -1.1097e-04, -8.1776e-05,  3.0777e-05,  1.3169e-04,
        -1.8801e-05, -5.5213e-05,  5.2798e-05, -4.6995e-05, -1.2156e-04,
         8.9855e-05,  8.9479e-05, -1.5219e-04,  2.9179e-05,  2.4533e-04,
         2.9859e-05,  3.0378e-05,  1.4170e-04, -2.3181e-04,  1.4078e-05,
         4.0492e-05,  8.6627e-05, -5.5133e-05,  1.5593e-05,  8.5658e-05,
        -4.1634e-06,  1.4742e-04,  7.6058e-05, -1.4061e-04, -4.1709e-05,
         4.1032e-06, -7.4337e-05, -9.6779e-05, -3.2031e-05,  8.7139e-05,
        -1.1026e-04,  3.0545e-05, -1.7988e-04, -2.5951e-04, -4.5359e-05,
         6.2850e-05,  3.8879e-05, -7.3059e-05, -7.2606e-05, -1.1966e-04,
        -6.3899e-05, -1.2850e-04,  1.0376e-04, -1.5689e-04, -2.3639e-05,
         2.7911e-05,  2.4651e-05,  2.3249e-04, -6.5137e-05,  7.9908e-05,
        -1.8192e-05, -6.0879e-05, -1.0549e-04, -8.5291e-05,  4.4066e-05,
        -2.5836e-05, -6.1451e-05,  3.0907e-05, -2.3137e-05,  7.1308e-05,
        -3.4100e-05,  1.8490e-04,  2.3701e-05, -9.5674e-05,  1.0865e-04,
         4.4715e-05, -2.4473e-04,  2.6017e-04,  7.9451e-05, -9.7461e-05,
         1.8092e-04, -2.0037e-04,  1.2605e-05, -2.4840e-04,  4.2121e-05,
         5.9068e-05, -2.0436e-04,  1.0160e-04, -3.8206e-05, -6.1905e-05,
        -6.9302e-05,  7.6991e-05, -5.8779e-06, -3.3171e-05, -3.2989e-04,
         6.4040e-05,  1.0160e-04, -1.7677e-04, -3.8394e-05, -5.5206e-05,
         5.3787e-05, -4.0658e-05,  1.5300e-05], device='cuda:0'), 'exp_avg_sq': tensor([6.6269e-07, 2.8823e-07, 4.4038e-07, 2.9372e-07, 5.5940e-07, 1.3360e-06,
        1.3597e-07, 5.1019e-07, 5.8484e-07, 8.8963e-07, 9.0666e-07, 3.4827e-07,
        1.1799e-06, 7.1791e-07, 6.0127e-07, 5.4579e-07, 5.2590e-07, 4.4487e-07,
        5.6791e-07, 7.1326e-07, 6.9670e-07, 7.0097e-07, 3.8922e-07, 3.1068e-07,
        3.8908e-07, 3.0060e-07, 4.7499e-07, 7.1684e-07, 3.9609e-07, 2.9731e-07,
        5.9186e-07, 9.3008e-07, 3.1685e-07, 2.9939e-07, 2.0507e-07, 3.9655e-07,
        2.5723e-07, 5.2404e-07, 3.7209e-07, 4.5231e-07, 3.1933e-07, 3.3776e-07,
        4.8096e-07, 5.6596e-07, 3.7118e-07, 3.4671e-07, 3.2824e-07, 1.0230e-06,
        6.3569e-07, 2.6896e-07, 5.8065e-07, 1.3088e-06, 4.8208e-07, 1.2764e-06,
        5.2186e-07, 6.5138e-07, 2.4605e-07, 3.7743e-07, 6.9650e-07, 5.3727e-07,
        2.7368e-07, 3.6388e-07, 3.3774e-07, 1.1507e-06, 2.5802e-07, 3.0083e-07,
        1.6783e-07, 2.6462e-07, 3.6860e-07, 1.1774e-06, 7.5297e-07, 4.2366e-07,
        1.2632e-06, 4.5781e-07, 5.7792e-07, 3.2614e-07, 4.8146e-07, 1.5234e-06,
        8.6013e-07, 4.9612e-07, 6.1462e-07, 8.9641e-07, 1.1569e-06, 7.4608e-07,
        1.2662e-06, 6.0657e-07, 5.3220e-07, 5.1270e-07, 4.8306e-07, 4.7292e-07,
        6.4251e-07, 4.6479e-07, 8.6938e-07, 1.9772e-07, 5.1638e-07, 4.5295e-07,
        7.4402e-07, 4.2249e-07, 7.9368e-07, 6.6303e-07, 3.0284e-07, 4.9301e-07,
        3.1369e-07, 9.7490e-07, 8.1160e-07, 4.7506e-07, 4.5937e-07, 3.4318e-07,
        6.3379e-07, 6.5240e-07, 5.0970e-07, 9.1573e-07, 4.8673e-07, 3.5923e-07,
        7.8330e-07, 2.5733e-07, 3.9810e-07, 4.3536e-07, 3.5357e-07, 2.9319e-07,
        4.4967e-07, 4.8455e-07, 3.0500e-07, 5.1365e-07, 3.4538e-07, 3.3771e-07,
        3.7701e-07, 4.1814e-07], device='cuda:0')}, 84: {'step': tensor(30200.), 'exp_avg': tensor([[-8.0161e-05, -2.2156e-04, -1.0352e-04,  ..., -1.7239e-04,
         -4.9244e-05,  1.1941e-05],
        [ 2.1301e-04, -1.8128e-04, -9.6071e-05,  ..., -2.7050e-05,
         -1.1189e-04, -2.3631e-05],
        [-3.4450e-05, -3.0783e-05,  2.3693e-04,  ..., -3.6948e-05,
         -8.4860e-05,  1.1506e-04],
        ...,
        [ 2.2492e-04,  7.0835e-05, -1.5382e-04,  ...,  3.9431e-05,
         -4.2287e-05,  8.0966e-05],
        [-1.2598e-04, -1.6633e-05,  1.0774e-04,  ..., -1.6614e-04,
          8.7230e-05, -1.4090e-05],
        [ 1.0858e-04, -2.4702e-05, -2.3130e-05,  ...,  3.3628e-05,
         -5.5979e-05, -3.6677e-06]], device='cuda:0'), 'exp_avg_sq': tensor([[2.1673e-07, 2.3605e-07, 2.4917e-07,  ..., 2.7119e-07, 3.5898e-07,
         3.2852e-07],
        [2.3744e-07, 1.8036e-07, 2.7915e-07,  ..., 3.5632e-07, 2.3904e-07,
         3.1758e-07],
        [3.8802e-07, 3.3722e-07, 5.4254e-07,  ..., 4.4278e-07, 5.5231e-07,
         6.2689e-07],
        ...,
        [5.2328e-07, 8.8839e-08, 1.5080e-07,  ..., 1.3718e-07, 2.2596e-07,
         1.4975e-07],
        [5.3967e-07, 3.8391e-07, 7.2695e-07,  ..., 9.4283e-07, 4.8958e-07,
         4.8389e-07],
        [1.6448e-07, 1.0940e-07, 1.7612e-07,  ..., 2.3304e-07, 2.2535e-07,
         1.8288e-07]], device='cuda:0')}, 85: {'step': tensor(30200.), 'exp_avg': tensor([ 1.4484e-04, -1.3044e-04,  9.3883e-05,  1.5034e-04,  7.7197e-05,
         4.4621e-05, -1.4211e-04, -8.2997e-05, -1.1352e-04, -1.5301e-04,
         9.8481e-05,  4.1224e-05, -8.5737e-06,  5.7283e-05,  3.2614e-04,
         8.0548e-05,  1.2119e-04,  3.2672e-06, -1.6730e-04, -1.6573e-05,
        -1.4899e-04, -1.8000e-05,  2.0565e-04,  2.1870e-05,  2.6936e-06,
        -2.0010e-05, -2.1573e-04,  1.7525e-04,  5.7612e-05, -4.4159e-05,
        -6.7082e-07, -1.1526e-04,  1.2577e-04,  1.0818e-04, -1.0750e-05,
         3.2213e-05,  5.1062e-06,  5.0639e-05,  8.4123e-05, -2.1894e-04,
         1.3323e-05,  9.6597e-05, -1.5148e-05,  2.5184e-05, -7.1381e-06,
        -4.4854e-06, -2.2939e-05, -3.1104e-04, -3.9586e-05,  4.0965e-05,
         1.0057e-04, -1.9761e-04, -6.8274e-05, -1.1020e-04, -1.1808e-05,
         4.8339e-05,  2.5341e-05,  1.3769e-04,  4.0449e-05, -1.8652e-04,
        -1.9131e-04,  7.5471e-05, -7.0603e-05,  1.9302e-04,  4.9609e-05,
        -7.6744e-05,  4.7449e-05,  1.2796e-05,  2.4542e-05,  7.0949e-05,
        -4.1455e-05, -1.9076e-05, -1.3770e-05,  1.1762e-04,  2.2735e-04,
         5.8878e-05, -3.0350e-05,  5.4069e-05, -1.3234e-04, -1.4086e-04,
        -3.9514e-05,  1.0076e-05, -2.6318e-04, -1.0238e-04,  1.3334e-04,
         1.0094e-04,  3.5639e-05, -1.6140e-04,  8.5734e-06, -8.8679e-05,
        -4.5957e-05, -2.7997e-05,  2.3930e-04, -7.7726e-06,  1.8305e-04,
        -2.8493e-06,  1.4162e-04, -9.2986e-05, -1.5845e-04, -8.3849e-05,
        -1.0593e-04, -1.1594e-04, -1.7007e-05,  5.9742e-06, -1.4080e-04,
         2.5421e-04, -2.8480e-05, -2.3819e-04, -1.3191e-04,  8.8070e-05,
        -2.4119e-04,  1.7154e-05,  2.8797e-04,  7.0691e-05,  3.8639e-05,
        -2.0964e-05,  7.3199e-05, -4.3389e-05, -1.1014e-04,  1.3273e-04,
        -1.0852e-04, -4.5507e-05, -1.4835e-04,  1.8850e-05,  1.0927e-04,
        -2.1731e-05, -1.1808e-04,  2.1798e-04, -1.0325e-04,  2.4810e-04,
         8.2613e-06,  1.0079e-04, -3.5769e-05,  6.1881e-05,  4.5112e-05,
        -2.2588e-04,  5.5278e-06, -1.5342e-04, -7.8543e-05,  2.6851e-05,
         2.9296e-05,  1.3280e-04, -4.1849e-05, -1.6665e-04, -3.3413e-05,
         5.0732e-05,  9.8460e-06,  1.7923e-04, -9.2369e-05,  1.4186e-04,
        -9.9678e-05,  2.9889e-05, -3.4469e-06, -2.6992e-04, -4.0570e-05,
         1.8781e-05,  5.6548e-05,  3.0315e-06,  9.9036e-05, -7.4060e-05,
        -1.1207e-04, -5.6989e-05,  4.3093e-05, -2.1825e-04, -6.7879e-05,
         9.7980e-06, -6.7654e-05,  7.5920e-05,  1.4484e-04,  7.4007e-05,
         1.7784e-04, -6.3214e-05, -4.4766e-05,  3.9483e-05,  1.8137e-06,
         5.5818e-05,  5.3091e-05, -1.0026e-04,  1.0249e-04,  2.1468e-04,
        -2.7777e-05, -2.8845e-05,  4.6642e-05, -1.3032e-04,  6.1141e-05,
        -8.3238e-05, -3.2532e-05, -5.8570e-05, -2.0606e-04, -1.7939e-04,
        -3.3491e-04, -1.2074e-04,  1.7719e-04, -1.1089e-04, -4.5026e-05,
         5.2493e-05,  2.7730e-05, -1.2317e-04, -9.0233e-05,  4.7125e-06,
        -9.3528e-05,  5.0906e-05,  1.4846e-05,  1.2026e-04,  9.0352e-05,
         5.8573e-05,  1.4177e-05, -7.3538e-05, -3.7757e-05,  7.9289e-05,
        -1.0562e-04,  1.1068e-04, -7.4616e-05,  2.2400e-05, -1.0708e-05,
        -4.3739e-05, -5.5423e-05,  1.8587e-04,  1.4490e-05, -2.1306e-04,
         4.9582e-05, -1.6470e-04, -7.1931e-06,  9.5936e-05, -3.7801e-04,
         7.5320e-05,  1.9330e-04,  1.1984e-05, -1.3790e-04,  3.6022e-05,
         4.4973e-05, -6.9627e-05,  1.9238e-04,  1.4803e-05,  9.0747e-05,
         1.7979e-04, -1.2585e-04, -1.9886e-05,  4.8650e-05,  5.0539e-05,
         1.5776e-04,  1.9080e-05,  3.7188e-05,  8.1483e-05, -2.0863e-04,
        -1.0070e-04, -5.9991e-05, -2.4624e-05, -1.8401e-05, -2.6223e-05,
        -1.3653e-04, -9.8551e-05,  6.9678e-06,  5.9789e-05,  8.4001e-05,
         1.5460e-06], device='cuda:0'), 'exp_avg_sq': tensor([4.0693e-07, 3.5762e-07, 4.9796e-07, 3.8423e-07, 1.3772e-07, 1.4974e-07,
        2.4378e-07, 3.5261e-07, 2.2611e-07, 3.2227e-07, 4.8420e-07, 2.4788e-07,
        9.7093e-07, 1.0794e-06, 6.3050e-07, 3.6060e-07, 3.4977e-07, 1.9254e-07,
        4.0765e-07, 6.2821e-07, 6.1578e-07, 4.0142e-07, 1.6379e-06, 4.1513e-07,
        4.3191e-07, 2.7030e-07, 4.5070e-07, 7.6518e-07, 9.1099e-07, 1.3074e-07,
        2.8216e-07, 2.4229e-07, 3.6389e-07, 1.1802e-06, 4.4935e-07, 1.4607e-06,
        5.2789e-07, 4.3486e-07, 7.3923e-07, 9.9348e-07, 2.7858e-07, 1.1387e-06,
        7.9845e-07, 1.3936e-07, 3.0219e-07, 2.4379e-07, 1.0605e-07, 3.0749e-07,
        2.4593e-07, 1.8792e-07, 1.1668e-07, 4.7233e-07, 1.7032e-07, 1.1596e-07,
        3.3309e-07, 3.5167e-07, 2.2192e-07, 6.6892e-07, 1.9107e-07, 3.8274e-07,
        6.3545e-07, 4.3885e-07, 9.7076e-07, 4.2337e-07, 6.7981e-08, 5.1404e-07,
        2.1473e-07, 8.7078e-07, 4.1252e-07, 8.4146e-07, 3.6190e-07, 2.6917e-07,
        2.6380e-07, 1.2999e-07, 9.5811e-07, 3.5879e-07, 3.6132e-07, 3.5884e-07,
        1.7167e-07, 5.5090e-07, 4.8091e-07, 2.0042e-07, 4.9588e-07, 1.9987e-07,
        3.7390e-07, 7.1492e-07, 1.6024e-07, 2.3125e-07, 1.6785e-07, 9.7558e-08,
        1.9108e-07, 3.7538e-07, 3.8685e-07, 4.5461e-07, 2.5780e-07, 1.5644e-07,
        3.9585e-07, 3.0092e-07, 4.6924e-07, 2.8842e-07, 3.1648e-07, 1.7419e-07,
        3.8812e-07, 3.1309e-07, 1.7331e-07, 7.3200e-07, 1.6588e-07, 9.9345e-07,
        1.8883e-07, 1.2246e-07, 6.2812e-07, 4.8697e-07, 1.6379e-06, 2.9357e-07,
        5.1502e-07, 1.0051e-07, 5.6234e-07, 2.0905e-07, 1.7162e-07, 8.7192e-07,
        2.1758e-07, 6.5216e-07, 2.0372e-07, 1.8503e-07, 1.5812e-06, 9.5743e-07,
        2.4206e-07, 5.2337e-07, 2.3827e-07, 5.1345e-07, 5.0807e-07, 4.5432e-07,
        1.7880e-07, 3.2832e-07, 1.3271e-07, 7.8420e-07, 1.3125e-07, 3.9568e-07,
        6.4450e-08, 6.9981e-07, 2.2234e-07, 1.7846e-07, 7.3991e-07, 9.7971e-07,
        1.3171e-07, 3.5715e-07, 2.9543e-07, 2.2395e-07, 1.7841e-07, 8.1591e-07,
        4.7053e-07, 4.1559e-07, 1.9512e-07, 1.0419e-06, 7.0448e-07, 3.5968e-07,
        2.8432e-07, 2.3822e-07, 4.5626e-07, 2.5001e-07, 2.3344e-07, 3.2583e-07,
        1.7235e-06, 6.8648e-07, 1.2056e-06, 1.6729e-06, 9.6173e-07, 2.5767e-07,
        1.8995e-07, 8.0732e-07, 2.1222e-07, 1.1335e-07, 2.1523e-07, 1.4493e-07,
        5.1729e-08, 1.6598e-07, 3.4267e-07, 5.8077e-07, 1.9476e-07, 7.2602e-07,
        6.2627e-07, 1.0496e-07, 1.0505e-07, 3.6371e-07, 1.6883e-07, 2.6741e-07,
        3.8490e-07, 1.6911e-07, 1.6976e-07, 3.1707e-07, 6.3177e-07, 8.5997e-07,
        1.0282e-06, 3.5029e-07, 2.1130e-07, 4.5467e-07, 2.3628e-07, 6.4027e-07,
        4.9230e-07, 2.1758e-07, 2.3462e-07, 2.0322e-07, 4.9899e-07, 7.2360e-07,
        1.2530e-06, 3.1881e-07, 3.9628e-06, 5.3354e-07, 1.8654e-07, 2.7800e-07,
        2.6160e-07, 5.0786e-07, 5.6689e-07, 3.7505e-07, 6.6743e-07, 1.1588e-06,
        2.3121e-07, 3.5819e-07, 1.0672e-07, 1.9489e-07, 9.3135e-07, 3.4616e-07,
        2.1031e-07, 1.1916e-06, 1.7601e-06, 2.8205e-07, 5.0423e-07, 8.6563e-08,
        2.9104e-07, 1.8822e-07, 8.8554e-07, 3.0809e-07, 3.3284e-07, 1.5618e-07,
        1.7032e-06, 1.0882e-06, 6.8128e-07, 1.0982e-07, 5.8365e-07, 1.7037e-07,
        2.6912e-07, 1.3221e-07, 2.2632e-07, 5.7664e-07, 9.4070e-07, 2.4665e-07,
        1.5430e-07, 3.0150e-07, 7.1860e-07, 5.6472e-07, 5.2620e-07, 3.9421e-07,
        2.3593e-07, 1.7922e-07, 6.0812e-07, 1.3063e-07], device='cuda:0')}, 86: {'step': tensor(30200.), 'exp_avg': tensor([[-1.2841e-04,  2.6937e-04,  2.7243e-05,  ..., -5.4606e-05,
         -2.2213e-05,  2.9971e-05],
        [-5.2900e-05, -1.1105e-04,  1.8420e-05,  ..., -1.1706e-05,
          2.0103e-05, -1.3882e-04],
        [-1.1545e-04,  1.4640e-04,  8.3724e-05,  ...,  1.9901e-05,
          8.9138e-05, -6.1881e-05],
        ...,
        [ 7.9147e-05, -2.0861e-04, -3.8082e-04,  ...,  1.8386e-05,
          2.7385e-04,  1.0720e-04],
        [ 2.5360e-06, -6.9608e-05, -5.5663e-05,  ..., -1.5541e-04,
          1.9732e-04,  8.4782e-05],
        [ 7.3187e-05,  1.8973e-05, -7.4828e-05,  ..., -9.4196e-05,
          3.5124e-05,  1.5578e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[2.6583e-07, 3.0593e-07, 6.3387e-07,  ..., 1.7142e-07, 5.0466e-07,
         2.5981e-07],
        [3.3324e-07, 2.3628e-07, 4.9277e-07,  ..., 2.2913e-07, 4.3133e-07,
         3.2234e-07],
        [1.8653e-07, 2.1114e-07, 2.8155e-07,  ..., 1.0227e-07, 4.9208e-07,
         2.2803e-07],
        ...,
        [3.8282e-07, 4.4164e-07, 7.3675e-07,  ..., 1.4256e-07, 6.9968e-07,
         4.0723e-07],
        [4.0870e-07, 2.2652e-07, 4.6225e-07,  ..., 1.4111e-07, 4.1169e-07,
         4.3456e-07],
        [2.9280e-07, 2.0098e-07, 3.1683e-07,  ..., 7.9930e-08, 3.2461e-07,
         2.9827e-07]], device='cuda:0')}, 87: {'step': tensor(30200.), 'exp_avg': tensor([-2.3330e-04, -5.1525e-05, -1.4066e-04, -2.7575e-04,  3.7842e-04,
        -1.3420e-04,  5.1453e-04,  3.1032e-04, -6.1050e-05, -4.9869e-04,
         1.7912e-04, -6.2589e-05,  1.1122e-04,  3.9008e-04, -2.0221e-04,
         2.2162e-04,  2.7094e-04,  4.0429e-04, -3.3012e-04,  2.6549e-04,
        -1.9725e-04, -1.8254e-04,  1.6038e-04, -3.1918e-04, -3.5393e-05,
        -9.6294e-05, -4.0004e-04, -2.0082e-04, -2.5155e-04,  2.5764e-04,
         7.1145e-05, -5.7520e-04,  3.2202e-04,  1.4125e-04,  1.0524e-04,
        -2.9302e-04,  7.7241e-05, -5.9098e-05,  2.5829e-04,  4.6433e-04,
         9.0385e-05, -2.5423e-04, -6.6104e-05, -2.1570e-04,  9.7257e-05,
        -3.2132e-04,  6.3786e-05,  8.0890e-05, -9.5817e-06, -1.5371e-04,
        -4.3516e-04, -2.7030e-04, -1.5336e-04,  1.3439e-04,  1.7146e-04,
         2.2060e-04,  3.5083e-04, -1.7746e-04,  2.7115e-04,  6.4473e-04,
        -3.5012e-04, -2.3472e-04,  9.2738e-05,  3.1688e-04,  5.5431e-04,
        -1.0852e-04, -1.1161e-04, -8.6212e-05, -4.8553e-04, -2.1992e-04,
         4.0735e-04,  1.4496e-04, -1.8292e-04, -6.2374e-04,  2.6299e-04,
        -4.1560e-04,  4.1805e-05, -5.4608e-05,  2.3080e-04, -2.6420e-04,
         1.1223e-04,  3.1138e-04, -1.3214e-04,  1.0480e-04, -1.9758e-04,
         7.9255e-05, -4.5467e-04,  1.7766e-04,  2.4766e-04,  3.7519e-04,
         9.3547e-05,  1.8146e-04,  2.8836e-04, -5.5127e-05,  8.3999e-06,
        -3.1234e-05,  9.0946e-05,  4.6221e-04, -4.5851e-05,  3.4426e-04,
        -1.7645e-04,  2.4826e-04, -3.2397e-05,  1.7500e-04, -4.3892e-04,
         4.2550e-04, -1.7994e-04,  5.3284e-05, -7.4201e-06, -1.3449e-04,
         4.6500e-04, -9.5642e-05,  3.0217e-04, -3.0712e-05,  4.4064e-04,
        -4.3430e-04, -1.0959e-04, -2.4115e-04,  2.7700e-04,  8.3612e-05,
         1.7960e-04,  5.2264e-05, -2.4372e-04,  1.9315e-04,  4.0301e-05,
        -2.4875e-04, -5.5481e-04, -2.1650e-04], device='cuda:0'), 'exp_avg_sq': tensor([5.4546e-06, 4.6359e-06, 1.3249e-06, 2.8227e-06, 3.2360e-06, 1.4379e-06,
        1.8373e-06, 2.4920e-06, 5.2148e-06, 1.7711e-06, 5.0383e-06, 1.0758e-06,
        9.2997e-06, 1.1107e-06, 1.8402e-06, 1.6022e-06, 3.2357e-06, 2.3227e-06,
        1.4621e-06, 7.2133e-06, 3.0099e-06, 5.1834e-06, 3.7785e-06, 3.8128e-06,
        1.7084e-06, 2.1782e-06, 5.0667e-06, 1.6888e-06, 2.4094e-06, 4.7485e-06,
        2.6891e-06, 4.0200e-06, 6.7501e-06, 2.7353e-06, 5.8630e-06, 5.4582e-06,
        1.7845e-06, 9.9371e-07, 1.2254e-05, 5.2005e-06, 2.8799e-06, 3.1010e-06,
        1.0575e-05, 7.2977e-06, 3.9833e-06, 3.9248e-06, 4.0665e-06, 1.0747e-05,
        1.6894e-06, 7.8451e-06, 6.4193e-06, 1.3297e-05, 1.8932e-06, 3.8845e-06,
        2.0709e-06, 6.2655e-06, 7.2471e-06, 1.4306e-06, 1.3853e-06, 4.2876e-06,
        9.6527e-07, 2.8477e-06, 1.1688e-06, 5.4704e-06, 3.4288e-06, 3.5263e-06,
        1.4233e-06, 1.0122e-06, 3.3860e-06, 2.2829e-06, 2.1364e-06, 1.5773e-06,
        1.2215e-06, 4.9721e-06, 2.4111e-06, 3.6815e-06, 4.4987e-06, 6.0302e-06,
        1.2405e-06, 1.8510e-06, 2.8423e-06, 2.8469e-06, 1.0191e-05, 2.7728e-06,
        2.2061e-06, 1.2763e-06, 3.7278e-06, 4.9253e-06, 4.4495e-06, 6.8776e-06,
        4.1035e-06, 1.1766e-06, 2.5568e-06, 3.9687e-06, 4.4354e-06, 4.4563e-06,
        3.1958e-06, 9.0583e-07, 1.0432e-06, 3.4879e-06, 1.4309e-06, 3.6162e-06,
        9.3666e-06, 1.0862e-06, 3.4265e-06, 7.2516e-06, 3.9538e-06, 2.2916e-06,
        1.6585e-06, 3.2480e-06, 2.6602e-06, 2.6622e-06, 2.1328e-06, 5.4317e-06,
        5.6129e-06, 2.5431e-06, 5.2053e-06, 4.5111e-06, 1.1239e-06, 1.2324e-06,
        5.2236e-06, 1.2458e-06, 2.9335e-06, 1.3863e-06, 3.2616e-06, 6.3508e-06,
        5.3694e-06, 1.9983e-06], device='cuda:0')}, 88: {'step': tensor(30200.), 'exp_avg': tensor([ 4.1947e-06, -6.5532e-04, -6.0075e-05, -1.9954e-04,  4.1285e-04,
        -3.2886e-04,  1.2797e-04, -4.1678e-04, -1.2397e-04,  4.8867e-04,
         8.4349e-05,  2.1048e-05, -7.0414e-04,  1.0095e-04,  5.0618e-04,
         5.4679e-04,  7.9654e-04,  2.8541e-04,  2.0557e-05,  6.2261e-04,
        -9.2494e-04, -6.0798e-04, -3.2004e-04,  8.7554e-04, -4.8198e-04,
         1.8146e-04,  5.0837e-04,  1.8658e-04, -8.7455e-05, -1.3669e-03,
        -6.8810e-04, -3.7667e-04, -6.3918e-04,  8.8742e-04,  5.0243e-04,
         7.0383e-04, -1.0834e-03,  1.0850e-04, -4.1707e-04,  6.5979e-05,
        -8.9453e-05, -3.0393e-04,  7.6230e-04, -4.3645e-04, -8.4220e-05,
         2.6251e-05,  1.1485e-04, -7.1463e-04, -4.4602e-04,  3.1619e-04,
        -6.8044e-04, -8.6499e-04,  4.7732e-04,  3.1926e-04,  7.4767e-04,
        -2.1944e-04, -5.3390e-04,  5.1012e-04,  3.7351e-04, -6.1707e-04,
        -1.5232e-04,  2.3534e-04,  5.3793e-04,  6.0617e-04,  1.8518e-05,
        -4.8300e-04,  2.4407e-04, -2.2124e-05, -1.7830e-04, -7.8325e-05,
         1.6983e-04,  3.3450e-04,  1.0935e-05,  3.5228e-05, -3.3885e-04,
         1.7303e-04,  6.4796e-04,  8.4462e-05, -1.9331e-04, -4.0313e-04,
         4.9596e-04, -1.0841e-03, -4.1430e-04,  3.3239e-05,  1.7478e-04,
         2.0268e-04, -4.3240e-05, -5.4751e-04,  7.7915e-05, -3.6355e-04,
         3.0415e-04,  5.5303e-04,  7.5830e-05,  2.1777e-04,  3.5047e-04,
         6.8360e-04, -4.3464e-05,  1.0457e-04,  2.8188e-04,  2.2890e-05,
         7.7169e-04, -3.5599e-04, -1.7420e-04,  1.4556e-04,  3.0138e-04,
         2.7678e-04,  6.5751e-04, -2.7160e-04,  3.0816e-04,  3.0937e-04,
         1.8275e-04, -7.1327e-04, -6.6667e-04, -1.1647e-04,  2.8984e-04,
        -2.8866e-04,  3.5088e-04,  2.2557e-04,  2.9102e-04,  8.1794e-04,
         1.6117e-04, -5.3732e-04,  1.4814e-04, -6.2050e-04,  6.3938e-05,
        -4.1200e-04,  3.5958e-04,  4.0225e-04], device='cuda:0'), 'exp_avg_sq': tensor([6.7144e-06, 4.0898e-06, 5.5534e-06, 8.1092e-06, 3.8376e-06, 1.9925e-06,
        2.8004e-06, 8.7643e-06, 3.5106e-06, 2.6722e-06, 5.0462e-06, 2.4022e-06,
        4.6724e-06, 8.9237e-06, 3.8296e-06, 3.7735e-06, 4.0545e-06, 3.4527e-06,
        2.2825e-06, 6.5296e-06, 6.1910e-06, 8.0844e-06, 2.9969e-06, 7.3333e-06,
        3.8996e-06, 5.2500e-06, 3.8489e-06, 3.1084e-06, 6.1154e-06, 6.0824e-06,
        3.2848e-06, 4.0011e-06, 3.6943e-06, 6.3061e-06, 5.8459e-06, 5.1885e-06,
        7.4206e-06, 2.8987e-06, 2.0269e-05, 4.6898e-06, 2.3931e-06, 3.4999e-06,
        5.7316e-06, 7.1103e-06, 4.5227e-06, 5.6371e-06, 3.6304e-06, 9.9108e-06,
        3.0913e-06, 3.8429e-06, 5.6561e-06, 7.8901e-06, 4.2411e-06, 3.8175e-06,
        6.7016e-06, 8.4821e-06, 8.0460e-06, 5.9881e-06, 2.2633e-06, 4.6352e-06,
        2.9203e-06, 3.7157e-06, 2.8796e-06, 4.5527e-06, 4.1823e-06, 6.5046e-06,
        2.0345e-06, 3.5219e-06, 3.7276e-06, 4.5842e-06, 2.7821e-06, 1.6240e-06,
        3.4238e-06, 3.6360e-06, 3.8699e-06, 3.2346e-06, 2.6219e-06, 8.3230e-06,
        3.6271e-06, 2.7282e-06, 2.8364e-06, 2.3819e-06, 1.1576e-05, 5.3839e-06,
        8.5454e-06, 4.8248e-06, 7.1664e-06, 4.1698e-06, 6.2039e-06, 3.3265e-06,
        2.6201e-06, 3.1919e-06, 1.7692e-06, 3.3743e-06, 3.3604e-06, 4.5007e-06,
        2.5320e-06, 2.4562e-06, 3.6776e-06, 3.5709e-06, 3.6932e-06, 4.7414e-06,
        5.4316e-06, 4.0092e-06, 5.8954e-06, 7.2810e-06, 4.0762e-06, 4.2968e-06,
        1.5200e-06, 6.6145e-06, 6.7434e-06, 3.7624e-06, 4.2927e-06, 3.3163e-06,
        5.9827e-06, 3.9699e-06, 1.9910e-06, 2.2037e-06, 5.1474e-06, 4.5320e-06,
        5.3418e-06, 9.4251e-06, 5.2853e-06, 5.0351e-06, 4.0798e-06, 1.0260e-05,
        5.7534e-06, 4.5880e-06], device='cuda:0')}, 89: {'step': tensor(30200.), 'exp_avg': tensor([-1.4252e-04, -2.9477e-04,  1.5542e-04,  1.2231e-04,  4.4659e-04,
        -9.0027e-05,  2.5800e-04,  3.7504e-04,  1.1958e-04, -7.2183e-04,
         3.0588e-04, -2.7060e-04, -1.2951e-04,  4.2172e-04, -1.8171e-05,
        -1.9680e-04,  7.9496e-05,  1.2472e-04, -3.7535e-04,  8.2624e-05,
        -3.0855e-04, -5.4946e-04, -2.6162e-04, -2.1224e-05, -9.7562e-05,
         5.3282e-05, -1.5223e-04, -3.4432e-04, -1.5663e-06,  1.6982e-04,
         3.7159e-04, -8.2961e-04,  4.0523e-04, -8.4788e-05, -2.2230e-05,
        -8.3369e-05,  2.2112e-04,  8.4111e-05,  4.7664e-04,  9.4792e-05,
         3.4706e-04, -3.1640e-04, -2.1486e-04, -1.4626e-04, -1.4695e-04,
        -5.3140e-04,  4.8467e-05, -3.1721e-04, -1.5654e-04, -1.0712e-04,
        -3.5985e-04, -3.9782e-04, -2.6331e-06,  3.4008e-04,  4.7493e-04,
         1.4169e-04,  1.8667e-04, -8.2528e-05,  1.6894e-04,  9.2213e-04,
        -5.5618e-04, -3.8624e-04,  1.0710e-04,  1.0146e-04,  5.1359e-04,
         1.9398e-05,  1.3324e-05, -2.5349e-04, -7.0339e-04, -2.8259e-04,
         5.3915e-04, -3.7124e-04, -3.6781e-04, -8.6882e-04,  2.5391e-04,
        -6.2801e-04, -2.6342e-04, -1.8062e-04,  3.6652e-04, -4.3727e-04,
         1.2656e-04,  3.5977e-04, -2.0097e-04,  1.1054e-04, -1.9656e-04,
        -3.0654e-05, -6.8905e-04,  3.6278e-04,  4.3245e-06,  5.0906e-04,
         1.6142e-04,  1.6865e-04,  2.5522e-04,  2.5943e-04, -1.1000e-04,
        -1.1091e-04,  2.2460e-04,  5.5491e-04,  3.0394e-04,  1.4802e-04,
        -7.9174e-05,  4.5035e-04,  1.3907e-04, -6.8642e-06, -5.5880e-04,
         6.0615e-04,  1.1879e-04,  2.6752e-04, -1.0521e-05, -3.3533e-04,
         2.3126e-04,  1.1167e-04, -5.1620e-05,  3.5492e-05,  1.8039e-04,
        -2.8209e-04, -1.2362e-04, -2.3621e-04,  4.3972e-04,  3.3268e-04,
         1.2652e-04, -1.0343e-04,  3.1902e-05, -1.1960e-04,  6.9331e-05,
        -4.3458e-04, -7.0746e-04, -5.8868e-04], device='cuda:0'), 'exp_avg_sq': tensor([9.1132e-06, 4.9757e-06, 5.7460e-06, 5.4248e-06, 5.1894e-06, 1.6071e-06,
        2.0469e-06, 4.1247e-06, 8.2564e-06, 2.9766e-06, 1.2310e-05, 1.2687e-06,
        1.5110e-05, 3.8386e-06, 5.7560e-06, 3.1569e-06, 7.0111e-06, 4.5416e-06,
        2.1100e-06, 1.3192e-05, 1.0300e-05, 8.9319e-06, 2.0817e-06, 5.4758e-06,
        4.6358e-06, 2.7698e-06, 3.8108e-06, 1.1551e-06, 3.2270e-06, 5.8279e-06,
        3.5457e-06, 7.5598e-06, 9.8817e-06, 7.9859e-06, 4.9107e-06, 1.0445e-05,
        3.5631e-06, 1.2371e-06, 2.0793e-05, 9.7788e-06, 3.8756e-06, 3.7712e-06,
        1.6970e-05, 1.3229e-05, 9.6873e-06, 7.2946e-06, 5.0573e-06, 2.3044e-05,
        2.2063e-06, 1.0690e-05, 1.0756e-05, 2.0556e-05, 2.6702e-06, 1.1882e-05,
        4.9504e-06, 1.0061e-05, 1.6840e-05, 1.8167e-06, 3.3543e-06, 9.2354e-06,
        5.1178e-06, 3.5518e-06, 2.4599e-06, 7.7949e-06, 5.8143e-06, 3.0854e-06,
        1.3213e-06, 1.5300e-06, 5.3684e-06, 3.9182e-06, 2.7770e-06, 2.3175e-06,
        2.0771e-06, 9.3259e-06, 3.7674e-06, 5.8658e-06, 1.0910e-05, 1.3937e-05,
        2.8184e-06, 2.5995e-06, 4.6590e-06, 3.9011e-06, 2.3048e-05, 4.3704e-06,
        5.1695e-06, 2.2271e-06, 6.0883e-06, 1.1329e-05, 5.9940e-06, 7.9790e-06,
        8.8057e-06, 3.2747e-06, 2.2945e-06, 4.6876e-06, 7.3945e-06, 5.2699e-06,
        4.2313e-06, 2.9819e-06, 2.9938e-06, 3.6552e-06, 4.1407e-06, 5.3331e-06,
        1.4348e-05, 4.5138e-06, 5.0388e-06, 1.2559e-05, 4.5806e-06, 5.1634e-06,
        1.0130e-06, 6.1620e-06, 6.9825e-06, 5.7129e-06, 1.2198e-05, 8.7087e-06,
        5.2361e-06, 2.2018e-06, 6.8335e-06, 5.8130e-06, 1.9998e-06, 4.6065e-06,
        6.9525e-06, 1.6524e-06, 3.2605e-06, 3.7217e-06, 3.9729e-06, 1.2672e-05,
        1.1094e-05, 3.9196e-06], device='cuda:0')}, 90: {'step': tensor(30200.), 'exp_avg': tensor([[ 1.5292e-04, -1.3908e-04, -8.7046e-05,  ..., -4.2530e-05,
         -1.8069e-04, -2.0097e-04],
        [-1.3382e-04, -1.8331e-05, -7.4130e-05,  ..., -1.3820e-04,
          6.3413e-05,  3.4984e-05],
        [ 8.3908e-05,  3.5029e-05,  3.0369e-05,  ...,  5.4760e-05,
         -1.1200e-04, -8.1708e-05],
        ...,
        [-4.1196e-05,  8.8929e-05,  2.4563e-05,  ..., -7.4771e-05,
         -8.5684e-05, -1.4019e-04],
        [ 8.3440e-05, -2.7563e-05,  2.2150e-04,  ..., -1.6509e-04,
         -2.5241e-05,  4.9113e-05],
        [-6.9285e-06, -4.0883e-04,  1.1688e-04,  ...,  4.8142e-05,
          1.7491e-04,  1.4577e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[3.7310e-07, 3.1278e-07, 1.9021e-07,  ..., 2.7304e-07, 4.7452e-07,
         7.1250e-07],
        [2.3557e-06, 2.0459e-06, 1.3821e-06,  ..., 2.4282e-06, 3.6232e-06,
         5.1315e-06],
        [4.7756e-07, 4.4831e-07, 2.4755e-07,  ..., 3.9949e-07, 6.8146e-07,
         9.5482e-07],
        ...,
        [8.4193e-08, 6.8252e-08, 7.2321e-08,  ..., 7.1171e-08, 6.9096e-08,
         1.0685e-07],
        [2.6995e-07, 2.1019e-07, 2.6078e-07,  ..., 2.8376e-07, 2.4735e-07,
         2.6226e-07],
        [4.2320e-07, 4.0690e-07, 4.8336e-07,  ..., 4.4089e-07, 4.0805e-07,
         4.2460e-07]], device='cuda:0')}, 91: {'step': tensor(30200.), 'exp_avg': tensor([[-5.0480e-05, -1.3899e-04, -1.0411e-05,  ...,  2.1103e-05,
         -4.2798e-05,  5.3060e-05],
        [-5.7622e-05,  9.5604e-06,  1.0950e-04,  ...,  2.2197e-05,
          6.1092e-05,  1.5473e-04],
        [-8.7103e-05, -8.1069e-05, -5.0193e-05,  ..., -1.3185e-06,
         -7.9914e-06,  9.3787e-05],
        ...,
        [ 5.2991e-05,  7.3860e-05,  6.6874e-05,  ...,  7.5473e-06,
          3.9509e-05, -1.1222e-05],
        [ 1.1114e-05,  6.7360e-05,  3.9006e-05,  ...,  2.4368e-05,
          6.2007e-05, -8.3857e-06],
        [ 3.7277e-05,  1.6582e-05, -1.2788e-05,  ...,  1.2268e-05,
         -3.0657e-05, -2.7683e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[7.7935e-08, 9.5853e-08, 1.3291e-07,  ..., 4.5420e-08, 8.0889e-08,
         8.1772e-08],
        [1.8875e-07, 2.4568e-07, 3.5209e-07,  ..., 9.3813e-08, 2.0752e-07,
         1.8858e-07],
        [1.0187e-07, 1.1148e-07, 1.6491e-07,  ..., 4.4770e-08, 9.1814e-08,
         1.0749e-07],
        ...,
        [9.8676e-08, 9.0418e-08, 1.3872e-07,  ..., 4.2780e-08, 8.3808e-08,
         1.1266e-07],
        [1.1245e-07, 1.3836e-07, 1.7870e-07,  ..., 6.0466e-08, 1.0156e-07,
         1.0938e-07],
        [6.0372e-08, 6.4556e-08, 8.1756e-08,  ..., 3.1064e-08, 5.7961e-08,
         5.5905e-08]], device='cuda:0')}, 92: {'step': tensor(30200.), 'exp_avg': tensor([ 1.4853e-04, -5.6507e-05,  6.5975e-06, -1.0851e-04,  6.7137e-06,
        -1.8425e-05,  1.5795e-04, -6.7035e-06,  7.9527e-05, -7.4418e-05,
         4.9619e-05,  3.6930e-07, -1.5355e-05,  1.6612e-04, -1.4904e-04,
        -9.7361e-05, -1.3635e-05,  6.6261e-05, -3.9276e-05,  3.6069e-05,
        -2.8558e-05,  2.9311e-05,  9.9275e-05,  3.6599e-05, -3.0092e-05,
         7.3223e-05,  1.0454e-04,  2.8852e-05,  4.8946e-05,  3.3573e-06,
        -1.3818e-04, -7.5402e-05, -2.7256e-06,  1.1651e-04,  7.3223e-05,
        -1.2699e-04,  5.5532e-05,  6.3991e-06,  1.0073e-04,  1.9176e-04,
         6.4743e-05, -1.0644e-04,  6.3650e-05, -2.4697e-06, -5.2426e-05,
         3.7662e-05, -4.3727e-04,  4.2723e-06, -2.1373e-05,  7.0878e-05,
        -2.5265e-04, -2.4821e-04, -1.3414e-04,  1.4995e-04, -8.4406e-05,
         6.4061e-05,  3.2309e-04, -7.6039e-05,  7.1650e-05,  6.9613e-05,
         3.1844e-05, -1.7112e-05,  7.4475e-05, -5.1801e-05,  1.0675e-04,
        -1.7783e-04, -1.2039e-04,  2.8859e-05, -2.1483e-04,  6.9224e-05,
         1.4527e-04,  2.5177e-06,  2.0894e-04, -1.2286e-04,  6.2908e-05,
        -1.4380e-04,  5.3128e-05,  1.7240e-05, -5.3588e-05,  5.0003e-05,
         6.6345e-05,  1.7991e-04,  3.3520e-05,  1.6019e-04,  1.5777e-06,
         1.6805e-05,  1.0950e-06,  8.5309e-05,  1.7725e-04,  1.3660e-04,
        -3.9144e-05, -7.6485e-05,  2.4496e-04, -8.9137e-05, -5.4619e-05,
         7.8347e-05,  1.8182e-04,  4.1691e-05, -2.0211e-04,  5.5922e-05,
        -2.7157e-05, -2.5908e-05,  2.1969e-04,  1.1719e-04, -3.3001e-04,
         1.4543e-04, -1.5016e-04,  2.0442e-04,  1.4083e-05,  5.7893e-05,
         1.1454e-05, -6.8643e-05,  8.9085e-06,  1.6811e-04,  2.4482e-04,
        -4.9131e-05, -1.3918e-04, -2.9605e-04, -2.9918e-05, -2.8099e-04,
         4.1331e-05,  3.7221e-05, -1.2719e-05,  8.2708e-05,  2.1126e-05,
        -6.1022e-07, -1.4689e-04, -1.6921e-04], device='cuda:0'), 'exp_avg_sq': tensor([3.8114e-07, 9.7188e-07, 4.4415e-07, 3.1948e-07, 4.7730e-07, 6.0874e-07,
        5.2682e-07, 2.2291e-07, 6.8566e-07, 4.1057e-07, 3.2693e-07, 2.4133e-07,
        9.5217e-07, 3.0670e-07, 8.4807e-07, 9.9698e-07, 1.2071e-07, 3.3542e-07,
        2.9294e-07, 4.7647e-07, 4.0771e-07, 9.0304e-07, 1.4785e-06, 3.8088e-07,
        2.6627e-07, 3.0969e-07, 1.3345e-06, 1.1093e-06, 9.8609e-07, 7.4367e-07,
        5.4355e-07, 7.9227e-07, 8.9204e-07, 1.6756e-07, 1.2541e-06, 4.3737e-07,
        1.1267e-07, 6.0690e-07, 1.1037e-06, 4.8058e-07, 7.1287e-07, 4.9125e-07,
        6.8981e-07, 4.9626e-07, 2.5028e-07, 1.2389e-06, 1.1704e-06, 3.6127e-07,
        1.0447e-06, 1.0104e-06, 9.9728e-07, 1.3465e-06, 9.4722e-07, 2.5934e-07,
        2.4684e-07, 5.3255e-07, 1.7732e-07, 3.7113e-07, 1.4173e-07, 4.6697e-07,
        8.5683e-07, 5.1095e-07, 7.5035e-07, 6.8693e-07, 8.9104e-07, 9.3812e-07,
        5.7963e-07, 2.7021e-07, 5.2190e-07, 5.2633e-07, 4.7828e-07, 4.8910e-07,
        6.0818e-07, 4.1784e-07, 5.9549e-07, 5.9550e-07, 4.8643e-07, 2.8583e-07,
        1.1987e-07, 5.1232e-07, 1.1015e-06, 3.7531e-07, 4.4362e-07, 3.4799e-07,
        1.9366e-07, 3.3603e-07, 4.3649e-07, 3.6130e-07, 8.7817e-07, 1.3539e-06,
        5.5678e-07, 1.9909e-07, 5.4527e-07, 5.9054e-07, 6.1670e-07, 6.9913e-07,
        5.1898e-07, 1.9961e-07, 6.7865e-07, 8.0077e-07, 3.7808e-07, 7.2241e-07,
        7.7894e-07, 4.8228e-07, 1.1519e-06, 5.4309e-07, 8.1937e-07, 5.8006e-07,
        7.5938e-07, 5.2740e-07, 2.2944e-07, 6.0035e-07, 6.6577e-07, 7.9723e-07,
        1.1910e-06, 7.6620e-07, 6.7367e-07, 1.0646e-06, 6.4276e-07, 1.0889e-06,
        8.5920e-07, 2.7766e-07, 4.8476e-07, 5.1765e-07, 7.9726e-07, 4.0884e-07,
        5.4116e-07, 2.5121e-07], device='cuda:0')}, 93: {'step': tensor(30200.), 'exp_avg': tensor([-2.9235e-04,  2.1001e-04, -1.3819e-04, -4.5054e-06, -1.7715e-04,
         1.2036e-04, -6.9783e-05,  6.1526e-05, -7.8638e-05,  3.8343e-05,
        -7.3879e-05,  4.8458e-05, -1.0404e-04,  2.2793e-04, -3.0589e-04,
        -4.1580e-05,  1.9900e-05,  1.5915e-05, -2.1917e-05,  3.0252e-04,
        -2.7965e-05, -2.9605e-05,  6.5918e-05, -1.3573e-04,  7.9529e-06,
         9.7337e-05, -3.2119e-05, -1.3697e-05, -5.0488e-05, -1.6250e-04,
        -1.1418e-04, -7.2200e-05, -7.7054e-05, -9.8000e-05,  4.3247e-05,
        -3.7600e-05,  4.7576e-05, -1.4165e-04, -2.2742e-04, -4.3468e-05,
        -3.4199e-05,  1.7573e-05,  6.4429e-05, -1.0872e-05, -1.3717e-04,
        -4.1736e-05, -1.4729e-04, -5.8488e-05,  7.6730e-05, -1.8579e-04,
         7.2613e-05,  6.0202e-05,  2.1096e-04,  7.8936e-07,  1.3562e-04,
         1.2508e-04,  2.5022e-05, -2.0033e-04, -3.9954e-05, -2.6729e-05,
        -2.7161e-04, -1.8348e-04,  6.5597e-05, -1.9488e-04,  1.8107e-04,
        -2.3789e-04,  1.9307e-04, -3.2383e-04, -2.3470e-04, -5.8081e-05,
        -2.2189e-04, -7.5359e-05, -7.7303e-05,  2.4927e-04, -2.6862e-04,
         1.4155e-05, -3.5420e-05, -5.9561e-05,  5.5022e-05, -9.4954e-05,
        -3.6327e-04,  2.2714e-05,  7.6265e-05, -6.1261e-05,  2.0187e-04,
         1.4906e-04, -1.4445e-04, -9.7930e-05, -6.8493e-06, -1.3216e-04,
        -8.5889e-06,  8.1315e-05, -2.2461e-04,  9.2749e-05, -2.1371e-05,
        -1.6368e-05,  1.0205e-04, -3.2322e-04, -9.0641e-06, -2.7919e-04,
        -8.2231e-05, -4.0377e-04, -1.5231e-04, -8.6280e-05,  1.8861e-04,
         2.6070e-05,  1.1174e-04, -1.7125e-04, -2.1489e-05, -2.7854e-05,
         1.1692e-04,  1.7873e-04, -3.8048e-05, -7.6054e-05,  2.1821e-04,
        -2.0008e-04,  1.4834e-04,  2.1502e-05,  1.6252e-04, -1.4662e-05,
        -1.5355e-05, -4.4962e-05,  6.7523e-05, -1.9004e-04,  4.0344e-05,
        -1.5464e-05, -8.0318e-05,  6.3566e-05], device='cuda:0'), 'exp_avg_sq': tensor([2.7901e-07, 3.6583e-07, 1.8990e-07, 1.8433e-07, 4.4693e-07, 1.8669e-07,
        2.0367e-07, 1.0107e-07, 1.7723e-07, 5.3152e-07, 1.9061e-07, 8.6710e-08,
        2.8519e-07, 1.8220e-07, 5.2014e-07, 5.9667e-07, 1.8070e-07, 1.0801e-07,
        1.6950e-07, 3.8038e-07, 3.2077e-07, 1.5045e-07, 2.3713e-07, 1.1246e-07,
        3.9303e-07, 1.8150e-07, 3.6410e-07, 2.9541e-07, 3.8580e-07, 3.7795e-07,
        3.2533e-07, 4.1761e-07, 3.6589e-07, 1.5603e-07, 6.8369e-07, 1.3331e-07,
        1.3729e-07, 4.6201e-07, 5.2662e-07, 3.5112e-07, 1.2805e-07, 1.9435e-07,
        4.8947e-07, 1.2633e-07, 1.6357e-07, 6.4566e-07, 2.2478e-07, 2.3389e-07,
        3.4972e-07, 4.0122e-07, 2.1139e-07, 1.2338e-07, 4.7315e-07, 2.5984e-07,
        2.0987e-07, 4.7278e-07, 2.5657e-07, 3.2980e-07, 2.1783e-07, 1.5759e-07,
        1.8182e-07, 2.1149e-07, 1.3076e-07, 4.0252e-07, 4.2165e-07, 1.7497e-07,
        2.0369e-07, 3.7125e-07, 1.8266e-07, 1.5229e-07, 2.7855e-07, 1.5492e-07,
        8.5835e-08, 2.8345e-07, 3.2492e-07, 8.8103e-08, 8.4707e-08, 1.0109e-07,
        1.2761e-07, 2.2760e-07, 4.1088e-07, 3.8812e-07, 2.3757e-07, 1.0019e-07,
        4.5636e-07, 1.8568e-07, 1.9792e-07, 4.7733e-07, 6.3484e-07, 4.6349e-07,
        8.3753e-08, 4.1780e-07, 5.6839e-07, 2.1818e-07, 2.4772e-07, 2.2443e-07,
        5.0190e-07, 3.2097e-07, 3.9822e-07, 1.7103e-07, 1.0574e-07, 3.6277e-07,
        4.0774e-07, 2.6747e-07, 1.7881e-07, 2.7243e-07, 3.9527e-07, 3.3063e-07,
        3.2989e-07, 1.1609e-07, 1.9684e-07, 3.1939e-07, 1.1580e-07, 1.9109e-07,
        2.7634e-07, 9.0176e-07, 1.2337e-07, 2.3861e-07, 5.5848e-07, 4.4399e-07,
        1.4426e-07, 1.1027e-07, 5.9208e-07, 4.9958e-07, 1.7070e-07, 8.0669e-08,
        1.4076e-07, 2.8906e-07], device='cuda:0')}, 94: {'step': tensor(30200.), 'exp_avg': tensor([-7.2707e-05, -1.2378e-05, -7.4586e-05, -3.8474e-05, -1.0787e-04,
         1.4514e-04,  8.2441e-05,  3.2126e-05,  9.6565e-05,  2.0110e-05,
         5.3040e-05, -2.1310e-05,  8.7505e-05,  2.0664e-04, -6.9388e-05,
        -2.4041e-05, -6.2427e-05,  2.4009e-05, -1.5203e-04,  4.4721e-05,
         7.0741e-06, -5.3543e-05,  2.5171e-04, -1.0518e-04,  2.1143e-04,
         9.8583e-05,  6.6666e-05,  2.4950e-05,  4.0117e-05, -2.3194e-05,
        -6.5499e-05, -8.2445e-05, -1.3242e-04,  7.5063e-05, -3.3780e-05,
        -1.4489e-04, -4.3486e-05, -2.3438e-05, -5.0228e-05,  2.5261e-04,
         7.5707e-05, -9.1172e-05,  5.4454e-05,  7.9291e-05,  2.3836e-05,
         3.8050e-05, -1.6618e-04, -6.7146e-05, -5.0733e-05, -1.0875e-04,
         2.9397e-05, -1.0379e-04, -2.0207e-04,  7.2574e-05, -7.6124e-06,
         9.2457e-05,  4.0129e-04, -1.4887e-04, -1.2049e-04,  6.7301e-05,
        -1.8457e-04, -1.2599e-04, -1.1428e-05,  1.1874e-04,  9.9873e-05,
        -1.9009e-04, -8.8506e-05, -1.7432e-04, -9.7466e-05, -9.7617e-05,
         1.5424e-04,  3.8968e-05,  1.0091e-04, -1.2774e-04,  1.5894e-04,
        -2.7994e-05,  1.0766e-04,  8.6849e-06,  6.7647e-05,  6.3357e-05,
         6.7014e-05,  2.0521e-04,  1.8968e-05,  2.1792e-05, -1.2193e-04,
         6.7625e-05, -9.2745e-05, -8.6524e-05,  2.0668e-04,  1.6406e-04,
         2.6710e-05, -7.4925e-05,  1.8230e-04, -1.0249e-04,  1.3225e-04,
         7.4502e-05,  4.3340e-05,  7.3596e-05, -2.3215e-04,  1.1460e-04,
        -2.2342e-05, -5.5559e-05,  2.0422e-04,  1.5922e-04, -2.0147e-04,
         4.5575e-06, -9.3217e-05,  1.1887e-04,  5.9668e-06,  2.9834e-05,
        -2.8520e-05,  2.4909e-05,  9.5092e-05,  1.2642e-04,  6.5382e-05,
        -1.5936e-04, -8.8842e-05, -2.4270e-04,  9.8793e-06, -2.4840e-04,
         1.1195e-04, -1.3022e-05,  8.9643e-05,  1.0955e-04, -6.7943e-06,
         8.6720e-05, -1.1625e-05, -1.3590e-04], device='cuda:0'), 'exp_avg_sq': tensor([2.1096e-07, 5.3262e-07, 4.3597e-07, 1.8439e-07, 4.0669e-07, 1.7135e-07,
        2.8760e-07, 8.0231e-08, 2.7126e-07, 5.7927e-07, 2.5435e-07, 1.6607e-07,
        4.8528e-07, 1.5790e-07, 6.0421e-07, 4.8766e-07, 2.1145e-07, 2.0054e-07,
        1.9336e-07, 2.7892e-07, 2.7309e-07, 2.1101e-07, 6.8803e-07, 1.6053e-07,
        3.5485e-07, 2.8265e-07, 5.3087e-07, 5.3091e-07, 3.3257e-07, 3.9722e-07,
        3.5358e-07, 5.7452e-07, 4.5978e-07, 1.8701e-07, 6.8297e-07, 1.4210e-07,
        1.2171e-07, 6.3023e-07, 8.1515e-07, 4.3293e-07, 2.1308e-07, 2.5826e-07,
        3.5230e-07, 1.3955e-07, 1.8251e-07, 6.4162e-07, 3.9738e-07, 3.2915e-07,
        7.1256e-07, 7.0250e-07, 2.6123e-07, 1.6328e-07, 6.3438e-07, 1.9899e-07,
        1.6101e-07, 4.5108e-07, 1.7593e-07, 4.8006e-07, 2.6795e-07, 2.1019e-07,
        3.3807e-07, 3.4212e-07, 2.1504e-07, 4.9309e-07, 5.8210e-07, 3.5366e-07,
        3.8795e-07, 4.9717e-07, 2.7451e-07, 2.9921e-07, 2.5539e-07, 2.6273e-07,
        1.5956e-07, 3.0094e-07, 2.8850e-07, 1.4212e-07, 1.1033e-07, 2.0322e-07,
        2.1679e-07, 3.2706e-07, 5.8643e-07, 3.9269e-07, 2.6067e-07, 1.2187e-07,
        2.9023e-07, 3.2730e-07, 3.6226e-07, 5.4909e-07, 6.6217e-07, 6.8002e-07,
        1.0904e-07, 3.6501e-07, 5.4860e-07, 2.1278e-07, 2.4686e-07, 3.2647e-07,
        5.5009e-07, 2.7538e-07, 4.4761e-07, 2.0447e-07, 2.2613e-07, 4.4526e-07,
        6.5709e-07, 3.5274e-07, 3.8808e-07, 2.7022e-07, 5.9467e-07, 4.0948e-07,
        4.5324e-07, 1.7074e-07, 2.4840e-07, 3.5362e-07, 1.8997e-07, 4.1757e-07,
        7.4947e-07, 5.6697e-07, 1.2063e-07, 4.2832e-07, 5.9900e-07, 8.1159e-07,
        2.3825e-07, 1.2911e-07, 5.8540e-07, 6.7309e-07, 4.0048e-07, 1.4190e-07,
        1.8259e-07, 2.1347e-07], device='cuda:0')}, 95: {'step': tensor(30200.), 'exp_avg': tensor([[-2.0959e-05, -1.1457e-04,  3.6375e-05,  ...,  4.1025e-05,
         -6.6627e-05, -3.5977e-05],
        [ 9.1535e-05,  5.4268e-05, -5.8231e-05,  ..., -9.9380e-07,
          6.2177e-06,  1.0354e-05],
        [-1.3920e-06,  3.3247e-05,  3.0153e-05,  ...,  5.5785e-05,
          8.9447e-05, -8.1191e-05],
        ...,
        [-7.9446e-05,  4.3077e-05,  1.0944e-06,  ...,  1.6245e-05,
         -2.0446e-05,  4.5572e-05],
        [ 1.3166e-04,  4.8075e-06, -4.9734e-05,  ...,  2.0456e-05,
          5.1023e-05, -3.5050e-05],
        [-1.3363e-04,  7.2642e-05,  3.0748e-06,  ..., -6.9190e-05,
          6.2477e-05, -5.9915e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[1.5520e-07, 2.0598e-07, 7.7650e-08,  ..., 1.1507e-07, 2.3450e-07,
         4.7644e-07],
        [5.0305e-08, 3.0210e-08, 1.7255e-08,  ..., 3.0580e-08, 4.6559e-08,
         9.1614e-08],
        [4.7382e-08, 2.0310e-08, 1.5752e-08,  ..., 4.6867e-08, 3.5883e-08,
         4.1492e-08],
        ...,
        [5.7756e-08, 3.2023e-08, 2.8155e-08,  ..., 4.0080e-08, 4.7514e-08,
         3.3675e-08],
        [4.7341e-08, 5.5398e-08, 2.3189e-08,  ..., 4.8763e-08, 1.0141e-07,
         1.4791e-07],
        [6.9944e-07, 4.5491e-07, 4.0713e-07,  ..., 5.2450e-07, 6.6627e-07,
         1.2626e-06]], device='cuda:0')}, 96: {'step': tensor(30200.), 'exp_avg': tensor([ 9.3692e-05,  5.5976e-05, -1.0709e-04,  4.5533e-06,  7.5312e-05,
        -1.8313e-04, -3.3916e-05,  6.5839e-05,  1.6250e-05, -2.8816e-05,
        -8.8003e-05, -2.7242e-05, -3.4375e-05,  2.2055e-05, -3.5772e-05,
         5.9953e-05, -5.4322e-04, -2.5054e-05, -3.8308e-05,  1.1356e-04,
        -1.2085e-06, -4.0948e-06, -6.6661e-05, -1.2169e-05,  2.4880e-05,
         4.8918e-05,  1.2117e-04, -1.3691e-04,  1.1018e-05,  8.0573e-05,
         4.7554e-05,  1.5151e-05,  1.0043e-04, -2.4329e-05,  3.0830e-05,
         1.0285e-05, -6.2542e-05,  3.8386e-07,  2.7350e-05, -8.8118e-05,
        -8.2503e-05,  1.3465e-05,  1.0613e-04,  1.0806e-05,  5.1960e-05,
         7.7168e-05,  1.3522e-05,  1.7450e-05, -1.1676e-04, -1.9409e-05,
        -6.6946e-05,  1.4763e-05, -1.5159e-05, -6.9537e-05,  3.8883e-05,
        -6.5584e-05, -7.1196e-05, -1.8583e-06,  1.5086e-05,  6.2133e-06,
        -3.5928e-05, -5.7245e-05,  2.5420e-05, -1.1218e-04, -6.6111e-06,
        -1.5575e-05,  9.5243e-05, -9.5476e-05, -1.3135e-05, -4.9373e-05,
         7.6393e-06, -2.8356e-05, -4.0799e-05, -4.4173e-05, -8.5568e-05,
        -1.2444e-04, -4.7108e-05,  7.4632e-06, -5.5802e-05,  1.6146e-05,
        -2.1399e-05, -4.2300e-05,  1.4461e-04,  4.2830e-05, -5.3069e-06,
        -1.1724e-05,  1.0546e-04, -8.6786e-06,  3.2643e-05,  3.9045e-05,
        -1.2158e-05,  9.0548e-05,  1.7163e-05,  5.0528e-05,  1.3048e-07,
         1.1507e-04, -6.7898e-06, -2.8679e-05,  1.1312e-04,  7.6616e-05,
        -6.0284e-05, -7.9934e-05, -6.5856e-05, -3.6208e-05,  3.2412e-05,
         4.5086e-05,  1.0673e-04,  7.4033e-05,  7.3581e-05,  3.1698e-05,
         3.7939e-05, -2.9761e-04, -2.7266e-06, -1.0351e-05,  9.5623e-06,
         4.0378e-05,  4.6196e-05,  8.0376e-05,  1.0368e-04, -5.4131e-05,
        -1.1287e-04,  6.9049e-05, -6.9491e-05, -2.2517e-06, -7.8238e-06,
        -5.7468e-06, -5.4999e-05,  5.7036e-05,  5.9045e-05,  1.7651e-05,
         1.2892e-05, -3.4935e-05, -1.4884e-04, -3.1841e-05, -5.6706e-05,
        -1.0880e-04, -3.2236e-05, -5.8247e-05,  4.1239e-05, -1.4664e-04,
         2.0392e-04,  4.3855e-05, -7.6336e-06,  4.4593e-05,  8.5829e-05,
        -8.1108e-05,  6.7877e-06,  2.6385e-06, -3.1915e-06, -1.5380e-04,
         3.2663e-05,  2.3816e-05, -4.4890e-05,  1.3029e-04,  5.4140e-05,
        -1.1983e-04, -3.1253e-05, -4.3806e-05, -4.1122e-05,  1.4997e-04,
        -9.4953e-05,  1.0081e-04, -1.2335e-04,  7.6515e-06,  8.3162e-06,
         6.1937e-06,  4.5436e-05, -1.7485e-05, -4.2862e-05, -6.2792e-05,
        -2.6583e-05, -8.7145e-06,  6.9220e-05, -3.8118e-06,  1.6223e-05,
        -3.6930e-06, -2.7025e-04, -1.3082e-06, -4.9149e-05, -1.1040e-06,
        -1.5495e-04,  2.5084e-06,  7.6990e-05,  3.9796e-05,  1.3393e-04,
         9.5154e-06, -4.5054e-05, -1.3885e-05, -6.8520e-05, -2.2247e-05,
         7.4767e-05,  8.9052e-05, -1.0966e-04, -4.9115e-05,  3.5893e-05,
         1.3554e-04,  4.8354e-06,  1.8642e-04,  5.2734e-06,  9.6731e-05,
         1.5571e-05,  4.0497e-05,  6.5362e-05, -3.3339e-05,  6.5413e-06,
         2.0361e-05,  3.7220e-05, -8.5460e-05, -9.2000e-05, -1.4353e-04,
         3.5998e-08, -1.4649e-04, -2.4672e-05, -2.6523e-06,  3.5820e-05,
         2.7476e-05, -2.6922e-05, -1.5165e-04,  1.4326e-04,  5.4879e-05,
        -4.3301e-05, -1.6106e-05, -1.2526e-05,  4.7704e-05, -1.3650e-04,
         6.7296e-05,  1.4150e-04, -4.6924e-05,  3.9197e-05, -1.9851e-04,
         6.2148e-05, -1.4742e-05,  4.2485e-06,  2.8798e-05,  9.5875e-05,
        -1.0735e-04, -1.0907e-04, -4.8602e-05, -9.1934e-05,  1.5693e-05,
         6.8729e-05, -4.4415e-05,  1.0034e-04, -4.3092e-05,  2.9399e-05,
        -4.3848e-05,  4.8802e-05, -1.1754e-04, -9.2405e-07,  3.0816e-05,
         1.5743e-05, -2.2347e-05,  8.1823e-05, -4.4155e-05, -1.3877e-05,
        -1.3506e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.9195e-07, 3.5655e-08, 3.8632e-08, 8.8147e-09, 8.7798e-08, 3.1412e-07,
        6.5496e-08, 3.4540e-07, 4.5542e-08, 2.5491e-08, 5.7300e-08, 6.8527e-08,
        7.8757e-08, 3.5524e-08, 6.9349e-09, 1.2555e-08, 5.8757e-07, 5.3126e-08,
        4.0893e-08, 2.6863e-07, 3.1800e-08, 1.3276e-07, 6.1293e-08, 2.8307e-07,
        9.7794e-09, 4.6883e-08, 5.4323e-08, 7.7265e-08, 5.6579e-08, 1.3996e-07,
        8.3793e-08, 3.5801e-08, 2.6209e-07, 1.0931e-07, 1.1539e-07, 4.2637e-08,
        4.7196e-08, 8.3018e-08, 2.3803e-07, 6.0579e-08, 1.5938e-07, 3.1542e-08,
        3.0735e-07, 1.2579e-07, 8.0094e-08, 2.1966e-07, 6.3097e-08, 2.9479e-07,
        6.1611e-07, 1.0076e-07, 1.6590e-07, 5.4067e-08, 1.6347e-07, 2.4756e-08,
        9.0773e-08, 5.1020e-08, 7.1478e-08, 2.9831e-07, 9.9961e-08, 7.0238e-08,
        1.0178e-07, 5.1540e-08, 3.4069e-08, 1.1123e-07, 5.1988e-07, 6.4174e-08,
        4.5634e-08, 1.3896e-07, 2.1169e-08, 5.4803e-08, 1.7749e-08, 3.0009e-08,
        5.0250e-08, 2.0661e-07, 2.6633e-08, 2.2434e-07, 3.3846e-08, 4.8904e-08,
        1.3901e-07, 2.9955e-08, 5.3336e-08, 1.4044e-07, 3.0876e-07, 1.0230e-08,
        1.2391e-07, 1.1215e-07, 1.8286e-07, 8.7940e-09, 7.8661e-08, 1.9351e-07,
        3.0905e-08, 2.7787e-07, 2.6654e-08, 5.8354e-08, 8.9212e-09, 1.7162e-07,
        4.6876e-08, 7.8877e-08, 2.5044e-07, 2.6907e-08, 3.3969e-07, 1.4522e-07,
        4.1524e-07, 8.2527e-08, 2.5057e-07, 2.4583e-08, 1.0322e-07, 9.0942e-08,
        6.2699e-08, 7.6860e-09, 5.9581e-08, 5.1863e-07, 1.3577e-07, 6.7443e-08,
        1.6389e-08, 9.1351e-08, 4.9000e-07, 1.5040e-07, 1.0852e-07, 1.1726e-07,
        9.4638e-08, 1.8466e-07, 1.1110e-07, 2.2083e-07, 4.0615e-08, 3.8368e-08,
        1.5672e-07, 1.0196e-07, 5.1761e-08, 7.0280e-08, 1.1600e-07, 2.7926e-07,
        2.1880e-07, 5.1621e-08, 1.9445e-07, 4.6496e-08, 7.2719e-08, 3.5541e-07,
        3.6972e-08, 2.0371e-07, 1.6541e-07, 2.5000e-08, 3.6365e-07, 4.7564e-08,
        9.9232e-08, 1.1337e-07, 7.3099e-08, 2.5607e-08, 3.4459e-07, 1.4552e-07,
        8.0592e-08, 6.8386e-08, 4.4043e-08, 1.7238e-07, 4.1422e-07, 2.0758e-07,
        5.9074e-08, 9.8301e-08, 2.9539e-08, 1.4217e-07, 7.0634e-08, 6.7264e-08,
        5.9709e-08, 2.2463e-07, 2.1793e-08, 8.0073e-08, 4.1362e-08, 1.3783e-07,
        6.1280e-08, 8.0521e-08, 1.8691e-07, 7.9995e-08, 2.7263e-08, 7.9890e-08,
        8.9415e-08, 3.9221e-07, 5.0588e-07, 3.9530e-08, 6.9447e-08, 5.5863e-08,
        6.4649e-08, 8.1405e-08, 2.1008e-07, 1.5869e-07, 1.2393e-07, 1.3226e-08,
        1.5286e-07, 2.4739e-07, 2.1292e-08, 2.9063e-07, 9.6138e-08, 2.7357e-08,
        8.3198e-08, 2.4042e-07, 7.8416e-08, 1.8189e-07, 2.6811e-08, 3.3565e-07,
        1.0815e-07, 4.2777e-08, 1.4800e-08, 4.3226e-08, 1.1917e-07, 6.5045e-08,
        5.7657e-08, 2.4854e-07, 4.7085e-08, 2.2790e-07, 8.5695e-08, 1.1494e-07,
        3.3007e-07, 3.1528e-07, 1.1084e-07, 2.9703e-08, 5.3390e-08, 1.9992e-08,
        1.5790e-07, 2.6909e-07, 1.6784e-07, 4.5942e-07, 3.3341e-08, 6.0069e-08,
        5.8315e-08, 5.3176e-08, 1.0071e-07, 9.4720e-08, 3.0425e-07, 8.4684e-08,
        1.7151e-08, 5.5858e-07, 1.8180e-07, 1.0248e-07, 8.7490e-08, 2.7802e-08,
        4.1240e-07, 2.3779e-07, 5.5476e-08, 4.2899e-08, 3.7351e-08, 8.6807e-08,
        2.7116e-08, 8.8472e-08, 8.9662e-08, 1.4499e-07, 2.9977e-07, 2.6745e-08,
        8.5159e-08, 4.2559e-08, 3.4892e-07, 2.4887e-07, 2.4962e-07, 3.9234e-08,
        2.8431e-08, 3.6963e-08, 5.2520e-08, 5.9614e-07], device='cuda:0')}, 97: {'step': tensor(30200.), 'exp_avg': tensor([[-4.6501e-06,  3.3400e-05, -1.5676e-05,  ..., -7.5190e-05,
          1.0049e-04, -1.2117e-05],
        [-4.3390e-05, -5.0409e-05,  5.3133e-05,  ...,  1.6172e-04,
         -1.1306e-04, -5.4054e-05],
        [ 2.6111e-05, -8.7282e-06,  6.1653e-05,  ...,  2.5534e-05,
          1.5240e-06,  2.1909e-05],
        ...,
        [-5.7504e-05,  4.3358e-05, -4.0355e-05,  ...,  4.7177e-05,
          1.9631e-05, -3.8000e-05],
        [-6.5670e-05,  4.7669e-07, -1.6060e-05,  ...,  3.7479e-05,
         -1.0772e-04, -5.9534e-05],
        [-2.0767e-05, -3.1418e-05,  8.6618e-06,  ...,  3.9345e-05,
         -5.0665e-05, -3.5990e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[5.7421e-08, 5.1270e-08, 1.3739e-08,  ..., 1.8826e-08, 6.2095e-08,
         1.2550e-08],
        [1.4466e-07, 9.8891e-08, 6.7904e-08,  ..., 1.4060e-07, 1.2260e-07,
         4.2593e-08],
        [5.0379e-08, 2.5718e-08, 1.4090e-08,  ..., 2.4798e-08, 3.0363e-08,
         1.9410e-08],
        ...,
        [8.3857e-08, 4.4958e-08, 1.3981e-08,  ..., 2.2138e-08, 5.4263e-08,
         4.0723e-08],
        [6.6795e-08, 6.3752e-08, 1.6160e-08,  ..., 1.3432e-08, 8.1958e-08,
         3.6316e-08],
        [2.4964e-08, 3.9790e-08, 1.5104e-08,  ..., 3.5259e-08, 2.3438e-08,
         1.0011e-08]], device='cuda:0')}, 98: {'step': tensor(30200.), 'exp_avg': tensor([ 8.9554e-05, -1.3137e-04,  6.4324e-06, -4.6573e-05,  9.6086e-05,
        -4.0867e-05,  9.8804e-05, -6.3471e-05, -9.4484e-05, -5.2444e-05,
        -2.1540e-07,  4.0287e-05, -1.0489e-04,  8.1441e-05, -2.6269e-05,
         3.6064e-05,  1.0382e-05,  6.1231e-05, -4.2880e-06, -4.8740e-05,
         3.5307e-05,  5.9967e-05,  3.8961e-05,  4.6441e-05, -1.1611e-04,
         1.6311e-05,  3.7002e-05,  1.7000e-04, -7.8419e-06,  5.1113e-05,
        -1.5120e-04,  1.7716e-05, -2.2697e-05,  3.1759e-05,  1.1903e-05,
        -6.2220e-06,  9.2695e-05, -3.6961e-05, -1.1861e-04,  1.8302e-04,
        -2.8473e-05,  7.1119e-05, -2.4892e-05,  3.3469e-05, -1.0996e-04,
         8.3421e-06, -1.3196e-04,  4.3437e-05,  1.0461e-04,  8.7461e-05,
        -8.7227e-05, -3.1940e-04, -1.1217e-04,  1.0548e-04, -3.7641e-05,
         1.5429e-04,  1.0438e-04, -7.2853e-06,  1.3709e-04,  8.5823e-05,
         8.4781e-05,  7.6328e-05,  8.6021e-05, -7.3775e-05,  6.5187e-05,
        -1.4603e-04,  2.0248e-05,  5.9144e-05, -1.7587e-04,  1.4501e-04,
         1.3003e-04, -1.0554e-05,  1.1933e-04, -1.6484e-04, -1.0757e-04,
        -1.0608e-04, -6.8027e-07,  4.9366e-05, -1.1204e-04, -8.2711e-06,
         6.4949e-05,  7.0736e-05,  1.7524e-05,  9.0436e-05,  5.0804e-06,
        -4.9375e-05, -2.4764e-05,  1.0315e-04,  1.4111e-04,  1.1627e-04,
        -1.3105e-04, -5.0978e-05,  1.2904e-04,  1.6589e-05, -3.4333e-05,
         5.0647e-05,  7.2992e-05,  3.0928e-05, -1.4033e-04,  2.7964e-05,
         3.7469e-06, -1.2708e-04,  1.0128e-04,  8.8345e-05, -2.1161e-04,
         2.0290e-05, -1.6868e-05,  1.1619e-04, -1.0498e-04, -2.8189e-05,
         4.9242e-05, -8.2962e-05,  4.5221e-05,  1.6453e-04,  1.7857e-04,
        -8.4861e-05, -1.2602e-04, -1.2951e-04, -1.1424e-04, -7.7415e-05,
         2.6969e-06,  1.0485e-04,  4.6719e-06, -4.5625e-05,  5.6743e-05,
         7.1092e-05, -1.0724e-04, -3.8123e-05], device='cuda:0'), 'exp_avg_sq': tensor([2.8616e-07, 5.5268e-07, 1.8277e-07, 2.2222e-07, 2.4632e-07, 4.4625e-07,
        2.7912e-07, 1.8923e-07, 3.9317e-07, 1.6634e-07, 1.6522e-07, 1.0982e-07,
        5.6340e-07, 1.7890e-07, 3.3675e-07, 5.4973e-07, 8.5388e-08, 2.8497e-07,
        2.1459e-07, 2.6086e-07, 1.7117e-07, 6.3032e-07, 7.3319e-07, 3.1420e-07,
        1.0042e-07, 1.7250e-07, 7.7256e-07, 6.2978e-07, 6.3237e-07, 4.1206e-07,
        2.8649e-07, 3.1187e-07, 4.9208e-07, 7.5353e-08, 6.6510e-07, 3.8476e-07,
        5.6430e-08, 2.3772e-07, 5.1384e-07, 3.4068e-07, 5.0748e-07, 3.4884e-07,
        4.1614e-07, 3.2207e-07, 1.1744e-07, 6.6800e-07, 7.1631e-07, 1.4246e-07,
        4.2835e-07, 4.3898e-07, 6.6187e-07, 1.1130e-06, 4.5691e-07, 1.4390e-07,
        1.4668e-07, 3.4829e-07, 9.4829e-08, 1.8112e-07, 1.2573e-07, 2.9873e-07,
        5.5250e-07, 2.5145e-07, 4.9662e-07, 4.4457e-07, 4.1252e-07, 5.7378e-07,
        2.6278e-07, 9.3236e-08, 3.3223e-07, 3.3985e-07, 2.6987e-07, 2.3858e-07,
        4.2846e-07, 2.5707e-07, 6.6701e-07, 4.6011e-07, 4.0690e-07, 1.7129e-07,
        1.1388e-07, 2.6019e-07, 5.4930e-07, 1.3962e-07, 2.1976e-07, 3.3792e-07,
        5.6670e-08, 1.2500e-07, 2.1524e-07, 1.4538e-07, 3.2342e-07, 7.1066e-07,
        4.4670e-07, 9.9294e-08, 2.0668e-07, 3.5975e-07, 4.2077e-07, 3.6615e-07,
        2.8680e-07, 6.3814e-08, 3.2013e-07, 5.4196e-07, 1.9461e-07, 3.8093e-07,
        3.6382e-07, 2.0456e-07, 6.4568e-07, 3.1193e-07, 3.9647e-07, 2.5193e-07,
        3.9363e-07, 3.4113e-07, 1.0776e-07, 2.9168e-07, 4.6396e-07, 4.6615e-07,
        5.1948e-07, 3.2810e-07, 5.3949e-07, 5.8043e-07, 2.7022e-07, 4.8715e-07,
        5.8589e-07, 2.2959e-07, 1.6256e-07, 1.1511e-07, 4.1532e-07, 3.5495e-07,
        4.0058e-07, 1.1615e-07], device='cuda:0')}, 99: {'step': tensor(30200.), 'exp_avg': tensor([-2.4680e-04,  2.7965e-04, -1.1803e-04, -3.6120e-05, -6.5486e-06,
        -1.7536e-04, -3.2275e-04, -1.1332e-04,  8.6257e-05,  2.1593e-04,
        -1.5556e-04,  3.0917e-05, -7.5070e-05, -3.3308e-04, -2.5271e-04,
        -1.6040e-04,  6.2510e-05,  9.6038e-05, -1.3784e-04,  8.7822e-05,
        -1.6266e-04, -1.5160e-04,  1.2307e-05, -1.2688e-04,  3.6273e-04,
        -2.5359e-04,  6.5771e-06,  2.8043e-05, -1.5714e-04, -2.2934e-04,
         1.0100e-04, -3.5573e-04, -3.5245e-04, -3.0636e-04,  2.5315e-04,
        -4.6564e-04,  1.4898e-04, -8.3106e-05, -5.7715e-04, -2.0493e-04,
        -3.0321e-04, -5.9823e-05,  4.0565e-05, -7.8940e-06, -6.3588e-05,
        -8.3676e-05, -5.1646e-04, -1.4571e-04,  1.2580e-04, -5.3430e-04,
        -2.2694e-04,  3.9046e-04,  3.6274e-04, -3.4349e-04, -1.6886e-04,
         1.6442e-04, -9.0157e-05, -8.1496e-05, -8.7519e-05,  3.2504e-05,
        -5.1028e-04, -3.5460e-04, -2.7690e-04, -1.7481e-04,  3.7572e-04,
        -5.5777e-04,  2.9055e-05, -1.3410e-04, -1.5445e-06,  1.3088e-04,
        -1.6930e-04, -1.6516e-04, -4.8283e-04, -1.2939e-04,  1.2970e-04,
         7.4680e-06, -4.8625e-04, -2.1579e-05,  3.3209e-05, -1.5522e-04,
         9.3194e-05, -1.8290e-04,  2.0034e-04,  1.3937e-04,  1.1989e-04,
         1.1670e-04, -6.2011e-05,  8.5970e-05, -1.7369e-04,  9.8730e-05,
         1.4134e-04, -1.3744e-04, -4.1175e-04, -2.4855e-04, -9.9487e-05,
         3.3910e-05,  2.6811e-04, -3.2514e-04, -1.2390e-04, -9.1908e-04,
         5.6568e-06, -1.5886e-04, -9.8481e-05, -3.2887e-04,  1.6119e-04,
        -3.1024e-04,  2.9242e-04, -2.5899e-04,  2.2612e-04, -2.2674e-04,
        -4.1566e-05, -6.6562e-05,  1.3809e-04, -2.5452e-04,  3.6648e-04,
        -4.0211e-04,  3.3484e-05, -2.3399e-04,  2.0043e-04,  1.4801e-04,
        -1.2349e-04, -3.2509e-04,  4.1630e-04, -2.1057e-04, -5.8779e-05,
        -1.2677e-04,  2.6103e-04, -1.2180e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.1855e-06, 2.5667e-06, 4.1355e-07, 6.3058e-07, 2.2510e-06, 2.1857e-06,
        9.7752e-07, 1.7536e-06, 1.3891e-06, 8.0378e-07, 9.4773e-07, 2.1881e-07,
        1.4401e-06, 1.5249e-06, 1.9785e-06, 2.9976e-06, 2.3363e-07, 6.1695e-07,
        1.8026e-06, 1.1953e-06, 1.0917e-06, 1.8554e-06, 1.6242e-06, 8.5750e-07,
        6.9227e-07, 7.6155e-07, 3.8629e-06, 2.5441e-06, 3.7416e-06, 1.7552e-06,
        9.5070e-07, 1.3205e-06, 1.7566e-06, 5.1694e-07, 3.1640e-06, 1.3790e-06,
        6.4886e-07, 8.3762e-07, 1.4911e-06, 8.6825e-07, 2.3413e-06, 9.2516e-07,
        9.5897e-07, 8.8159e-07, 4.9034e-07, 2.8935e-06, 2.2964e-06, 6.7620e-07,
        1.0305e-06, 1.5412e-06, 2.9996e-06, 2.4954e-06, 1.7514e-06, 7.0258e-07,
        1.6548e-06, 1.1977e-06, 8.5860e-07, 1.3454e-06, 6.2454e-07, 8.0206e-07,
        3.6434e-06, 9.7612e-07, 1.1944e-06, 1.7294e-06, 1.1595e-06, 1.3934e-06,
        1.1132e-06, 3.9622e-07, 9.3344e-07, 8.3096e-07, 1.8924e-06, 7.7353e-07,
        9.9556e-07, 1.2971e-06, 4.2688e-06, 1.4152e-06, 9.9014e-07, 6.5981e-07,
        2.9031e-07, 1.0083e-06, 1.4143e-06, 9.4133e-07, 1.3302e-06, 1.4032e-06,
        4.5164e-07, 4.1712e-07, 8.1618e-07, 5.5483e-07, 2.0391e-06, 1.4907e-06,
        8.7948e-07, 6.4799e-07, 1.8039e-06, 2.0496e-06, 1.5327e-06, 1.2320e-06,
        1.8814e-06, 3.6333e-07, 1.5003e-06, 3.5173e-06, 5.4110e-07, 1.4575e-06,
        1.4855e-06, 6.7370e-07, 1.4189e-06, 1.4127e-06, 1.4864e-06, 1.1658e-06,
        1.9457e-06, 9.5582e-07, 4.9928e-07, 7.7722e-07, 1.1776e-06, 1.0714e-06,
        1.1323e-06, 2.5845e-06, 3.2696e-06, 1.3084e-06, 1.0620e-06, 1.1363e-06,
        2.1361e-06, 1.0304e-06, 1.5957e-06, 6.2126e-07, 1.2915e-06, 1.5697e-06,
        2.1610e-06, 9.0758e-07], device='cuda:0')}, 100: {'step': tensor(30200.), 'exp_avg': tensor([ 1.1325e-04, -7.8034e-05, -3.1808e-05, -8.9233e-06,  2.4021e-04,
        -2.4172e-04,  3.7176e-04,  8.1150e-05, -2.3036e-04, -1.7593e-04,
         1.1302e-04,  2.2077e-04, -7.9932e-05, -6.7532e-06, -1.9363e-04,
         2.2179e-04,  9.6993e-06,  3.0590e-04, -2.4659e-04, -1.3920e-04,
         1.7798e-04, -4.0265e-05,  3.6777e-04,  3.5856e-05, -2.1482e-04,
        -3.3815e-05,  1.5518e-04, -7.8917e-05, -2.6490e-04,  2.4105e-04,
        -3.1703e-04,  9.2568e-05,  3.6338e-05,  1.3830e-04, -1.5921e-04,
        -1.5997e-04,  1.2734e-04, -8.4126e-05, -1.5876e-04,  1.0543e-04,
        -1.8760e-04, -1.2666e-04, -5.9148e-05,  1.7380e-04,  2.0294e-06,
         2.9757e-04, -2.2981e-04,  1.3247e-04,  2.5695e-04,  2.3704e-04,
        -2.1521e-04, -4.9900e-04, -1.9750e-04,  2.6560e-04,  8.6594e-05,
         1.1487e-04,  1.8641e-04, -3.0622e-04,  2.7020e-04,  1.9196e-04,
        -6.8495e-05,  2.3217e-04, -9.4001e-05, -1.7591e-04,  8.9568e-05,
        -3.8544e-04, -1.6162e-04,  1.1131e-04, -3.7462e-04,  1.3055e-04,
         2.0861e-04,  2.3295e-05,  4.0194e-04, -2.9471e-04,  1.7113e-04,
        -2.4659e-04,  7.7388e-05,  1.9620e-04, -2.3782e-04, -1.5396e-04,
         2.0083e-04,  9.8421e-05,  1.5004e-04,  4.5583e-04,  2.1235e-05,
        -1.8224e-04, -2.2604e-04,  2.0076e-04,  4.1044e-04,  4.5594e-04,
        -6.2257e-05,  3.7440e-05,  3.8233e-04,  2.0374e-04, -8.0643e-05,
         8.9264e-06, -6.8986e-05,  7.6339e-05, -2.3363e-04,  2.8254e-04,
         3.0936e-05, -1.3222e-04,  7.4813e-05,  2.9456e-04, -3.8117e-04,
        -8.8487e-05, -1.1511e-04,  1.8279e-04, -1.8537e-04,  9.3337e-05,
         1.1506e-04, -2.0392e-04,  7.7152e-05,  8.7942e-05,  4.6273e-04,
        -3.9498e-04, -2.7774e-04, -2.7545e-04, -2.2849e-04, -2.0093e-04,
         6.9035e-05,  2.2032e-04,  3.4036e-05, -1.9014e-04, -1.4234e-04,
         2.1475e-04, -1.2032e-04, -4.5580e-05], device='cuda:0'), 'exp_avg_sq': tensor([1.8451e-06, 3.0080e-06, 1.1819e-06, 9.8805e-07, 1.4802e-06, 2.6977e-06,
        1.6987e-06, 1.1602e-06, 2.4237e-06, 9.8395e-07, 9.7408e-07, 6.3765e-07,
        3.2018e-06, 9.7748e-07, 1.7070e-06, 3.2130e-06, 4.3560e-07, 1.6598e-06,
        1.4996e-06, 1.4292e-06, 9.4760e-07, 4.0754e-06, 4.2987e-06, 1.7689e-06,
        5.3268e-07, 1.0771e-06, 4.4935e-06, 4.0925e-06, 3.6422e-06, 2.3211e-06,
        1.5886e-06, 1.7515e-06, 2.8136e-06, 4.3024e-07, 4.0517e-06, 2.4025e-06,
        3.4839e-07, 1.2942e-06, 3.0491e-06, 2.2331e-06, 3.1879e-06, 2.2481e-06,
        2.3212e-06, 1.8776e-06, 5.6636e-07, 3.8609e-06, 4.0968e-06, 7.1473e-07,
        2.2976e-06, 2.6110e-06, 3.7121e-06, 6.1098e-06, 2.4486e-06, 8.9955e-07,
        7.4684e-07, 2.2677e-06, 5.9965e-07, 1.2089e-06, 8.0284e-07, 1.9164e-06,
        3.2997e-06, 1.3542e-06, 2.8721e-06, 2.3443e-06, 2.5862e-06, 3.2498e-06,
        1.7083e-06, 6.1148e-07, 1.9083e-06, 1.9916e-06, 1.6313e-06, 1.3960e-06,
        2.9120e-06, 1.4531e-06, 3.8806e-06, 2.5781e-06, 2.3651e-06, 9.0232e-07,
        5.5835e-07, 1.4157e-06, 2.9105e-06, 8.7182e-07, 1.3658e-06, 2.0814e-06,
        2.5666e-07, 8.3330e-07, 1.2732e-06, 9.2741e-07, 2.1684e-06, 3.9758e-06,
        2.4049e-06, 5.5667e-07, 1.4521e-06, 1.9740e-06, 2.4575e-06, 2.2951e-06,
        1.7259e-06, 3.0598e-07, 1.6958e-06, 3.2076e-06, 9.8867e-07, 1.9003e-06,
        2.3358e-06, 1.2510e-06, 3.4900e-06, 1.9075e-06, 2.4556e-06, 1.3096e-06,
        2.3297e-06, 2.1141e-06, 6.5362e-07, 1.4935e-06, 2.6341e-06, 2.7797e-06,
        3.0982e-06, 1.8854e-06, 3.2469e-06, 3.2696e-06, 1.5980e-06, 2.5942e-06,
        3.2315e-06, 1.4633e-06, 9.6719e-07, 6.5443e-07, 2.4976e-06, 2.1222e-06,
        2.2366e-06, 5.4038e-07], device='cuda:0')}, 101: {'step': tensor(30200.), 'exp_avg': tensor([[ 1.8530e-03, -6.9326e-04, -1.0003e-04,  3.0535e-03, -8.8849e-04,
         -1.7649e-03, -2.5524e-03,  1.4685e-03, -5.9290e-04, -1.5230e-03,
          1.0173e-03, -4.1091e-04, -5.8098e-04, -1.7960e-03, -3.8471e-05,
         -6.5934e-04, -1.5167e-03,  1.9782e-03,  4.0932e-04, -6.4897e-03,
          1.0839e-03,  6.0175e-04, -1.0135e-03, -1.8646e-04,  3.3142e-03,
          3.4273e-03, -9.1056e-04,  4.5880e-04, -3.6802e-03,  1.5792e-03,
          1.3361e-03, -9.2284e-04,  2.0839e-03, -3.0852e-03, -3.7831e-03,
          3.5853e-03,  2.2463e-03, -2.8254e-04,  2.1334e-03,  1.1913e-03,
          1.4464e-03,  1.2170e-04, -3.1145e-03,  3.6087e-04, -3.1184e-04,
          3.1760e-03, -1.6607e-03, -1.8496e-03,  1.0602e-03, -2.5781e-03,
         -1.5291e-03,  1.0836e-03,  3.2396e-03, -3.1655e-03,  8.6318e-04,
          9.0498e-04, -3.2614e-03, -3.0312e-03,  3.5483e-03,  3.7204e-04,
         -1.5922e-04, -3.8147e-03,  2.0078e-03, -3.3996e-03, -1.4609e-03,
         -3.5138e-03, -9.9573e-04,  3.9530e-03,  7.7457e-04, -9.2964e-04,
          2.5677e-03, -2.3694e-03,  1.3392e-03,  1.0270e-03,  2.5234e-03,
         -2.0535e-03,  2.6667e-03,  8.0395e-04,  6.1771e-04, -1.0738e-03,
         -3.0450e-04,  2.8785e-03, -2.5289e-03,  3.1070e-03,  1.4587e-03,
          2.4393e-03, -1.6052e-03, -1.4044e-03,  7.7588e-04,  4.5190e-03,
          5.2814e-04,  2.2444e-03,  1.3448e-04, -1.3721e-03,  1.5018e-04,
         -3.5506e-04,  3.5140e-04, -3.5545e-03, -1.7733e-03,  3.2286e-04,
         -1.1515e-04,  4.6842e-03,  4.0442e-05, -2.0010e-03,  1.4658e-03,
         -1.1794e-03,  2.2365e-03, -1.7419e-03,  9.4637e-04,  3.3415e-03,
          2.1600e-03, -2.3043e-03, -2.3878e-03,  1.6128e-03, -5.1983e-03,
         -2.6424e-03, -1.7713e-03, -8.9932e-04,  3.2849e-04,  3.5831e-04,
         -1.0372e-03,  2.0598e-03,  9.7505e-04,  1.6349e-03, -3.3667e-04,
          3.0641e-04,  1.9273e-03, -1.9057e-03],
        [-3.5598e-04,  1.3651e-03,  3.8696e-04, -1.7835e-04,  8.4631e-05,
          1.3702e-04, -1.4893e-03, -7.6133e-04,  3.0115e-04,  1.2213e-04,
         -5.4058e-04,  2.6030e-04,  4.6041e-04, -2.4415e-05,  8.9634e-04,
         -1.4237e-03,  6.3351e-04, -1.0039e-04, -5.0421e-04,  8.2092e-04,
         -1.0172e-03, -6.6242e-04, -6.8590e-04,  2.4635e-04, -1.0145e-03,
          4.5652e-04, -1.3766e-03,  1.6512e-03,  1.2296e-03, -1.1822e-03,
          8.1007e-04, -1.1718e-03,  3.6435e-04,  3.9589e-04,  2.8405e-03,
          4.1882e-04, -7.5793e-04,  7.1361e-04,  1.4909e-04, -1.0516e-03,
          7.1214e-04,  1.7196e-04,  3.0969e-04, -9.6095e-04, -1.9817e-04,
         -1.1009e-03,  1.5539e-04,  2.2869e-04, -9.6191e-04, -5.1319e-04,
          9.7782e-05,  7.2541e-04, -1.3758e-03,  1.1349e-03, -2.7273e-04,
         -1.4166e-03, -5.0071e-04,  2.8626e-04, -1.0027e-03, -1.1619e-03,
          1.4180e-03,  4.6176e-04, -4.9773e-04,  1.1857e-03,  1.0388e-03,
          5.3213e-04,  5.5749e-04,  3.7048e-04, -1.3965e-04,  1.0435e-03,
         -3.7736e-04,  7.3791e-04,  4.4165e-04,  5.3993e-04, -6.4165e-04,
          1.5807e-03, -1.5129e-03, -1.0110e-04, -3.7712e-04,  5.5304e-04,
         -1.5114e-03,  2.2284e-04,  7.5754e-04, -5.5108e-04, -1.0164e-04,
         -2.7991e-04, -6.4196e-05,  4.0376e-04, -2.6685e-04, -1.6364e-03,
          6.5396e-04, -2.2812e-04, -7.3798e-04,  8.4917e-05, -8.3920e-04,
         -5.2745e-05, -3.4921e-04,  6.4661e-04,  9.7620e-04, -1.1882e-03,
          4.3266e-04, -1.4043e-03,  7.7487e-04, -6.2539e-04,  1.5782e-03,
          2.9418e-04, -1.3634e-03,  3.4457e-04,  1.3060e-03, -8.7054e-04,
         -4.1194e-04,  4.4101e-04, -1.5456e-03, -9.2308e-05, -1.5679e-03,
          6.9963e-04,  2.1619e-03,  5.4142e-04, -3.1715e-04,  1.3744e-03,
          6.2934e-04, -1.0918e-03, -7.7194e-04,  9.4390e-04,  9.0442e-04,
         -5.6030e-04,  3.3583e-04,  1.8435e-04],
        [ 9.7300e-04,  5.8003e-04, -9.3569e-04,  2.2955e-03,  3.7321e-04,
         -6.9254e-04, -7.1899e-04,  1.2179e-03,  6.9572e-04, -1.2241e-03,
         -5.5135e-04,  2.8737e-04, -7.4714e-04, -1.4576e-03,  1.9908e-03,
         -1.4425e-04,  1.3966e-03,  1.9770e-04,  6.0508e-04, -5.9139e-04,
          2.3269e-04,  5.9851e-04, -1.3614e-03,  1.2531e-03, -2.0170e-03,
         -9.1764e-04,  2.5169e-04,  4.0594e-04,  1.2297e-03,  6.0942e-04,
         -2.9718e-05,  1.5574e-03,  1.3431e-03, -1.1009e-03,  6.3164e-04,
          1.9059e-03, -2.7643e-04,  7.2201e-04,  4.5566e-04, -1.8184e-03,
         -8.2307e-04,  1.6134e-03,  1.4373e-04, -1.6017e-04, -3.9185e-04,
         -1.1949e-03,  1.5169e-03,  1.1593e-03,  6.2037e-04,  3.4569e-05,
         -9.0186e-04, -3.2687e-04, -1.3233e-03, -7.0700e-04,  9.1708e-04,
         -1.1031e-03, -1.4954e-03,  4.7727e-04,  1.0413e-03, -1.2355e-03,
          2.5743e-04,  6.7602e-05, -1.1305e-03,  2.0082e-03, -2.7717e-04,
          5.1753e-04,  1.8555e-03,  1.3137e-03,  1.9700e-04,  5.5281e-04,
         -2.5002e-03, -9.5472e-04, -1.6239e-03,  6.0073e-04, -8.9481e-04,
          1.1467e-03, -9.2109e-05, -8.6617e-05, -4.9350e-04,  2.8663e-04,
         -1.7592e-03, -2.2876e-03,  1.2357e-04, -5.1147e-04,  1.7849e-03,
         -1.0271e-03,  3.2842e-04,  1.0719e-03, -1.8980e-03, -2.7337e-05,
         -3.8909e-04,  7.3559e-04, -1.6446e-03, -1.7724e-03, -1.5892e-03,
          5.0062e-04, -1.4567e-03, -1.4698e-03,  2.8878e-03, -9.6069e-04,
          7.1295e-04,  2.9922e-04,  8.4797e-05, -1.6838e-03,  1.4308e-04,
          8.6363e-04, -8.3311e-04, -9.9184e-04,  1.1068e-03,  3.5702e-04,
          1.2975e-03, -6.9051e-04, -7.6378e-04,  3.8430e-04, -1.1487e-03,
          3.4729e-04,  1.4537e-03,  1.8139e-03, -6.8519e-04,  1.7538e-03,
         -4.3675e-05, -3.1738e-04, -2.5729e-03, -3.3840e-06,  1.2396e-03,
         -2.6481e-04, -3.2057e-04,  2.2720e-03],
        [-1.5742e-03, -3.1269e-04,  1.2099e-03, -2.7341e-03, -5.2046e-04,
          9.7323e-04,  8.7294e-04, -1.1040e-03, -6.3377e-04,  8.7591e-04,
          8.3537e-04, -1.4063e-04,  5.8829e-04,  1.4927e-03, -2.3081e-03,
          2.2146e-04, -1.2693e-03, -5.2046e-04, -6.3597e-04,  1.0128e-03,
         -3.2753e-04, -3.0035e-04,  1.2292e-03, -1.3125e-03,  1.7531e-03,
          1.1551e-03, -2.3515e-04, -4.3992e-05, -1.4171e-03, -1.2320e-03,
          3.3788e-05, -2.0363e-03, -1.3908e-03,  1.3950e-03, -1.2802e-04,
         -1.7251e-03, -4.5285e-05, -3.5949e-04, -4.0552e-04,  2.1613e-03,
          1.3291e-03, -1.4483e-03,  2.6237e-04, -6.7188e-05,  4.6373e-04,
          1.1113e-03, -1.8703e-03, -1.1677e-03, -7.4110e-04, -2.0833e-04,
          9.6519e-04,  9.4533e-05,  7.5465e-04,  8.5323e-04, -1.0781e-03,
          9.4973e-04,  1.8301e-03, -4.9288e-04, -1.1876e-03,  1.1819e-03,
         -2.6718e-05,  3.0243e-04,  1.1484e-03, -1.6978e-03,  3.1308e-04,
         -5.6168e-04, -1.8364e-03, -1.3008e-03, -1.4854e-04, -7.4630e-05,
          2.6258e-03,  1.2860e-03,  1.8984e-03, -1.0908e-03,  8.3616e-04,
         -1.1304e-03,  3.3879e-05,  4.3280e-04,  3.8155e-04, -2.5811e-04,
          1.4831e-03,  2.5610e-03,  1.3056e-04,  1.5747e-04, -1.3204e-03,
          5.5788e-04, -3.9451e-04, -9.1359e-04,  1.8993e-03, -4.4098e-04,
          1.4843e-04, -8.2956e-04,  2.0435e-03,  1.5337e-03,  1.3732e-03,
         -3.7561e-04,  1.4069e-03,  1.9938e-03, -3.1326e-03,  7.4071e-04,
         -6.7484e-04, -9.8629e-04,  1.9553e-04,  2.0497e-03, -4.8958e-04,
         -3.9680e-04,  6.0713e-04,  8.8882e-04, -8.9223e-04, -5.7070e-04,
         -1.4418e-03,  1.0810e-03,  5.7843e-04,  8.2712e-06,  1.0638e-03,
         -3.0823e-04, -1.1120e-03, -1.8519e-03,  4.5002e-06, -2.1835e-03,
          1.6685e-04,  4.4221e-04,  2.2022e-03, -1.0754e-04, -7.7735e-04,
          1.1158e-04,  1.3251e-04, -2.4448e-03],
        [-2.9559e-03,  1.2721e-03, -5.6871e-04, -1.2624e-03,  6.9386e-04,
         -4.5428e-04,  5.1715e-03,  2.2310e-04,  1.0995e-03,  1.9528e-03,
         -3.4321e-04, -1.3336e-03,  5.7936e-04, -1.0501e-03, -2.0688e-03,
          2.1554e-03,  2.6800e-03, -1.1780e-03,  1.4506e-04,  4.9472e-03,
          3.0997e-07, -4.9805e-04,  1.8493e-03, -1.6975e-03, -2.7133e-03,
         -3.2923e-03,  1.2344e-03, -1.9879e-03,  1.6213e-03, -2.0749e-04,
         -1.2940e-03,  3.1447e-03, -4.5409e-03,  3.9691e-05,  2.0927e-03,
         -2.9638e-03, -5.5980e-03, -1.4287e-03, -4.1503e-03, -1.6923e-03,
         -2.4130e-03, -3.1723e-04,  2.5318e-03,  7.2192e-04,  2.9332e-03,
         -6.8506e-04,  1.9561e-03,  3.3369e-03, -2.4812e-04,  4.4409e-03,
          9.2287e-04, -8.2183e-04, -1.9836e-03,  1.5601e-05,  1.9656e-03,
         -1.6282e-03,  2.2838e-03,  7.3725e-04, -2.8873e-03, -4.9125e-04,
         -2.6136e-03,  3.1846e-03, -2.6837e-03,  2.4873e-03,  2.1217e-03,
          3.2020e-04,  1.2501e-03, -4.7293e-03,  1.1291e-03,  1.1510e-03,
         -1.1015e-03,  1.1164e-03, -3.0920e-03,  2.1422e-03, -1.6618e-03,
          2.4634e-03,  7.2511e-04, -1.2553e-04, -3.5308e-04,  8.1143e-04,
         -3.2084e-04, -3.0728e-03,  2.6444e-03, -3.1461e-03,  8.8762e-04,
         -2.4172e-03,  1.1515e-03, -1.2353e-03, -1.3644e-03, -2.4793e-03,
          7.3287e-04,  7.7988e-04,  7.6136e-04,  3.0028e-04,  2.6953e-03,
          1.2613e-03, -1.1263e-03,  1.8217e-04,  8.1337e-04,  4.7266e-03,
          2.7548e-04, -4.1277e-03, -1.4271e-03,  3.7658e-03, -2.3551e-03,
         -1.8172e-03, -1.6020e-03,  1.1870e-03, -1.5313e-03, -2.8326e-03,
         -1.8788e-03,  2.3095e-03,  3.3050e-03, -2.2947e-03,  5.6265e-03,
          2.5893e-05,  3.9794e-04,  7.7096e-04, -5.0062e-04,  1.3401e-04,
          3.1888e-04, -6.2434e-04, -1.3127e-03, -4.4756e-03,  1.6429e-04,
          7.1350e-04,  2.4922e-04,  5.0061e-03],
        [ 2.0601e-03, -2.2113e-03,  7.5723e-06, -1.1742e-03,  2.5724e-04,
          1.8015e-03, -1.2837e-03, -1.0441e-03, -8.6968e-04, -2.0365e-04,
         -4.1754e-04,  1.3375e-03, -2.9994e-04,  2.8354e-03,  1.5282e-03,
         -1.4959e-04, -1.9242e-03, -3.7706e-04, -1.9285e-05,  3.0020e-04,
          2.7781e-05,  2.6057e-04, -1.7664e-05,  1.6970e-03,  6.7755e-04,
         -8.2904e-04,  1.0363e-03, -4.8398e-04,  1.0167e-03,  4.3304e-04,
         -8.5623e-04, -5.7122e-04,  2.1403e-03,  2.3555e-03, -1.6537e-03,
         -1.2212e-03,  4.4314e-03,  6.3509e-04,  1.8177e-03,  1.2098e-03,
         -2.5163e-04, -1.4156e-04, -1.3305e-04,  1.0552e-04, -2.4951e-03,
         -1.3064e-03, -9.7353e-05, -1.7076e-03,  2.7057e-04, -1.1758e-03,
          4.4509e-04, -7.5489e-04,  6.8840e-04,  1.8688e-03, -2.3951e-03,
          2.2932e-03,  1.1437e-03,  2.0233e-03,  4.8796e-04,  1.3347e-03,
          1.1241e-03, -2.0168e-04,  1.1558e-03, -5.8367e-04, -1.7355e-03,
          2.7057e-03, -8.3091e-04,  3.9293e-04, -1.8125e-03, -1.7431e-03,
         -1.2145e-03,  1.8381e-04,  1.0367e-03, -3.2190e-03, -1.6132e-04,
         -2.0069e-03, -1.8207e-03, -9.2350e-04,  2.2444e-04, -3.1923e-04,
          2.4127e-03, -3.0185e-04, -1.1271e-03,  9.4425e-04, -2.7092e-03,
          7.2716e-04,  5.8401e-04,  2.0776e-03,  8.5403e-04,  6.4998e-05,
         -1.6743e-03, -2.7022e-03, -5.5678e-04,  1.2256e-03, -1.7902e-03,
         -9.7851e-04,  1.1739e-03,  2.2018e-03,  2.2853e-04, -3.6413e-03,
         -6.3111e-04,  1.5348e-03,  3.3147e-04, -1.5053e-03, -3.4230e-04,
          2.2356e-03,  9.5492e-04,  3.1329e-04, -9.3566e-04,  5.7530e-04,
          2.7504e-04, -8.3661e-04,  8.1371e-04,  3.8165e-04,  1.2245e-03,
          1.8779e-03, -1.1303e-03, -3.7510e-04,  1.1700e-03, -1.4371e-03,
         -3.4148e-05, -4.6843e-04,  1.4804e-03,  2.0077e-03, -1.1943e-03,
         -3.0638e-04, -2.3243e-03, -3.1120e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[8.3365e-05, 7.3019e-05, 4.1491e-05, 3.1506e-04, 2.7204e-04, 1.0538e-04,
         6.8681e-05, 2.5904e-04, 1.0352e-04, 1.3500e-04, 1.7191e-04, 5.1627e-05,
         1.1034e-04, 3.1836e-04, 1.9717e-04, 2.6714e-04, 6.7645e-05, 5.3303e-05,
         1.4969e-04, 1.6810e-04, 2.4458e-04, 5.7188e-05, 1.0783e-04, 8.6557e-05,
         1.4063e-04, 1.0398e-04, 1.6696e-04, 1.6553e-04, 2.9204e-04, 2.2494e-04,
         7.1737e-05, 1.5788e-04, 1.0618e-04, 2.2512e-04, 9.5464e-05, 1.1180e-04,
         2.2425e-04, 2.0037e-04, 7.7576e-05, 4.8243e-05, 9.1521e-05, 8.0131e-05,
         9.2183e-05, 1.5840e-04, 2.0073e-04, 1.1147e-04, 8.7969e-05, 1.0030e-04,
         5.7806e-05, 5.8374e-05, 1.2189e-04, 6.0483e-05, 1.0198e-04, 3.1592e-04,
         3.1561e-04, 6.0161e-05, 2.3812e-04, 1.4887e-04, 1.1762e-04, 4.6434e-05,
         2.3848e-04, 1.3180e-04, 6.7955e-05, 1.3394e-04, 9.3812e-05, 5.1061e-05,
         1.0918e-04, 7.5364e-05, 6.0190e-05, 6.4189e-05, 1.0853e-04, 5.5161e-05,
         4.5045e-05, 1.1325e-04, 1.1426e-04, 6.0514e-05, 1.0592e-04, 4.7811e-05,
         5.4716e-05, 2.2161e-04, 1.0106e-04, 1.4809e-04, 9.9542e-05, 7.0584e-05,
         3.8179e-04, 8.9776e-05, 8.5571e-05, 9.1339e-05, 1.2397e-04, 8.2099e-05,
         5.0940e-05, 1.7159e-04, 1.7900e-04, 1.9843e-04, 1.1456e-04, 7.4112e-05,
         2.3072e-04, 1.9809e-04, 6.6415e-05, 1.5826e-04, 6.6430e-05, 2.1295e-04,
         9.1728e-05, 6.8124e-05, 5.7067e-05, 1.5337e-04, 7.4693e-05, 1.6614e-04,
         8.0304e-05, 1.0295e-04, 1.3764e-04, 1.5980e-04, 8.2276e-05, 5.1064e-05,
         6.6157e-05, 3.6457e-04, 8.8284e-05, 4.7760e-05, 1.0482e-04, 5.7500e-05,
         1.1529e-04, 9.9316e-05, 1.3256e-04, 3.1913e-04, 9.5916e-05, 9.9796e-05,
         1.2418e-04, 3.4749e-04],
        [2.5222e-05, 1.5457e-05, 1.7753e-05, 1.3835e-05, 2.2885e-05, 3.0393e-05,
         1.0731e-05, 1.2091e-05, 2.1938e-05, 1.5993e-05, 1.7196e-05, 1.3396e-05,
         1.9420e-05, 4.4672e-05, 1.8282e-05, 1.7787e-05, 1.8296e-05, 2.0789e-05,
         1.8901e-05, 3.0523e-05, 1.1137e-05, 1.5438e-05, 1.3364e-05, 3.2367e-05,
         3.5789e-05, 1.1347e-05, 1.7470e-05, 3.4369e-05, 2.1075e-05, 1.0819e-05,
         3.5857e-05, 3.8890e-05, 3.2457e-05, 2.1261e-05, 3.3107e-05, 2.1528e-05,
         2.0808e-05, 2.0555e-05, 3.2824e-05, 2.3239e-05, 1.4870e-05, 1.5993e-05,
         3.3584e-05, 3.4589e-05, 1.1949e-05, 3.3574e-05, 2.4931e-05, 3.9288e-05,
         4.2215e-05, 2.3097e-05, 3.5552e-05, 2.1329e-05, 2.8605e-05, 1.4474e-05,
         4.0381e-05, 1.6216e-05, 2.9741e-05, 2.0687e-05, 1.4889e-05, 2.1040e-05,
         1.4174e-05, 1.6234e-05, 2.5503e-05, 2.0819e-05, 4.1713e-05, 1.1982e-05,
         1.7899e-05, 2.2223e-05, 3.5892e-05, 2.1198e-05, 3.9539e-05, 2.3493e-05,
         1.7017e-05, 1.4747e-05, 2.4596e-05, 1.2852e-05, 1.7101e-05, 2.2967e-05,
         1.8628e-05, 1.2414e-05, 2.5846e-05, 1.5124e-05, 1.9197e-05, 2.0932e-05,
         3.3170e-05, 1.0303e-05, 2.2654e-05, 1.9420e-05, 1.6324e-05, 4.2733e-05,
         1.6853e-05, 2.3107e-05, 1.4701e-05, 2.6804e-05, 2.5462e-05, 2.4202e-05,
         1.1410e-05, 2.5092e-05, 1.3564e-05, 1.3514e-05, 2.0915e-05, 1.3463e-05,
         2.6316e-05, 1.3134e-05, 1.5996e-05, 1.8980e-05, 1.8903e-05, 1.9351e-05,
         2.0236e-05, 1.7185e-05, 2.2807e-05, 3.1216e-05, 2.2550e-05, 1.6987e-05,
         1.5752e-05, 1.1741e-05, 2.7234e-05, 2.3610e-05, 2.2926e-05, 1.4618e-05,
         2.1586e-05, 1.7886e-05, 1.6402e-05, 1.7437e-05, 2.2790e-05, 1.5471e-05,
         1.6878e-05, 6.5756e-05],
        [1.3371e-05, 2.4475e-06, 4.4973e-06, 2.1270e-05, 1.1027e-05, 1.0551e-05,
         5.3756e-06, 9.6577e-06, 1.3293e-05, 6.7053e-06, 4.3004e-06, 2.6910e-06,
         5.1346e-06, 1.2831e-05, 1.6477e-05, 9.0278e-06, 7.6913e-06, 6.0061e-06,
         2.0447e-05, 3.9340e-06, 3.2596e-06, 9.1625e-06, 9.4886e-06, 1.7960e-05,
         1.2973e-05, 4.6408e-06, 3.5916e-06, 5.9514e-06, 1.6967e-05, 7.5238e-06,
         3.5943e-06, 8.6705e-06, 1.0893e-05, 1.9392e-05, 4.4238e-06, 2.6119e-05,
         4.3428e-06, 6.4947e-06, 6.2460e-06, 8.5571e-06, 5.2974e-06, 9.6193e-06,
         6.8272e-06, 4.4912e-06, 8.7019e-06, 1.8722e-05, 6.5952e-06, 4.3856e-06,
         4.7263e-06, 1.0832e-05, 1.0442e-05, 7.4316e-06, 1.4068e-05, 1.5102e-05,
         1.0687e-05, 3.5130e-06, 1.1954e-05, 8.5589e-06, 7.6405e-06, 4.8141e-06,
         9.5095e-06, 7.7369e-06, 4.8039e-06, 1.0768e-05, 1.8543e-06, 4.7101e-06,
         2.1453e-05, 1.3344e-05, 3.2855e-06, 7.5856e-06, 3.5233e-05, 8.9802e-06,
         6.5470e-06, 8.4673e-06, 2.5351e-05, 6.8611e-06, 3.9335e-06, 3.2752e-06,
         3.4363e-06, 6.7033e-06, 1.7574e-05, 1.6594e-05, 6.1903e-06, 1.1314e-05,
         2.5795e-05, 3.9006e-06, 2.4482e-06, 9.7268e-06, 1.5772e-05, 8.1454e-06,
         5.5625e-06, 6.6318e-06, 1.3940e-05, 1.4540e-05, 1.9821e-05, 9.1611e-06,
         8.5279e-06, 1.7934e-05, 2.9296e-05, 1.2018e-05, 2.5657e-06, 6.4372e-06,
         4.1895e-06, 1.0981e-05, 3.0736e-06, 1.4266e-05, 4.9463e-06, 6.0751e-06,
         7.8736e-06, 5.5794e-06, 1.3669e-05, 5.8485e-06, 5.4209e-06, 5.8534e-06,
         5.8726e-06, 1.3272e-05, 1.4936e-05, 1.3841e-05, 4.8999e-06, 8.8197e-06,
         4.8650e-06, 4.7502e-06, 1.7949e-05, 5.3965e-06, 2.0586e-05, 1.0382e-05,
         7.7607e-06, 2.8580e-05],
        [1.7990e-05, 5.5791e-06, 4.8186e-06, 1.9668e-05, 7.6379e-06, 1.0158e-05,
         5.8239e-06, 8.9607e-06, 1.0949e-05, 7.9416e-06, 6.1605e-06, 4.0316e-06,
         5.0567e-06, 1.1636e-05, 2.3815e-05, 8.0157e-06, 7.9488e-06, 7.1780e-06,
         1.9528e-05, 3.2661e-06, 4.5203e-06, 1.0900e-05, 1.0917e-05, 2.0670e-05,
         1.2864e-05, 4.8044e-06, 3.4123e-06, 5.3477e-06, 2.0244e-05, 7.0116e-06,
         2.5263e-06, 7.8456e-06, 1.0782e-05, 1.7550e-05, 5.6805e-06, 3.1240e-05,
         4.6828e-06, 7.4503e-06, 7.8336e-06, 9.8642e-06, 5.7179e-06, 1.1552e-05,
         7.1482e-06, 3.5299e-06, 1.1492e-05, 2.2287e-05, 7.6614e-06, 5.9675e-06,
         6.0605e-06, 1.3849e-05, 1.0222e-05, 7.9167e-06, 1.3056e-05, 9.8518e-06,
         1.0932e-05, 5.1664e-06, 1.2591e-05, 1.3238e-05, 8.9383e-06, 6.0969e-06,
         7.6716e-06, 4.1395e-06, 4.2304e-06, 9.7168e-06, 2.2634e-06, 4.5031e-06,
         2.5000e-05, 1.6055e-05, 3.4581e-06, 7.5618e-06, 4.0836e-05, 1.0775e-05,
         7.9369e-06, 5.8847e-06, 3.2388e-05, 7.1791e-06, 3.7149e-06, 2.3049e-06,
         3.2650e-06, 8.8985e-06, 2.2097e-05, 1.7770e-05, 1.0028e-05, 1.2400e-05,
         2.9241e-05, 5.3789e-06, 3.6587e-06, 9.8903e-06, 1.7733e-05, 8.9632e-06,
         6.6305e-06, 5.8824e-06, 1.9669e-05, 1.5659e-05, 1.9057e-05, 1.1805e-05,
         1.0505e-05, 1.7148e-05, 3.2506e-05, 1.4714e-05, 2.6905e-06, 4.4307e-06,
         3.9274e-06, 1.2744e-05, 3.0379e-06, 1.6175e-05, 6.3277e-06, 5.3340e-06,
         7.9021e-06, 5.5782e-06, 1.4049e-05, 6.3069e-06, 5.4687e-06, 6.1120e-06,
         8.0075e-06, 1.7504e-05, 1.9537e-05, 1.6314e-05, 7.3966e-06, 1.0139e-05,
         5.1543e-06, 6.0689e-06, 2.1753e-05, 1.2322e-05, 2.1541e-05, 1.1371e-05,
         8.3234e-06, 2.8182e-05],
        [1.0946e-04, 1.4104e-04, 5.3813e-05, 3.5844e-04, 2.3624e-04, 1.5614e-04,
         6.5209e-05, 2.1241e-04, 8.5914e-05, 1.2493e-04, 1.6089e-04, 5.8151e-05,
         6.5155e-05, 3.7759e-04, 2.0121e-04, 2.7340e-04, 7.6866e-05, 6.3700e-05,
         1.1921e-04, 1.9692e-04, 2.7921e-04, 8.8207e-05, 1.2421e-04, 7.4694e-05,
         1.4129e-04, 1.2760e-04, 1.6306e-04, 1.0955e-04, 3.1814e-04, 2.2926e-04,
         8.6305e-05, 2.0807e-04, 9.2526e-05, 2.1943e-04, 1.0147e-04, 9.1598e-05,
         2.6471e-04, 1.9687e-04, 9.3659e-05, 1.2612e-04, 1.2136e-04, 6.3907e-05,
         1.0954e-04, 1.6531e-04, 2.7066e-04, 1.0955e-04, 9.1314e-05, 1.6641e-04,
         8.3889e-05, 9.8288e-05, 1.0631e-04, 1.2292e-04, 1.0614e-04, 3.5871e-04,
         4.0144e-04, 1.1269e-04, 3.3606e-04, 1.8338e-04, 1.0922e-04, 9.4243e-05,
         2.7348e-04, 1.2862e-04, 8.1580e-05, 1.5569e-04, 9.4674e-05, 9.8095e-05,
         9.2029e-05, 6.8922e-05, 7.6699e-05, 5.6718e-05, 1.1273e-04, 7.3989e-05,
         7.8550e-05, 1.6769e-04, 1.7701e-04, 1.2988e-04, 1.1232e-04, 6.0955e-05,
         6.7629e-05, 2.0487e-04, 1.1010e-04, 2.2696e-04, 1.1738e-04, 8.5769e-05,
         4.0581e-04, 1.2799e-04, 1.0065e-04, 9.1872e-05, 1.6534e-04, 1.1429e-04,
         6.1244e-05, 2.1248e-04, 1.7197e-04, 1.7326e-04, 8.4379e-05, 1.0011e-04,
         2.6928e-04, 1.8058e-04, 1.1266e-04, 1.9928e-04, 7.3220e-05, 2.3895e-04,
         1.1162e-04, 7.7140e-05, 9.9312e-05, 1.8530e-04, 8.0911e-05, 1.6925e-04,
         1.0754e-04, 1.0334e-04, 9.8933e-05, 1.4943e-04, 8.9558e-05, 7.5742e-05,
         8.1369e-05, 3.5952e-04, 1.0759e-04, 1.1619e-04, 1.0261e-04, 1.0228e-04,
         8.0486e-05, 1.0252e-04, 1.4011e-04, 3.6856e-04, 7.3934e-05, 1.3068e-04,
         1.9996e-04, 4.7889e-04],
        [7.9725e-05, 1.4348e-04, 2.9858e-05, 2.6266e-04, 1.8020e-04, 5.9399e-05,
         6.2396e-05, 1.6389e-04, 6.8044e-05, 1.4186e-04, 1.0516e-04, 4.5255e-05,
         8.4918e-05, 1.8585e-04, 8.3110e-05, 8.0955e-05, 3.3638e-05, 3.7863e-05,
         1.0604e-04, 7.1423e-05, 1.7513e-04, 6.8405e-05, 3.9232e-05, 6.9888e-05,
         1.4226e-04, 5.6755e-05, 5.0457e-05, 1.4001e-04, 8.4861e-05, 7.9589e-05,
         5.4930e-05, 6.6013e-05, 9.6964e-05, 1.1512e-04, 8.8811e-05, 1.0277e-04,
         2.0510e-04, 4.4048e-05, 6.7568e-05, 9.6688e-05, 5.0605e-05, 7.6817e-05,
         3.7597e-05, 4.4317e-05, 1.5861e-04, 9.2487e-05, 7.4568e-05, 1.1783e-04,
         3.7232e-05, 6.5377e-05, 5.9936e-05, 9.7075e-05, 8.7095e-05, 2.3096e-04,
         2.0601e-04, 1.0742e-04, 2.5937e-04, 8.0651e-05, 8.1761e-05, 9.3338e-05,
         8.3204e-05, 6.2708e-05, 5.6321e-05, 7.9054e-05, 7.8630e-05, 8.8811e-05,
         9.7101e-05, 5.4588e-05, 5.0172e-05, 4.7856e-05, 1.2628e-04, 5.5715e-05,
         6.0040e-05, 9.3495e-05, 1.1281e-04, 1.2202e-04, 4.9259e-05, 3.4186e-05,
         4.5422e-05, 1.9166e-04, 5.3270e-05, 2.1725e-04, 1.2193e-04, 6.5916e-05,
         3.4960e-04, 1.1098e-04, 9.3582e-05, 6.6605e-05, 1.0208e-04, 3.8163e-05,
         5.0892e-05, 9.1153e-05, 8.0320e-05, 1.4584e-04, 1.1018e-04, 7.5338e-05,
         2.4470e-04, 1.1212e-04, 1.2043e-04, 8.0419e-05, 4.4610e-05, 1.4716e-04,
         7.9954e-05, 5.4773e-05, 7.3744e-05, 4.4275e-05, 6.3735e-05, 1.1655e-04,
         8.1175e-05, 3.1887e-05, 1.1542e-04, 4.2586e-05, 4.2787e-05, 5.4719e-05,
         3.7408e-05, 1.8470e-04, 1.0799e-04, 8.5083e-05, 1.1885e-04, 7.6724e-05,
         7.3212e-05, 4.9247e-05, 1.6191e-04, 2.5046e-04, 7.9818e-05, 4.4531e-05,
         1.4559e-04, 3.7550e-04]], device='cuda:0')}, 102: {'step': tensor(30200.), 'exp_avg': tensor([-1.2289e-03, -7.6675e-05,  1.3596e-03, -1.3827e-03, -3.6724e-04,
         1.6960e-03], device='cuda:0'), 'exp_avg_sq': tensor([1.2445e-04, 2.0533e-05, 8.8275e-06, 1.0256e-05, 1.3765e-04, 9.1736e-05],
       device='cuda:0')}}
param_groups 	 [{'lr': 3.250000000000074e-05, 'betas': (0.9, 0.999), 'eps': 1e-06, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102]}]
End time:  2023-09-05 05:22:22.796577
Total time:  10:13:13.989829
